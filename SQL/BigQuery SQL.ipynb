{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to SQL\n",
    "Learn SQL for working with databases, using Google BigQuery to scale to massive datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dataset & Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data\n",
    "- [Hacker News](https://news.ycombinator.com/)\n",
    "- [Chicago Crime](https://www.kaggle.com/chicago/chicago-crime)\n",
    "- [OpenAQ](https://openaq.org/#/?_k=l7rozu)\n",
    "- [San Francisco Open Data](https://www.kaggle.com/datasf/san-francisco)\n",
    "- [Google Analytics Sample](https://www.kaggle.com/bigquery/google-analytics-sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### APIs and reference\n",
    "https://cloud.google.com/bigquery/docs/reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Getting Started With SQL and BigQuery\n",
    "Learn the workflow for handling big datasets with BigQuery and SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# To use BigQuery, we'll import the Python package below:\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![Client, Dataset, Table](https://i.imgur.com/biYqbUB.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/getting-started-with-sql-and-bigquery </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Client\n",
    "The first step in the workflow is to create a `Client` object. As you'll soon see, this `Client` object will play a central role in retrieving information from BigQuery datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a \"Client\" object.\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dataset\n",
    "In BigQuery, each dataset is contained in a corresponding project. In this case, our `hacker_news` dataset is contained in the `bigquery-public-data` project. To access the dataset,\n",
    "\n",
    "- We begin by constructing a reference to the dataset with the `dataset()` method.\n",
    "- Next, we use the `get_dataset()` method, along with the reference we just constructed, to fetch the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Construct a reference to the \"hacker_news\" dataset\n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Table\n",
    "Every dataset is just a collection of tables. You can think of a dataset as a spreadsheet file containing multiple tables, all composed of rows and columns.\n",
    "\n",
    "We use the `list_tables()` method to list the tables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# List all the tables in the \"hacker_news\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print number of tables in the dataset\n",
    "print(len(tables))\n",
    "\n",
    "# Print names of all tables in the dataset (there are four!)\n",
    "for table in tables:  \n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Similar to how we fetched a dataset, we can fetch a table. In the code cell below, we fetch the `full` table in the `hacker_news` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Construct a reference to the \"full\" table\n",
    "table_ref = dataset_ref.table(\"full\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Print information on all the columns in the \"full\" table in the \"hacker_news\" dataset\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Each `SchemaField` tells us about a specific column (which we also refer to as a **field**). In order, the information is:\n",
    "\n",
    "- The **name** of the column\n",
    "- The **field type** (or datatype) in the column\n",
    "- The **mode** of the column (`'NULLABLE'` means that a column allows NULL values, and is the default)\n",
    "- A **description** of the data in that column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Row\n",
    "We can use the `list_rows()` method to check just the first five lines of of the `full` table to make sure this is right. (Sometimes databases have outdated descriptions, so it's good to check.) This returns a BigQuery `RowIterator` object that can quickly be converted to a pandas DataFrame with the `to_dataframe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Preview the first five lines of the \"full\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `list_rows()` method will also let us look at just the information in a specific column. If we want to see the first five entries in the `by` column, for example, we can do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Preview the first five entries in the \"by\" column of the \"full\" table\n",
    "client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Select, From & Where\n",
    "The foundational compontents for all SQL queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### SELECT ... FROM\n",
    "![SELECT ... FROM](https://i.imgur.com/c3GxYRt.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/select-from-where </center>\n",
    "\n",
    "Note that when writing an SQL query, the argument we pass to **FROM** is not in single or double quotation marks (' or \"). It is in backticks (`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### WHERE ...\n",
    "![WHERE ..](https://i.imgur.com/HJOT8Kb.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/select-from-where </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Submitting the query to the dataset\n",
    "- the first step is to create a `Client` object.\n",
    "- set up the query with the `query()` method.\n",
    "- Next, we run the query and convert the results to a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Set up the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "us_cities = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Working with big datasets\n",
    "Estimate the size of any query before running it  \n",
    "To see how much data a query will scan, we create a `QueryJobConfig` object and set the `dry_run` parameter to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a QueryJobConfig object to estimate size of query without running it.\n",
    "dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "\n",
    "# API request - dry run query to estimate costs.\n",
    "dry_run_query_job = client.query(query, job_config=dry_run_config)\n",
    "\n",
    "print(\"This query will process {} bytes.\".format(dry_run_query_job.total_bytes_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Only run the query if it's less than 1 MB.\n",
    "ONE_MB = 1000*1000\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)\n",
    "\n",
    "# Set up the query (will only run if it's less than 1 MB).\n",
    "safe_query_job = client.query(query, job_config=safe_config)\n",
    "\n",
    "# API request - try to run the query, and return a pandas DataFrame.\n",
    "safe_query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Group by, Having & Count  \n",
    "Get more interesting insights directly from your SQL queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### COUNT()\n",
    "**COUNT()** is an example of an **aggregate function**, which takes many values and returns one. (Other examples of aggregate functions include **SUM()**, **AVG()**, **MIN()**, and **MAX()**.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### GROUP BY\n",
    "**GROUP BY** takes the name of one or more columns, and treats all rows with the same value in that column as a single group when you apply aggregate functions like **COUNT()**.  \n",
    "\n",
    "Note that because it tells SQL how to apply aggregate functions (like **COUNT()**), it doesn't make sense to use **GROUP BY** without an aggregate function. Similarly, if you have any **GROUP BY** clause, then all variables must be passed to either a\n",
    "\n",
    "- **GROUP BY** command, or\n",
    "- an aggregation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### GROUP BY ... HAVING\n",
    "**HAVING** is used in combination with **GROUP BY** to ignore groups that don't meet certain criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Order By\n",
    "Order your results to focus on the most important data for your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ORDER BY\n",
    "**ORDER BY** is usually the last clause in your query, and it sorts the results returned by the rest of your query.  \n",
    "You can reverse the order using the **DESC** argument (short for 'descending'). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dates\n",
    "There are two ways that dates can be stored in BigQuery: as a **DATE** or as a **DATETIME**.\n",
    "\n",
    "The **DATE** format has the year first, then the month, and then the day. It looks like this:\n",
    "```\n",
    "YYYY-[M]M-[D]D\n",
    "```\n",
    "- ```YYYY```: Four-digit year\n",
    "- ```[M]M```: One or two digit month\n",
    "- ```[D]D```: One or two digit day  \n",
    "\n",
    "The **DATETIME** format is like the date format ... but with time added at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### EXTRACT\n",
    "Often you'll want to look at part of a date, like the year or the day. You can do this with **EXTRACT**.\n",
    "\n",
    "![EXTRACT](https://i.imgur.com/PhoWBO0.png)\n",
    "![EXTRACT](https://i.imgur.com/A5hqGxY.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/order-by </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## As & With\n",
    "Organize your query for better readability. This becomes especially important for complex queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### AS\n",
    "use **AS** to rename the columns generated by your queries, which is also known as **aliasing**.  \n",
    " \n",
    "![AS](https://i.imgur.com/teF84tU.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/as-with </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### WITH ... AS\n",
    "On its own, **AS** is a convenient way to clean up the data returned by your query. It's even more powerful when combined with **WITH** in what's called a \"common table expression\".  \n",
    "\n",
    "A **common table expression** (or **CTE**) is a temporary table that you return within your query. CTEs are helpful for splitting your queries into readable chunks, and you can write queries against them.\n",
    "\n",
    "![WITH ... AS](https://i.imgur.com/3xQZM4p.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/as-with </center>  \n",
    "\n",
    "Also, it's important to note that CTEs only exist inside the query where you create them, and you can't reference them in later queries. So, any query that uses a CTE is always broken into two parts: (1) first, we create the CTE, and then (2) we write a query that uses the CTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Joining Data\n",
    "Combine data sources. Critical for almost all real-world data problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### JOIN\n",
    "Using **JOIN**, we can write a query to create a table with just two columns.  \n",
    "\n",
    "![JOIN](https://i.imgur.com/fLlng42.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/joining-data </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced SQL\n",
    "Take your SQL skills to the next level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## JOINs and UNIONs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### JOINs\n",
    "use an **INNER JOIN** to pull rows from both tables  \n",
    "a **FULL JOIN** returns all rows from both tables  \n",
    "\n",
    "![JOINs](https://i.imgur.com/1Dvmg8S.png)\n",
    "<center>Ref: https://www.kaggle.com/alexisbcook/joins-and-unions </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### UNIONs\n",
    "\n",
    "As you've seen, **JOINs** horizontally combine results from different tables. If you instead would like to vertically concatenate columns, you can do so with a **UNION**.  \n",
    "\n",
    "Note that with a **UNION**, the data types of both columns must be the same, but the column names can be different.  \n",
    "\n",
    "We use **UNION ALL** to include duplicate values. If you'd like to drop duplicate values, you need only change **UNION ALL** in the query to **UNION DISTINCT**.\n",
    "\n",
    "![UNIONs](https://i.imgur.com/oa6VDig.png)\n",
    "<center>Ref: https://www.kaggle.com/alexisbcook/joins-and-unions </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Analytic Functions\n",
    "unlike aggregate functions, analytic functions return a (potentially different) value for each row in the original table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Syntax\n",
    "All analytic functions have an **OVER** clause, which defines the sets of rows used in each calculation. The **OVER** clause has three (optional) parts:\n",
    "\n",
    "- The **PARTITION BY** clause divides the rows of the table into different groups. In the query above, we divide by id so that the calculations are separated by runner.\n",
    "- The **ORDER BY** clause defines an ordering within each partition. In the sample query, ordering by the date column ensures that earlier training sessions appear first.\n",
    "- The final clause (```ROWS BETWEEN 1 PRECEDING AND CURRENT ROW```) is known as a **window frame** clause. It identifies the set of rows used in each calculation. We can refer to this group of rows as a **window**. *(Actually, analytic functions are sometimes referred to as analytic window functions or simply window functions!)*\n",
    "\n",
    "There are many ways to write window frame clauses:\n",
    "\n",
    "- ```ROWS BETWEEN 1 PRECEDING AND CURRENT ROW``` - the previous row and the current row.\n",
    "- ```ROWS BETWEEN 3 PRECEDING AND 1 FOLLOWING``` - the 3 previous rows, the current row, and the following row.\n",
    "- ```ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING``` - all rows in the partition.\n",
    "\n",
    "![Syntax](https://i.imgur.com/rehp8HM.png)\n",
    "![Syntax](https://i.imgur.com/GjiKlA7.png)\n",
    "<center>Ref: https://www.kaggle.com/alexisbcook/analytic-functions </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Three types of analytic functions\n",
    "1) Analytic aggregate functionsÂ¶\n",
    "As you might recall, **AVG()** (from the example above) is an aggregate function. The **OVER** clause is what ensures that it's treated as an analytic (aggregate) function. **Aggregate functions** take all of the values within the window as input and return a single value.\n",
    "\n",
    "- **MIN()** (or **MAX()**) - Returns the minimum (or maximum) of input values\n",
    "- **AVG()** (or **SUM()**) - Returns the average (or sum) of input values\n",
    "- **COUNT()** - Returns the number of rows in the input  \n",
    "\n",
    "2) Analytic navigation functions\n",
    "**Navigation functions** assign a value based on the value in a (usually) different row than the current row.\n",
    "\n",
    "- **FIRST_VALUE()** (or **LAST_VALUE()**) - Returns the first (or last) value in the input\n",
    "- **LEAD()** (and **LAG()**) - Returns the value on a subsequent (or preceding) row  \n",
    "\n",
    "3) Analytic numbering functions\n",
    "**Numbering functions** assign integer values to each row based on the ordering.\n",
    "\n",
    "- **ROW_NUMBER()** - Returns the order in which rows appear in the input (starting with 1)\n",
    "- **RANK()** - All rows with the same value in the ordering column receive the same rank value, where the next row receives a rank value which increments by the number of rows with the previous rank value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Nested and Repeated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Nested data\n",
    "Nested columns have type **STRUCT** (or type **RECORD**).  \n",
    "To query a column with nested data, we need to identify each field in the context of the column that contains it.  \n",
    "\n",
    "![Nested data](https://i.imgur.com/wxuogYA.png)\n",
    "![Nested data](https://i.imgur.com/eE2Gt62.png)\n",
    "<center>Ref: https://www.kaggle.com/alexisbcook/nested-and-repeated-data </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Repeated data\n",
    "Each entry in a repeated field is an **ARRAY**, or an ordered list of (zero or more) values with the same datatype.  \n",
    "\n",
    "When querying repeated data, we need to put the name of the column containing the repeated data inside an **UNNEST()** function.  \n",
    "\n",
    "![Repeated data](https://i.imgur.com/S93FJTE.png)\n",
    "![Repeated data](https://i.imgur.com/p3fXPxY.png)\n",
    "<center>Ref: https://www.kaggle.com/alexisbcook/nested-and-repeated-data </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Nested and repeated data\n",
    "\n",
    "![Nested and repeated data](https://i.imgur.com/psKtza2.png)\n",
    "![Nested and repeated data](https://i.imgur.com/DiMCZaO.png)\n",
    "<center>Ref: https://www.kaggle.com/alexisbcook/nested-and-repeated-data </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Efficient Queires\n",
    "Most database systems have a **query optimizer** that attempts to interpret/execute your query in the most effective way possible. But several strategies can still yield huge savings in many cases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions\n",
    "We will use two functions to compare the efficiency of different queries:\n",
    "\n",
    "- ```show_amount_of_data_scanned()``` shows the amount of data the query uses.\n",
    "- ```show_time_to_run()``` prints how long it takes for the query to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from time import time\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "def show_amount_of_data_scanned(query):\n",
    "    # dry_run lets us see how much data the query uses without running it\n",
    "    dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "    query_job = client.query(query, job_config=dry_run_config)\n",
    "    print('Data processed: {} GB'.format(round(query_job.total_bytes_processed / 10**9, 3)))\n",
    "    \n",
    "def show_time_to_run(query):\n",
    "    time_config = bigquery.QueryJobConfig(use_query_cache=False)\n",
    "    start = time()\n",
    "    query_result = client.query(query, job_config=time_config).result()\n",
    "    end = time()\n",
    "    print('Time to run: {} seconds'.format(round(end-start, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategies\n",
    "1) Only select the columns you want.  \n",
    "It is tempting to start queries with **SELECT * FROM ...**. It's convenient because you don't need to think about which columns you need. But it can be very inefficient.  \n",
    "\n",
    "2) Read less data.  \n",
    "\n",
    "3) Avoid N:N JOINs.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

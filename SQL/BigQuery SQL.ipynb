{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to SQL\n",
    "Learn SQL for working with databases, using Google BigQuery to scale to massive datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dataset & Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Data\n",
    "- [Hacker News](https://news.ycombinator.com/)\n",
    "- [Chicago Crime](https://www.kaggle.com/chicago/chicago-crime)\n",
    "- [OpenAQ](https://openaq.org/#/?_k=l7rozu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### APIs and reference\n",
    "https://cloud.google.com/bigquery/docs/reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Getting Started With SQL and BigQuery\n",
    "Learn the workflow for handling big datasets with BigQuery and SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# To use BigQuery, we'll import the Python package below:\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![Client, Dataset, Table](https://i.imgur.com/biYqbUB.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/getting-started-with-sql-and-bigquery </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Client\n",
    "The first step in the workflow is to create a `Client` object. As you'll soon see, this `Client` object will play a central role in retrieving information from BigQuery datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a \"Client\" object.\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dataset\n",
    "In BigQuery, each dataset is contained in a corresponding project. In this case, our `hacker_news` dataset is contained in the `bigquery-public-data` project. To access the dataset,\n",
    "\n",
    "- We begin by constructing a reference to the dataset with the `dataset()` method.\n",
    "- Next, we use the `get_dataset()` method, along with the reference we just constructed, to fetch the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Construct a reference to the \"hacker_news\" dataset\n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Table\n",
    "Every dataset is just a collection of tables. You can think of a dataset as a spreadsheet file containing multiple tables, all composed of rows and columns.\n",
    "\n",
    "We use the `list_tables()` method to list the tables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# List all the tables in the \"hacker_news\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print number of tables in the dataset\n",
    "print(len(tables))\n",
    "\n",
    "# Print names of all tables in the dataset (there are four!)\n",
    "for table in tables:  \n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Similar to how we fetched a dataset, we can fetch a table. In the code cell below, we fetch the `full` table in the `hacker_news` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Construct a reference to the \"full\" table\n",
    "table_ref = dataset_ref.table(\"full\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Print information on all the columns in the \"full\" table in the \"hacker_news\" dataset\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Each `SchemaField` tells us about a specific column (which we also refer to as a **field**). In order, the information is:\n",
    "\n",
    "- The **name** of the column\n",
    "- The **field type** (or datatype) in the column\n",
    "- The **mode** of the column (`'NULLABLE'` means that a column allows NULL values, and is the default)\n",
    "- A **description** of the data in that column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Row\n",
    "We can use the `list_rows()` method to check just the first five lines of of the `full` table to make sure this is right. (Sometimes databases have outdated descriptions, so it's good to check.) This returns a BigQuery `RowIterator` object that can quickly be converted to a pandas DataFrame with the `to_dataframe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Preview the first five lines of the \"full\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `list_rows()` method will also let us look at just the information in a specific column. If we want to see the first five entries in the `by` column, for example, we can do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Preview the first five entries in the \"by\" column of the \"full\" table\n",
    "client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Select, From & Where\n",
    "The foundational compontents for all SQL queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### SELECT ... FROM\n",
    "![SELECT ... FROM](https://i.imgur.com/c3GxYRt.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/select-from-where </center>\n",
    "\n",
    "Note that when writing an SQL query, the argument we pass to **FROM** is not in single or double quotation marks (' or \"). It is in backticks (`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### WHERE ...\n",
    "![WHERE ..](https://i.imgur.com/HJOT8Kb.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/select-from-where </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Submitting the query to the dataset\n",
    "- the first step is to create a `Client` object.\n",
    "- set up the query with the `query()` method.\n",
    "- Next, we run the query and convert the results to a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Set up the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "us_cities = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Working with big datasets\n",
    "Estimate the size of any query before running it  \n",
    "To see how much data a query will scan, we create a `QueryJobConfig` object and set the `dry_run` parameter to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a QueryJobConfig object to estimate size of query without running it.\n",
    "dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "\n",
    "# API request - dry run query to estimate costs.\n",
    "dry_run_query_job = client.query(query, job_config=dry_run_config)\n",
    "\n",
    "print(\"This query will process {} bytes.\".format(dry_run_query_job.total_bytes_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Only run the query if it's less than 1 MB.\n",
    "ONE_MB = 1000*1000\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)\n",
    "\n",
    "# Set up the query (will only run if it's less than 1 MB).\n",
    "safe_query_job = client.query(query, job_config=safe_config)\n",
    "\n",
    "# API request - try to run the query, and return a pandas DataFrame.\n",
    "safe_query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Group by, Having & Count  \n",
    "Get more interesting insights directly from your SQL queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### COUNT()\n",
    "**COUNT()** is an example of an **aggregate function**, which takes many values and returns one. (Other examples of aggregate functions include **SUM()**, **AVG()**, **MIN()**, and **MAX()**.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### GROUP BY\n",
    "**GROUP BY** takes the name of one or more columns, and treats all rows with the same value in that column as a single group when you apply aggregate functions like **COUNT()**.  \n",
    "\n",
    "Note that because it tells SQL how to apply aggregate functions (like **COUNT()**), it doesn't make sense to use **GROUP BY** without an aggregate function. Similarly, if you have any **GROUP BY** clause, then all variables must be passed to either a\n",
    "\n",
    "- **GROUP BY** command, or\n",
    "- an aggregation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### GROUP BY ... HAVING\n",
    "**HAVING** is used in combination with **GROUP BY** to ignore groups that don't meet certain criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Order By\n",
    "Order your results to focus on the most important data for your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ORDER BY\n",
    "**ORDER BY** is usually the last clause in your query, and it sorts the results returned by the rest of your query.  \n",
    "You can reverse the order using the **DESC** argument (short for 'descending'). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dates\n",
    "There are two ways that dates can be stored in BigQuery: as a **DATE** or as a **DATETIME**.\n",
    "\n",
    "The **DATE** format has the year first, then the month, and then the day. It looks like this:\n",
    "```\n",
    "YYYY-[M]M-[D]D\n",
    "```\n",
    "- ```YYYY```: Four-digit year\n",
    "- ```[M]M```: One or two digit month\n",
    "- ```[D]D```: One or two digit day  \n",
    "\n",
    "The **DATETIME** format is like the date format ... but with time added at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### EXTRACT\n",
    "Often you'll want to look at part of a date, like the year or the day. You can do this with **EXTRACT**.\n",
    "\n",
    "![EXTRACT](https://i.imgur.com/PhoWBO0.png)\n",
    "![EXTRACT](https://i.imgur.com/A5hqGxY.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/order-by </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## As & With\n",
    "Organize your query for better readability. This becomes especially important for complex queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### AS\n",
    "use **AS** to rename the columns generated by your queries, which is also known as **aliasing**.  \n",
    " \n",
    "![AS](https://i.imgur.com/teF84tU.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/as-with </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### WITH ... AS\n",
    "On its own, **AS** is a convenient way to clean up the data returned by your query. It's even more powerful when combined with **WITH** in what's called a \"common table expression\".  \n",
    "\n",
    "A **common table expression** (or **CTE**) is a temporary table that you return within your query. CTEs are helpful for splitting your queries into readable chunks, and you can write queries against them.\n",
    "\n",
    "![WITH ... AS](https://i.imgur.com/3xQZM4p.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/as-with </center>  \n",
    "\n",
    "Also, it's important to note that CTEs only exist inside the query where you create them, and you can't reference them in later queries. So, any query that uses a CTE is always broken into two parts: (1) first, we create the CTE, and then (2) we write a query that uses the CTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Joining Data\n",
    "Combine data sources. Critical for almost all real-world data problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### JOIN\n",
    "Using **JOIN**, we can write a query to create a table with just two columns.  \n",
    "\n",
    "![JOIN](https://i.imgur.com/fLlng42.png)\n",
    "<center>Ref: https://www.kaggle.com/dansbecker/joining-data </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced SQL\n",
    "Take your SQL skills to the next level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOINs and UNIONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested and Repeated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Efficient Queires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 什么是PyTorch\n",
    "\n",
    "PyTorch是一个基于Python的科学计算库，它有以下特点:\n",
    "\n",
    "- 类似于NumPy，但是它可以使用GPU\n",
    "- 可以用它定义深度学习模型，可以灵活地进行深度学习模型的训练和使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "Tensor类似与NumPy的ndarray，唯一的区别是Tensor可以在GPU上加速运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造一个未初始化的5x3矩阵:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.8251e+05, 7.8893e-43, 2.8251e+05],\n",
       "        [7.8893e-43, 2.8251e+05, 7.8893e-43],\n",
       "        [2.8251e+05, 7.8893e-43, 2.8251e+05],\n",
       "        [7.8893e-43, 2.8251e+05, 7.8893e-43],\n",
       "        [2.8251e+05, 7.8893e-43, 2.8251e+05]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建一个随机初始化的矩阵: torch.rand是均匀分布，torch.randn是标准正态分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7054, 0.0115, 0.9597],\n",
       "        [0.9421, 0.4642, 0.4273],\n",
       "        [0.5290, 0.8471, 0.4369],\n",
       "        [0.3095, 0.1544, 0.9498],\n",
       "        [0.0889, 0.9291, 0.5059]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建一个全部为0，类型为long的矩阵:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(5,3,dtype=torch.long)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(5,3).long()  # 强制类型转换\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从数据直接直接构建tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 3.0000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.5,3]) # 1*2的矩阵\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以从一个已有的tensor构建一个tensor。这些方法会重用原来tensor的特征，例如，数据类型，除非提供新的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.new_ones(5,3, dtype=torch.double) # \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5924,  0.9863,  1.0319],\n",
       "        [ 0.4186, -0.8391, -0.0890],\n",
       "        [-1.7492, -0.2189,  0.3351],\n",
       "        [ 1.1020, -1.2133,  1.4746],\n",
       "        [-0.1461,  1.0083,  0.8271]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float) # 随机产生跟x形状相同的tensor\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到tensor的形状:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>注意</h4><p>``torch.Size`` 返回的是一个tuple</p></div>\n",
    "\n",
    "Operations\n",
    "\n",
    "\n",
    "有很多种tensor运算。我们先介绍加法运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9765, 0.4238, 0.2948],\n",
       "        [0.7273, 0.9435, 0.3466],\n",
       "        [0.6223, 0.9892, 0.7007],\n",
       "        [0.1638, 0.5064, 0.0386],\n",
       "        [0.5196, 0.8638, 0.3709]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5689,  1.4100,  1.3267],\n",
       "        [ 1.1459,  0.1044,  0.2576],\n",
       "        [-1.1269,  0.7703,  1.0358],\n",
       "        [ 1.2658, -0.7070,  1.5132],\n",
       "        [ 0.3736,  1.8721,  1.1980]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y # 两个tensor直接相加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种着加法的写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5689,  1.4100,  1.3267],\n",
       "        [ 1.1459,  0.1044,  0.2576],\n",
       "        [-1.1269,  0.7703,  1.0358],\n",
       "        [ 1.2658, -0.7070,  1.5132],\n",
       "        [ 0.3736,  1.8721,  1.1980]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, y)  # tensor相加函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加法：把输出作为一个变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5689,  1.4100,  1.3267],\n",
       "        [ 1.1459,  0.1044,  0.2576],\n",
       "        [-1.1269,  0.7703,  1.0358],\n",
       "        [ 1.2658, -0.7070,  1.5132],\n",
       "        [ 0.3736,  1.8721,  1.1980]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "torch.add(x, y, out=result)\n",
    "# result = x + y\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in-place加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5689,  1.4100,  1.3267],\n",
       "        [ 1.1459,  0.1044,  0.2576],\n",
       "        [-1.1269,  0.7703,  1.0358],\n",
       "        [ 1.2658, -0.7070,  1.5132],\n",
       "        [ 0.3736,  1.8721,  1.1980]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x)  # 直接在y上做更改，也就是返回值放到y中\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>注意</h4><p>任何in-place的运算都会以``_``结尾。\n",
    "    举例来说：``x.copy_(y)``, ``x.t_()``, 会改变 ``x``。</p></div>\n",
    "\n",
    "各种类似NumPy的indexing都可以在PyTorch tensor上面使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8391, -0.0890],\n",
       "        [-0.2189,  0.3351],\n",
       "        [-1.2133,  1.4746],\n",
       "        [ 1.0083,  0.8271]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:, 1:] # 切片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing: 如果你希望resize/reshape一个tensor，可以使用``torch.view``："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0205,  0.5863, -1.3809, -0.7456, -2.0674, -0.7317,  2.5107, -0.1470],\n",
       "        [-0.8988, -1.4296,  1.7932,  0.3143, -0.4821,  0.1191,  1.0049,  0.2906]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4,4)\n",
    "y = x.view(16)   # 将x转为16维的tensor\n",
    "z = x.view(-1,8) # 任何维度写成-1就会自动识别具体数值\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你有一个只有一个元素的tensor，使用``.item()``方法可以把里面的value变成Python数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2214])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2214466333389282"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.item()  # tensor ==> python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0205, -0.8988],\n",
       "        [ 0.5863, -1.4296],\n",
       "        [-1.3809,  1.7932],\n",
       "        [-0.7456,  0.3143],\n",
       "        [-2.0674, -0.4821],\n",
       "        [-0.7317,  0.1191],\n",
       "        [ 2.5107,  1.0049],\n",
       "        [-0.1470,  0.2906]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.transpose(1,0)  # 矩阵的维度互换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**更多阅读**\n",
    "\n",
    "\n",
    "  各种Tensor operations, 包括transposing, indexing, slicing,\n",
    "  mathematical operations, linear algebra, random numbers在\n",
    "  `<https://pytorch.org/docs/torch>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy和Tensor之间的转化\n",
    "\n",
    "在Torch Tensor和NumPy array之间相互转化非常容易。\n",
    "\n",
    "**Torch Tensor和NumPy array会共享内存，所以改变其中一项也会改变另一项。**\n",
    "\n",
    "把Torch Tensor转变成NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy()    # tensor ===> numpy\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改变numpy array里面的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1] = 2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把NumPy ndarray转成Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)    # numpy ===> tensor\n",
    "np.add(a, 1, out=a)        # numpy的相加函数\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有CPU上的Tensor都支持转成numpy或者从numpy转成Tensor。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Tensors\n",
    "\n",
    "使用``.to``方法，Tensor可以被移动到别的device上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2214], device='cuda:0')\n",
      "tensor([-0.2214], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x, device=device)\n",
    "    x = x.to(device)    # 把tensor搬到GPU\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))    # 把tensor从GPU搬回到CPU\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU上的tensor不可以转为numpy，所以必搬回到CPU才能转为numpy，因为numpy是在CPU的\n",
    "y.to(\"cpu\").data.numpy()\n",
    "y.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把model搬到cuda\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 用numpy实现两层神经网络\n",
    "\n",
    "一个全连接ReLU神经网络，一个隐藏层，没有bias。用来从x预测y，使用L2 Loss。\n",
    "- $h = W_1X$\n",
    "- $a = max(0, h)$\n",
    "- $y_{hat} = W_2a$\n",
    "\n",
    "这一实现完全使用numpy来计算前向神经网络，loss，和反向传播。\n",
    "- forward pass\n",
    "- loss\n",
    "- backward pass\n",
    "\n",
    "numpy ndarray是一个普通的n维array。它不知道任何关于深度学习或者梯度(gradient)的知识，也不知道计算图(computation graph)，只是一种用来计算数学运算的数据结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 31589010.97757206\n",
      "1 32032361.415442623\n",
      "2 36532286.92206487\n",
      "3 38370295.270497814\n",
      "4 32607056.55221738\n",
      "5 20820217.776104927\n",
      "6 10550873.812148217\n",
      "7 4884393.869130288\n",
      "8 2492604.7173278416\n",
      "9 1525314.8289688863\n",
      "10 1093955.1952010193\n",
      "11 861240.2854857739\n",
      "12 710396.2568568155\n",
      "13 599738.5452808375\n",
      "14 512760.62678585073\n",
      "15 441878.9869910692\n",
      "16 383086.90872362204\n",
      "17 333786.5498639076\n",
      "18 292110.2385405301\n",
      "19 256550.88948888215\n",
      "20 226137.89787798238\n",
      "21 200003.8651590041\n",
      "22 177469.78649526235\n",
      "23 157927.17434944655\n",
      "24 140922.51610387655\n",
      "25 126068.12137287592\n",
      "26 113057.2017217832\n",
      "27 101609.05986083572\n",
      "28 91507.39374227289\n",
      "29 82560.44391924681\n",
      "30 74621.71579432023\n",
      "31 67571.28595227773\n",
      "32 61289.69514277215\n",
      "33 55677.382032707894\n",
      "34 50651.41427469961\n",
      "35 46147.40230452048\n",
      "36 42097.54446727611\n",
      "37 38451.06413643714\n",
      "38 35160.844602185316\n",
      "39 32188.421539585855\n",
      "40 29500.32697434475\n",
      "41 27058.404850120576\n",
      "42 24841.87571415577\n",
      "43 22832.064123187614\n",
      "44 21007.401921595723\n",
      "45 19347.685780595522\n",
      "46 17834.335648431414\n",
      "47 16452.89305334504\n",
      "48 15190.943661370864\n",
      "49 14037.139055253569\n",
      "50 12981.67076412759\n",
      "51 12014.17544736835\n",
      "52 11127.442137480122\n",
      "53 10313.826478437746\n",
      "54 9565.632973898239\n",
      "55 8877.571415614046\n",
      "56 8243.81043198174\n",
      "57 7659.77777991758\n",
      "58 7121.180565517324\n",
      "59 6624.190422021961\n",
      "60 6165.166391697446\n",
      "61 5740.971457747657\n",
      "62 5348.543355503574\n",
      "63 4985.557244137015\n",
      "64 4649.4018065429755\n",
      "65 4338.0606138157855\n",
      "66 4049.342250188571\n",
      "67 3781.4567871531135\n",
      "68 3532.8523326039067\n",
      "69 3302.0944364054053\n",
      "70 3087.626301881375\n",
      "71 2888.3231334686434\n",
      "72 2703.1468854872473\n",
      "73 2530.757570854956\n",
      "74 2370.204385337108\n",
      "75 2220.6663382688257\n",
      "76 2081.0516574170892\n",
      "77 1950.9611358272177\n",
      "78 1829.647877813891\n",
      "79 1716.5207327768649\n",
      "80 1610.9073052468184\n",
      "81 1512.3593999247248\n",
      "82 1420.2426206741372\n",
      "83 1334.1497564062033\n",
      "84 1253.6672582553642\n",
      "85 1178.3954941180104\n",
      "86 1108.0085732439204\n",
      "87 1042.0732747803736\n",
      "88 980.3375034637387\n",
      "89 922.5866776838839\n",
      "90 868.5280881155151\n",
      "91 817.810168671963\n",
      "92 770.2575803965498\n",
      "93 725.6794361923285\n",
      "94 683.8316898580026\n",
      "95 644.5537889472772\n",
      "96 607.6734408045397\n",
      "97 573.0434333106945\n",
      "98 540.516336605192\n",
      "99 509.9446901859369\n",
      "100 481.24200457322775\n",
      "101 454.2449613812371\n",
      "102 428.8392699499741\n",
      "103 404.93844008557164\n",
      "104 382.44743832791676\n",
      "105 361.27529335821123\n",
      "106 341.3428263913095\n",
      "107 322.59213917057343\n",
      "108 305.08541378343295\n",
      "109 288.5860780777415\n",
      "110 273.0295367361684\n",
      "111 258.3610247579643\n",
      "112 244.51607255305206\n",
      "113 231.45320792396268\n",
      "114 219.12963941866343\n",
      "115 207.4922322083222\n",
      "116 196.50974226917106\n",
      "117 186.1391789559151\n",
      "118 176.3383924595448\n",
      "119 167.0798625292977\n",
      "120 158.33228477629666\n",
      "121 150.06537298373033\n",
      "122 142.25058030537966\n",
      "123 134.85896879892707\n",
      "124 127.8727958097894\n",
      "125 121.26373172303279\n",
      "126 115.00842009019328\n",
      "127 109.08995185742353\n",
      "128 103.48956167301405\n",
      "129 98.18836904997585\n",
      "130 93.16946990630589\n",
      "131 88.42517304165816\n",
      "132 83.935311460581\n",
      "133 79.68418731331091\n",
      "134 75.65468070447889\n",
      "135 71.83516173836121\n",
      "136 68.21651745078769\n",
      "137 64.78717928966469\n",
      "138 61.536480686543776\n",
      "139 58.45523891809077\n",
      "140 55.53333149513673\n",
      "141 52.76558577813743\n",
      "142 50.138502375450145\n",
      "143 47.64560510462224\n",
      "144 45.28163714057236\n",
      "145 43.0384149165053\n",
      "146 40.91034895307354\n",
      "147 38.891471103928524\n",
      "148 36.9745438286686\n",
      "149 35.15580982235006\n",
      "150 33.429395838596484\n",
      "151 31.789417297290367\n",
      "152 30.23312441668144\n",
      "153 28.75504689568151\n",
      "154 27.350961614556045\n",
      "155 26.01745200046625\n",
      "156 24.75057147602249\n",
      "157 23.547205964038277\n",
      "158 22.40482806850639\n",
      "159 21.3191679809225\n",
      "160 20.287360724209222\n",
      "161 19.306399704831662\n",
      "162 18.374320656784512\n",
      "163 17.488347458310095\n",
      "164 16.645829660227477\n",
      "165 15.84494070239408\n",
      "166 15.083442288421175\n",
      "167 14.359861989709621\n",
      "168 13.672079125764771\n",
      "169 13.017404323358964\n",
      "170 12.394716043856082\n",
      "171 11.802634532476876\n",
      "172 11.239609633443694\n",
      "173 10.703827223017992\n",
      "174 10.194355383364158\n",
      "175 9.7093872779833\n",
      "176 9.248090002605794\n",
      "177 8.810090583724223\n",
      "178 8.392609777823564\n",
      "179 7.995448032775691\n",
      "180 7.617371537693465\n",
      "181 7.257619219897325\n",
      "182 6.915172530024256\n",
      "183 6.589083808706329\n",
      "184 6.278708293576411\n",
      "185 5.983180609149647\n",
      "186 5.701997029160891\n",
      "187 5.434317449122798\n",
      "188 5.1792402531882304\n",
      "189 4.936425377104973\n",
      "190 4.705158559786582\n",
      "191 4.484914015985544\n",
      "192 4.275123659689041\n",
      "193 4.07528205624744\n",
      "194 3.8849221061026107\n",
      "195 3.703588909852165\n",
      "196 3.5310020016227024\n",
      "197 3.3665671479653123\n",
      "198 3.2097921565818104\n",
      "199 3.0605188726204307\n",
      "200 2.9182190152817746\n",
      "201 2.7826809488665454\n",
      "202 2.6534758034184005\n",
      "203 2.53034455842206\n",
      "204 2.413067140430253\n",
      "205 2.301302124157715\n",
      "206 2.1948026324489787\n",
      "207 2.0933258260692975\n",
      "208 1.9965520391928704\n",
      "209 1.9042905696149404\n",
      "210 1.8163695315137052\n",
      "211 1.732528136518791\n",
      "212 1.6526200541177047\n",
      "213 1.5764457793943725\n",
      "214 1.5038351744194922\n",
      "215 1.4345980775962186\n",
      "216 1.3686166290321164\n",
      "217 1.305742814922063\n",
      "218 1.2457212288428445\n",
      "219 1.1885087419519316\n",
      "220 1.1339698035133505\n",
      "221 1.0819254752660186\n",
      "222 1.0323034362291126\n",
      "223 0.9849936877322027\n",
      "224 0.9398602226357511\n",
      "225 0.8968401359388076\n",
      "226 0.8558013115956756\n",
      "227 0.8166912690574304\n",
      "228 0.7793613321555963\n",
      "229 0.7437368225482444\n",
      "230 0.7097622811780804\n",
      "231 0.6773534807609458\n",
      "232 0.6464454977049672\n",
      "233 0.6169623927849266\n",
      "234 0.5888411012623788\n",
      "235 0.5620021108316846\n",
      "236 0.5364191285011916\n",
      "237 0.5120101841187902\n",
      "238 0.48871973304612915\n",
      "239 0.4664849538530348\n",
      "240 0.44526788972511816\n",
      "241 0.4250330522117852\n",
      "242 0.4057275984230779\n",
      "243 0.3872997572472371\n",
      "244 0.3697148604338921\n",
      "245 0.3529409213944989\n",
      "246 0.3369283835235341\n",
      "247 0.3216489560102198\n",
      "248 0.3070842870397188\n",
      "249 0.29316801289845706\n",
      "250 0.27989463787805613\n",
      "251 0.2672244129703598\n",
      "252 0.25512980426763976\n",
      "253 0.24358972263448553\n",
      "254 0.2325747749897071\n",
      "255 0.22205667332372747\n",
      "256 0.21202006655068048\n",
      "257 0.20243938408831813\n",
      "258 0.19329930155859984\n",
      "259 0.184584957396015\n",
      "260 0.17625149427351613\n",
      "261 0.16829758122706856\n",
      "262 0.1607069829697685\n",
      "263 0.15346048339119558\n",
      "264 0.14654134781257472\n",
      "265 0.13993701753784515\n",
      "266 0.13363226173565676\n",
      "267 0.12761685514314322\n",
      "268 0.12187140685426079\n",
      "269 0.11638911130886226\n",
      "270 0.11115639352853399\n",
      "271 0.10615698921099144\n",
      "272 0.10138269249537059\n",
      "273 0.09682384393758076\n",
      "274 0.09247222932090493\n",
      "275 0.0883184419771566\n",
      "276 0.08435281810209105\n",
      "277 0.0805648527837611\n",
      "278 0.07694711839145514\n",
      "279 0.0734941419644275\n",
      "280 0.0701973976852929\n",
      "281 0.06705023397965135\n",
      "282 0.06404278543642684\n",
      "283 0.06117257320841475\n",
      "284 0.05843194589441242\n",
      "285 0.055812793639973046\n",
      "286 0.05331256658224792\n",
      "287 0.05092479596692086\n",
      "288 0.04864451173401809\n",
      "289 0.046466449695561476\n",
      "290 0.044386124181325995\n",
      "291 0.042400640810264054\n",
      "292 0.040506463739207986\n",
      "293 0.03869414043170091\n",
      "294 0.036963498378535756\n",
      "295 0.03531065804222913\n",
      "296 0.03373230364009504\n",
      "297 0.032224743841013224\n",
      "298 0.030784745984295023\n",
      "299 0.029409296185399343\n",
      "300 0.028096495638689135\n",
      "301 0.02684206958265683\n",
      "302 0.025643674709404856\n",
      "303 0.024500209591068557\n",
      "304 0.023407275293664834\n",
      "305 0.022362953846162822\n",
      "306 0.02136529018208029\n",
      "307 0.020412371115414114\n",
      "308 0.019502445714145406\n",
      "309 0.018633211613540403\n",
      "310 0.01780259812867921\n",
      "311 0.01700907580001721\n",
      "312 0.01625124708451403\n",
      "313 0.015527285310957765\n",
      "314 0.014836204135928571\n",
      "315 0.014175574829091419\n",
      "316 0.013544616197115944\n",
      "317 0.012941891383475778\n",
      "318 0.012365752655823849\n",
      "319 0.011815446690942545\n",
      "320 0.011289686334704098\n",
      "321 0.010787707874741106\n",
      "322 0.01030789008061949\n",
      "323 0.009849410534854783\n",
      "324 0.009411597126383998\n",
      "325 0.008993602058875685\n",
      "326 0.008594035291840135\n",
      "327 0.00821202631650653\n",
      "328 0.007847102062780251\n",
      "329 0.007498537912528643\n",
      "330 0.007165384500606772\n",
      "331 0.006847124447105351\n",
      "332 0.0065430947024959635\n",
      "333 0.006252739015282489\n",
      "334 0.0059751423912446575\n",
      "335 0.005709886770746457\n",
      "336 0.005456569523835154\n",
      "337 0.005214649510076234\n",
      "338 0.004983312535773229\n",
      "339 0.004762314309394823\n",
      "340 0.004551094289760404\n",
      "341 0.004349412665863199\n",
      "342 0.004156515936714886\n",
      "343 0.003972226141366747\n",
      "344 0.003796131084421254\n",
      "345 0.0036278757804670586\n",
      "346 0.0034670820974309763\n",
      "347 0.003313435094960144\n",
      "348 0.003166753421403457\n",
      "349 0.003026592409353332\n",
      "350 0.0028925492585303637\n",
      "351 0.002764459145881954\n",
      "352 0.0026420376018980807\n",
      "353 0.0025250730524842358\n",
      "354 0.0024132594330178213\n",
      "355 0.002306425084520512\n",
      "356 0.0022043878480215435\n",
      "357 0.002106893464214039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358 0.0020136527013626046\n",
      "359 0.0019245706631653133\n",
      "360 0.0018395008358377683\n",
      "361 0.0017581383060139802\n",
      "362 0.001680376752287538\n",
      "363 0.001606052153033938\n",
      "364 0.0015350380863258764\n",
      "365 0.0014672169929995595\n",
      "366 0.0014023423249155441\n",
      "367 0.0013403456065524994\n",
      "368 0.001281116845712786\n",
      "369 0.0012244926890471483\n",
      "370 0.0011703752264242066\n",
      "371 0.0011186955919421245\n",
      "372 0.0010693017465316092\n",
      "373 0.0010220938779933139\n",
      "374 0.0009769594926719825\n",
      "375 0.0009338044349611398\n",
      "376 0.0008925746643684667\n",
      "377 0.0008531598459401686\n",
      "378 0.0008154866829858569\n",
      "379 0.000779484668504332\n",
      "380 0.0007450799387795288\n",
      "381 0.0007122107663852029\n",
      "382 0.0006807724738051952\n",
      "383 0.000650765381256051\n",
      "384 0.0006220513425231174\n",
      "385 0.0005946014935396558\n",
      "386 0.0005683683001121029\n",
      "387 0.0005433039239757075\n",
      "388 0.0005193400989004649\n",
      "389 0.0004964472150734609\n",
      "390 0.00047455419439608037\n",
      "391 0.0004536382024296203\n",
      "392 0.0004336349315978706\n",
      "393 0.0004145164088530977\n",
      "394 0.00039624858300219435\n",
      "395 0.0003787954326159242\n",
      "396 0.0003620979052997754\n",
      "397 0.0003461472149706439\n",
      "398 0.00033089226208777363\n",
      "399 0.00031631486560551955\n",
      "400 0.0003023759427301559\n",
      "401 0.00028905189956554404\n",
      "402 0.0002763217129884013\n",
      "403 0.0002641491327331145\n",
      "404 0.0002525131954419712\n",
      "405 0.00024139945955661615\n",
      "406 0.00023077366356078977\n",
      "407 0.00022061630260046978\n",
      "408 0.00021090443778246575\n",
      "409 0.0002016193116094424\n",
      "410 0.00019274410797657707\n",
      "411 0.00018425933409244787\n",
      "412 0.00017614802249925582\n",
      "413 0.000168400025715068\n",
      "414 0.00016098930089809333\n",
      "415 0.00015390431638067988\n",
      "416 0.00014713113816829213\n",
      "417 0.00014066085230810774\n",
      "418 0.00013447713018110318\n",
      "419 0.000128561579801664\n",
      "420 0.00012290597699438917\n",
      "421 0.00011750379736509842\n",
      "422 0.00011233517664667534\n",
      "423 0.00010739417516388952\n",
      "424 0.00010267161532363194\n",
      "425 9.815712874310822e-05\n",
      "426 9.384201370130754e-05\n",
      "427 8.971616315223209e-05\n",
      "428 8.577296220077524e-05\n",
      "429 8.200482263400059e-05\n",
      "430 7.840311359745672e-05\n",
      "431 7.495646141225128e-05\n",
      "432 7.166256081834874e-05\n",
      "433 6.851281069323784e-05\n",
      "434 6.55015543188445e-05\n",
      "435 6.262332198279694e-05\n",
      "436 5.987187020803758e-05\n",
      "437 5.7242265425260653e-05\n",
      "438 5.472752299171067e-05\n",
      "439 5.23237196325245e-05\n",
      "440 5.002491939869087e-05\n",
      "441 4.7827879341949856e-05\n",
      "442 4.5728631064954884e-05\n",
      "443 4.37208410286496e-05\n",
      "444 4.180075328216532e-05\n",
      "445 3.996598683693764e-05\n",
      "446 3.8211246858489546e-05\n",
      "447 3.653342523062905e-05\n",
      "448 3.492927164783109e-05\n",
      "449 3.33957531140152e-05\n",
      "450 3.192960943482511e-05\n",
      "451 3.052801192209353e-05\n",
      "452 2.9187852901963743e-05\n",
      "453 2.7907841527733123e-05\n",
      "454 2.668385184151054e-05\n",
      "455 2.5512583719642835e-05\n",
      "456 2.4392812695675997e-05\n",
      "457 2.3322644812166625e-05\n",
      "458 2.2299128802168425e-05\n",
      "459 2.1320525972266425e-05\n",
      "460 2.038537116431501e-05\n",
      "461 1.949157495738097e-05\n",
      "462 1.8636546604284705e-05\n",
      "463 1.7819172865070325e-05\n",
      "464 1.703765640285242e-05\n",
      "465 1.6290651903073564e-05\n",
      "466 1.5576336819061053e-05\n",
      "467 1.4893230552259551e-05\n",
      "468 1.4240059020282879e-05\n",
      "469 1.3615807259569193e-05\n",
      "470 1.3018818706550523e-05\n",
      "471 1.2448030155624266e-05\n",
      "472 1.190218622701264e-05\n",
      "473 1.1380313029327698e-05\n",
      "474 1.0881424333847272e-05\n",
      "475 1.0404373170173484e-05\n",
      "476 9.948235809479159e-06\n",
      "477 9.512714222619028e-06\n",
      "478 9.096024270417763e-06\n",
      "479 8.697299563815202e-06\n",
      "480 8.316068301950844e-06\n",
      "481 7.951632260983307e-06\n",
      "482 7.603211738677674e-06\n",
      "483 7.27009233014443e-06\n",
      "484 6.951527708576127e-06\n",
      "485 6.647050749316472e-06\n",
      "486 6.355869438692925e-06\n",
      "487 6.0773812510469895e-06\n",
      "488 5.811199633276736e-06\n",
      "489 5.556782990477425e-06\n",
      "490 5.31332330742387e-06\n",
      "491 5.080580299456113e-06\n",
      "492 4.858050983282305e-06\n",
      "493 4.6452935025914905e-06\n",
      "494 4.441901140227019e-06\n",
      "495 4.24745051360025e-06\n",
      "496 4.061455443423622e-06\n",
      "497 3.883611502138114e-06\n",
      "498 3.713546770628685e-06\n",
      "499 3.5509235649691807e-06\n"
     ]
    }
   ],
   "source": [
    "# 64个训练数据, 输入是1000维, 隐藏层是100维, 输出是10维\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建一些训练数据,正态分布\n",
    "x = np.random.randn(N, D_in)    # 64个训练数据,每个维度是1000\n",
    "y = np.random.randn(N, D_out)   # 输出是10维\n",
    "\n",
    "w1 = np.random.randn(D_in, H)   # 输入层 ==> 隐藏层\n",
    "w2 = np.random.randn(H, D_out)  # 隐藏层 ==> 输出层\n",
    "\n",
    "learning_rate = 1e-6            # 学习率\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    h = x.dot(w1)               # N * H\n",
    "    h_relu = np.maximum(h, 0)   # N * H\n",
    "    y_pred = h_relu.dot(w2)     # N * D_out\n",
    "    \n",
    "    # compute loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(it, loss)\n",
    "    \n",
    "    # Backward pass\n",
    "    # compute the gradient\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    # update weights of w1 and w2\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: Tensors\n",
    "\n",
    "这次我们使用PyTorch tensors来创建前向神经网络，计算损失，以及反向传播。\n",
    "\n",
    "一个PyTorch Tensor很像一个numpy的ndarray。但是它和numpy ndarray最大的区别是，PyTorch Tensor可以在CPU或者GPU上运算。如果想要在GPU上运算，就需要把Tensor换成cuda类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 34576312.0\n",
      "1 32510804.0\n",
      "2 34094456.0\n",
      "3 33462306.0\n",
      "4 27375170.0\n",
      "5 17991892.0\n",
      "6 9881738.0\n",
      "7 5087395.5\n",
      "8 2782959.5\n",
      "9 1734153.25\n",
      "10 1228542.625\n",
      "11 950661.5\n",
      "12 773756.625\n",
      "13 647202.75\n",
      "14 549723.5625\n",
      "15 471403.875\n",
      "16 406932.3125\n",
      "17 353084.46875\n",
      "18 307790.5\n",
      "19 269375.8125\n",
      "20 236593.90625\n",
      "21 208498.21875\n",
      "22 184310.5625\n",
      "23 163393.125\n",
      "24 145251.8125\n",
      "25 129458.296875\n",
      "26 115659.046875\n",
      "27 103561.484375\n",
      "28 92932.5625\n",
      "29 83571.8203125\n",
      "30 75300.2109375\n",
      "31 67973.671875\n",
      "32 61469.37109375\n",
      "33 55681.40625\n",
      "34 50518.44140625\n",
      "35 45905.5390625\n",
      "36 41776.42578125\n",
      "37 38071.5234375\n",
      "38 34743.53125\n",
      "39 31748.9765625\n",
      "40 29049.58984375\n",
      "41 26611.625\n",
      "42 24406.646484375\n",
      "43 22409.712890625\n",
      "44 20598.01171875\n",
      "45 18953.95703125\n",
      "46 17459.67578125\n",
      "47 16098.291015625\n",
      "48 14856.2099609375\n",
      "49 13722.8232421875\n",
      "50 12687.0947265625\n",
      "51 11739.0966796875\n",
      "52 10870.513671875\n",
      "53 10073.9970703125\n",
      "54 9342.740234375\n",
      "55 8670.7529296875\n",
      "56 8052.81787109375\n",
      "57 7483.79443359375\n",
      "58 6959.6083984375\n",
      "59 6476.2353515625\n",
      "60 6030.0576171875\n",
      "61 5618.17138671875\n",
      "62 5237.24560546875\n",
      "63 4884.8037109375\n",
      "64 4558.5166015625\n",
      "65 4256.19921875\n",
      "66 3975.93408203125\n",
      "67 3715.95166015625\n",
      "68 3474.691650390625\n",
      "69 3250.55078125\n",
      "70 3042.27197265625\n",
      "71 2848.517578125\n",
      "72 2668.245361328125\n",
      "73 2500.38720703125\n",
      "74 2344.09521484375\n",
      "75 2198.47802734375\n",
      "76 2062.606689453125\n",
      "77 1935.8272705078125\n",
      "78 1817.4720458984375\n",
      "79 1706.9437255859375\n",
      "80 1603.6722412109375\n",
      "81 1507.155029296875\n",
      "82 1416.9083251953125\n",
      "83 1332.4810791015625\n",
      "84 1253.4776611328125\n",
      "85 1179.497314453125\n",
      "86 1110.234130859375\n",
      "87 1045.3311767578125\n",
      "88 984.479248046875\n",
      "89 927.46142578125\n",
      "90 873.9467163085938\n",
      "91 823.7273559570312\n",
      "92 776.5869750976562\n",
      "93 732.3204956054688\n",
      "94 690.74951171875\n",
      "95 651.6869506835938\n",
      "96 614.9716796875\n",
      "97 580.4654541015625\n",
      "98 548.0252685546875\n",
      "99 517.4948120117188\n",
      "100 488.7740478515625\n",
      "101 461.7311096191406\n",
      "102 436.275634765625\n",
      "103 412.31048583984375\n",
      "104 389.7484436035156\n",
      "105 368.4761047363281\n",
      "106 348.4281921386719\n",
      "107 329.5309753417969\n",
      "108 311.70635986328125\n",
      "109 294.9027099609375\n",
      "110 279.06231689453125\n",
      "111 264.10894775390625\n",
      "112 249.99737548828125\n",
      "113 236.673828125\n",
      "114 224.09458923339844\n",
      "115 212.21649169921875\n",
      "116 201.00128173828125\n",
      "117 190.4060821533203\n",
      "118 180.39735412597656\n",
      "119 170.94403076171875\n",
      "120 162.0004119873047\n",
      "121 153.5471649169922\n",
      "122 145.55714416503906\n",
      "123 137.9987030029297\n",
      "124 130.8484649658203\n",
      "125 124.08436584472656\n",
      "126 117.68370819091797\n",
      "127 111.6265640258789\n",
      "128 105.89400482177734\n",
      "129 100.46916961669922\n",
      "130 95.33113098144531\n",
      "131 90.46868896484375\n",
      "132 85.86176300048828\n",
      "133 81.49911499023438\n",
      "134 77.36897277832031\n",
      "135 73.45499420166016\n",
      "136 69.74368286132812\n",
      "137 66.2269287109375\n",
      "138 62.894126892089844\n",
      "139 59.734962463378906\n",
      "140 56.7396125793457\n",
      "141 53.89823532104492\n",
      "142 51.20509338378906\n",
      "143 48.65152359008789\n",
      "144 46.228492736816406\n",
      "145 43.93046951293945\n",
      "146 41.75126266479492\n",
      "147 39.68156814575195\n",
      "148 37.71870422363281\n",
      "149 35.85562515258789\n",
      "150 34.087318420410156\n",
      "151 32.41061019897461\n",
      "152 30.81711196899414\n",
      "153 29.304550170898438\n",
      "154 27.86756134033203\n",
      "155 26.503305435180664\n",
      "156 25.20771598815918\n",
      "157 23.977453231811523\n",
      "158 22.808822631835938\n",
      "159 21.69847869873047\n",
      "160 20.643665313720703\n",
      "161 19.641361236572266\n",
      "162 18.68907928466797\n",
      "163 17.7838191986084\n",
      "164 16.923683166503906\n",
      "165 16.106136322021484\n",
      "166 15.329402923583984\n",
      "167 14.590599060058594\n",
      "168 13.889440536499023\n",
      "169 13.222081184387207\n",
      "170 12.587139129638672\n",
      "171 11.983485221862793\n",
      "172 11.409354209899902\n",
      "173 10.863466262817383\n",
      "174 10.344154357910156\n",
      "175 9.850468635559082\n",
      "176 9.380913734436035\n",
      "177 8.933428764343262\n",
      "178 8.508393287658691\n",
      "179 8.10417652130127\n",
      "180 7.719250679016113\n",
      "181 7.352909088134766\n",
      "182 7.004497051239014\n",
      "183 6.673051834106445\n",
      "184 6.357140064239502\n",
      "185 6.057281017303467\n",
      "186 5.770960807800293\n",
      "187 5.498938083648682\n",
      "188 5.239876747131348\n",
      "189 4.993168830871582\n",
      "190 4.758261203765869\n",
      "191 4.534688949584961\n",
      "192 4.321630001068115\n",
      "193 4.1190185546875\n",
      "194 3.9258666038513184\n",
      "195 3.7419815063476562\n",
      "196 3.5668320655822754\n",
      "197 3.4000768661499023\n",
      "198 3.2413673400878906\n",
      "199 3.0900914669036865\n",
      "200 2.9457898139953613\n",
      "201 2.808579206466675\n",
      "202 2.677898406982422\n",
      "203 2.5532784461975098\n",
      "204 2.4347474575042725\n",
      "205 2.3215506076812744\n",
      "206 2.2137513160705566\n",
      "207 2.1110827922821045\n",
      "208 2.0130183696746826\n",
      "209 1.91987144947052\n",
      "210 1.8309227228164673\n",
      "211 1.7462561130523682\n",
      "212 1.6656025648117065\n",
      "213 1.5885932445526123\n",
      "214 1.5152133703231812\n",
      "215 1.4454474449157715\n",
      "216 1.3789201974868774\n",
      "217 1.3153178691864014\n",
      "218 1.2546874284744263\n",
      "219 1.1970325708389282\n",
      "220 1.142000436782837\n",
      "221 1.0894826650619507\n",
      "222 1.0394785404205322\n",
      "223 0.9918224811553955\n",
      "224 0.9463026523590088\n",
      "225 0.9029433131217957\n",
      "226 0.8615129590034485\n",
      "227 0.8221302628517151\n",
      "228 0.7845509648323059\n",
      "229 0.748671293258667\n",
      "230 0.7144540548324585\n",
      "231 0.6818474531173706\n",
      "232 0.6506950855255127\n",
      "233 0.6210418343544006\n",
      "234 0.5926470756530762\n",
      "235 0.5656463503837585\n",
      "236 0.5399647355079651\n",
      "237 0.5153345465660095\n",
      "238 0.49185895919799805\n",
      "239 0.4695708453655243\n",
      "240 0.4482293725013733\n",
      "241 0.42786332964897156\n",
      "242 0.4084008038043976\n",
      "243 0.3899157643318176\n",
      "244 0.3722519278526306\n",
      "245 0.3553536832332611\n",
      "246 0.33923932909965515\n",
      "247 0.3239138722419739\n",
      "248 0.3092450797557831\n",
      "249 0.2952243983745575\n",
      "250 0.28189778327941895\n",
      "251 0.26914575695991516\n",
      "252 0.2569674849510193\n",
      "253 0.24539734423160553\n",
      "254 0.2343006432056427\n",
      "255 0.22375920414924622\n",
      "256 0.21365728974342346\n",
      "257 0.2039998322725296\n",
      "258 0.1948084682226181\n",
      "259 0.18601912260055542\n",
      "260 0.17767415940761566\n",
      "261 0.16970644891262054\n",
      "262 0.1620381772518158\n",
      "263 0.1547551155090332\n",
      "264 0.14782190322875977\n",
      "265 0.14120639860630035\n",
      "266 0.13486935198307037\n",
      "267 0.12879419326782227\n",
      "268 0.12302012741565704\n",
      "269 0.11752943694591522\n",
      "270 0.11224039644002914\n",
      "271 0.10719141364097595\n",
      "272 0.10241295397281647\n",
      "273 0.09782561659812927\n",
      "274 0.0934525802731514\n",
      "275 0.0892852321267128\n",
      "276 0.08529987186193466\n",
      "277 0.08148202300071716\n",
      "278 0.07783913612365723\n",
      "279 0.07434634864330292\n",
      "280 0.07105999439954758\n",
      "281 0.06788697838783264\n",
      "282 0.06485573202371597\n",
      "283 0.061981379985809326\n",
      "284 0.05920982360839844\n",
      "285 0.05657237023115158\n",
      "286 0.054054904729127884\n",
      "287 0.05165012925863266\n",
      "288 0.04935497045516968\n",
      "289 0.04716861620545387\n",
      "290 0.04507631063461304\n",
      "291 0.04307994619011879\n",
      "292 0.041170693933963776\n",
      "293 0.03935087099671364\n",
      "294 0.03760029375553131\n",
      "295 0.035945866256952286\n",
      "296 0.034336868673563004\n",
      "297 0.03283705934882164\n",
      "298 0.03138357028365135\n",
      "299 0.029989836737513542\n",
      "300 0.02867388166487217\n",
      "301 0.027394862845540047\n",
      "302 0.026192782446742058\n",
      "303 0.02504582330584526\n",
      "304 0.02394619956612587\n",
      "305 0.02289617992937565\n",
      "306 0.021889980882406235\n",
      "307 0.020929038524627686\n",
      "308 0.019998911768198013\n",
      "309 0.019122332334518433\n",
      "310 0.01828859932720661\n",
      "311 0.01749570667743683\n",
      "312 0.016740214079618454\n",
      "313 0.016009416431188583\n",
      "314 0.015307017602026463\n",
      "315 0.014639485627412796\n",
      "316 0.014006472192704678\n",
      "317 0.013393513858318329\n",
      "318 0.012824177742004395\n",
      "319 0.012269889004528522\n",
      "320 0.011746239848434925\n",
      "321 0.011237365193665028\n",
      "322 0.010744977742433548\n",
      "323 0.010291469283401966\n",
      "324 0.009844863787293434\n",
      "325 0.00942105334252119\n",
      "326 0.009019552730023861\n",
      "327 0.008634740486741066\n",
      "328 0.008269686251878738\n",
      "329 0.00792135763913393\n",
      "330 0.0075879329815506935\n",
      "331 0.007273025345057249\n",
      "332 0.006966122426092625\n",
      "333 0.006665931083261967\n",
      "334 0.006392176728695631\n",
      "335 0.006128191482275724\n",
      "336 0.0058710090816020966\n",
      "337 0.005632319487631321\n",
      "338 0.0053986902348697186\n",
      "339 0.005170433782041073\n",
      "340 0.004961680620908737\n",
      "341 0.00475938618183136\n",
      "342 0.004562912508845329\n",
      "343 0.004381775390356779\n",
      "344 0.004204577766358852\n",
      "345 0.004034013953059912\n",
      "346 0.0038697661366313696\n",
      "347 0.0037182471714913845\n",
      "348 0.0035690777003765106\n",
      "349 0.0034291089978069067\n",
      "350 0.003295954316854477\n",
      "351 0.0031650648452341557\n",
      "352 0.0030460404232144356\n",
      "353 0.002925823675468564\n",
      "354 0.0028127506375312805\n",
      "355 0.0027053856756538153\n",
      "356 0.002600278239697218\n",
      "357 0.0025025615468621254\n",
      "358 0.0024097845889627934\n",
      "359 0.002318641170859337\n",
      "360 0.0022320752032101154\n",
      "361 0.0021502855233848095\n",
      "362 0.0020678492728620768\n",
      "363 0.001994543941691518\n",
      "364 0.0019213538616895676\n",
      "365 0.001852691755630076\n",
      "366 0.001786887412890792\n",
      "367 0.0017223090399056673\n",
      "368 0.0016614985652267933\n",
      "369 0.0016009382670745254\n",
      "370 0.0015451156068593264\n",
      "371 0.0014913607155904174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372 0.0014411802403628826\n",
      "373 0.001391457743011415\n",
      "374 0.0013453233987092972\n",
      "375 0.0012995358556509018\n",
      "376 0.0012558529851958156\n",
      "377 0.0012115391436964273\n",
      "378 0.0011727800592780113\n",
      "379 0.0011330812703818083\n",
      "380 0.0010954414028674364\n",
      "381 0.001058986410498619\n",
      "382 0.0010246583260595798\n",
      "383 0.0009920638985931873\n",
      "384 0.000960951205343008\n",
      "385 0.0009319901582784951\n",
      "386 0.0009013290982693434\n",
      "387 0.0008743526414036751\n",
      "388 0.0008464703569188714\n",
      "389 0.0008192691020667553\n",
      "390 0.0007957531488500535\n",
      "391 0.0007711197249591351\n",
      "392 0.000747534038964659\n",
      "393 0.0007259614649228752\n",
      "394 0.000703289988450706\n",
      "395 0.0006827063043601811\n",
      "396 0.0006629342096857727\n",
      "397 0.0006426958134397864\n",
      "398 0.0006252044113352895\n",
      "399 0.000607246533036232\n",
      "400 0.0005891717737540603\n",
      "401 0.0005724278744310141\n",
      "402 0.0005563916638493538\n",
      "403 0.000541627814527601\n",
      "404 0.0005272082053124905\n",
      "405 0.0005129955243319273\n",
      "406 0.0004990817396901548\n",
      "407 0.0004859707551077008\n",
      "408 0.0004727276391349733\n",
      "409 0.000460826006019488\n",
      "410 0.00044788033119402826\n",
      "411 0.0004360286402516067\n",
      "412 0.00042538525303825736\n",
      "413 0.000414828333305195\n",
      "414 0.00040345749584957957\n",
      "415 0.00039338975329883397\n",
      "416 0.0003834483213722706\n",
      "417 0.0003747186274267733\n",
      "418 0.00036427448503673077\n",
      "419 0.0003560760524123907\n",
      "420 0.000346381712006405\n",
      "421 0.00033812635228969157\n",
      "422 0.0003301899996586144\n",
      "423 0.00032222707523033023\n",
      "424 0.00031424974440597\n",
      "425 0.0003060760791413486\n",
      "426 0.00029922983958385885\n",
      "427 0.00029258945141918957\n",
      "428 0.0002856335195247084\n",
      "429 0.0002783164964057505\n",
      "430 0.0002730756241362542\n",
      "431 0.00026629207422956824\n",
      "432 0.00026088758022524416\n",
      "433 0.000254922459134832\n",
      "434 0.00024983708863146603\n",
      "435 0.0002439003437757492\n",
      "436 0.00023825415701139718\n",
      "437 0.00023281727044377476\n",
      "438 0.00022820994490757585\n",
      "439 0.0002233460108982399\n",
      "440 0.0002186650672229007\n",
      "441 0.00021445774473249912\n",
      "442 0.00020961873815394938\n",
      "443 0.00020560782286338508\n",
      "444 0.00020142138237133622\n",
      "445 0.00019724124285858124\n",
      "446 0.00019331791554577649\n",
      "447 0.00018943034228868783\n",
      "448 0.00018537748837843537\n",
      "449 0.00018161254411097616\n",
      "450 0.00017797932378016412\n",
      "451 0.00017456737987231463\n",
      "452 0.00017160773859359324\n",
      "453 0.00016825893544591963\n",
      "454 0.0001652691571507603\n",
      "455 0.0001624045253265649\n",
      "456 0.00015906883345451206\n",
      "457 0.00015583724598400295\n",
      "458 0.00015327843721024692\n",
      "459 0.00015026262553874403\n",
      "460 0.00014794482558500022\n",
      "461 0.00014512786583509296\n",
      "462 0.00014256520080380142\n",
      "463 0.00013941210636403412\n",
      "464 0.00013712186773773283\n",
      "465 0.0001350857492070645\n",
      "466 0.0001324336917605251\n",
      "467 0.0001300764415645972\n",
      "468 0.00012785861326847225\n",
      "469 0.0001256904361071065\n",
      "470 0.00012356872321106493\n",
      "471 0.00012135108408983797\n",
      "472 0.00011926583829335868\n",
      "473 0.00011719646136043593\n",
      "474 0.00011553896911209449\n",
      "475 0.0001136140781454742\n",
      "476 0.00011193392856512219\n",
      "477 0.00011020917736459523\n",
      "478 0.00010816867870744318\n",
      "479 0.00010639245010679588\n",
      "480 0.00010468635446159169\n",
      "481 0.00010309163189958781\n",
      "482 0.00010166893480345607\n",
      "483 9.976036380976439e-05\n",
      "484 9.817433601710945e-05\n",
      "485 9.666576806921512e-05\n",
      "486 9.510150994174182e-05\n",
      "487 9.362725540995598e-05\n",
      "488 9.219865023624152e-05\n",
      "489 9.093631524592638e-05\n",
      "490 8.962735591921955e-05\n",
      "491 8.821442315820605e-05\n",
      "492 8.675824938109145e-05\n",
      "493 8.550933853257447e-05\n",
      "494 8.45646791276522e-05\n",
      "495 8.327935211127624e-05\n",
      "496 8.207014616345987e-05\n",
      "497 8.109851478366181e-05\n",
      "498 7.997723150765523e-05\n",
      "499 7.866085070418194e-05\n"
     ]
    }
   ],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建一些训练数据\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "w1 = torch.randn(D_in, H)\n",
    "w2 = torch.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    h = x.mm(w1)             # N * H, 矩阵乘法\n",
    "    h_relu = h.clamp(min=0)  # N * H, 下限是0\n",
    "    y_pred = h_relu.mm(w2)   # N * D_out\n",
    "    \n",
    "    # compute loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()   # tensor转为python表示\n",
    "    print(it, loss)\n",
    "    \n",
    "    # Backward pass \n",
    "    # compute the gradient (手动)\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "    \n",
    "    # update weights of w1 and w2\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单的autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(2.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "y = w*x + b     # y = 2*1+3\n",
    "\n",
    "y.backward()    # \n",
    "\n",
    "# dy / dw = x\n",
    "print(w.grad)\n",
    "print(x.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: Tensor和autograd  \n",
    "\n",
    "**PyTorch的一个重要功能就是autograd，也就是说只要定义了forward pass(前向神经网络)，计算了loss之后，PyTorch可以自动求导计算模型所有参数的梯度。**\n",
    "\n",
    "一个PyTorch的Tensor表示计算图中的一个节点。如果``x``是一个Tensor并且``x.requires_grad=True``那么``x.grad``是另一个储存着``x``当前梯度(相对于一个scalar，常常是loss)的向量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 30404994.0\n",
      "1 25766830.0\n",
      "2 24082324.0\n",
      "3 21928268.0\n",
      "4 18106224.0\n",
      "5 13207399.0\n",
      "6 8685804.0\n",
      "7 5391984.5\n",
      "8 3338013.0\n",
      "9 2152406.5\n",
      "10 1479057.375\n",
      "11 1084818.25\n",
      "12 840327.75\n",
      "13 677745.875\n",
      "14 562169.0\n",
      "15 475117.5\n",
      "16 406805.84375\n",
      "17 351438.21875\n",
      "18 305637.5\n",
      "19 267208.90625\n",
      "20 234634.734375\n",
      "21 206842.109375\n",
      "22 182954.859375\n",
      "23 162364.578125\n",
      "24 144476.53125\n",
      "25 128903.2421875\n",
      "26 115301.6015625\n",
      "27 103363.3125\n",
      "28 92890.09375\n",
      "29 83643.1171875\n",
      "30 75463.6015625\n",
      "31 68207.453125\n",
      "32 61756.71484375\n",
      "33 56002.2265625\n",
      "34 50856.8828125\n",
      "35 46242.8828125\n",
      "36 42112.625\n",
      "37 38400.4921875\n",
      "38 35057.40625\n",
      "39 32040.736328125\n",
      "40 29314.3828125\n",
      "41 26848.125\n",
      "42 24612.9609375\n",
      "43 22583.958984375\n",
      "44 20741.703125\n",
      "45 19064.09765625\n",
      "46 17535.896484375\n",
      "47 16143.1767578125\n",
      "48 14870.91796875\n",
      "49 13708.2177734375\n",
      "50 12645.310546875\n",
      "51 11672.44921875\n",
      "52 10780.8671875\n",
      "53 9963.33203125\n",
      "54 9212.75390625\n",
      "55 8523.4814453125\n",
      "56 7889.79736328125\n",
      "57 7306.9697265625\n",
      "58 6770.46923828125\n",
      "59 6276.3115234375\n",
      "60 5820.9130859375\n",
      "61 5401.083984375\n",
      "62 5013.55712890625\n",
      "63 4655.89697265625\n",
      "64 4325.61279296875\n",
      "65 4020.195068359375\n",
      "66 3737.828125\n",
      "67 3476.629150390625\n",
      "68 3234.762939453125\n",
      "69 3010.7705078125\n",
      "70 2803.266845703125\n",
      "71 2610.966552734375\n",
      "72 2432.69189453125\n",
      "73 2267.2890625\n",
      "74 2113.82666015625\n",
      "75 1971.4697265625\n",
      "76 1839.15087890625\n",
      "77 1716.23388671875\n",
      "78 1601.956298828125\n",
      "79 1495.6759033203125\n",
      "80 1396.8289794921875\n",
      "81 1304.87890625\n",
      "82 1219.361328125\n",
      "83 1139.7088623046875\n",
      "84 1065.5062255859375\n",
      "85 996.38623046875\n",
      "86 931.97216796875\n",
      "87 871.9270629882812\n",
      "88 815.9622802734375\n",
      "89 763.7560424804688\n",
      "90 715.046875\n",
      "91 669.6030883789062\n",
      "92 627.1802978515625\n",
      "93 587.59912109375\n",
      "94 550.61376953125\n",
      "95 516.05029296875\n",
      "96 483.7651062011719\n",
      "97 453.5906982421875\n",
      "98 425.38470458984375\n",
      "99 399.02227783203125\n",
      "100 374.35546875\n",
      "101 351.2832946777344\n",
      "102 329.69757080078125\n",
      "103 309.5062255859375\n",
      "104 290.61138916015625\n",
      "105 272.9238586425781\n",
      "106 256.3533935546875\n",
      "107 240.83172607421875\n",
      "108 226.29234313964844\n",
      "109 212.66751098632812\n",
      "110 199.89987182617188\n",
      "111 187.93270874023438\n",
      "112 176.70571899414062\n",
      "113 166.17774963378906\n",
      "114 156.30276489257812\n",
      "115 147.03707885742188\n",
      "116 138.34458923339844\n",
      "117 130.18597412109375\n",
      "118 122.52694702148438\n",
      "119 115.33525085449219\n",
      "120 108.58314514160156\n",
      "121 102.2452392578125\n",
      "122 96.28655242919922\n",
      "123 90.69197082519531\n",
      "124 85.43639373779297\n",
      "125 80.4933090209961\n",
      "126 75.8499984741211\n",
      "127 71.4823226928711\n",
      "128 67.37821197509766\n",
      "129 63.51930236816406\n",
      "130 59.88702392578125\n",
      "131 56.47169494628906\n",
      "132 53.25699234008789\n",
      "133 50.23164749145508\n",
      "134 47.38364791870117\n",
      "135 44.70610046386719\n",
      "136 42.18364715576172\n",
      "137 39.809112548828125\n",
      "138 37.57062911987305\n",
      "139 35.46305465698242\n",
      "140 33.478309631347656\n",
      "141 31.608503341674805\n",
      "142 29.84648895263672\n",
      "143 28.186479568481445\n",
      "144 26.620975494384766\n",
      "145 25.14595603942871\n",
      "146 23.7552433013916\n",
      "147 22.444496154785156\n",
      "148 21.20802116394043\n",
      "149 20.042179107666016\n",
      "150 18.942089080810547\n",
      "151 17.904821395874023\n",
      "152 16.92664909362793\n",
      "153 16.002185821533203\n",
      "154 15.130480766296387\n",
      "155 14.307519912719727\n",
      "156 13.531855583190918\n",
      "157 12.799091339111328\n",
      "158 12.107294082641602\n",
      "159 11.452897071838379\n",
      "160 10.835968017578125\n",
      "161 10.253143310546875\n",
      "162 9.702738761901855\n",
      "163 9.182355880737305\n",
      "164 8.690844535827637\n",
      "165 8.226633071899414\n",
      "166 7.787643909454346\n",
      "167 7.372824668884277\n",
      "168 6.981114387512207\n",
      "169 6.610524654388428\n",
      "170 6.260284900665283\n",
      "171 5.929120063781738\n",
      "172 5.615858554840088\n",
      "173 5.319737434387207\n",
      "174 5.039629936218262\n",
      "175 4.774416446685791\n",
      "176 4.523897171020508\n",
      "177 4.286838054656982\n",
      "178 4.062403202056885\n",
      "179 3.850013017654419\n",
      "180 3.648991584777832\n",
      "181 3.458880662918091\n",
      "182 3.279019355773926\n",
      "183 3.1087567806243896\n",
      "184 2.9472646713256836\n",
      "185 2.794661283493042\n",
      "186 2.650074005126953\n",
      "187 2.5131418704986572\n",
      "188 2.3836965560913086\n",
      "189 2.260831117630005\n",
      "190 2.1445605754852295\n",
      "191 2.0343523025512695\n",
      "192 1.9299041032791138\n",
      "193 1.8309743404388428\n",
      "194 1.7372536659240723\n",
      "195 1.6484988927841187\n",
      "196 1.5643576383590698\n",
      "197 1.4847025871276855\n",
      "198 1.4090542793273926\n",
      "199 1.3373535871505737\n",
      "200 1.2695013284683228\n",
      "201 1.2049846649169922\n",
      "202 1.143983006477356\n",
      "203 1.0861061811447144\n",
      "204 1.0312933921813965\n",
      "205 0.9791579842567444\n",
      "206 0.9296756982803345\n",
      "207 0.8828979134559631\n",
      "208 0.8385050892829895\n",
      "209 0.7964553833007812\n",
      "210 0.756424605846405\n",
      "211 0.7184737324714661\n",
      "212 0.682614803314209\n",
      "213 0.648405909538269\n",
      "214 0.6159677505493164\n",
      "215 0.5852698087692261\n",
      "216 0.5561097860336304\n",
      "217 0.528427004814148\n",
      "218 0.5019921660423279\n",
      "219 0.477111279964447\n",
      "220 0.4534343183040619\n",
      "221 0.43096283078193665\n",
      "222 0.40952569246292114\n",
      "223 0.38934338092803955\n",
      "224 0.37003573775291443\n",
      "225 0.3518069386482239\n",
      "226 0.33441704511642456\n",
      "227 0.31790754199028015\n",
      "228 0.30229705572128296\n",
      "229 0.28741219639778137\n",
      "230 0.2732870280742645\n",
      "231 0.25986433029174805\n",
      "232 0.24707990884780884\n",
      "233 0.23495787382125854\n",
      "234 0.22343601286411285\n",
      "235 0.21252478659152985\n",
      "236 0.20210124552249908\n",
      "237 0.1922563910484314\n",
      "238 0.18288350105285645\n",
      "239 0.17395031452178955\n",
      "240 0.1654682755470276\n",
      "241 0.15743935108184814\n",
      "242 0.1497499942779541\n",
      "243 0.14249499142169952\n",
      "244 0.13556645810604095\n",
      "245 0.12898027896881104\n",
      "246 0.12275192886590958\n",
      "247 0.1168004646897316\n",
      "248 0.11114989966154099\n",
      "249 0.10578171163797379\n",
      "250 0.10066837817430496\n",
      "251 0.09578881412744522\n",
      "252 0.0911564975976944\n",
      "253 0.0867796540260315\n",
      "254 0.08259967714548111\n",
      "255 0.07861015200614929\n",
      "256 0.07486674189567566\n",
      "257 0.07124742120504379\n",
      "258 0.06782021373510361\n",
      "259 0.06459247320890427\n",
      "260 0.061491627246141434\n",
      "261 0.05855977535247803\n",
      "262 0.05576327443122864\n",
      "263 0.05308737978339195\n",
      "264 0.050547223538160324\n",
      "265 0.04813364893198013\n",
      "266 0.04583417624235153\n",
      "267 0.043656304478645325\n",
      "268 0.04158389940857887\n",
      "269 0.03959834575653076\n",
      "270 0.03772089257836342\n",
      "271 0.03593691438436508\n",
      "272 0.03421342372894287\n",
      "273 0.03259311616420746\n",
      "274 0.031045766547322273\n",
      "275 0.029581492766737938\n",
      "276 0.02818356826901436\n",
      "277 0.02686256356537342\n",
      "278 0.025591712445020676\n",
      "279 0.0243889931589365\n",
      "280 0.023238681256771088\n",
      "281 0.022149687632918358\n",
      "282 0.02109878696501255\n",
      "283 0.020114077255129814\n",
      "284 0.019179049879312515\n",
      "285 0.01827872171998024\n",
      "286 0.01742079108953476\n",
      "287 0.016606148332357407\n",
      "288 0.01583905518054962\n",
      "289 0.015098962001502514\n",
      "290 0.01440420188009739\n",
      "291 0.013743015937507153\n",
      "292 0.013099822215735912\n",
      "293 0.012503935024142265\n",
      "294 0.011924474500119686\n",
      "295 0.011384868063032627\n",
      "296 0.010859965346753597\n",
      "297 0.010354872792959213\n",
      "298 0.009880933910608292\n",
      "299 0.009429770521819592\n",
      "300 0.009004751220345497\n",
      "301 0.008592871949076653\n",
      "302 0.008202646858990192\n",
      "303 0.007836214266717434\n",
      "304 0.007479489780962467\n",
      "305 0.007146293763071299\n",
      "306 0.006827143486589193\n",
      "307 0.006518515758216381\n",
      "308 0.006226402707397938\n",
      "309 0.005953371059149504\n",
      "310 0.005692126229405403\n",
      "311 0.005436201114207506\n",
      "312 0.005199413280934095\n",
      "313 0.004969308152794838\n",
      "314 0.0047532375901937485\n",
      "315 0.0045418147929012775\n",
      "316 0.004344813991338015\n",
      "317 0.004154845140874386\n",
      "318 0.003977430984377861\n",
      "319 0.003806938184425235\n",
      "320 0.0036444664001464844\n",
      "321 0.003488172311335802\n",
      "322 0.0033383925911039114\n",
      "323 0.003194512100890279\n",
      "324 0.0030612756963819265\n",
      "325 0.0029315275605767965\n",
      "326 0.0028088311664760113\n",
      "327 0.002690172754228115\n",
      "328 0.002576894359663129\n",
      "329 0.0024709822610020638\n",
      "330 0.002368844347074628\n",
      "331 0.0022725616581737995\n",
      "332 0.0021805427968502045\n",
      "333 0.002091804752126336\n",
      "334 0.0020079873502254486\n",
      "335 0.0019282677676528692\n",
      "336 0.001852249028161168\n",
      "337 0.0017795386957004666\n",
      "338 0.0017105104634538293\n",
      "339 0.0016413667472079396\n",
      "340 0.0015781749971210957\n",
      "341 0.0015181672060862184\n",
      "342 0.0014606836484745145\n",
      "343 0.001403716509230435\n",
      "344 0.0013494867598637938\n",
      "345 0.0012993799755349755\n",
      "346 0.0012512268731370568\n",
      "347 0.001203424297273159\n",
      "348 0.001159778330475092\n",
      "349 0.0011148260673508048\n",
      "350 0.0010743167949840426\n",
      "351 0.0010359423467889428\n",
      "352 0.0009997838642448187\n",
      "353 0.0009633247973397374\n",
      "354 0.0009276446071453393\n",
      "355 0.0008942288695834577\n",
      "356 0.0008636568672955036\n",
      "357 0.0008330047130584717\n",
      "358 0.0008045324357226491\n",
      "359 0.0007757532875984907\n",
      "360 0.0007487668190151453\n",
      "361 0.0007231988129206002\n",
      "362 0.0006991169066168368\n",
      "363 0.000675276096444577\n",
      "364 0.000652783433906734\n",
      "365 0.0006312662735581398\n",
      "366 0.0006098559824749827\n",
      "367 0.0005893043125979602\n",
      "368 0.0005704469513148069\n",
      "369 0.000551746052224189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370 0.0005328041152097285\n",
      "371 0.0005164493923075497\n",
      "372 0.000500017311424017\n",
      "373 0.00048426532885059714\n",
      "374 0.00046968174865469337\n",
      "375 0.00045600911835208535\n",
      "376 0.0004418102907948196\n",
      "377 0.00042840218520723283\n",
      "378 0.00041617045644670725\n",
      "379 0.0004022885113954544\n",
      "380 0.00039072285289876163\n",
      "381 0.0003796450619120151\n",
      "382 0.0003684004186652601\n",
      "383 0.00035825936356559396\n",
      "384 0.000347874709405005\n",
      "385 0.00033767143031582236\n",
      "386 0.00032777353771962225\n",
      "387 0.0003186811809428036\n",
      "388 0.0003095779102295637\n",
      "389 0.00030074219102971256\n",
      "390 0.0002925771404989064\n",
      "391 0.00028477847808972\n",
      "392 0.0002767588593997061\n",
      "393 0.00026941223768517375\n",
      "394 0.00026266323402523994\n",
      "395 0.0002555839892011136\n",
      "396 0.00024919724091887474\n",
      "397 0.00024217991449404508\n",
      "398 0.0002357291814405471\n",
      "399 0.00022972399892751127\n",
      "400 0.00022320299467537552\n",
      "401 0.00021784694399684668\n",
      "402 0.00021212741557974368\n",
      "403 0.0002063465362880379\n",
      "404 0.00020168907940387726\n",
      "405 0.0001961248053703457\n",
      "406 0.0001914820313686505\n",
      "407 0.00018643178918864578\n",
      "408 0.00018264651589561254\n",
      "409 0.0001780392340151593\n",
      "410 0.00017381826182827353\n",
      "411 0.00016979247448034585\n",
      "412 0.00016566721023991704\n",
      "413 0.00016210424655582756\n",
      "414 0.00015792566409800202\n",
      "415 0.00015414564404636621\n",
      "416 0.0001510797010269016\n",
      "417 0.00014757215103600174\n",
      "418 0.00014422900858335197\n",
      "419 0.00014113412180449814\n",
      "420 0.0001376414584228769\n",
      "421 0.00013444981595966965\n",
      "422 0.00013172050239518285\n",
      "423 0.00012862762378063053\n",
      "424 0.00012605366646312177\n",
      "425 0.00012359295214992017\n",
      "426 0.00012054649414494634\n",
      "427 0.00011808839917648584\n",
      "428 0.00011537488171597943\n",
      "429 0.0001133506593760103\n",
      "430 0.00011080389958806336\n",
      "431 0.0001082189119188115\n",
      "432 0.00010600227687973529\n",
      "433 0.0001036644825944677\n",
      "434 0.00010155230120290071\n",
      "435 9.941295866155997e-05\n",
      "436 9.78232201305218e-05\n",
      "437 9.567844972480088e-05\n",
      "438 9.40937825362198e-05\n",
      "439 9.203287481795996e-05\n",
      "440 9.041079465532675e-05\n",
      "441 8.855120540829375e-05\n",
      "442 8.681826147949323e-05\n",
      "443 8.519423863617703e-05\n",
      "444 8.376660116482526e-05\n",
      "445 8.225829515140504e-05\n",
      "446 8.053707279032096e-05\n",
      "447 7.920302596176043e-05\n",
      "448 7.778087456244975e-05\n",
      "449 7.627779996255413e-05\n",
      "450 7.487262337235734e-05\n",
      "451 7.380997703876346e-05\n",
      "452 7.250826456584036e-05\n",
      "453 7.131016172934324e-05\n",
      "454 7.01068202033639e-05\n",
      "455 6.906670023454353e-05\n",
      "456 6.782451237086207e-05\n",
      "457 6.685580592602491e-05\n",
      "458 6.580309855053201e-05\n",
      "459 6.4553547417745e-05\n",
      "460 6.348639726638794e-05\n",
      "461 6.219377974048257e-05\n",
      "462 6.146664236439392e-05\n",
      "463 6.0496113292174414e-05\n",
      "464 5.9523274103412405e-05\n",
      "465 5.8621510106604546e-05\n",
      "466 5.7798217312665656e-05\n",
      "467 5.69257463212125e-05\n",
      "468 5.5993856221903116e-05\n",
      "469 5.5350956245092675e-05\n",
      "470 5.414190673036501e-05\n",
      "471 5.341765790944919e-05\n",
      "472 5.2640854846686125e-05\n",
      "473 5.172422606847249e-05\n",
      "474 5.109609992359765e-05\n",
      "475 5.007669824408367e-05\n",
      "476 4.9488910008221865e-05\n",
      "477 4.8964619054459035e-05\n",
      "478 4.817117951461114e-05\n",
      "479 4.7484521928709e-05\n",
      "480 4.692404763773084e-05\n",
      "481 4.630332114174962e-05\n",
      "482 4.557604916044511e-05\n",
      "483 4.495167377172038e-05\n",
      "484 4.425840961630456e-05\n",
      "485 4.3754593207268044e-05\n",
      "486 4.3296739022480324e-05\n",
      "487 4.2597897845553234e-05\n",
      "488 4.2068215407198295e-05\n",
      "489 4.14627866121009e-05\n",
      "490 4.1030656575458124e-05\n",
      "491 4.044385423185304e-05\n",
      "492 4.001330671599135e-05\n",
      "493 3.9285750972339883e-05\n",
      "494 3.878245479427278e-05\n",
      "495 3.830065543297678e-05\n",
      "496 3.778178142965771e-05\n",
      "497 3.723633199115284e-05\n",
      "498 3.674552499433048e-05\n",
      "499 3.628433478297666e-05\n"
     ]
    }
   ],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建一些训练数据\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "w1 = torch.randn(D_in, H, requires_grad=True)   # 模型参数W1需要gradient\n",
    "w2 = torch.randn(H, D_out, requires_grad=True)  # 模型参数W2需要gradient\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    # compute loss\n",
    "    loss = (y_pred - y).pow(2).sum() # computation graph\n",
    "    print(it, loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()                  # 自动求导\n",
    "    \n",
    "    # update weights of w1 and w2\n",
    "    with torch.no_grad():              # 不会把W1和W2的gradients记住,节约内存\n",
    "        w1 -= learning_rate * w1.grad  # 梯度下降\n",
    "        w2 -= learning_rate * w2.grad  # \n",
    "        w1.grad.zero_()                # gradient必须清零, 否则gradient会不断累加\n",
    "        w2.grad.zero_()                # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: nn  \n",
    "\n",
    "这次我们使用PyTorch中nn这个库来构建网络。\n",
    "用PyTorch autograd来构建计算图和计算gradients，\n",
    "然后PyTorch会帮我们自动计算gradient。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 30584082.0\n",
      "1 27407488.0\n",
      "2 27411188.0\n",
      "3 26371430.0\n",
      "4 22369450.0\n",
      "5 16013351.0\n",
      "6 9947126.0\n",
      "7 5671097.0\n",
      "8 3233256.0\n",
      "9 1955288.875\n",
      "10 1294840.5\n",
      "11 934720.375\n",
      "12 721134.125\n",
      "13 581780.5\n",
      "14 482886.8125\n",
      "15 407987.0625\n",
      "16 348679.3125\n",
      "17 300402.1875\n",
      "18 260369.46875\n",
      "19 226770.265625\n",
      "20 198309.1875\n",
      "21 174049.203125\n",
      "22 153255.453125\n",
      "23 135330.75\n",
      "24 119811.8984375\n",
      "25 106337.0859375\n",
      "26 94587.265625\n",
      "27 84326.15625\n",
      "28 75330.28125\n",
      "29 67426.015625\n",
      "30 60455.8203125\n",
      "31 54293.1328125\n",
      "32 48837.6328125\n",
      "33 43995.109375\n",
      "34 39691.5859375\n",
      "35 35856.9765625\n",
      "36 32435.734375\n",
      "37 29382.40234375\n",
      "38 26646.267578125\n",
      "39 24191.486328125\n",
      "40 21987.462890625\n",
      "41 20006.26171875\n",
      "42 18222.091796875\n",
      "43 16612.62890625\n",
      "44 15159.1015625\n",
      "45 13843.458984375\n",
      "46 12652.052734375\n",
      "47 11571.60546875\n",
      "48 10592.5322265625\n",
      "49 9703.494140625\n",
      "50 8894.634765625\n",
      "51 8158.60546875\n",
      "52 7488.68115234375\n",
      "53 6877.5263671875\n",
      "54 6319.71240234375\n",
      "55 5810.2685546875\n",
      "56 5344.748046875\n",
      "57 4919.052734375\n",
      "58 4529.76416015625\n",
      "59 4173.2646484375\n",
      "60 3846.3330078125\n",
      "61 3546.72314453125\n",
      "62 3272.3935546875\n",
      "63 3020.47802734375\n",
      "64 2789.18505859375\n",
      "65 2576.58203125\n",
      "66 2381.097900390625\n",
      "67 2201.299072265625\n",
      "68 2035.878662109375\n",
      "69 1883.5721435546875\n",
      "70 1743.298828125\n",
      "71 1613.99462890625\n",
      "72 1494.7596435546875\n",
      "73 1384.8094482421875\n",
      "74 1283.39404296875\n",
      "75 1189.8055419921875\n",
      "76 1103.36328125\n",
      "77 1023.496826171875\n",
      "78 949.711181640625\n",
      "79 881.50634765625\n",
      "80 818.4429931640625\n",
      "81 760.0912475585938\n",
      "82 706.1004028320312\n",
      "83 656.1364135742188\n",
      "84 609.8796997070312\n",
      "85 567.02490234375\n",
      "86 527.3424072265625\n",
      "87 490.5758056640625\n",
      "88 456.469970703125\n",
      "89 424.8415832519531\n",
      "90 395.49761962890625\n",
      "91 368.2691650390625\n",
      "92 343.002197265625\n",
      "93 319.5307312011719\n",
      "94 297.7478332519531\n",
      "95 277.50732421875\n",
      "96 258.6925354003906\n",
      "97 241.20541381835938\n",
      "98 224.96192932128906\n",
      "99 209.85543823242188\n",
      "100 195.79339599609375\n",
      "101 182.7110137939453\n",
      "102 170.53590393066406\n",
      "103 159.2119140625\n",
      "104 148.6649932861328\n",
      "105 138.83889770507812\n",
      "106 129.6888427734375\n",
      "107 121.16447448730469\n",
      "108 113.22163391113281\n",
      "109 105.81977081298828\n",
      "110 98.92084503173828\n",
      "111 92.49055480957031\n",
      "112 86.48914337158203\n",
      "113 80.88905334472656\n",
      "114 75.66621398925781\n",
      "115 70.79366302490234\n",
      "116 66.24354553222656\n",
      "117 61.995872497558594\n",
      "118 58.029640197753906\n",
      "119 54.32692337036133\n",
      "120 50.86872863769531\n",
      "121 47.639286041259766\n",
      "122 44.61902618408203\n",
      "123 41.7987060546875\n",
      "124 39.160465240478516\n",
      "125 36.69538879394531\n",
      "126 34.3892936706543\n",
      "127 32.23652648925781\n",
      "128 30.219242095947266\n",
      "129 28.333263397216797\n",
      "130 26.56890296936035\n",
      "131 24.916208267211914\n",
      "132 23.370136260986328\n",
      "133 21.92321014404297\n",
      "134 20.567943572998047\n",
      "135 19.30028533935547\n",
      "136 18.111648559570312\n",
      "137 16.999147415161133\n",
      "138 15.957202911376953\n",
      "139 14.980405807495117\n",
      "140 14.06509017944336\n",
      "141 13.207941055297852\n",
      "142 12.403493881225586\n",
      "143 11.6498384475708\n",
      "144 10.942953109741211\n",
      "145 10.281211853027344\n",
      "146 9.659847259521484\n",
      "147 9.077080726623535\n",
      "148 8.530643463134766\n",
      "149 8.01773738861084\n",
      "150 7.536869525909424\n",
      "151 7.0846967697143555\n",
      "152 6.661084175109863\n",
      "153 6.263556480407715\n",
      "154 5.890081405639648\n",
      "155 5.539330959320068\n",
      "156 5.209921836853027\n",
      "157 4.900886535644531\n",
      "158 4.610630512237549\n",
      "159 4.3379225730896\n",
      "160 4.081780433654785\n",
      "161 3.8408708572387695\n",
      "162 3.614790439605713\n",
      "163 3.402160167694092\n",
      "164 3.202241897583008\n",
      "165 3.014450788497925\n",
      "166 2.838029384613037\n",
      "167 2.6721479892730713\n",
      "168 2.516273021697998\n",
      "169 2.3696751594543457\n",
      "170 2.231524705886841\n",
      "171 2.1020710468292236\n",
      "172 1.9800379276275635\n",
      "173 1.8651621341705322\n",
      "174 1.7571628093719482\n",
      "175 1.6554973125457764\n",
      "176 1.559861421585083\n",
      "177 1.470018744468689\n",
      "178 1.38541841506958\n",
      "179 1.3057382106781006\n",
      "180 1.2307425737380981\n",
      "181 1.1601002216339111\n",
      "182 1.0935509204864502\n",
      "183 1.0310053825378418\n",
      "184 0.9721009135246277\n",
      "185 0.9165968894958496\n",
      "186 0.8643227815628052\n",
      "187 0.8150125741958618\n",
      "188 0.7686717510223389\n",
      "189 0.7250284552574158\n",
      "190 0.6839218139648438\n",
      "191 0.6451250314712524\n",
      "192 0.6086008548736572\n",
      "193 0.5742324590682983\n",
      "194 0.5417230129241943\n",
      "195 0.5111801624298096\n",
      "196 0.4823407530784607\n",
      "197 0.4552287459373474\n",
      "198 0.4296330213546753\n",
      "199 0.4054658114910126\n",
      "200 0.38270270824432373\n",
      "201 0.3612978160381317\n",
      "202 0.3409996032714844\n",
      "203 0.3219517767429352\n",
      "204 0.30396050214767456\n",
      "205 0.28693389892578125\n",
      "206 0.2709866166114807\n",
      "207 0.25584912300109863\n",
      "208 0.241620734333992\n",
      "209 0.2281821072101593\n",
      "210 0.2154628336429596\n",
      "211 0.20354655385017395\n",
      "212 0.19226568937301636\n",
      "213 0.18167051672935486\n",
      "214 0.17159181833267212\n",
      "215 0.1621204912662506\n",
      "216 0.15317793190479279\n",
      "217 0.14471924304962158\n",
      "218 0.13674117624759674\n",
      "219 0.12920786440372467\n",
      "220 0.12212280184030533\n",
      "221 0.11541877686977386\n",
      "222 0.10904639959335327\n",
      "223 0.10306184738874435\n",
      "224 0.09744087606668472\n",
      "225 0.09210985153913498\n",
      "226 0.08705650269985199\n",
      "227 0.08230771869421005\n",
      "228 0.07781245559453964\n",
      "229 0.07358063012361526\n",
      "230 0.06955263018608093\n",
      "231 0.06576618552207947\n",
      "232 0.06217624619603157\n",
      "233 0.058796174824237823\n",
      "234 0.055613938719034195\n",
      "235 0.05257752537727356\n",
      "236 0.04973876103758812\n",
      "237 0.047043658792972565\n",
      "238 0.04449078068137169\n",
      "239 0.04208582639694214\n",
      "240 0.039812907576560974\n",
      "241 0.03766826540231705\n",
      "242 0.03563384711742401\n",
      "243 0.033718355000019073\n",
      "244 0.03190285339951515\n",
      "245 0.030176356434822083\n",
      "246 0.028558984398841858\n",
      "247 0.027029410004615784\n",
      "248 0.025587471202015877\n",
      "249 0.024202533066272736\n",
      "250 0.022916458547115326\n",
      "251 0.021692102774977684\n",
      "252 0.020534003153443336\n",
      "253 0.01944960653781891\n",
      "254 0.018414724618196487\n",
      "255 0.017432348802685738\n",
      "256 0.016507025808095932\n",
      "257 0.01563292369246483\n",
      "258 0.014809060841798782\n",
      "259 0.014028964564204216\n",
      "260 0.013292290270328522\n",
      "261 0.012594064697623253\n",
      "262 0.01193320658057928\n",
      "263 0.011311561800539494\n",
      "264 0.01072445698082447\n",
      "265 0.010167399421334267\n",
      "266 0.009633999317884445\n",
      "267 0.00913592055439949\n",
      "268 0.008664770051836967\n",
      "269 0.008213143795728683\n",
      "270 0.0077911680564284325\n",
      "271 0.0073958332650363445\n",
      "272 0.0070199002511799335\n",
      "273 0.006659906357526779\n",
      "274 0.006322847213596106\n",
      "275 0.005997224245220423\n",
      "276 0.005694531835615635\n",
      "277 0.00541001558303833\n",
      "278 0.005140399094671011\n",
      "279 0.004882270935922861\n",
      "280 0.0046446663327515125\n",
      "281 0.004412462003529072\n",
      "282 0.0041983360424637794\n",
      "283 0.003995279315859079\n",
      "284 0.0037972466088831425\n",
      "285 0.0036129746586084366\n",
      "286 0.003438816871494055\n",
      "287 0.003272496396675706\n",
      "288 0.0031148609705269337\n",
      "289 0.0029694042168557644\n",
      "290 0.0028233991470187902\n",
      "291 0.0026930090971291065\n",
      "292 0.0025675715878605843\n",
      "293 0.00244783703237772\n",
      "294 0.002334203803911805\n",
      "295 0.002229241654276848\n",
      "296 0.0021282965317368507\n",
      "297 0.0020292175468057394\n",
      "298 0.0019416542490944266\n",
      "299 0.001853371737524867\n",
      "300 0.0017711821710690856\n",
      "301 0.0016936272149905562\n",
      "302 0.0016188628505915403\n",
      "303 0.0015496157575398684\n",
      "304 0.0014818995259702206\n",
      "305 0.0014201204758137465\n",
      "306 0.0013601232785731554\n",
      "307 0.0013040904887020588\n",
      "308 0.0012487138155847788\n",
      "309 0.0011955935042351484\n",
      "310 0.0011460840469226241\n",
      "311 0.0010993333999067545\n",
      "312 0.0010552271269261837\n",
      "313 0.001014425652101636\n",
      "314 0.0009732886683195829\n",
      "315 0.000934229523409158\n",
      "316 0.0008981864084489644\n",
      "317 0.0008640856249257922\n",
      "318 0.0008307809475809336\n",
      "319 0.0007995743653737009\n",
      "320 0.0007693451480008662\n",
      "321 0.0007410842226818204\n",
      "322 0.0007118051289580762\n",
      "323 0.00068610196467489\n",
      "324 0.0006611462449654937\n",
      "325 0.0006357367965392768\n",
      "326 0.0006139230681583285\n",
      "327 0.0005930857150815427\n",
      "328 0.000572503253351897\n",
      "329 0.0005529064801521599\n",
      "330 0.0005332138389348984\n",
      "331 0.0005150311626493931\n",
      "332 0.0004976377822458744\n",
      "333 0.0004797996662091464\n",
      "334 0.0004643768770620227\n",
      "335 0.000449534272775054\n",
      "336 0.0004326881899032742\n",
      "337 0.000420338474214077\n",
      "338 0.0004068560665473342\n",
      "339 0.0003942431940231472\n",
      "340 0.0003822057042270899\n",
      "341 0.0003697702195495367\n",
      "342 0.0003577380266506225\n",
      "343 0.00034727551974356174\n",
      "344 0.00033700434141792357\n",
      "345 0.00032640976132825017\n",
      "346 0.0003168222610838711\n",
      "347 0.0003078986774198711\n",
      "348 0.0002982046571560204\n",
      "349 0.00028957947506569326\n",
      "350 0.00028287037275731564\n",
      "351 0.0002751594583969563\n",
      "352 0.00026725270436145365\n",
      "353 0.0002587165799923241\n",
      "354 0.00025206469581462443\n",
      "355 0.0002444931014906615\n",
      "356 0.0002376981865381822\n",
      "357 0.00023128501197788864\n",
      "358 0.00022500980412587523\n",
      "359 0.0002198539732489735\n",
      "360 0.00021309293515514582\n",
      "361 0.0002077389508485794\n",
      "362 0.0002025187131948769\n",
      "363 0.00019722459546756\n",
      "364 0.0001924082898767665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 0.0001878506736829877\n",
      "366 0.00018308285507373512\n",
      "367 0.00017855956684798002\n",
      "368 0.0001748212380334735\n",
      "369 0.00017010618466883898\n",
      "370 0.00016587047139182687\n",
      "371 0.00016235324437730014\n",
      "372 0.0001590313040651381\n",
      "373 0.0001551359164295718\n",
      "374 0.00015127583174034953\n",
      "375 0.00014766555977985263\n",
      "376 0.0001444069785065949\n",
      "377 0.00014071290206629783\n",
      "378 0.00013767943892162293\n",
      "379 0.00013477879110723734\n",
      "380 0.0001322646567132324\n",
      "381 0.00012937886640429497\n",
      "382 0.00012646598042920232\n",
      "383 0.0001234419905813411\n",
      "384 0.00012085858907084912\n",
      "385 0.00011868035653606057\n",
      "386 0.00011608334898483008\n",
      "387 0.00011425316915847361\n",
      "388 0.00011180944420630112\n",
      "389 0.00010900234337896109\n",
      "390 0.00010676450619939715\n",
      "391 0.00010481813660589978\n",
      "392 0.00010279849084326997\n",
      "393 0.0001007954851957038\n",
      "394 9.859858255367726e-05\n",
      "395 9.672382293501869e-05\n",
      "396 9.456236875848845e-05\n",
      "397 9.289037552662194e-05\n",
      "398 9.047762432601303e-05\n",
      "399 8.896305371308699e-05\n",
      "400 8.69113500812091e-05\n",
      "401 8.499843534082174e-05\n",
      "402 8.416582568315789e-05\n",
      "403 8.260088361566886e-05\n",
      "404 8.111110946629196e-05\n",
      "405 7.962682866491377e-05\n",
      "406 7.81249109422788e-05\n",
      "407 7.705077587161213e-05\n",
      "408 7.56330118747428e-05\n",
      "409 7.417588494718075e-05\n",
      "410 7.286276377271861e-05\n",
      "411 7.18147712177597e-05\n",
      "412 7.038994954200462e-05\n",
      "413 6.929489609319717e-05\n",
      "414 6.816817040089518e-05\n",
      "415 6.726069113938138e-05\n",
      "416 6.615257007069886e-05\n",
      "417 6.517925066873431e-05\n",
      "418 6.418320117518306e-05\n",
      "419 6.288731674430892e-05\n",
      "420 6.220088835107163e-05\n",
      "421 6.136052979854867e-05\n",
      "422 6.0293801652733237e-05\n",
      "423 5.9407317166915163e-05\n",
      "424 5.849522858625278e-05\n",
      "425 5.755021993536502e-05\n",
      "426 5.647800207952969e-05\n",
      "427 5.590444925474003e-05\n",
      "428 5.5085689382394776e-05\n",
      "429 5.434137710835785e-05\n",
      "430 5.329132545739412e-05\n",
      "431 5.235806020209566e-05\n",
      "432 5.16739055456128e-05\n",
      "433 5.079736729385331e-05\n",
      "434 5.020293974666856e-05\n",
      "435 4.9549729737918824e-05\n",
      "436 4.891055141342804e-05\n",
      "437 4.796368375536986e-05\n",
      "438 4.7369583626277745e-05\n",
      "439 4.666012682719156e-05\n",
      "440 4.6100067265797406e-05\n",
      "441 4.5438991946866736e-05\n",
      "442 4.485474346438423e-05\n",
      "443 4.436207382241264e-05\n",
      "444 4.373557021608576e-05\n",
      "445 4.336352867539972e-05\n",
      "446 4.294609243515879e-05\n",
      "447 4.226677629048936e-05\n",
      "448 4.182406701147556e-05\n",
      "449 4.1134357161354274e-05\n",
      "450 4.078991696587764e-05\n",
      "451 4.011646888102405e-05\n",
      "452 3.957869193982333e-05\n",
      "453 3.902228127117269e-05\n",
      "454 3.8570535252802074e-05\n",
      "455 3.828632543445565e-05\n",
      "456 3.7742112908745185e-05\n",
      "457 3.7257574149407446e-05\n",
      "458 3.685228148242459e-05\n",
      "459 3.6441750125959516e-05\n",
      "460 3.5909906728193164e-05\n",
      "461 3.563061181921512e-05\n",
      "462 3.5062232200289145e-05\n",
      "463 3.4647309803403914e-05\n",
      "464 3.447263588896021e-05\n",
      "465 3.411746729398146e-05\n",
      "466 3.384249430382624e-05\n",
      "467 3.348249811097048e-05\n",
      "468 3.319154347991571e-05\n",
      "469 3.285970160504803e-05\n",
      "470 3.252788883401081e-05\n",
      "471 3.206237670383416e-05\n",
      "472 3.176267637172714e-05\n",
      "473 3.1315008527599275e-05\n",
      "474 3.094971543760039e-05\n",
      "475 3.049528277188074e-05\n",
      "476 3.0186529329512268e-05\n",
      "477 2.9865474061807618e-05\n",
      "478 2.9551174520747736e-05\n",
      "479 2.9378014005487785e-05\n",
      "480 2.906539521063678e-05\n",
      "481 2.8669364837696776e-05\n",
      "482 2.8377920898492448e-05\n",
      "483 2.816963205987122e-05\n",
      "484 2.7859932743012905e-05\n",
      "485 2.756196408881806e-05\n",
      "486 2.7342324756318703e-05\n",
      "487 2.706547820707783e-05\n",
      "488 2.6883128157351166e-05\n",
      "489 2.6738103770185262e-05\n",
      "490 2.641517494339496e-05\n",
      "491 2.6030840672319755e-05\n",
      "492 2.5709243345772848e-05\n",
      "493 2.549502460169606e-05\n",
      "494 2.5204273697454482e-05\n",
      "495 2.4851413400028832e-05\n",
      "496 2.4467528419336304e-05\n",
      "497 2.429868618492037e-05\n",
      "498 2.429037522233557e-05\n",
      "499 2.3968979803612456e-05\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建一些训练数据\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# 定义一个model,包含一系列层(线性层==>非线性层==>线性层)\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H, bias=False),  # w_1 * x + b_1\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out, bias=False),\n",
    ")\n",
    "\n",
    "# 初始化第一和第三层的权重为标准正态分布\n",
    "torch.nn.init.normal_(model[0].weight)\n",
    "torch.nn.init.normal_(model[2].weight)\n",
    "\n",
    "# 在CUDA上操作\n",
    "# model = model.cuda()\n",
    "\n",
    "# 定义loss function\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    y_pred = model(x) # model.forward() \n",
    "    \n",
    "    # compute loss\n",
    "    loss = loss_fn(y_pred, y) # computation graph\n",
    "    print(it, loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update weights of w1 and w2\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():          # param (tensor, grad)\n",
    "            param -= learning_rate * param.grad   # 更新每个parameter的gradient\n",
    "            \n",
    "    model.zero_grad()    # 在下一次做backward之前, 要把model中所有的gradients清零"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4157,  0.5799,  0.8094,  ...,  0.7169, -0.1234,  0.0714],\n",
       "        [ 0.3616,  0.3003, -0.7448,  ...,  1.7456,  0.4496,  1.4171],\n",
       "        [ 0.5597,  0.5766, -0.1384,  ..., -0.7784,  0.2010, -0.4795],\n",
       "        ...,\n",
       "        [ 0.7863,  1.4226,  0.0921,  ..., -0.7318,  0.4703, -1.4407],\n",
       "        [-1.2247,  0.7996,  0.3422,  ...,  1.0790, -0.7005, -1.3105],\n",
       "        [ 0.6267, -0.2989, -1.8842,  ..., -0.2625,  0.9338, -1.2195]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拿到model中第一层的权重值\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: optim\n",
    "\n",
    "这一次我们不再手动更新模型的weights,而是使用optim这个包来帮助我们更新参数。\n",
    "optim这个package提供了各种不同的模型优化方法，包括SGD+momentum, RMSProp, Adam等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 25701622.0\n",
      "1 19079542.0\n",
      "2 16068579.0\n",
      "3 14051148.0\n",
      "4 12072919.0\n",
      "5 9941292.0\n",
      "6 7767226.0\n",
      "7 5804557.5\n",
      "8 4201435.0\n",
      "9 2997906.0\n",
      "10 2139265.0\n",
      "11 1546468.125\n",
      "12 1141855.875\n",
      "13 865508.25\n",
      "14 674153.5\n",
      "15 538986.375\n",
      "16 440507.375\n",
      "17 366907.28125\n",
      "18 310321.09375\n",
      "19 265740.375\n",
      "20 229801.53125\n",
      "21 200220.109375\n",
      "22 175543.28125\n",
      "23 154712.125\n",
      "24 136921.203125\n",
      "25 121619.90625\n",
      "26 108366.5625\n",
      "27 96822.8984375\n",
      "28 86730.4609375\n",
      "29 77876.015625\n",
      "30 70082.109375\n",
      "31 63193.2265625\n",
      "32 57075.359375\n",
      "33 51639.19921875\n",
      "34 46800.8203125\n",
      "35 42481.48046875\n",
      "36 38616.953125\n",
      "37 35158.9609375\n",
      "38 32057.267578125\n",
      "39 29273.125\n",
      "40 26763.650390625\n",
      "41 24498.216796875\n",
      "42 22449.0390625\n",
      "43 20593.20703125\n",
      "44 18911.91796875\n",
      "45 17385.615234375\n",
      "46 15998.322265625\n",
      "47 14736.3427734375\n",
      "48 13585.8681640625\n",
      "49 12536.798828125\n",
      "50 11579.095703125\n",
      "51 10702.66796875\n",
      "52 9900.484375\n",
      "53 9166.28125\n",
      "54 8492.826171875\n",
      "55 7874.24658203125\n",
      "56 7305.67138671875\n",
      "57 6782.3173828125\n",
      "58 6300.42822265625\n",
      "59 5856.1904296875\n",
      "60 5446.380859375\n",
      "61 5068.076171875\n",
      "62 4718.35546875\n",
      "63 4394.958984375\n",
      "64 4095.814453125\n",
      "65 3818.729736328125\n",
      "66 3562.004638671875\n",
      "67 3324.009033203125\n",
      "68 3103.255859375\n",
      "69 2898.376708984375\n",
      "70 2708.15283203125\n",
      "71 2531.342529296875\n",
      "72 2366.998046875\n",
      "73 2214.12841796875\n",
      "74 2071.85693359375\n",
      "75 1939.4033203125\n",
      "76 1816.0616455078125\n",
      "77 1701.122314453125\n",
      "78 1593.944580078125\n",
      "79 1494.054443359375\n",
      "80 1400.8856201171875\n",
      "81 1313.877197265625\n",
      "82 1232.5880126953125\n",
      "83 1156.658935546875\n",
      "84 1085.71484375\n",
      "85 1019.3853149414062\n",
      "86 957.358642578125\n",
      "87 899.3551635742188\n",
      "88 845.079345703125\n",
      "89 794.25634765625\n",
      "90 746.6972045898438\n",
      "91 702.1213989257812\n",
      "92 660.3516845703125\n",
      "93 621.2059936523438\n",
      "94 584.5082397460938\n",
      "95 550.10205078125\n",
      "96 517.8291015625\n",
      "97 487.5485534667969\n",
      "98 459.15350341796875\n",
      "99 432.49591064453125\n",
      "100 407.46142578125\n",
      "101 383.9328918457031\n",
      "102 361.8302307128906\n",
      "103 341.0525817871094\n",
      "104 321.5272216796875\n",
      "105 303.17291259765625\n",
      "106 285.91314697265625\n",
      "107 269.6834411621094\n",
      "108 254.41436767578125\n",
      "109 240.0587158203125\n",
      "110 226.53927612304688\n",
      "111 213.81219482421875\n",
      "112 201.8317413330078\n",
      "113 190.55245971679688\n",
      "114 179.93338012695312\n",
      "115 169.92578125\n",
      "116 160.49868774414062\n",
      "117 151.620361328125\n",
      "118 143.25367736816406\n",
      "119 135.36778259277344\n",
      "120 127.92606353759766\n",
      "121 120.90808868408203\n",
      "122 114.28977966308594\n",
      "123 108.04935455322266\n",
      "124 102.1602554321289\n",
      "125 96.6052474975586\n",
      "126 91.36439514160156\n",
      "127 86.41732788085938\n",
      "128 81.74848937988281\n",
      "129 77.3388671875\n",
      "130 73.17501831054688\n",
      "131 69.24169158935547\n",
      "132 65.52799987792969\n",
      "133 62.020118713378906\n",
      "134 58.70671844482422\n",
      "135 55.577457427978516\n",
      "136 52.61960220336914\n",
      "137 49.82372283935547\n",
      "138 47.18061447143555\n",
      "139 44.68105697631836\n",
      "140 42.31840515136719\n",
      "141 40.08635711669922\n",
      "142 37.974849700927734\n",
      "143 35.98008346557617\n",
      "144 34.08928680419922\n",
      "145 32.30190658569336\n",
      "146 30.610559463500977\n",
      "147 29.012920379638672\n",
      "148 27.507722854614258\n",
      "149 26.082544326782227\n",
      "150 24.73391342163086\n",
      "151 23.458314895629883\n",
      "152 22.249624252319336\n",
      "153 21.105932235717773\n",
      "154 20.021800994873047\n",
      "155 18.995136260986328\n",
      "156 18.021987915039062\n",
      "157 17.099924087524414\n",
      "158 16.228036880493164\n",
      "159 15.401350975036621\n",
      "160 14.617507934570312\n",
      "161 13.875114440917969\n",
      "162 13.170828819274902\n",
      "163 12.503700256347656\n",
      "164 11.87097454071045\n",
      "165 11.271875381469727\n",
      "166 10.70322036743164\n",
      "167 10.163886070251465\n",
      "168 9.65308666229248\n",
      "169 9.16804313659668\n",
      "170 8.708011627197266\n",
      "171 8.271966934204102\n",
      "172 7.858051776885986\n",
      "173 7.4656476974487305\n",
      "174 7.093413352966309\n",
      "175 6.739631175994873\n",
      "176 6.404818534851074\n",
      "177 6.086394786834717\n",
      "178 5.784363746643066\n",
      "179 5.497523784637451\n",
      "180 5.225332260131836\n",
      "181 4.967175483703613\n",
      "182 4.721896171569824\n",
      "183 4.488709926605225\n",
      "184 4.267472743988037\n",
      "185 4.057602405548096\n",
      "186 3.8582701683044434\n",
      "187 3.669203996658325\n",
      "188 3.489950180053711\n",
      "189 3.3194658756256104\n",
      "190 3.15735125541687\n",
      "191 3.0032544136047363\n",
      "192 2.8569414615631104\n",
      "193 2.7178354263305664\n",
      "194 2.5857136249542236\n",
      "195 2.4602341651916504\n",
      "196 2.3407421112060547\n",
      "197 2.2274017333984375\n",
      "198 2.1194746494293213\n",
      "199 2.0168495178222656\n",
      "200 1.9196094274520874\n",
      "201 1.8269312381744385\n",
      "202 1.7391753196716309\n",
      "203 1.6551387310028076\n",
      "204 1.57549250125885\n",
      "205 1.4997491836547852\n",
      "206 1.4276561737060547\n",
      "207 1.3591530323028564\n",
      "208 1.2940616607666016\n",
      "209 1.2320574522018433\n",
      "210 1.1732059717178345\n",
      "211 1.1170027256011963\n",
      "212 1.063759446144104\n",
      "213 1.01288640499115\n",
      "214 0.9646851420402527\n",
      "215 0.918795645236969\n",
      "216 0.8749939799308777\n",
      "217 0.833383321762085\n",
      "218 0.7937614321708679\n",
      "219 0.756070613861084\n",
      "220 0.7202405333518982\n",
      "221 0.6861412525177002\n",
      "222 0.6536092162132263\n",
      "223 0.6227185130119324\n",
      "224 0.5932962894439697\n",
      "225 0.565228283405304\n",
      "226 0.5385526418685913\n",
      "227 0.5131843686103821\n",
      "228 0.4889836609363556\n",
      "229 0.4659116566181183\n",
      "230 0.4439918100833893\n",
      "231 0.4231678545475006\n",
      "232 0.4032254219055176\n",
      "233 0.3843012750148773\n",
      "234 0.3663586676120758\n",
      "235 0.3491222858428955\n",
      "236 0.3328532576560974\n",
      "237 0.317218154668808\n",
      "238 0.3023154139518738\n",
      "239 0.2882469892501831\n",
      "240 0.27478209137916565\n",
      "241 0.2619096338748932\n",
      "242 0.24973876774311066\n",
      "243 0.23808681964874268\n",
      "244 0.2269739806652069\n",
      "245 0.21642988920211792\n",
      "246 0.20631805062294006\n",
      "247 0.19674783945083618\n",
      "248 0.18766137957572937\n",
      "249 0.17895568907260895\n",
      "250 0.17062725126743317\n",
      "251 0.16274192929267883\n",
      "252 0.15518978238105774\n",
      "253 0.14801110327243805\n",
      "254 0.14115454256534576\n",
      "255 0.13462688028812408\n",
      "256 0.12842431664466858\n",
      "257 0.12248110771179199\n",
      "258 0.1168556734919548\n",
      "259 0.11145429313182831\n",
      "260 0.10630813241004944\n",
      "261 0.1014448031783104\n",
      "262 0.09679515659809113\n",
      "263 0.09233467280864716\n",
      "264 0.08807680010795593\n",
      "265 0.0840587243437767\n",
      "266 0.08017268031835556\n",
      "267 0.07648511230945587\n",
      "268 0.07297414541244507\n",
      "269 0.06967291235923767\n",
      "270 0.06648857891559601\n",
      "271 0.0634421557188034\n",
      "272 0.0605449303984642\n",
      "273 0.0577583871781826\n",
      "274 0.055148180574178696\n",
      "275 0.05260154977440834\n",
      "276 0.05021773278713226\n",
      "277 0.04792457073926926\n",
      "278 0.04575371742248535\n",
      "279 0.043676238507032394\n",
      "280 0.0416729710996151\n",
      "281 0.03978333622217178\n",
      "282 0.03799809142947197\n",
      "283 0.03627271205186844\n",
      "284 0.03463798388838768\n",
      "285 0.03306331858038902\n",
      "286 0.03157060965895653\n",
      "287 0.030144568532705307\n",
      "288 0.028783338144421577\n",
      "289 0.027479536831378937\n",
      "290 0.02625424973666668\n",
      "291 0.02506233938038349\n",
      "292 0.023927001282572746\n",
      "293 0.022854866459965706\n",
      "294 0.021816501393914223\n",
      "295 0.020845362916588783\n",
      "296 0.019903631880879402\n",
      "297 0.019018718972802162\n",
      "298 0.018169144168496132\n",
      "299 0.017355792224407196\n",
      "300 0.01658010110259056\n",
      "301 0.0158441923558712\n",
      "302 0.015131013467907906\n",
      "303 0.014459018595516682\n",
      "304 0.01382212433964014\n",
      "305 0.013215151615440845\n",
      "306 0.012627137824892998\n",
      "307 0.012071085162460804\n",
      "308 0.01154298335313797\n",
      "309 0.011035515926778316\n",
      "310 0.010551548562943935\n",
      "311 0.010094273835420609\n",
      "312 0.009648476727306843\n",
      "313 0.009230493567883968\n",
      "314 0.008826025761663914\n",
      "315 0.008444424718618393\n",
      "316 0.008081034757196903\n",
      "317 0.0077305324375629425\n",
      "318 0.007401452399790287\n",
      "319 0.007078395690768957\n",
      "320 0.006770770065486431\n",
      "321 0.006479344330728054\n",
      "322 0.006206473335623741\n",
      "323 0.005942661315202713\n",
      "324 0.005688530392944813\n",
      "325 0.005451334174722433\n",
      "326 0.005219556391239166\n",
      "327 0.0050004469230771065\n",
      "328 0.004788409452885389\n",
      "329 0.004587059840559959\n",
      "330 0.004398562014102936\n",
      "331 0.0042135757394135\n",
      "332 0.004042319022119045\n",
      "333 0.0038791976403445005\n",
      "334 0.003718402236700058\n",
      "335 0.0035668632481247187\n",
      "336 0.0034233066253364086\n",
      "337 0.003283842233940959\n",
      "338 0.003150488482788205\n",
      "339 0.003023541299626231\n",
      "340 0.0028982614167034626\n",
      "341 0.002787979319691658\n",
      "342 0.0026736739091575146\n",
      "343 0.0025697187520563602\n",
      "344 0.002467419020831585\n",
      "345 0.0023726208601146936\n",
      "346 0.0022787977941334248\n",
      "347 0.002192160114645958\n",
      "348 0.0021082886960357428\n",
      "349 0.002028333256021142\n",
      "350 0.001955184619873762\n",
      "351 0.001879752380773425\n",
      "352 0.001810681540518999\n",
      "353 0.0017428426072001457\n",
      "354 0.0016794810071587563\n",
      "355 0.0016161845996975899\n",
      "356 0.0015571340918540955\n",
      "357 0.0015020682476460934\n",
      "358 0.0014469659654423594\n",
      "359 0.0013953393790870905\n",
      "360 0.0013429962564259768\n",
      "361 0.0012967174407094717\n",
      "362 0.001250994042493403\n",
      "363 0.001208924106322229\n",
      "364 0.001168818329460919\n",
      "365 0.0011271375697106123\n",
      "366 0.0010894836159422994\n",
      "367 0.0010514622554183006\n",
      "368 0.001017021364532411\n",
      "369 0.0009825873421505094\n",
      "370 0.0009528053924441338\n",
      "371 0.0009195574093610048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372 0.0008906740695238113\n",
      "373 0.000860811211168766\n",
      "374 0.0008342242217622697\n",
      "375 0.000808666693046689\n",
      "376 0.0007823614869266748\n",
      "377 0.0007579271332360804\n",
      "378 0.0007335823611356318\n",
      "379 0.0007114170002751052\n",
      "380 0.0006893493700772524\n",
      "381 0.0006672799936495721\n",
      "382 0.0006469915388152003\n",
      "383 0.0006274401093833148\n",
      "384 0.0006093415431678295\n",
      "385 0.0005897798691876233\n",
      "386 0.0005732934223487973\n",
      "387 0.0005575974937528372\n",
      "388 0.0005410705343820155\n",
      "389 0.0005251782131381333\n",
      "390 0.0005095519009046257\n",
      "391 0.0004958304343745112\n",
      "392 0.0004805728094652295\n",
      "393 0.00046700192615389824\n",
      "394 0.00045495288213714957\n",
      "395 0.0004424403887242079\n",
      "396 0.0004310978692956269\n",
      "397 0.00041862763464450836\n",
      "398 0.00040753581561148167\n",
      "399 0.00039663855568505824\n",
      "400 0.0003858022391796112\n",
      "401 0.0003751878102775663\n",
      "402 0.0003657260676845908\n",
      "403 0.00035614476655609906\n",
      "404 0.0003474010736681521\n",
      "405 0.0003383298171684146\n",
      "406 0.0003288863517809659\n",
      "407 0.00032129453029483557\n",
      "408 0.00031325648888014257\n",
      "409 0.0003063096955884248\n",
      "410 0.00029821929638274014\n",
      "411 0.0002910414768848568\n",
      "412 0.0002840538800228387\n",
      "413 0.0002769209095276892\n",
      "414 0.00027006532764062285\n",
      "415 0.00026393518783152103\n",
      "416 0.00025797635316848755\n",
      "417 0.0002520294801797718\n",
      "418 0.000246036215685308\n",
      "419 0.00024105243210215122\n",
      "420 0.00023520343529526144\n",
      "421 0.0002299907646374777\n",
      "422 0.0002247816591989249\n",
      "423 0.00022044405341148376\n",
      "424 0.0002146563056157902\n",
      "425 0.00020994314400013536\n",
      "426 0.00020549827604554594\n",
      "427 0.00020129488257225603\n",
      "428 0.00019684988365042955\n",
      "429 0.00019235156651120633\n",
      "430 0.00018935361003968865\n",
      "431 0.0001857425959315151\n",
      "432 0.00018165538494940847\n",
      "433 0.00017790419224184006\n",
      "434 0.00017394268070347607\n",
      "435 0.00017064718122128397\n",
      "436 0.0001675605890341103\n",
      "437 0.00016387342475354671\n",
      "438 0.0001599796232767403\n",
      "439 0.0001567582949064672\n",
      "440 0.00015410021296702325\n",
      "441 0.00015053643437568098\n",
      "442 0.0001480940409237519\n",
      "443 0.00014536753587890416\n",
      "444 0.0001424055953975767\n",
      "445 0.00013950055290479213\n",
      "446 0.0001373133563902229\n",
      "447 0.00013479565677698702\n",
      "448 0.00013223561109043658\n",
      "449 0.00012970577517990023\n",
      "450 0.00012768439773935825\n",
      "451 0.00012500771845225245\n",
      "452 0.0001229273620992899\n",
      "453 0.00012124703061999753\n",
      "454 0.00011921761324629188\n",
      "455 0.00011666843056445941\n",
      "456 0.00011458263907115906\n",
      "457 0.0001125681956182234\n",
      "458 0.00011105417070211843\n",
      "459 0.00010886452218983322\n",
      "460 0.00010699374251998961\n",
      "461 0.00010541714436840266\n",
      "462 0.0001038719856296666\n",
      "463 0.00010223162826150656\n",
      "464 0.00010020144691225141\n",
      "465 9.852253424469382e-05\n",
      "466 9.67895975918509e-05\n",
      "467 9.547011723043397e-05\n",
      "468 9.386364399688318e-05\n",
      "469 9.280430822400376e-05\n",
      "470 9.141195914708078e-05\n",
      "471 8.989343041321263e-05\n",
      "472 8.814226021058857e-05\n",
      "473 8.671649266034365e-05\n",
      "474 8.554755913792178e-05\n",
      "475 8.41834262246266e-05\n",
      "476 8.309746044687927e-05\n",
      "477 8.17457985249348e-05\n",
      "478 8.042764966376126e-05\n",
      "479 7.927282422315329e-05\n",
      "480 7.830543472664431e-05\n",
      "481 7.700280548306182e-05\n",
      "482 7.621718395967036e-05\n",
      "483 7.523325621150434e-05\n",
      "484 7.403987547149882e-05\n",
      "485 7.312516390811652e-05\n",
      "486 7.180662214523181e-05\n",
      "487 7.106662087608129e-05\n",
      "488 6.997273158049211e-05\n",
      "489 6.887676136102527e-05\n",
      "490 6.798060348955914e-05\n",
      "491 6.723219848936424e-05\n",
      "492 6.625609967159107e-05\n",
      "493 6.528507947223261e-05\n",
      "494 6.409008346963674e-05\n",
      "495 6.345602741930634e-05\n",
      "496 6.258804205572233e-05\n",
      "497 6.165751983644441e-05\n",
      "498 6.084525739424862e-05\n",
      "499 5.993224840494804e-05\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建一些训练数据\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H, bias=False), # w_1 * x + b_1\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out, bias=False),\n",
    ")\n",
    "\n",
    "torch.nn.init.normal_(model[0].weight)\n",
    "torch.nn.init.normal_(model[2].weight)\n",
    "\n",
    "# model = model.cuda()\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "# learning_rate = 1e-4\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "# 定义优化器,参数必须是model的parameters\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    y_pred = model(x) # model.forward() \n",
    "    \n",
    "    # compute loss\n",
    "    loss = loss_fn(y_pred, y) # computation graph\n",
    "    print(it, loss.item())\n",
    "\n",
    "    optimizer.zero_grad()     # 求导(backward)之前需要清零优化器\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update model parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: 自定义 nn Modules  \n",
    "\n",
    "我们可以定义一个模型，这个模型继承自nn.Module类。如果需要定义一个比Sequential模型更加复杂的模型，就需要定义nn.Module模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 612.8851928710938\n",
      "1 596.4942626953125\n",
      "2 580.6094360351562\n",
      "3 565.1251220703125\n",
      "4 550.0615234375\n",
      "5 535.4725341796875\n",
      "6 521.3463745117188\n",
      "7 507.6250915527344\n",
      "8 494.3796081542969\n",
      "9 481.5726318359375\n",
      "10 469.1031188964844\n",
      "11 457.09967041015625\n",
      "12 445.44354248046875\n",
      "13 434.09368896484375\n",
      "14 423.11212158203125\n",
      "15 412.403076171875\n",
      "16 401.92144775390625\n",
      "17 391.70135498046875\n",
      "18 381.7684326171875\n",
      "19 372.1032409667969\n",
      "20 362.67822265625\n",
      "21 353.500244140625\n",
      "22 344.55584716796875\n",
      "23 335.8111572265625\n",
      "24 327.3143310546875\n",
      "25 319.0458984375\n",
      "26 311.01580810546875\n",
      "27 303.20648193359375\n",
      "28 295.5889587402344\n",
      "29 288.1719665527344\n",
      "30 280.933349609375\n",
      "31 273.88067626953125\n",
      "32 267.0078125\n",
      "33 260.31976318359375\n",
      "34 253.7830047607422\n",
      "35 247.40472412109375\n",
      "36 241.19911193847656\n",
      "37 235.16195678710938\n",
      "38 229.24734497070312\n",
      "39 223.470703125\n",
      "40 217.82260131835938\n",
      "41 212.28904724121094\n",
      "42 206.87698364257812\n",
      "43 201.5718536376953\n",
      "44 196.37486267089844\n",
      "45 191.2836151123047\n",
      "46 186.3026580810547\n",
      "47 181.42311096191406\n",
      "48 176.65049743652344\n",
      "49 171.97012329101562\n",
      "50 167.3846893310547\n",
      "51 162.904052734375\n",
      "52 158.5208282470703\n",
      "53 154.2330322265625\n",
      "54 150.04168701171875\n",
      "55 145.94664001464844\n",
      "56 141.94277954101562\n",
      "57 138.0323028564453\n",
      "58 134.21142578125\n",
      "59 130.48623657226562\n",
      "60 126.85002899169922\n",
      "61 123.28298950195312\n",
      "62 119.79676818847656\n",
      "63 116.3940658569336\n",
      "64 113.06074523925781\n",
      "65 109.80817413330078\n",
      "66 106.63324737548828\n",
      "67 103.53556823730469\n",
      "68 100.51158905029297\n",
      "69 97.55938720703125\n",
      "70 94.67405700683594\n",
      "71 91.85968017578125\n",
      "72 89.10997009277344\n",
      "73 86.42217254638672\n",
      "74 83.80006408691406\n",
      "75 81.24700164794922\n",
      "76 78.74485778808594\n",
      "77 76.31024169921875\n",
      "78 73.9325180053711\n",
      "79 71.61405944824219\n",
      "80 69.34325408935547\n",
      "81 67.13202667236328\n",
      "82 64.98377990722656\n",
      "83 62.88585662841797\n",
      "84 60.841514587402344\n",
      "85 58.850921630859375\n",
      "86 56.914546966552734\n",
      "87 55.02603530883789\n",
      "88 53.19043731689453\n",
      "89 51.40377426147461\n",
      "90 49.66022872924805\n",
      "91 47.96391296386719\n",
      "92 46.30983352661133\n",
      "93 44.703453063964844\n",
      "94 43.14109420776367\n",
      "95 41.62309646606445\n",
      "96 40.14998245239258\n",
      "97 38.7197151184082\n",
      "98 37.333404541015625\n",
      "99 35.98664474487305\n",
      "100 34.681663513183594\n",
      "101 33.4153938293457\n",
      "102 32.18781280517578\n",
      "103 30.99921989440918\n",
      "104 29.850282669067383\n",
      "105 28.736995697021484\n",
      "106 27.660667419433594\n",
      "107 26.618391036987305\n",
      "108 25.607942581176758\n",
      "109 24.630905151367188\n",
      "110 23.688039779663086\n",
      "111 22.773954391479492\n",
      "112 21.89130210876465\n",
      "113 21.03813934326172\n",
      "114 20.214937210083008\n",
      "115 19.418790817260742\n",
      "116 18.650449752807617\n",
      "117 17.90750503540039\n",
      "118 17.18925666809082\n",
      "119 16.497461318969727\n",
      "120 15.828974723815918\n",
      "121 15.185250282287598\n",
      "122 14.563626289367676\n",
      "123 13.9644775390625\n",
      "124 13.387916564941406\n",
      "125 12.833817481994629\n",
      "126 12.299635887145996\n",
      "127 11.784817695617676\n",
      "128 11.289834022521973\n",
      "129 10.812923431396484\n",
      "130 10.353445053100586\n",
      "131 9.910965919494629\n",
      "132 9.486239433288574\n",
      "133 9.077614784240723\n",
      "134 8.684545516967773\n",
      "135 8.307241439819336\n",
      "136 7.944153308868408\n",
      "137 7.595917701721191\n",
      "138 7.261131763458252\n",
      "139 6.939231872558594\n",
      "140 6.6300811767578125\n",
      "141 6.333056926727295\n",
      "142 6.048220634460449\n",
      "143 5.7753987312316895\n",
      "144 5.5133442878723145\n",
      "145 5.26243257522583\n",
      "146 5.021986961364746\n",
      "147 4.791652202606201\n",
      "148 4.570805549621582\n",
      "149 4.35980749130249\n",
      "150 4.157459259033203\n",
      "151 3.9639744758605957\n",
      "152 3.778719186782837\n",
      "153 3.601492404937744\n",
      "154 3.4321017265319824\n",
      "155 3.269834041595459\n",
      "156 3.1148521900177\n",
      "157 2.966689348220825\n",
      "158 2.8251166343688965\n",
      "159 2.6897780895233154\n",
      "160 2.56028151512146\n",
      "161 2.436882495880127\n",
      "162 2.318983554840088\n",
      "163 2.2063515186309814\n",
      "164 2.098783016204834\n",
      "165 1.9962693452835083\n",
      "166 1.8984031677246094\n",
      "167 1.8049148321151733\n",
      "168 1.7159082889556885\n",
      "169 1.6309922933578491\n",
      "170 1.5499218702316284\n",
      "171 1.4727208614349365\n",
      "172 1.3991199731826782\n",
      "173 1.3288942575454712\n",
      "174 1.2620658874511719\n",
      "175 1.198520541191101\n",
      "176 1.1378549337387085\n",
      "177 1.0801165103912354\n",
      "178 1.025155782699585\n",
      "179 0.9728503227233887\n",
      "180 0.9230827689170837\n",
      "181 0.8756695985794067\n",
      "182 0.8305333852767944\n",
      "183 0.7876771688461304\n",
      "184 0.7469558119773865\n",
      "185 0.7082395553588867\n",
      "186 0.6715055704116821\n",
      "187 0.6366267204284668\n",
      "188 0.6034899950027466\n",
      "189 0.5719579458236694\n",
      "190 0.5420255661010742\n",
      "191 0.5135899782180786\n",
      "192 0.48659205436706543\n",
      "193 0.4609465003013611\n",
      "194 0.4366144835948944\n",
      "195 0.41351112723350525\n",
      "196 0.39156675338745117\n",
      "197 0.3707534968852997\n",
      "198 0.3510507643222809\n",
      "199 0.3323766887187958\n",
      "200 0.31462302803993225\n",
      "201 0.2978186309337616\n",
      "202 0.28187334537506104\n",
      "203 0.26676493883132935\n",
      "204 0.2524219751358032\n",
      "205 0.23883482813835144\n",
      "206 0.22596986591815948\n",
      "207 0.21376414597034454\n",
      "208 0.20220550894737244\n",
      "209 0.19125162065029144\n",
      "210 0.1808720827102661\n",
      "211 0.17102614045143127\n",
      "212 0.1616954505443573\n",
      "213 0.1528579592704773\n",
      "214 0.14447905123233795\n",
      "215 0.13656078279018402\n",
      "216 0.12905701994895935\n",
      "217 0.12195336818695068\n",
      "218 0.1152309998869896\n",
      "219 0.10887185484170914\n",
      "220 0.10285034030675888\n",
      "221 0.09715442359447479\n",
      "222 0.09176686406135559\n",
      "223 0.08667205274105072\n",
      "224 0.08185213804244995\n",
      "225 0.07729512453079224\n",
      "226 0.07298427075147629\n",
      "227 0.06890961527824402\n",
      "228 0.06505836546421051\n",
      "229 0.061416421085596085\n",
      "230 0.0579775795340538\n",
      "231 0.054725825786590576\n",
      "232 0.051653508096933365\n",
      "233 0.04875172674655914\n",
      "234 0.046012040227651596\n",
      "235 0.04342242702841759\n",
      "236 0.04097772017121315\n",
      "237 0.03866807371377945\n",
      "238 0.03648962080478668\n",
      "239 0.03443045914173126\n",
      "240 0.032489366829395294\n",
      "241 0.03065291792154312\n",
      "242 0.028921963647007942\n",
      "243 0.027288008481264114\n",
      "244 0.025745436549186707\n",
      "245 0.024289943277835846\n",
      "246 0.022916700690984726\n",
      "247 0.021622296422719955\n",
      "248 0.02039860561490059\n",
      "249 0.01924772746860981\n",
      "250 0.018160998821258545\n",
      "251 0.017136044800281525\n",
      "252 0.01616930216550827\n",
      "253 0.015257534570991993\n",
      "254 0.01439657062292099\n",
      "255 0.013584611937403679\n",
      "256 0.012818793766200542\n",
      "257 0.01209576427936554\n",
      "258 0.011414481326937675\n",
      "259 0.010771604254841805\n",
      "260 0.010165318846702576\n",
      "261 0.009593510068953037\n",
      "262 0.00905411783605814\n",
      "263 0.008545340038836002\n",
      "264 0.00806533731520176\n",
      "265 0.007612975314259529\n",
      "266 0.007186357397586107\n",
      "267 0.00678360927850008\n",
      "268 0.006404008250683546\n",
      "269 0.006046018097549677\n",
      "270 0.005708367098122835\n",
      "271 0.005390016827732325\n",
      "272 0.005089710000902414\n",
      "273 0.0048065148293972015\n",
      "274 0.004539466463029385\n",
      "275 0.0042875963263213634\n",
      "276 0.004050003364682198\n",
      "277 0.0038260940928012133\n",
      "278 0.0036147076170891523\n",
      "279 0.0034154350869357586\n",
      "280 0.003227655775845051\n",
      "281 0.0030504362657666206\n",
      "282 0.002883299021050334\n",
      "283 0.0027255527675151825\n",
      "284 0.0025767707265913486\n",
      "285 0.0024363636039197445\n",
      "286 0.002303880173712969\n",
      "287 0.002178872236981988\n",
      "288 0.0020610748324543238\n",
      "289 0.0019498481415212154\n",
      "290 0.0018448750488460064\n",
      "291 0.0017458283109590411\n",
      "292 0.001652317587286234\n",
      "293 0.0015639977063983679\n",
      "294 0.0014807775150984526\n",
      "295 0.0014020148664712906\n",
      "296 0.0013277202378958464\n",
      "297 0.0012575825676321983\n",
      "298 0.0011913063935935497\n",
      "299 0.0011286989320069551\n",
      "300 0.0010695563396438956\n",
      "301 0.0010136888595297933\n",
      "302 0.0009608787950128317\n",
      "303 0.0009109789971262217\n",
      "304 0.0008638183353468776\n",
      "305 0.0008192363893613219\n",
      "306 0.0007770962547510862\n",
      "307 0.0007372311665676534\n",
      "308 0.0006995497387833893\n",
      "309 0.0006638513877987862\n",
      "310 0.0006301038665696979\n",
      "311 0.0005981653230264783\n",
      "312 0.0005679666646756232\n",
      "313 0.0005393210449256003\n",
      "314 0.0005122408038005233\n",
      "315 0.0004866071685682982\n",
      "316 0.0004622976412065327\n",
      "317 0.00043929507955908775\n",
      "318 0.00041748597868718207\n",
      "319 0.0003968195233028382\n",
      "320 0.0003772337513510138\n",
      "321 0.0003586688544601202\n",
      "322 0.0003410670906305313\n",
      "323 0.0003243654500693083\n",
      "324 0.00030854882788844407\n",
      "325 0.0002935136726591736\n",
      "326 0.00027927299379371107\n",
      "327 0.00026574297226034105\n",
      "328 0.0002529046614654362\n",
      "329 0.00024071555526461452\n",
      "330 0.0002291377168148756\n",
      "331 0.0002181414165534079\n",
      "332 0.00020769776892848313\n",
      "333 0.00019776844419538975\n",
      "334 0.00018833938520401716\n",
      "335 0.0001793756673578173\n",
      "336 0.00017085732542909682\n",
      "337 0.00016275460075121373\n",
      "338 0.00015505374176427722\n",
      "339 0.00014772856957279146\n",
      "340 0.00014075517538003623\n",
      "341 0.00013412705447990447\n",
      "342 0.00012781916302628815\n",
      "343 0.00012181539204902947\n",
      "344 0.00011609710054472089\n",
      "345 0.0001106583877117373\n",
      "346 0.0001054792373906821\n",
      "347 0.00010055084567284212\n",
      "348 9.584860526956618e-05\n",
      "349 9.13775511435233e-05\n",
      "350 8.711937698535621e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351 8.305721712531522e-05\n",
      "352 7.918832125142217e-05\n",
      "353 7.550574810011312e-05\n",
      "354 7.198997627710924e-05\n",
      "355 6.864087481517345e-05\n",
      "356 6.54560572002083e-05\n",
      "357 6.24128442723304e-05\n",
      "358 5.951173807261512e-05\n",
      "359 5.6746710470179096e-05\n",
      "360 5.4109827033244073e-05\n",
      "361 5.159877036930993e-05\n",
      "362 4.919943239656277e-05\n",
      "363 4.6911678509786725e-05\n",
      "364 4.473177978070453e-05\n",
      "365 4.26536425948143e-05\n",
      "366 4.066774999955669e-05\n",
      "367 3.8775269786128774e-05\n",
      "368 3.6969780921936035e-05\n",
      "369 3.52479110006243e-05\n",
      "370 3.360582559253089e-05\n",
      "371 3.2037216442404315e-05\n",
      "372 3.05416360788513e-05\n",
      "373 2.9115142751834355e-05\n",
      "374 2.775425855361391e-05\n",
      "375 2.64569534920156e-05\n",
      "376 2.521764690754935e-05\n",
      "377 2.4034838133957237e-05\n",
      "378 2.2906850063009188e-05\n",
      "379 2.183021388191264e-05\n",
      "380 2.080512058455497e-05\n",
      "381 1.9824223272735253e-05\n",
      "382 1.889078521344345e-05\n",
      "383 1.7998743714997545e-05\n",
      "384 1.7148997358162887e-05\n",
      "385 1.633744250284508e-05\n",
      "386 1.5563589840894565e-05\n",
      "387 1.4824500794929918e-05\n",
      "388 1.4120972991804592e-05\n",
      "389 1.3449205653159879e-05\n",
      "390 1.2807834536943119e-05\n",
      "391 1.2197713658679277e-05\n",
      "392 1.1614180039032362e-05\n",
      "393 1.1058916243200656e-05\n",
      "394 1.0528500752116088e-05\n",
      "395 1.0022788956121076e-05\n",
      "396 9.541594408801757e-06\n",
      "397 9.082015822059475e-06\n",
      "398 8.643369255878497e-06\n",
      "399 8.226169484260026e-06\n",
      "400 7.827053195796907e-06\n",
      "401 7.447849384334404e-06\n",
      "402 7.086864570737816e-06\n",
      "403 6.741897323081503e-06\n",
      "404 6.413419669115683e-06\n",
      "405 6.100181508372771e-06\n",
      "406 5.802266059617978e-06\n",
      "407 5.517496902029961e-06\n",
      "408 5.2461241466517095e-06\n",
      "409 4.9889945330505725e-06\n",
      "410 4.743523732031463e-06\n",
      "411 4.509187419898808e-06\n",
      "412 4.2857504922722e-06\n",
      "413 4.073812760907458e-06\n",
      "414 3.871774424624164e-06\n",
      "415 3.679480187201989e-06\n",
      "416 3.4957274692715146e-06\n",
      "417 3.321502390463138e-06\n",
      "418 3.155358172080014e-06\n",
      "419 2.99677049042657e-06\n",
      "420 2.8467370611906517e-06\n",
      "421 2.703666268644156e-06\n",
      "422 2.5668771286291303e-06\n",
      "423 2.437941930111265e-06\n",
      "424 2.313856839464279e-06\n",
      "425 2.1968814962747274e-06\n",
      "426 2.0852353372902144e-06\n",
      "427 1.979329454115941e-06\n",
      "428 1.878382590803085e-06\n",
      "429 1.7823289226726047e-06\n",
      "430 1.6910182694118703e-06\n",
      "431 1.6040505670389393e-06\n",
      "432 1.5219311535474844e-06\n",
      "433 1.4435937600865145e-06\n",
      "434 1.3690976174984826e-06\n",
      "435 1.298174652220041e-06\n",
      "436 1.2310309784879792e-06\n",
      "437 1.167141817859374e-06\n",
      "438 1.106205218093237e-06\n",
      "439 1.0486852488611476e-06\n",
      "440 9.939865321939578e-07\n",
      "441 9.417186674909317e-07\n",
      "442 8.924078542804637e-07\n",
      "443 8.456008231405576e-07\n",
      "444 8.011797376639151e-07\n",
      "445 7.588356538690277e-07\n",
      "446 7.187911137407355e-07\n",
      "447 6.806610031162563e-07\n",
      "448 6.445823714784638e-07\n",
      "449 6.103234113652434e-07\n",
      "450 5.777110914095829e-07\n",
      "451 5.468478434522694e-07\n",
      "452 5.176782451599138e-07\n",
      "453 4.899271175418107e-07\n",
      "454 4.6367966888283263e-07\n",
      "455 4.388672891764145e-07\n",
      "456 4.1505143144604517e-07\n",
      "457 3.9266600992959866e-07\n",
      "458 3.7135916386432655e-07\n",
      "459 3.51215362570656e-07\n",
      "460 3.3222127626686415e-07\n",
      "461 3.141480533486174e-07\n",
      "462 2.969581771594676e-07\n",
      "463 2.807664145620947e-07\n",
      "464 2.6535417418926954e-07\n",
      "465 2.509387684312969e-07\n",
      "466 2.3701696250100213e-07\n",
      "467 2.2392562470940902e-07\n",
      "468 2.1171639730255265e-07\n",
      "469 1.9993227340364683e-07\n",
      "470 1.8899706333286304e-07\n",
      "471 1.7844699584657064e-07\n",
      "472 1.6845135064613714e-07\n",
      "473 1.5914562823127198e-07\n",
      "474 1.502911004536145e-07\n",
      "475 1.4190860042617714e-07\n",
      "476 1.3392381958965416e-07\n",
      "477 1.2629649859263736e-07\n",
      "478 1.193550787093045e-07\n",
      "479 1.1257527887664764e-07\n",
      "480 1.0617281986924354e-07\n",
      "481 1.0020279717082303e-07\n",
      "482 9.455050076212501e-08\n",
      "483 8.915599636338811e-08\n",
      "484 8.407211993244346e-08\n",
      "485 7.930414369639038e-08\n",
      "486 7.482639574618588e-08\n",
      "487 7.059598772229947e-08\n",
      "488 6.647437089668529e-08\n",
      "489 6.269645069778562e-08\n",
      "490 5.911687139814603e-08\n",
      "491 5.5709243440560385e-08\n",
      "492 5.248719503470056e-08\n",
      "493 4.950448939666785e-08\n",
      "494 4.664773456397597e-08\n",
      "495 4.3941565053273735e-08\n",
      "496 4.1396344130362195e-08\n",
      "497 3.9016541109049285e-08\n",
      "498 3.675143034342909e-08\n",
      "499 3.46266553208352e-08\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建一些训练数据\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# 自定义两层model\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        # define the model architecture\n",
    "        self.linear1 = torch.nn.Linear(D_in, H, bias=False)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear2(self.linear1(x).clamp(min=0))  # 计算预测值\n",
    "        return y_pred\n",
    "\n",
    "# 初始化model\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "# 定义loss function\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "\n",
    "# 定义优化器\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 开始训练\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    y_pred = model(x)          # model.forward() \n",
    "    \n",
    "    # compute loss\n",
    "    loss = loss_fn(y_pred, y)  # computation graph\n",
    "    print(it, loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update model parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FizzBuzz\n",
    "\n",
    "FizzBuzz是一个简单的小游戏。游戏规则如下：从1开始往上数数，当遇到3的倍数的时候，说fizz，当遇到5的倍数，说buzz，当遇到15的倍数，就说fizzbuzz，其他情况下则正常数数。\n",
    "\n",
    "我们可以写一个简单的小程序来决定要返回正常数值还是fizz, buzz 或者 fizzbuzz。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "buzz\n",
      "fizz\n",
      "fizzbuzz\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the desired outputs: [number, \"fizz\", \"buzz\", \"fizzbuzz\"]\n",
    "def fizz_buzz_encode(i):\n",
    "    if   i % 15 == 0: return 3\n",
    "    elif i % 5  == 0: return 2\n",
    "    elif i % 3  == 0: return 1\n",
    "    else:             return 0\n",
    "    \n",
    "def fizz_buzz_decode(i, prediction):\n",
    "    return [str(i), \"fizz\", \"buzz\", \"fizzbuzz\"][prediction]\n",
    "\n",
    "print(fizz_buzz_decode(1, fizz_buzz_encode(1)))\n",
    "print(fizz_buzz_decode(2, fizz_buzz_encode(2)))\n",
    "print(fizz_buzz_decode(5, fizz_buzz_encode(5)))\n",
    "print(fizz_buzz_decode(12, fizz_buzz_encode(12)))\n",
    "print(fizz_buzz_decode(15, fizz_buzz_encode(15)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先定义模型的输入与输出(训练数据)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([923, 10]) torch.Size([923])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "NUM_DIGITS = 10\n",
    "\n",
    "# Represent each input by an array of its binary digits.\n",
    "def binary_encode(i, num_digits):\n",
    "    return np.array([i >> d & 1 for d in range(num_digits)])  # 用num_digits长度的二进制表示一个十进制数字\n",
    "\n",
    "# 定义训练数据: 输入是923*10, 输出是923*1\n",
    "trX = torch.Tensor([binary_encode(i, NUM_DIGITS) for i in range(101, 2 ** NUM_DIGITS)])\n",
    "trY = torch.LongTensor([fizz_buzz_encode(i) for i in range(101, 2 ** NUM_DIGITS)])\n",
    "print(trX.shape, trY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们用PyTorch定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model.\n",
    "NUM_HIDDEN = 100\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(NUM_DIGITS, NUM_HIDDEN),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(NUM_HIDDEN, 4)    # 四分类问题\n",
    ")\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 为了让我们的模型学会FizzBuzz这个游戏，我们需要定义一个损失函数，和一个优化算法。\n",
    "- 这个优化算法会不断优化（降低）损失函数，使得模型的在该任务上取得尽可能低的损失值。\n",
    "- 损失值低往往表示我们的模型表现好，损失值高表示我们的模型表现差。\n",
    "- 由于FizzBuzz游戏本质上是一个分类问题，我们选用Cross Entropyy Loss函数。\n",
    "- 优化函数我们选用Stochastic Gradient Descent。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义分类问题的损失函数和优化器\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是模型的训练代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 1.1671295166015625\n",
      "Epoch: 1 Loss: 1.1505825519561768\n",
      "Epoch: 2 Loss: 1.1473468542099\n",
      "Epoch: 3 Loss: 1.1460673809051514\n",
      "Epoch: 4 Loss: 1.1453193426132202\n",
      "Epoch: 5 Loss: 1.1447807550430298\n",
      "Epoch: 6 Loss: 1.1443426609039307\n",
      "Epoch: 7 Loss: 1.1439651250839233\n",
      "Epoch: 8 Loss: 1.143627405166626\n",
      "Epoch: 9 Loss: 1.1433199644088745\n",
      "Epoch: 10 Loss: 1.1430312395095825\n",
      "Epoch: 11 Loss: 1.1427569389343262\n",
      "Epoch: 12 Loss: 1.1424994468688965\n",
      "Epoch: 13 Loss: 1.14225435256958\n",
      "Epoch: 14 Loss: 1.1420193910598755\n",
      "Epoch: 15 Loss: 1.1417971849441528\n",
      "Epoch: 16 Loss: 1.1415824890136719\n",
      "Epoch: 17 Loss: 1.1413750648498535\n",
      "Epoch: 18 Loss: 1.1411782503128052\n",
      "Epoch: 19 Loss: 1.140988826751709\n",
      "Epoch: 20 Loss: 1.1408054828643799\n",
      "Epoch: 21 Loss: 1.1406307220458984\n",
      "Epoch: 22 Loss: 1.14046049118042\n",
      "Epoch: 23 Loss: 1.140296220779419\n",
      "Epoch: 24 Loss: 1.1401362419128418\n",
      "Epoch: 25 Loss: 1.1399821043014526\n",
      "Epoch: 26 Loss: 1.1398342847824097\n",
      "Epoch: 27 Loss: 1.1396851539611816\n",
      "Epoch: 28 Loss: 1.1395463943481445\n",
      "Epoch: 29 Loss: 1.1394093036651611\n",
      "Epoch: 30 Loss: 1.1392781734466553\n",
      "Epoch: 31 Loss: 1.1391481161117554\n",
      "Epoch: 32 Loss: 1.1390221118927002\n",
      "Epoch: 33 Loss: 1.1388994455337524\n",
      "Epoch: 34 Loss: 1.1387792825698853\n",
      "Epoch: 35 Loss: 1.1386610269546509\n",
      "Epoch: 36 Loss: 1.1385462284088135\n",
      "Epoch: 37 Loss: 1.1384351253509521\n",
      "Epoch: 38 Loss: 1.1383271217346191\n",
      "Epoch: 39 Loss: 1.1382218599319458\n",
      "Epoch: 40 Loss: 1.1381192207336426\n",
      "Epoch: 41 Loss: 1.138019323348999\n",
      "Epoch: 42 Loss: 1.137919306755066\n",
      "Epoch: 43 Loss: 1.1378200054168701\n",
      "Epoch: 44 Loss: 1.1377251148223877\n",
      "Epoch: 45 Loss: 1.1376301050186157\n",
      "Epoch: 46 Loss: 1.1375361680984497\n",
      "Epoch: 47 Loss: 1.1374435424804688\n",
      "Epoch: 48 Loss: 1.1373528242111206\n",
      "Epoch: 49 Loss: 1.1372625827789307\n",
      "Epoch: 50 Loss: 1.1371738910675049\n",
      "Epoch: 51 Loss: 1.137084722518921\n",
      "Epoch: 52 Loss: 1.1369954347610474\n",
      "Epoch: 53 Loss: 1.1369097232818604\n",
      "Epoch: 54 Loss: 1.1368242502212524\n",
      "Epoch: 55 Loss: 1.1367390155792236\n",
      "Epoch: 56 Loss: 1.1366524696350098\n",
      "Epoch: 57 Loss: 1.1365692615509033\n",
      "Epoch: 58 Loss: 1.13648521900177\n",
      "Epoch: 59 Loss: 1.1364035606384277\n",
      "Epoch: 60 Loss: 1.1363219022750854\n",
      "Epoch: 61 Loss: 1.1362396478652954\n",
      "Epoch: 62 Loss: 1.13615882396698\n",
      "Epoch: 63 Loss: 1.136075735092163\n",
      "Epoch: 64 Loss: 1.1359950304031372\n",
      "Epoch: 65 Loss: 1.135913610458374\n",
      "Epoch: 66 Loss: 1.1358329057693481\n",
      "Epoch: 67 Loss: 1.1357520818710327\n",
      "Epoch: 68 Loss: 1.135671854019165\n",
      "Epoch: 69 Loss: 1.1355928182601929\n",
      "Epoch: 70 Loss: 1.1355115175247192\n",
      "Epoch: 71 Loss: 1.1354328393936157\n",
      "Epoch: 72 Loss: 1.1353540420532227\n",
      "Epoch: 73 Loss: 1.1352747678756714\n",
      "Epoch: 74 Loss: 1.1351970434188843\n",
      "Epoch: 75 Loss: 1.1351182460784912\n",
      "Epoch: 76 Loss: 1.1350390911102295\n",
      "Epoch: 77 Loss: 1.1349618434906006\n",
      "Epoch: 78 Loss: 1.1348826885223389\n",
      "Epoch: 79 Loss: 1.1348042488098145\n",
      "Epoch: 80 Loss: 1.1347246170043945\n",
      "Epoch: 81 Loss: 1.1346462965011597\n",
      "Epoch: 82 Loss: 1.134566068649292\n",
      "Epoch: 83 Loss: 1.1344889402389526\n",
      "Epoch: 84 Loss: 1.1344112157821655\n",
      "Epoch: 85 Loss: 1.1343307495117188\n",
      "Epoch: 86 Loss: 1.134254813194275\n",
      "Epoch: 87 Loss: 1.1341755390167236\n",
      "Epoch: 88 Loss: 1.1340982913970947\n",
      "Epoch: 89 Loss: 1.1340209245681763\n",
      "Epoch: 90 Loss: 1.1339426040649414\n",
      "Epoch: 91 Loss: 1.1338653564453125\n",
      "Epoch: 92 Loss: 1.1337894201278687\n",
      "Epoch: 93 Loss: 1.1337100267410278\n",
      "Epoch: 94 Loss: 1.1336342096328735\n",
      "Epoch: 95 Loss: 1.1335546970367432\n",
      "Epoch: 96 Loss: 1.133476972579956\n",
      "Epoch: 97 Loss: 1.1333954334259033\n",
      "Epoch: 98 Loss: 1.1333163976669312\n",
      "Epoch: 99 Loss: 1.1332378387451172\n",
      "Epoch: 100 Loss: 1.13316011428833\n",
      "Epoch: 101 Loss: 1.1330795288085938\n",
      "Epoch: 102 Loss: 1.1329997777938843\n",
      "Epoch: 103 Loss: 1.1329185962677002\n",
      "Epoch: 104 Loss: 1.1328397989273071\n",
      "Epoch: 105 Loss: 1.1327600479125977\n",
      "Epoch: 106 Loss: 1.132680058479309\n",
      "Epoch: 107 Loss: 1.132597804069519\n",
      "Epoch: 108 Loss: 1.1325175762176514\n",
      "Epoch: 109 Loss: 1.1324347257614136\n",
      "Epoch: 110 Loss: 1.1323531866073608\n",
      "Epoch: 111 Loss: 1.1322742700576782\n",
      "Epoch: 112 Loss: 1.132187843322754\n",
      "Epoch: 113 Loss: 1.1321089267730713\n",
      "Epoch: 114 Loss: 1.1320234537124634\n",
      "Epoch: 115 Loss: 1.1319410800933838\n",
      "Epoch: 116 Loss: 1.1318557262420654\n",
      "Epoch: 117 Loss: 1.1317683458328247\n",
      "Epoch: 118 Loss: 1.131687045097351\n",
      "Epoch: 119 Loss: 1.1315945386886597\n",
      "Epoch: 120 Loss: 1.1315093040466309\n",
      "Epoch: 121 Loss: 1.1314233541488647\n",
      "Epoch: 122 Loss: 1.1313339471817017\n",
      "Epoch: 123 Loss: 1.1312459707260132\n",
      "Epoch: 124 Loss: 1.1311559677124023\n",
      "Epoch: 125 Loss: 1.1310633420944214\n",
      "Epoch: 126 Loss: 1.1309741735458374\n",
      "Epoch: 127 Loss: 1.130883812904358\n",
      "Epoch: 128 Loss: 1.1307884454727173\n",
      "Epoch: 129 Loss: 1.130698800086975\n",
      "Epoch: 130 Loss: 1.1306084394454956\n",
      "Epoch: 131 Loss: 1.1305128335952759\n",
      "Epoch: 132 Loss: 1.130421757698059\n",
      "Epoch: 133 Loss: 1.1303259134292603\n",
      "Epoch: 134 Loss: 1.1302355527877808\n",
      "Epoch: 135 Loss: 1.1301394701004028\n",
      "Epoch: 136 Loss: 1.130041480064392\n",
      "Epoch: 137 Loss: 1.129953145980835\n",
      "Epoch: 138 Loss: 1.129858374595642\n",
      "Epoch: 139 Loss: 1.1297675371170044\n",
      "Epoch: 140 Loss: 1.129664421081543\n",
      "Epoch: 141 Loss: 1.1295756101608276\n",
      "Epoch: 142 Loss: 1.1294742822647095\n",
      "Epoch: 143 Loss: 1.129370093345642\n",
      "Epoch: 144 Loss: 1.1292784214019775\n",
      "Epoch: 145 Loss: 1.1291677951812744\n",
      "Epoch: 146 Loss: 1.1290723085403442\n",
      "Epoch: 147 Loss: 1.1289786100387573\n",
      "Epoch: 148 Loss: 1.128865361213684\n",
      "Epoch: 149 Loss: 1.1287710666656494\n",
      "Epoch: 150 Loss: 1.128670573234558\n",
      "Epoch: 151 Loss: 1.128552794456482\n",
      "Epoch: 152 Loss: 1.1284613609313965\n",
      "Epoch: 153 Loss: 1.1283440589904785\n",
      "Epoch: 154 Loss: 1.1282390356063843\n",
      "Epoch: 155 Loss: 1.1281280517578125\n",
      "Epoch: 156 Loss: 1.1280256509780884\n",
      "Epoch: 157 Loss: 1.1279217004776\n",
      "Epoch: 158 Loss: 1.12781822681427\n",
      "Epoch: 159 Loss: 1.127707600593567\n",
      "Epoch: 160 Loss: 1.127575159072876\n",
      "Epoch: 161 Loss: 1.1274793148040771\n",
      "Epoch: 162 Loss: 1.127347469329834\n",
      "Epoch: 163 Loss: 1.1272557973861694\n",
      "Epoch: 164 Loss: 1.127122402191162\n",
      "Epoch: 165 Loss: 1.1270180940628052\n",
      "Epoch: 166 Loss: 1.126904010772705\n",
      "Epoch: 167 Loss: 1.1267958879470825\n",
      "Epoch: 168 Loss: 1.126686453819275\n",
      "Epoch: 169 Loss: 1.1265711784362793\n",
      "Epoch: 170 Loss: 1.1264586448669434\n",
      "Epoch: 171 Loss: 1.126344919204712\n",
      "Epoch: 172 Loss: 1.1262290477752686\n",
      "Epoch: 173 Loss: 1.1261146068572998\n",
      "Epoch: 174 Loss: 1.1260007619857788\n",
      "Epoch: 175 Loss: 1.1258841753005981\n",
      "Epoch: 176 Loss: 1.125765085220337\n",
      "Epoch: 177 Loss: 1.1256468296051025\n",
      "Epoch: 178 Loss: 1.1255265474319458\n",
      "Epoch: 179 Loss: 1.1254111528396606\n",
      "Epoch: 180 Loss: 1.1252866983413696\n",
      "Epoch: 181 Loss: 1.1251730918884277\n",
      "Epoch: 182 Loss: 1.125068187713623\n",
      "Epoch: 183 Loss: 1.124946117401123\n",
      "Epoch: 184 Loss: 1.124843716621399\n",
      "Epoch: 185 Loss: 1.1247271299362183\n",
      "Epoch: 186 Loss: 1.1246024370193481\n",
      "Epoch: 187 Loss: 1.124501347541809\n",
      "Epoch: 188 Loss: 1.1243799924850464\n",
      "Epoch: 189 Loss: 1.1242880821228027\n",
      "Epoch: 190 Loss: 1.1241421699523926\n",
      "Epoch: 191 Loss: 1.1240243911743164\n",
      "Epoch: 192 Loss: 1.1239135265350342\n",
      "Epoch: 193 Loss: 1.1238154172897339\n",
      "Epoch: 194 Loss: 1.1236706972122192\n",
      "Epoch: 195 Loss: 1.1235631704330444\n",
      "Epoch: 196 Loss: 1.123435139656067\n",
      "Epoch: 197 Loss: 1.123322606086731\n",
      "Epoch: 198 Loss: 1.12319016456604\n",
      "Epoch: 199 Loss: 1.1230652332305908\n",
      "Epoch: 200 Loss: 1.1229883432388306\n",
      "Epoch: 201 Loss: 1.1228276491165161\n",
      "Epoch: 202 Loss: 1.1227093935012817\n",
      "Epoch: 203 Loss: 1.1225932836532593\n",
      "Epoch: 204 Loss: 1.1224710941314697\n",
      "Epoch: 205 Loss: 1.122359275817871\n",
      "Epoch: 206 Loss: 1.1222186088562012\n",
      "Epoch: 207 Loss: 1.1221040487289429\n",
      "Epoch: 208 Loss: 1.1219860315322876\n",
      "Epoch: 209 Loss: 1.1218178272247314\n",
      "Epoch: 210 Loss: 1.1217244863510132\n",
      "Epoch: 211 Loss: 1.1215821504592896\n",
      "Epoch: 212 Loss: 1.1214568614959717\n",
      "Epoch: 213 Loss: 1.121327519416809\n",
      "Epoch: 214 Loss: 1.1211915016174316\n",
      "Epoch: 215 Loss: 1.12108314037323\n",
      "Epoch: 216 Loss: 1.1209431886672974\n",
      "Epoch: 217 Loss: 1.1207959651947021\n",
      "Epoch: 218 Loss: 1.120678424835205\n",
      "Epoch: 219 Loss: 1.1205474138259888\n",
      "Epoch: 220 Loss: 1.1204131841659546\n",
      "Epoch: 221 Loss: 1.1202548742294312\n",
      "Epoch: 222 Loss: 1.1201356649398804\n",
      "Epoch: 223 Loss: 1.1199990510940552\n",
      "Epoch: 224 Loss: 1.11985182762146\n",
      "Epoch: 225 Loss: 1.1197293996810913\n",
      "Epoch: 226 Loss: 1.1195584535598755\n",
      "Epoch: 227 Loss: 1.119423270225525\n",
      "Epoch: 228 Loss: 1.1192796230316162\n",
      "Epoch: 229 Loss: 1.1191519498825073\n",
      "Epoch: 230 Loss: 1.1190404891967773\n",
      "Epoch: 231 Loss: 1.1188976764678955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 232 Loss: 1.1187427043914795\n",
      "Epoch: 233 Loss: 1.118605613708496\n",
      "Epoch: 234 Loss: 1.118482232093811\n",
      "Epoch: 235 Loss: 1.118325114250183\n",
      "Epoch: 236 Loss: 1.118159294128418\n",
      "Epoch: 237 Loss: 1.1180609464645386\n",
      "Epoch: 238 Loss: 1.1179159879684448\n",
      "Epoch: 239 Loss: 1.1177430152893066\n",
      "Epoch: 240 Loss: 1.117587685585022\n",
      "Epoch: 241 Loss: 1.117477536201477\n",
      "Epoch: 242 Loss: 1.117321252822876\n",
      "Epoch: 243 Loss: 1.117167353630066\n",
      "Epoch: 244 Loss: 1.1170377731323242\n",
      "Epoch: 245 Loss: 1.1168949604034424\n",
      "Epoch: 246 Loss: 1.1167738437652588\n",
      "Epoch: 247 Loss: 1.1166027784347534\n",
      "Epoch: 248 Loss: 1.1164711713790894\n",
      "Epoch: 249 Loss: 1.1163445711135864\n",
      "Epoch: 250 Loss: 1.1161770820617676\n",
      "Epoch: 251 Loss: 1.1160564422607422\n",
      "Epoch: 252 Loss: 1.1158812046051025\n",
      "Epoch: 253 Loss: 1.1157456636428833\n",
      "Epoch: 254 Loss: 1.1156063079833984\n",
      "Epoch: 255 Loss: 1.1154855489730835\n",
      "Epoch: 256 Loss: 1.115277886390686\n",
      "Epoch: 257 Loss: 1.115141749382019\n",
      "Epoch: 258 Loss: 1.1150747537612915\n",
      "Epoch: 259 Loss: 1.1148408651351929\n",
      "Epoch: 260 Loss: 1.1147109270095825\n",
      "Epoch: 261 Loss: 1.1145445108413696\n",
      "Epoch: 262 Loss: 1.1144132614135742\n",
      "Epoch: 263 Loss: 1.1142468452453613\n",
      "Epoch: 264 Loss: 1.1140801906585693\n",
      "Epoch: 265 Loss: 1.113951563835144\n",
      "Epoch: 266 Loss: 1.1137781143188477\n",
      "Epoch: 267 Loss: 1.1135822534561157\n",
      "Epoch: 268 Loss: 1.113425374031067\n",
      "Epoch: 269 Loss: 1.113250732421875\n",
      "Epoch: 270 Loss: 1.113085389137268\n",
      "Epoch: 271 Loss: 1.112931728363037\n",
      "Epoch: 272 Loss: 1.112802505493164\n",
      "Epoch: 273 Loss: 1.1126117706298828\n",
      "Epoch: 274 Loss: 1.1124364137649536\n",
      "Epoch: 275 Loss: 1.112308144569397\n",
      "Epoch: 276 Loss: 1.1121139526367188\n",
      "Epoch: 277 Loss: 1.1119585037231445\n",
      "Epoch: 278 Loss: 1.111772060394287\n",
      "Epoch: 279 Loss: 1.1116262674331665\n",
      "Epoch: 280 Loss: 1.1114414930343628\n",
      "Epoch: 281 Loss: 1.111322045326233\n",
      "Epoch: 282 Loss: 1.1110512018203735\n",
      "Epoch: 283 Loss: 1.1108568906784058\n",
      "Epoch: 284 Loss: 1.1107494831085205\n",
      "Epoch: 285 Loss: 1.1105449199676514\n",
      "Epoch: 286 Loss: 1.1103847026824951\n",
      "Epoch: 287 Loss: 1.1102217435836792\n",
      "Epoch: 288 Loss: 1.1100256443023682\n",
      "Epoch: 289 Loss: 1.1098350286483765\n",
      "Epoch: 290 Loss: 1.1096580028533936\n",
      "Epoch: 291 Loss: 1.109511137008667\n",
      "Epoch: 292 Loss: 1.1093286275863647\n",
      "Epoch: 293 Loss: 1.109169602394104\n",
      "Epoch: 294 Loss: 1.1089651584625244\n",
      "Epoch: 295 Loss: 1.108820915222168\n",
      "Epoch: 296 Loss: 1.1085810661315918\n",
      "Epoch: 297 Loss: 1.1084078550338745\n",
      "Epoch: 298 Loss: 1.1082127094268799\n",
      "Epoch: 299 Loss: 1.1079975366592407\n",
      "Epoch: 300 Loss: 1.1077946424484253\n",
      "Epoch: 301 Loss: 1.1076446771621704\n",
      "Epoch: 302 Loss: 1.1074239015579224\n",
      "Epoch: 303 Loss: 1.1072814464569092\n",
      "Epoch: 304 Loss: 1.1071314811706543\n",
      "Epoch: 305 Loss: 1.10689377784729\n",
      "Epoch: 306 Loss: 1.1067534685134888\n",
      "Epoch: 307 Loss: 1.1064741611480713\n",
      "Epoch: 308 Loss: 1.106361746788025\n",
      "Epoch: 309 Loss: 1.1060715913772583\n",
      "Epoch: 310 Loss: 1.1059856414794922\n",
      "Epoch: 311 Loss: 1.1057019233703613\n",
      "Epoch: 312 Loss: 1.1055253744125366\n",
      "Epoch: 313 Loss: 1.1052626371383667\n",
      "Epoch: 314 Loss: 1.1051819324493408\n",
      "Epoch: 315 Loss: 1.104894757270813\n",
      "Epoch: 316 Loss: 1.104765772819519\n",
      "Epoch: 317 Loss: 1.1044596433639526\n",
      "Epoch: 318 Loss: 1.1043107509613037\n",
      "Epoch: 319 Loss: 1.1040737628936768\n",
      "Epoch: 320 Loss: 1.1040130853652954\n",
      "Epoch: 321 Loss: 1.1036224365234375\n",
      "Epoch: 322 Loss: 1.103365421295166\n",
      "Epoch: 323 Loss: 1.1032307147979736\n",
      "Epoch: 324 Loss: 1.102937936782837\n",
      "Epoch: 325 Loss: 1.102683424949646\n",
      "Epoch: 326 Loss: 1.1024454832077026\n",
      "Epoch: 327 Loss: 1.1023341417312622\n",
      "Epoch: 328 Loss: 1.101958155632019\n",
      "Epoch: 329 Loss: 1.1018348932266235\n",
      "Epoch: 330 Loss: 1.1014721393585205\n",
      "Epoch: 331 Loss: 1.1011881828308105\n",
      "Epoch: 332 Loss: 1.100959062576294\n",
      "Epoch: 333 Loss: 1.100738525390625\n",
      "Epoch: 334 Loss: 1.1006773710250854\n",
      "Epoch: 335 Loss: 1.100377082824707\n",
      "Epoch: 336 Loss: 1.099965214729309\n",
      "Epoch: 337 Loss: 1.0998719930648804\n",
      "Epoch: 338 Loss: 1.0995382070541382\n",
      "Epoch: 339 Loss: 1.0991629362106323\n",
      "Epoch: 340 Loss: 1.099111795425415\n",
      "Epoch: 341 Loss: 1.0987135171890259\n",
      "Epoch: 342 Loss: 1.0984954833984375\n",
      "Epoch: 343 Loss: 1.0983308553695679\n",
      "Epoch: 344 Loss: 1.0978620052337646\n",
      "Epoch: 345 Loss: 1.097603678703308\n",
      "Epoch: 346 Loss: 1.097247838973999\n",
      "Epoch: 347 Loss: 1.0970436334609985\n",
      "Epoch: 348 Loss: 1.0969078540802002\n",
      "Epoch: 349 Loss: 1.0965522527694702\n",
      "Epoch: 350 Loss: 1.0961402654647827\n",
      "Epoch: 351 Loss: 1.0958863496780396\n",
      "Epoch: 352 Loss: 1.0955740213394165\n",
      "Epoch: 353 Loss: 1.0953582525253296\n",
      "Epoch: 354 Loss: 1.0949848890304565\n",
      "Epoch: 355 Loss: 1.0948035717010498\n",
      "Epoch: 356 Loss: 1.094381332397461\n",
      "Epoch: 357 Loss: 1.0940707921981812\n",
      "Epoch: 358 Loss: 1.0938724279403687\n",
      "Epoch: 359 Loss: 1.093587875366211\n",
      "Epoch: 360 Loss: 1.0932948589324951\n",
      "Epoch: 361 Loss: 1.092939853668213\n",
      "Epoch: 362 Loss: 1.0927058458328247\n",
      "Epoch: 363 Loss: 1.0922791957855225\n",
      "Epoch: 364 Loss: 1.0922069549560547\n",
      "Epoch: 365 Loss: 1.0917422771453857\n",
      "Epoch: 366 Loss: 1.0913752317428589\n",
      "Epoch: 367 Loss: 1.0912532806396484\n",
      "Epoch: 368 Loss: 1.090764045715332\n",
      "Epoch: 369 Loss: 1.0905295610427856\n",
      "Epoch: 370 Loss: 1.090165615081787\n",
      "Epoch: 371 Loss: 1.0898767709732056\n",
      "Epoch: 372 Loss: 1.0895668268203735\n",
      "Epoch: 373 Loss: 1.0893744230270386\n",
      "Epoch: 374 Loss: 1.089114785194397\n",
      "Epoch: 375 Loss: 1.0885374546051025\n",
      "Epoch: 376 Loss: 1.0884202718734741\n",
      "Epoch: 377 Loss: 1.0880736112594604\n",
      "Epoch: 378 Loss: 1.08770751953125\n",
      "Epoch: 379 Loss: 1.0872447490692139\n",
      "Epoch: 380 Loss: 1.0870214700698853\n",
      "Epoch: 381 Loss: 1.08657705783844\n",
      "Epoch: 382 Loss: 1.0864075422286987\n",
      "Epoch: 383 Loss: 1.0860342979431152\n",
      "Epoch: 384 Loss: 1.0856131315231323\n",
      "Epoch: 385 Loss: 1.085331916809082\n",
      "Epoch: 386 Loss: 1.0849441289901733\n",
      "Epoch: 387 Loss: 1.084560751914978\n",
      "Epoch: 388 Loss: 1.0844316482543945\n",
      "Epoch: 389 Loss: 1.0839725732803345\n",
      "Epoch: 390 Loss: 1.083743929862976\n",
      "Epoch: 391 Loss: 1.0832068920135498\n",
      "Epoch: 392 Loss: 1.0831283330917358\n",
      "Epoch: 393 Loss: 1.082468867301941\n",
      "Epoch: 394 Loss: 1.0823872089385986\n",
      "Epoch: 395 Loss: 1.0821113586425781\n",
      "Epoch: 396 Loss: 1.0816059112548828\n",
      "Epoch: 397 Loss: 1.081314206123352\n",
      "Epoch: 398 Loss: 1.08086097240448\n",
      "Epoch: 399 Loss: 1.080592155456543\n",
      "Epoch: 400 Loss: 1.0801482200622559\n",
      "Epoch: 401 Loss: 1.0799692869186401\n",
      "Epoch: 402 Loss: 1.0796279907226562\n",
      "Epoch: 403 Loss: 1.0792156457901\n",
      "Epoch: 404 Loss: 1.0788081884384155\n",
      "Epoch: 405 Loss: 1.078506588935852\n",
      "Epoch: 406 Loss: 1.078194260597229\n",
      "Epoch: 407 Loss: 1.0778836011886597\n",
      "Epoch: 408 Loss: 1.0773940086364746\n",
      "Epoch: 409 Loss: 1.0771217346191406\n",
      "Epoch: 410 Loss: 1.076892375946045\n",
      "Epoch: 411 Loss: 1.0765206813812256\n",
      "Epoch: 412 Loss: 1.0762696266174316\n",
      "Epoch: 413 Loss: 1.0760409832000732\n",
      "Epoch: 414 Loss: 1.075575828552246\n",
      "Epoch: 415 Loss: 1.0750598907470703\n",
      "Epoch: 416 Loss: 1.0747007131576538\n",
      "Epoch: 417 Loss: 1.074476957321167\n",
      "Epoch: 418 Loss: 1.073912262916565\n",
      "Epoch: 419 Loss: 1.0735870599746704\n",
      "Epoch: 420 Loss: 1.0732166767120361\n",
      "Epoch: 421 Loss: 1.0730292797088623\n",
      "Epoch: 422 Loss: 1.0724462270736694\n",
      "Epoch: 423 Loss: 1.0723507404327393\n",
      "Epoch: 424 Loss: 1.0719044208526611\n",
      "Epoch: 425 Loss: 1.0712937116622925\n",
      "Epoch: 426 Loss: 1.0711498260498047\n",
      "Epoch: 427 Loss: 1.0708365440368652\n",
      "Epoch: 428 Loss: 1.0704774856567383\n",
      "Epoch: 429 Loss: 1.0699957609176636\n",
      "Epoch: 430 Loss: 1.0697476863861084\n",
      "Epoch: 431 Loss: 1.0692304372787476\n",
      "Epoch: 432 Loss: 1.0688750743865967\n",
      "Epoch: 433 Loss: 1.0689023733139038\n",
      "Epoch: 434 Loss: 1.068163514137268\n",
      "Epoch: 435 Loss: 1.067905306816101\n",
      "Epoch: 436 Loss: 1.0674265623092651\n",
      "Epoch: 437 Loss: 1.0669593811035156\n",
      "Epoch: 438 Loss: 1.0667030811309814\n",
      "Epoch: 439 Loss: 1.0664899349212646\n",
      "Epoch: 440 Loss: 1.0658680200576782\n",
      "Epoch: 441 Loss: 1.0657275915145874\n",
      "Epoch: 442 Loss: 1.0651705265045166\n",
      "Epoch: 443 Loss: 1.0647549629211426\n",
      "Epoch: 444 Loss: 1.0647404193878174\n",
      "Epoch: 445 Loss: 1.0639516115188599\n",
      "Epoch: 446 Loss: 1.063620924949646\n",
      "Epoch: 447 Loss: 1.063288927078247\n",
      "Epoch: 448 Loss: 1.0632954835891724\n",
      "Epoch: 449 Loss: 1.062530279159546\n",
      "Epoch: 450 Loss: 1.0620478391647339\n",
      "Epoch: 451 Loss: 1.0619783401489258\n",
      "Epoch: 452 Loss: 1.0610945224761963\n",
      "Epoch: 453 Loss: 1.0610188245773315\n",
      "Epoch: 454 Loss: 1.0606021881103516\n",
      "Epoch: 455 Loss: 1.060579538345337\n",
      "Epoch: 456 Loss: 1.059868574142456\n",
      "Epoch: 457 Loss: 1.059515118598938\n",
      "Epoch: 458 Loss: 1.059103012084961\n",
      "Epoch: 459 Loss: 1.0586607456207275\n",
      "Epoch: 460 Loss: 1.0587595701217651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 461 Loss: 1.0576612949371338\n",
      "Epoch: 462 Loss: 1.05746591091156\n",
      "Epoch: 463 Loss: 1.0572350025177002\n",
      "Epoch: 464 Loss: 1.0565558671951294\n",
      "Epoch: 465 Loss: 1.056056261062622\n",
      "Epoch: 466 Loss: 1.055806040763855\n",
      "Epoch: 467 Loss: 1.0552853345870972\n",
      "Epoch: 468 Loss: 1.0549802780151367\n",
      "Epoch: 469 Loss: 1.0545657873153687\n",
      "Epoch: 470 Loss: 1.0539137125015259\n",
      "Epoch: 471 Loss: 1.0535575151443481\n",
      "Epoch: 472 Loss: 1.053863286972046\n",
      "Epoch: 473 Loss: 1.0530118942260742\n",
      "Epoch: 474 Loss: 1.0524027347564697\n",
      "Epoch: 475 Loss: 1.05244779586792\n",
      "Epoch: 476 Loss: 1.0515512228012085\n",
      "Epoch: 477 Loss: 1.0511388778686523\n",
      "Epoch: 478 Loss: 1.0507194995880127\n",
      "Epoch: 479 Loss: 1.050369381904602\n",
      "Epoch: 480 Loss: 1.0503205060958862\n",
      "Epoch: 481 Loss: 1.0492684841156006\n",
      "Epoch: 482 Loss: 1.0495191812515259\n",
      "Epoch: 483 Loss: 1.0488884449005127\n",
      "Epoch: 484 Loss: 1.0481494665145874\n",
      "Epoch: 485 Loss: 1.048030138015747\n",
      "Epoch: 486 Loss: 1.0474677085876465\n",
      "Epoch: 487 Loss: 1.047338604927063\n",
      "Epoch: 488 Loss: 1.0470020771026611\n",
      "Epoch: 489 Loss: 1.0461170673370361\n",
      "Epoch: 490 Loss: 1.0456502437591553\n",
      "Epoch: 491 Loss: 1.0455552339553833\n",
      "Epoch: 492 Loss: 1.0448999404907227\n",
      "Epoch: 493 Loss: 1.0443137884140015\n",
      "Epoch: 494 Loss: 1.0440057516098022\n",
      "Epoch: 495 Loss: 1.0438082218170166\n",
      "Epoch: 496 Loss: 1.0430095195770264\n",
      "Epoch: 497 Loss: 1.0428056716918945\n",
      "Epoch: 498 Loss: 1.0425622463226318\n",
      "Epoch: 499 Loss: 1.0415276288986206\n",
      "Epoch: 500 Loss: 1.0415314435958862\n",
      "Epoch: 501 Loss: 1.0410583019256592\n",
      "Epoch: 502 Loss: 1.0408381223678589\n",
      "Epoch: 503 Loss: 1.0400571823120117\n",
      "Epoch: 504 Loss: 1.0396562814712524\n",
      "Epoch: 505 Loss: 1.0391613245010376\n",
      "Epoch: 506 Loss: 1.038989782333374\n",
      "Epoch: 507 Loss: 1.0384516716003418\n",
      "Epoch: 508 Loss: 1.037999153137207\n",
      "Epoch: 509 Loss: 1.0374581813812256\n",
      "Epoch: 510 Loss: 1.0370872020721436\n",
      "Epoch: 511 Loss: 1.0366075038909912\n",
      "Epoch: 512 Loss: 1.0362366437911987\n",
      "Epoch: 513 Loss: 1.035475730895996\n",
      "Epoch: 514 Loss: 1.035235047340393\n",
      "Epoch: 515 Loss: 1.0347837209701538\n",
      "Epoch: 516 Loss: 1.0343154668807983\n",
      "Epoch: 517 Loss: 1.0338752269744873\n",
      "Epoch: 518 Loss: 1.0330991744995117\n",
      "Epoch: 519 Loss: 1.0329121351242065\n",
      "Epoch: 520 Loss: 1.0323959589004517\n",
      "Epoch: 521 Loss: 1.0323642492294312\n",
      "Epoch: 522 Loss: 1.031504511833191\n",
      "Epoch: 523 Loss: 1.0311667919158936\n",
      "Epoch: 524 Loss: 1.030677318572998\n",
      "Epoch: 525 Loss: 1.0299187898635864\n",
      "Epoch: 526 Loss: 1.0297282934188843\n",
      "Epoch: 527 Loss: 1.0292919874191284\n",
      "Epoch: 528 Loss: 1.0289392471313477\n",
      "Epoch: 529 Loss: 1.0283265113830566\n",
      "Epoch: 530 Loss: 1.0276998281478882\n",
      "Epoch: 531 Loss: 1.0273253917694092\n",
      "Epoch: 532 Loss: 1.0268632173538208\n",
      "Epoch: 533 Loss: 1.026431918144226\n",
      "Epoch: 534 Loss: 1.0257999897003174\n",
      "Epoch: 535 Loss: 1.0259381532669067\n",
      "Epoch: 536 Loss: 1.0248912572860718\n",
      "Epoch: 537 Loss: 1.0246555805206299\n",
      "Epoch: 538 Loss: 1.0242432355880737\n",
      "Epoch: 539 Loss: 1.0236092805862427\n",
      "Epoch: 540 Loss: 1.0230778455734253\n",
      "Epoch: 541 Loss: 1.022297739982605\n",
      "Epoch: 542 Loss: 1.0219652652740479\n",
      "Epoch: 543 Loss: 1.0219593048095703\n",
      "Epoch: 544 Loss: 1.0211948156356812\n",
      "Epoch: 545 Loss: 1.0207644701004028\n",
      "Epoch: 546 Loss: 1.0206681489944458\n",
      "Epoch: 547 Loss: 1.019490122795105\n",
      "Epoch: 548 Loss: 1.0195400714874268\n",
      "Epoch: 549 Loss: 1.0184590816497803\n",
      "Epoch: 550 Loss: 1.0180532932281494\n",
      "Epoch: 551 Loss: 1.0181735754013062\n",
      "Epoch: 552 Loss: 1.016984224319458\n",
      "Epoch: 553 Loss: 1.01679265499115\n",
      "Epoch: 554 Loss: 1.0161669254302979\n",
      "Epoch: 555 Loss: 1.016005039215088\n",
      "Epoch: 556 Loss: 1.0150659084320068\n",
      "Epoch: 557 Loss: 1.0149497985839844\n",
      "Epoch: 558 Loss: 1.0145957469940186\n",
      "Epoch: 559 Loss: 1.0138609409332275\n",
      "Epoch: 560 Loss: 1.0138959884643555\n",
      "Epoch: 561 Loss: 1.0126559734344482\n",
      "Epoch: 562 Loss: 1.0129075050354004\n",
      "Epoch: 563 Loss: 1.0120530128479004\n",
      "Epoch: 564 Loss: 1.0110723972320557\n",
      "Epoch: 565 Loss: 1.010796308517456\n",
      "Epoch: 566 Loss: 1.0102795362472534\n",
      "Epoch: 567 Loss: 1.0095270872116089\n",
      "Epoch: 568 Loss: 1.0093096494674683\n",
      "Epoch: 569 Loss: 1.0086767673492432\n",
      "Epoch: 570 Loss: 1.0092674493789673\n",
      "Epoch: 571 Loss: 1.0075770616531372\n",
      "Epoch: 572 Loss: 1.0070239305496216\n",
      "Epoch: 573 Loss: 1.0071368217468262\n",
      "Epoch: 574 Loss: 1.0067189931869507\n",
      "Epoch: 575 Loss: 1.005845308303833\n",
      "Epoch: 576 Loss: 1.0052077770233154\n",
      "Epoch: 577 Loss: 1.0051435232162476\n",
      "Epoch: 578 Loss: 1.004773736000061\n",
      "Epoch: 579 Loss: 1.0036416053771973\n",
      "Epoch: 580 Loss: 1.0033499002456665\n",
      "Epoch: 581 Loss: 1.002799153327942\n",
      "Epoch: 582 Loss: 1.0021681785583496\n",
      "Epoch: 583 Loss: 1.001208782196045\n",
      "Epoch: 584 Loss: 1.0007492303848267\n",
      "Epoch: 585 Loss: 1.0005030632019043\n",
      "Epoch: 586 Loss: 1.000880241394043\n",
      "Epoch: 587 Loss: 0.999466598033905\n",
      "Epoch: 588 Loss: 0.9993190169334412\n",
      "Epoch: 589 Loss: 0.9985387921333313\n",
      "Epoch: 590 Loss: 0.9982687830924988\n",
      "Epoch: 591 Loss: 0.9976974129676819\n",
      "Epoch: 592 Loss: 0.9965413808822632\n",
      "Epoch: 593 Loss: 0.9971968531608582\n",
      "Epoch: 594 Loss: 0.9955685138702393\n",
      "Epoch: 595 Loss: 0.9948620200157166\n",
      "Epoch: 596 Loss: 0.9954386949539185\n",
      "Epoch: 597 Loss: 0.9946462512016296\n",
      "Epoch: 598 Loss: 0.9940120577812195\n",
      "Epoch: 599 Loss: 0.9933605194091797\n",
      "Epoch: 600 Loss: 0.9923307299613953\n",
      "Epoch: 601 Loss: 0.992092490196228\n",
      "Epoch: 602 Loss: 0.9916055798530579\n",
      "Epoch: 603 Loss: 0.9915523529052734\n",
      "Epoch: 604 Loss: 0.9906783103942871\n",
      "Epoch: 605 Loss: 0.9896360635757446\n",
      "Epoch: 606 Loss: 0.9887871742248535\n",
      "Epoch: 607 Loss: 0.9885542392730713\n",
      "Epoch: 608 Loss: 0.9884048700332642\n",
      "Epoch: 609 Loss: 0.9875437617301941\n",
      "Epoch: 610 Loss: 0.9868627786636353\n",
      "Epoch: 611 Loss: 0.9864149689674377\n",
      "Epoch: 612 Loss: 0.9863080382347107\n",
      "Epoch: 613 Loss: 0.9848232865333557\n",
      "Epoch: 614 Loss: 0.9847645163536072\n",
      "Epoch: 615 Loss: 0.9845446348190308\n",
      "Epoch: 616 Loss: 0.9834323525428772\n",
      "Epoch: 617 Loss: 0.9840430021286011\n",
      "Epoch: 618 Loss: 0.9823457598686218\n",
      "Epoch: 619 Loss: 0.9819291830062866\n",
      "Epoch: 620 Loss: 0.9817140102386475\n",
      "Epoch: 621 Loss: 0.9809179902076721\n",
      "Epoch: 622 Loss: 0.9805630445480347\n",
      "Epoch: 623 Loss: 0.9800552725791931\n",
      "Epoch: 624 Loss: 0.979607105255127\n",
      "Epoch: 625 Loss: 0.9784045815467834\n",
      "Epoch: 626 Loss: 0.977672815322876\n",
      "Epoch: 627 Loss: 0.9780541062355042\n",
      "Epoch: 628 Loss: 0.9769532680511475\n",
      "Epoch: 629 Loss: 0.9758796095848083\n",
      "Epoch: 630 Loss: 0.9759665131568909\n",
      "Epoch: 631 Loss: 0.9749433994293213\n",
      "Epoch: 632 Loss: 0.974126935005188\n",
      "Epoch: 633 Loss: 0.9734199643135071\n",
      "Epoch: 634 Loss: 0.9731519818305969\n",
      "Epoch: 635 Loss: 0.9731361865997314\n",
      "Epoch: 636 Loss: 0.9719986915588379\n",
      "Epoch: 637 Loss: 0.9729319214820862\n",
      "Epoch: 638 Loss: 0.9719097018241882\n",
      "Epoch: 639 Loss: 0.9704419374465942\n",
      "Epoch: 640 Loss: 0.9703392386436462\n",
      "Epoch: 641 Loss: 0.9687076807022095\n",
      "Epoch: 642 Loss: 0.9684181213378906\n",
      "Epoch: 643 Loss: 0.9689069390296936\n",
      "Epoch: 644 Loss: 0.967960774898529\n",
      "Epoch: 645 Loss: 0.966795027256012\n",
      "Epoch: 646 Loss: 0.9663569927215576\n",
      "Epoch: 647 Loss: 0.9651756882667542\n",
      "Epoch: 648 Loss: 0.9648787379264832\n",
      "Epoch: 649 Loss: 0.9648401737213135\n",
      "Epoch: 650 Loss: 0.9641734957695007\n",
      "Epoch: 651 Loss: 0.9641439914703369\n",
      "Epoch: 652 Loss: 0.9626096487045288\n",
      "Epoch: 653 Loss: 0.9616018533706665\n",
      "Epoch: 654 Loss: 0.9617791771888733\n",
      "Epoch: 655 Loss: 0.960303008556366\n",
      "Epoch: 656 Loss: 0.9603161811828613\n",
      "Epoch: 657 Loss: 0.9591930508613586\n",
      "Epoch: 658 Loss: 0.9591120481491089\n",
      "Epoch: 659 Loss: 0.9581086039543152\n",
      "Epoch: 660 Loss: 0.9578981995582581\n",
      "Epoch: 661 Loss: 0.9570335149765015\n",
      "Epoch: 662 Loss: 0.957402765750885\n",
      "Epoch: 663 Loss: 0.9556030631065369\n",
      "Epoch: 664 Loss: 0.9546840786933899\n",
      "Epoch: 665 Loss: 0.9543982744216919\n",
      "Epoch: 666 Loss: 0.9554135799407959\n",
      "Epoch: 667 Loss: 0.9542235732078552\n",
      "Epoch: 668 Loss: 0.9525762796401978\n",
      "Epoch: 669 Loss: 0.9520730376243591\n",
      "Epoch: 670 Loss: 0.9524216055870056\n",
      "Epoch: 671 Loss: 0.9513838291168213\n",
      "Epoch: 672 Loss: 0.950896143913269\n",
      "Epoch: 673 Loss: 0.9495679140090942\n",
      "Epoch: 674 Loss: 0.9495530724525452\n",
      "Epoch: 675 Loss: 0.9491268396377563\n",
      "Epoch: 676 Loss: 0.9481030702590942\n",
      "Epoch: 677 Loss: 0.9474408030509949\n",
      "Epoch: 678 Loss: 0.9464775919914246\n",
      "Epoch: 679 Loss: 0.9459536075592041\n",
      "Epoch: 680 Loss: 0.9466984272003174\n",
      "Epoch: 681 Loss: 0.9446340799331665\n",
      "Epoch: 682 Loss: 0.9438779354095459\n",
      "Epoch: 683 Loss: 0.9435402154922485\n",
      "Epoch: 684 Loss: 0.9448978304862976\n",
      "Epoch: 685 Loss: 0.94310063123703\n",
      "Epoch: 686 Loss: 0.9427123665809631\n",
      "Epoch: 687 Loss: 0.9420596957206726\n",
      "Epoch: 688 Loss: 0.9405302405357361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 689 Loss: 0.9402035474777222\n",
      "Epoch: 690 Loss: 0.9396965503692627\n",
      "Epoch: 691 Loss: 0.9394804239273071\n",
      "Epoch: 692 Loss: 0.9383803606033325\n",
      "Epoch: 693 Loss: 0.9381263256072998\n",
      "Epoch: 694 Loss: 0.9378105401992798\n",
      "Epoch: 695 Loss: 0.937196671962738\n",
      "Epoch: 696 Loss: 0.9359325170516968\n",
      "Epoch: 697 Loss: 0.9357682466506958\n",
      "Epoch: 698 Loss: 0.9363159537315369\n",
      "Epoch: 699 Loss: 0.9349292516708374\n",
      "Epoch: 700 Loss: 0.9337396025657654\n",
      "Epoch: 701 Loss: 0.9325191378593445\n",
      "Epoch: 702 Loss: 0.9320878386497498\n",
      "Epoch: 703 Loss: 0.9331204295158386\n",
      "Epoch: 704 Loss: 0.9317018985748291\n",
      "Epoch: 705 Loss: 0.9308800101280212\n",
      "Epoch: 706 Loss: 0.9301913380622864\n",
      "Epoch: 707 Loss: 0.9293592572212219\n",
      "Epoch: 708 Loss: 0.9280061721801758\n",
      "Epoch: 709 Loss: 0.9275913238525391\n",
      "Epoch: 710 Loss: 0.9270132184028625\n",
      "Epoch: 711 Loss: 0.9266520142555237\n",
      "Epoch: 712 Loss: 0.9265201091766357\n",
      "Epoch: 713 Loss: 0.9251084327697754\n",
      "Epoch: 714 Loss: 0.9243316650390625\n",
      "Epoch: 715 Loss: 0.9247979521751404\n",
      "Epoch: 716 Loss: 0.9232249855995178\n",
      "Epoch: 717 Loss: 0.9244890809059143\n",
      "Epoch: 718 Loss: 0.9223723411560059\n",
      "Epoch: 719 Loss: 0.9216189980506897\n",
      "Epoch: 720 Loss: 0.9213535189628601\n",
      "Epoch: 721 Loss: 0.9204690456390381\n",
      "Epoch: 722 Loss: 0.9191257357597351\n",
      "Epoch: 723 Loss: 0.9185614585876465\n",
      "Epoch: 724 Loss: 0.9187449216842651\n",
      "Epoch: 725 Loss: 0.9195300340652466\n",
      "Epoch: 726 Loss: 0.9168968796730042\n",
      "Epoch: 727 Loss: 0.9160236120223999\n",
      "Epoch: 728 Loss: 0.9153631329536438\n",
      "Epoch: 729 Loss: 0.9145969748497009\n",
      "Epoch: 730 Loss: 0.9147213697433472\n",
      "Epoch: 731 Loss: 0.9142310619354248\n",
      "Epoch: 732 Loss: 0.9135965704917908\n",
      "Epoch: 733 Loss: 0.912486732006073\n",
      "Epoch: 734 Loss: 0.9112942218780518\n",
      "Epoch: 735 Loss: 0.9102646708488464\n",
      "Epoch: 736 Loss: 0.9103950262069702\n",
      "Epoch: 737 Loss: 0.9092010259628296\n",
      "Epoch: 738 Loss: 0.9093442559242249\n",
      "Epoch: 739 Loss: 0.9086360335350037\n",
      "Epoch: 740 Loss: 0.9072059392929077\n",
      "Epoch: 741 Loss: 0.9064054489135742\n",
      "Epoch: 742 Loss: 0.9063541293144226\n",
      "Epoch: 743 Loss: 0.9051945209503174\n",
      "Epoch: 744 Loss: 0.9040884971618652\n",
      "Epoch: 745 Loss: 0.9042605757713318\n",
      "Epoch: 746 Loss: 0.9035100936889648\n",
      "Epoch: 747 Loss: 0.9027194976806641\n",
      "Epoch: 748 Loss: 0.9027417302131653\n",
      "Epoch: 749 Loss: 0.901374340057373\n",
      "Epoch: 750 Loss: 0.9009859561920166\n",
      "Epoch: 751 Loss: 0.9004325866699219\n",
      "Epoch: 752 Loss: 0.8992859721183777\n",
      "Epoch: 753 Loss: 0.9000232815742493\n",
      "Epoch: 754 Loss: 0.8975750803947449\n",
      "Epoch: 755 Loss: 0.8978947997093201\n",
      "Epoch: 756 Loss: 0.8962343335151672\n",
      "Epoch: 757 Loss: 0.8960500955581665\n",
      "Epoch: 758 Loss: 0.8950425982475281\n",
      "Epoch: 759 Loss: 0.8948943018913269\n",
      "Epoch: 760 Loss: 0.8944159746170044\n",
      "Epoch: 761 Loss: 0.8925331830978394\n",
      "Epoch: 762 Loss: 0.8919810652732849\n",
      "Epoch: 763 Loss: 0.8920995593070984\n",
      "Epoch: 764 Loss: 0.8915975093841553\n",
      "Epoch: 765 Loss: 0.8900531530380249\n",
      "Epoch: 766 Loss: 0.8891499042510986\n",
      "Epoch: 767 Loss: 0.8882303833961487\n",
      "Epoch: 768 Loss: 0.8883121013641357\n",
      "Epoch: 769 Loss: 0.8872679471969604\n",
      "Epoch: 770 Loss: 0.8862667083740234\n",
      "Epoch: 771 Loss: 0.8863163590431213\n",
      "Epoch: 772 Loss: 0.8852733373641968\n",
      "Epoch: 773 Loss: 0.8860980868339539\n",
      "Epoch: 774 Loss: 0.8846304416656494\n",
      "Epoch: 775 Loss: 0.88294917345047\n",
      "Epoch: 776 Loss: 0.882257878780365\n",
      "Epoch: 777 Loss: 0.8813740611076355\n",
      "Epoch: 778 Loss: 0.8815998435020447\n",
      "Epoch: 779 Loss: 0.8805439472198486\n",
      "Epoch: 780 Loss: 0.8791654706001282\n",
      "Epoch: 781 Loss: 0.8806759119033813\n",
      "Epoch: 782 Loss: 0.8784986138343811\n",
      "Epoch: 783 Loss: 0.8792363405227661\n",
      "Epoch: 784 Loss: 0.8765811324119568\n",
      "Epoch: 785 Loss: 0.8760274648666382\n",
      "Epoch: 786 Loss: 0.8767827749252319\n",
      "Epoch: 787 Loss: 0.8749868869781494\n",
      "Epoch: 788 Loss: 0.8737624287605286\n",
      "Epoch: 789 Loss: 0.8730448484420776\n",
      "Epoch: 790 Loss: 0.8747959136962891\n",
      "Epoch: 791 Loss: 0.8723501563072205\n",
      "Epoch: 792 Loss: 0.8706629872322083\n",
      "Epoch: 793 Loss: 0.8721123933792114\n",
      "Epoch: 794 Loss: 0.8702184557914734\n",
      "Epoch: 795 Loss: 0.8694026470184326\n",
      "Epoch: 796 Loss: 0.8693532943725586\n",
      "Epoch: 797 Loss: 0.868234395980835\n",
      "Epoch: 798 Loss: 0.8667879700660706\n",
      "Epoch: 799 Loss: 0.8662824034690857\n",
      "Epoch: 800 Loss: 0.8648093938827515\n",
      "Epoch: 801 Loss: 0.8638328909873962\n",
      "Epoch: 802 Loss: 0.8648772239685059\n",
      "Epoch: 803 Loss: 0.864072322845459\n",
      "Epoch: 804 Loss: 0.8620994091033936\n",
      "Epoch: 805 Loss: 0.8624704480171204\n",
      "Epoch: 806 Loss: 0.8614914417266846\n",
      "Epoch: 807 Loss: 0.8601531982421875\n",
      "Epoch: 808 Loss: 0.8604055643081665\n",
      "Epoch: 809 Loss: 0.8588958382606506\n",
      "Epoch: 810 Loss: 0.8577859401702881\n",
      "Epoch: 811 Loss: 0.8584861159324646\n",
      "Epoch: 812 Loss: 0.8566892147064209\n",
      "Epoch: 813 Loss: 0.8561370968818665\n",
      "Epoch: 814 Loss: 0.8553144931793213\n",
      "Epoch: 815 Loss: 0.8552982807159424\n",
      "Epoch: 816 Loss: 0.8542934060096741\n",
      "Epoch: 817 Loss: 0.8530002236366272\n",
      "Epoch: 818 Loss: 0.8513256311416626\n",
      "Epoch: 819 Loss: 0.8507735133171082\n",
      "Epoch: 820 Loss: 0.8507674932479858\n",
      "Epoch: 821 Loss: 0.8493956327438354\n",
      "Epoch: 822 Loss: 0.8502305150032043\n",
      "Epoch: 823 Loss: 0.8480852246284485\n",
      "Epoch: 824 Loss: 0.8470544815063477\n",
      "Epoch: 825 Loss: 0.8468488454818726\n",
      "Epoch: 826 Loss: 0.8458262085914612\n",
      "Epoch: 827 Loss: 0.8445645570755005\n",
      "Epoch: 828 Loss: 0.8445495963096619\n",
      "Epoch: 829 Loss: 0.8443816900253296\n",
      "Epoch: 830 Loss: 0.8431374430656433\n",
      "Epoch: 831 Loss: 0.8419345021247864\n",
      "Epoch: 832 Loss: 0.8405612707138062\n",
      "Epoch: 833 Loss: 0.8399940133094788\n",
      "Epoch: 834 Loss: 0.8417214751243591\n",
      "Epoch: 835 Loss: 0.8389235734939575\n",
      "Epoch: 836 Loss: 0.8371381163597107\n",
      "Epoch: 837 Loss: 0.8370071649551392\n",
      "Epoch: 838 Loss: 0.836053729057312\n",
      "Epoch: 839 Loss: 0.837007999420166\n",
      "Epoch: 840 Loss: 0.8344486951828003\n",
      "Epoch: 841 Loss: 0.8331491947174072\n",
      "Epoch: 842 Loss: 0.8333651423454285\n",
      "Epoch: 843 Loss: 0.8316935896873474\n",
      "Epoch: 844 Loss: 0.8316571116447449\n",
      "Epoch: 845 Loss: 0.8307468295097351\n",
      "Epoch: 846 Loss: 0.829894483089447\n",
      "Epoch: 847 Loss: 0.8277652859687805\n",
      "Epoch: 848 Loss: 0.8296633958816528\n",
      "Epoch: 849 Loss: 0.8264901041984558\n",
      "Epoch: 850 Loss: 0.8266367316246033\n",
      "Epoch: 851 Loss: 0.8249275088310242\n",
      "Epoch: 852 Loss: 0.8244854807853699\n",
      "Epoch: 853 Loss: 0.8234022259712219\n",
      "Epoch: 854 Loss: 0.8225893378257751\n",
      "Epoch: 855 Loss: 0.8209017515182495\n",
      "Epoch: 856 Loss: 0.820393443107605\n",
      "Epoch: 857 Loss: 0.8202272653579712\n",
      "Epoch: 858 Loss: 0.8184807896614075\n",
      "Epoch: 859 Loss: 0.8177122473716736\n",
      "Epoch: 860 Loss: 0.8177322745323181\n",
      "Epoch: 861 Loss: 0.8165014982223511\n",
      "Epoch: 862 Loss: 0.8159669637680054\n",
      "Epoch: 863 Loss: 0.8151320219039917\n",
      "Epoch: 864 Loss: 0.8141038417816162\n",
      "Epoch: 865 Loss: 0.8123712539672852\n",
      "Epoch: 866 Loss: 0.8121601343154907\n",
      "Epoch: 867 Loss: 0.8108798265457153\n",
      "Epoch: 868 Loss: 0.8099146485328674\n",
      "Epoch: 869 Loss: 0.8090997934341431\n",
      "Epoch: 870 Loss: 0.8075357675552368\n",
      "Epoch: 871 Loss: 0.8075338006019592\n",
      "Epoch: 872 Loss: 0.8057376742362976\n",
      "Epoch: 873 Loss: 0.8052059412002563\n",
      "Epoch: 874 Loss: 0.8040773868560791\n",
      "Epoch: 875 Loss: 0.8041212558746338\n",
      "Epoch: 876 Loss: 0.8042187690734863\n",
      "Epoch: 877 Loss: 0.8015456795692444\n",
      "Epoch: 878 Loss: 0.8011847138404846\n",
      "Epoch: 879 Loss: 0.8004581928253174\n",
      "Epoch: 880 Loss: 0.7987592220306396\n",
      "Epoch: 881 Loss: 0.7982860803604126\n",
      "Epoch: 882 Loss: 0.7967932224273682\n",
      "Epoch: 883 Loss: 0.79600590467453\n",
      "Epoch: 884 Loss: 0.7970632910728455\n",
      "Epoch: 885 Loss: 0.7944902181625366\n",
      "Epoch: 886 Loss: 0.795183002948761\n",
      "Epoch: 887 Loss: 0.792688250541687\n",
      "Epoch: 888 Loss: 0.7923831343650818\n",
      "Epoch: 889 Loss: 0.7916980385780334\n",
      "Epoch: 890 Loss: 0.7895097136497498\n",
      "Epoch: 891 Loss: 0.7886884808540344\n",
      "Epoch: 892 Loss: 0.7888873219490051\n",
      "Epoch: 893 Loss: 0.7878271341323853\n",
      "Epoch: 894 Loss: 0.7870425581932068\n",
      "Epoch: 895 Loss: 0.7854029536247253\n",
      "Epoch: 896 Loss: 0.7847694754600525\n",
      "Epoch: 897 Loss: 0.7833943367004395\n",
      "Epoch: 898 Loss: 0.7834633588790894\n",
      "Epoch: 899 Loss: 0.7823451161384583\n",
      "Epoch: 900 Loss: 0.7817824482917786\n",
      "Epoch: 901 Loss: 0.7796052098274231\n",
      "Epoch: 902 Loss: 0.7790927290916443\n",
      "Epoch: 903 Loss: 0.778513491153717\n",
      "Epoch: 904 Loss: 0.7771899104118347\n",
      "Epoch: 905 Loss: 0.776828944683075\n",
      "Epoch: 906 Loss: 0.7755649089813232\n",
      "Epoch: 907 Loss: 0.7754218578338623\n",
      "Epoch: 908 Loss: 0.7732018232345581\n",
      "Epoch: 909 Loss: 0.773049533367157\n",
      "Epoch: 910 Loss: 0.7723431587219238\n",
      "Epoch: 911 Loss: 0.7703527212142944\n",
      "Epoch: 912 Loss: 0.769629716873169\n",
      "Epoch: 913 Loss: 0.7688260078430176\n",
      "Epoch: 914 Loss: 0.7693289518356323\n",
      "Epoch: 915 Loss: 0.7678055763244629\n",
      "Epoch: 916 Loss: 0.7662830948829651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 917 Loss: 0.7658336758613586\n",
      "Epoch: 918 Loss: 0.7644246816635132\n",
      "Epoch: 919 Loss: 0.7642066478729248\n",
      "Epoch: 920 Loss: 0.7636033296585083\n",
      "Epoch: 921 Loss: 0.7617868185043335\n",
      "Epoch: 922 Loss: 0.7605236172676086\n",
      "Epoch: 923 Loss: 0.7596681118011475\n",
      "Epoch: 924 Loss: 0.7591968178749084\n",
      "Epoch: 925 Loss: 0.7579259276390076\n",
      "Epoch: 926 Loss: 0.7570577263832092\n",
      "Epoch: 927 Loss: 0.755851686000824\n",
      "Epoch: 928 Loss: 0.7550821900367737\n",
      "Epoch: 929 Loss: 0.7555748820304871\n",
      "Epoch: 930 Loss: 0.7537617683410645\n",
      "Epoch: 931 Loss: 0.7533740997314453\n",
      "Epoch: 932 Loss: 0.7519095540046692\n",
      "Epoch: 933 Loss: 0.7503618597984314\n",
      "Epoch: 934 Loss: 0.7508559226989746\n",
      "Epoch: 935 Loss: 0.7491081357002258\n",
      "Epoch: 936 Loss: 0.7479967474937439\n",
      "Epoch: 937 Loss: 0.7467458844184875\n",
      "Epoch: 938 Loss: 0.7469519376754761\n",
      "Epoch: 939 Loss: 0.7451224327087402\n",
      "Epoch: 940 Loss: 0.7452773451805115\n",
      "Epoch: 941 Loss: 0.7438775897026062\n",
      "Epoch: 942 Loss: 0.7440063953399658\n",
      "Epoch: 943 Loss: 0.7416478991508484\n",
      "Epoch: 944 Loss: 0.7409866452217102\n",
      "Epoch: 945 Loss: 0.7407333254814148\n",
      "Epoch: 946 Loss: 0.7397807836532593\n",
      "Epoch: 947 Loss: 0.7388880848884583\n",
      "Epoch: 948 Loss: 0.7371573448181152\n",
      "Epoch: 949 Loss: 0.7371749877929688\n",
      "Epoch: 950 Loss: 0.7353942394256592\n",
      "Epoch: 951 Loss: 0.7355028986930847\n",
      "Epoch: 952 Loss: 0.7343140244483948\n",
      "Epoch: 953 Loss: 0.7335684895515442\n",
      "Epoch: 954 Loss: 0.731621265411377\n",
      "Epoch: 955 Loss: 0.7306050658226013\n",
      "Epoch: 956 Loss: 0.7299386262893677\n",
      "Epoch: 957 Loss: 0.7286848425865173\n",
      "Epoch: 958 Loss: 0.7292149662971497\n",
      "Epoch: 959 Loss: 0.7268946170806885\n",
      "Epoch: 960 Loss: 0.726043164730072\n",
      "Epoch: 961 Loss: 0.7260994911193848\n",
      "Epoch: 962 Loss: 0.7241031527519226\n",
      "Epoch: 963 Loss: 0.7234448790550232\n",
      "Epoch: 964 Loss: 0.7233800888061523\n",
      "Epoch: 965 Loss: 0.7218992114067078\n",
      "Epoch: 966 Loss: 0.7213122844696045\n",
      "Epoch: 967 Loss: 0.7196944952011108\n",
      "Epoch: 968 Loss: 0.7203447222709656\n",
      "Epoch: 969 Loss: 0.7178343534469604\n",
      "Epoch: 970 Loss: 0.7182825207710266\n",
      "Epoch: 971 Loss: 0.7160305380821228\n",
      "Epoch: 972 Loss: 0.7148135900497437\n",
      "Epoch: 973 Loss: 0.7148820757865906\n",
      "Epoch: 974 Loss: 0.7140876650810242\n",
      "Epoch: 975 Loss: 0.7120444178581238\n",
      "Epoch: 976 Loss: 0.7112337350845337\n",
      "Epoch: 977 Loss: 0.712172269821167\n",
      "Epoch: 978 Loss: 0.7110525369644165\n",
      "Epoch: 979 Loss: 0.7078072428703308\n",
      "Epoch: 980 Loss: 0.7087839245796204\n",
      "Epoch: 981 Loss: 0.7073322534561157\n",
      "Epoch: 982 Loss: 0.7066418528556824\n",
      "Epoch: 983 Loss: 0.7054805159568787\n",
      "Epoch: 984 Loss: 0.7043437361717224\n",
      "Epoch: 985 Loss: 0.7045240998268127\n",
      "Epoch: 986 Loss: 0.7024405598640442\n",
      "Epoch: 987 Loss: 0.701066255569458\n",
      "Epoch: 988 Loss: 0.6998966932296753\n",
      "Epoch: 989 Loss: 0.699153482913971\n",
      "Epoch: 990 Loss: 0.6981661319732666\n",
      "Epoch: 991 Loss: 0.6975107789039612\n",
      "Epoch: 992 Loss: 0.6975551247596741\n",
      "Epoch: 993 Loss: 0.6953892707824707\n",
      "Epoch: 994 Loss: 0.6959301233291626\n",
      "Epoch: 995 Loss: 0.6947282552719116\n",
      "Epoch: 996 Loss: 0.6935967206954956\n",
      "Epoch: 997 Loss: 0.6922389268875122\n",
      "Epoch: 998 Loss: 0.6910529136657715\n",
      "Epoch: 999 Loss: 0.6914209127426147\n",
      "Epoch: 1000 Loss: 0.6895052790641785\n",
      "Epoch: 1001 Loss: 0.6887175440788269\n",
      "Epoch: 1002 Loss: 0.6875007152557373\n",
      "Epoch: 1003 Loss: 0.687535285949707\n",
      "Epoch: 1004 Loss: 0.6854391098022461\n",
      "Epoch: 1005 Loss: 0.6852331161499023\n",
      "Epoch: 1006 Loss: 0.6832631826400757\n",
      "Epoch: 1007 Loss: 0.6829302906990051\n",
      "Epoch: 1008 Loss: 0.681903600692749\n",
      "Epoch: 1009 Loss: 0.68069988489151\n",
      "Epoch: 1010 Loss: 0.6801074147224426\n",
      "Epoch: 1011 Loss: 0.6790413856506348\n",
      "Epoch: 1012 Loss: 0.679767906665802\n",
      "Epoch: 1013 Loss: 0.679188072681427\n",
      "Epoch: 1014 Loss: 0.676799476146698\n",
      "Epoch: 1015 Loss: 0.67635577917099\n",
      "Epoch: 1016 Loss: 0.6757270097732544\n",
      "Epoch: 1017 Loss: 0.6739007234573364\n",
      "Epoch: 1018 Loss: 0.6738092303276062\n",
      "Epoch: 1019 Loss: 0.6728076338768005\n",
      "Epoch: 1020 Loss: 0.6718547940254211\n",
      "Epoch: 1021 Loss: 0.6701841950416565\n",
      "Epoch: 1022 Loss: 0.6693399548530579\n",
      "Epoch: 1023 Loss: 0.6680368185043335\n",
      "Epoch: 1024 Loss: 0.6682525873184204\n",
      "Epoch: 1025 Loss: 0.6667543053627014\n",
      "Epoch: 1026 Loss: 0.666499137878418\n",
      "Epoch: 1027 Loss: 0.6657741665840149\n",
      "Epoch: 1028 Loss: 0.6640245318412781\n",
      "Epoch: 1029 Loss: 0.6638358235359192\n",
      "Epoch: 1030 Loss: 0.6628357172012329\n",
      "Epoch: 1031 Loss: 0.661492645740509\n",
      "Epoch: 1032 Loss: 0.6604442596435547\n",
      "Epoch: 1033 Loss: 0.6590974926948547\n",
      "Epoch: 1034 Loss: 0.6579622626304626\n",
      "Epoch: 1035 Loss: 0.6585046648979187\n",
      "Epoch: 1036 Loss: 0.6573895215988159\n",
      "Epoch: 1037 Loss: 0.656106173992157\n",
      "Epoch: 1038 Loss: 0.6558315753936768\n",
      "Epoch: 1039 Loss: 0.6542606353759766\n",
      "Epoch: 1040 Loss: 0.6535154581069946\n",
      "Epoch: 1041 Loss: 0.6520102024078369\n",
      "Epoch: 1042 Loss: 0.653200626373291\n",
      "Epoch: 1043 Loss: 0.6501811146736145\n",
      "Epoch: 1044 Loss: 0.650414764881134\n",
      "Epoch: 1045 Loss: 0.64829421043396\n",
      "Epoch: 1046 Loss: 0.6475111246109009\n",
      "Epoch: 1047 Loss: 0.6482959389686584\n",
      "Epoch: 1048 Loss: 0.6456201076507568\n",
      "Epoch: 1049 Loss: 0.6452354192733765\n",
      "Epoch: 1050 Loss: 0.6435734629631042\n",
      "Epoch: 1051 Loss: 0.6440201997756958\n",
      "Epoch: 1052 Loss: 0.642553448677063\n",
      "Epoch: 1053 Loss: 0.6424815654754639\n",
      "Epoch: 1054 Loss: 0.6413895487785339\n",
      "Epoch: 1055 Loss: 0.6400511264801025\n",
      "Epoch: 1056 Loss: 0.6387056708335876\n",
      "Epoch: 1057 Loss: 0.6382201910018921\n",
      "Epoch: 1058 Loss: 0.6378809213638306\n",
      "Epoch: 1059 Loss: 0.6366603970527649\n",
      "Epoch: 1060 Loss: 0.6348059773445129\n",
      "Epoch: 1061 Loss: 0.6340509057044983\n",
      "Epoch: 1062 Loss: 0.6331567168235779\n",
      "Epoch: 1063 Loss: 0.6315113306045532\n",
      "Epoch: 1064 Loss: 0.6308647990226746\n",
      "Epoch: 1065 Loss: 0.6298930048942566\n",
      "Epoch: 1066 Loss: 0.6294078826904297\n",
      "Epoch: 1067 Loss: 0.6274597644805908\n",
      "Epoch: 1068 Loss: 0.6272784471511841\n",
      "Epoch: 1069 Loss: 0.6259149312973022\n",
      "Epoch: 1070 Loss: 0.6247583031654358\n",
      "Epoch: 1071 Loss: 0.6240695714950562\n",
      "Epoch: 1072 Loss: 0.6228683590888977\n",
      "Epoch: 1073 Loss: 0.6213265061378479\n",
      "Epoch: 1074 Loss: 0.6214772462844849\n",
      "Epoch: 1075 Loss: 0.6201381087303162\n",
      "Epoch: 1076 Loss: 0.6186183094978333\n",
      "Epoch: 1077 Loss: 0.6178039908409119\n",
      "Epoch: 1078 Loss: 0.6166980266571045\n",
      "Epoch: 1079 Loss: 0.615586519241333\n",
      "Epoch: 1080 Loss: 0.6151725053787231\n",
      "Epoch: 1081 Loss: 0.6138404011726379\n",
      "Epoch: 1082 Loss: 0.6129373908042908\n",
      "Epoch: 1083 Loss: 0.611801028251648\n",
      "Epoch: 1084 Loss: 0.6113685965538025\n",
      "Epoch: 1085 Loss: 0.6101540923118591\n",
      "Epoch: 1086 Loss: 0.6098706126213074\n",
      "Epoch: 1087 Loss: 0.6086574196815491\n",
      "Epoch: 1088 Loss: 0.6076081991195679\n",
      "Epoch: 1089 Loss: 0.6067571640014648\n",
      "Epoch: 1090 Loss: 0.6052443981170654\n",
      "Epoch: 1091 Loss: 0.6051852703094482\n",
      "Epoch: 1092 Loss: 0.6033948659896851\n",
      "Epoch: 1093 Loss: 0.602715015411377\n",
      "Epoch: 1094 Loss: 0.6012200713157654\n",
      "Epoch: 1095 Loss: 0.6007455587387085\n",
      "Epoch: 1096 Loss: 0.5995863080024719\n",
      "Epoch: 1097 Loss: 0.5988271832466125\n",
      "Epoch: 1098 Loss: 0.5978882908821106\n",
      "Epoch: 1099 Loss: 0.5966308116912842\n",
      "Epoch: 1100 Loss: 0.5963206887245178\n",
      "Epoch: 1101 Loss: 0.5953530073165894\n",
      "Epoch: 1102 Loss: 0.5940694212913513\n",
      "Epoch: 1103 Loss: 0.5928331017494202\n",
      "Epoch: 1104 Loss: 0.592182993888855\n",
      "Epoch: 1105 Loss: 0.5911890864372253\n",
      "Epoch: 1106 Loss: 0.5900278687477112\n",
      "Epoch: 1107 Loss: 0.5898397564888\n",
      "Epoch: 1108 Loss: 0.5885818004608154\n",
      "Epoch: 1109 Loss: 0.5872271656990051\n",
      "Epoch: 1110 Loss: 0.5863556265830994\n",
      "Epoch: 1111 Loss: 0.5860519409179688\n",
      "Epoch: 1112 Loss: 0.5845165252685547\n",
      "Epoch: 1113 Loss: 0.5836762189865112\n",
      "Epoch: 1114 Loss: 0.5830022096633911\n",
      "Epoch: 1115 Loss: 0.5824652910232544\n",
      "Epoch: 1116 Loss: 0.5809525847434998\n",
      "Epoch: 1117 Loss: 0.5798592567443848\n",
      "Epoch: 1118 Loss: 0.5787220597267151\n",
      "Epoch: 1119 Loss: 0.5779539942741394\n",
      "Epoch: 1120 Loss: 0.5767520070075989\n",
      "Epoch: 1121 Loss: 0.5765615105628967\n",
      "Epoch: 1122 Loss: 0.5756430625915527\n",
      "Epoch: 1123 Loss: 0.574386715888977\n",
      "Epoch: 1124 Loss: 0.5729444026947021\n",
      "Epoch: 1125 Loss: 0.5722498297691345\n",
      "Epoch: 1126 Loss: 0.5714660882949829\n",
      "Epoch: 1127 Loss: 0.5708966851234436\n",
      "Epoch: 1128 Loss: 0.569464385509491\n",
      "Epoch: 1129 Loss: 0.5688768625259399\n",
      "Epoch: 1130 Loss: 0.5677973628044128\n",
      "Epoch: 1131 Loss: 0.5666533708572388\n",
      "Epoch: 1132 Loss: 0.5659987330436707\n",
      "Epoch: 1133 Loss: 0.5650312304496765\n",
      "Epoch: 1134 Loss: 0.5637196898460388\n",
      "Epoch: 1135 Loss: 0.5633097887039185\n",
      "Epoch: 1136 Loss: 0.5620519518852234\n",
      "Epoch: 1137 Loss: 0.5611621737480164\n",
      "Epoch: 1138 Loss: 0.5600271821022034\n",
      "Epoch: 1139 Loss: 0.5589486360549927\n",
      "Epoch: 1140 Loss: 0.5584301948547363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1141 Loss: 0.5578786134719849\n",
      "Epoch: 1142 Loss: 0.5572047829627991\n",
      "Epoch: 1143 Loss: 0.5561752319335938\n",
      "Epoch: 1144 Loss: 0.554753303527832\n",
      "Epoch: 1145 Loss: 0.5540217757225037\n",
      "Epoch: 1146 Loss: 0.5529293417930603\n",
      "Epoch: 1147 Loss: 0.5527163147926331\n",
      "Epoch: 1148 Loss: 0.5513776540756226\n",
      "Epoch: 1149 Loss: 0.5501625537872314\n",
      "Epoch: 1150 Loss: 0.5498420000076294\n",
      "Epoch: 1151 Loss: 0.5484408736228943\n",
      "Epoch: 1152 Loss: 0.5476326942443848\n",
      "Epoch: 1153 Loss: 0.5470748543739319\n",
      "Epoch: 1154 Loss: 0.5459793210029602\n",
      "Epoch: 1155 Loss: 0.5454975366592407\n",
      "Epoch: 1156 Loss: 0.5441316366195679\n",
      "Epoch: 1157 Loss: 0.5430188775062561\n",
      "Epoch: 1158 Loss: 0.5423689484596252\n",
      "Epoch: 1159 Loss: 0.54164057970047\n",
      "Epoch: 1160 Loss: 0.5406807661056519\n",
      "Epoch: 1161 Loss: 0.5396685600280762\n",
      "Epoch: 1162 Loss: 0.5391404032707214\n",
      "Epoch: 1163 Loss: 0.538253128528595\n",
      "Epoch: 1164 Loss: 0.5368703007698059\n",
      "Epoch: 1165 Loss: 0.5366700291633606\n",
      "Epoch: 1166 Loss: 0.5359495878219604\n",
      "Epoch: 1167 Loss: 0.5345215797424316\n",
      "Epoch: 1168 Loss: 0.5335323214530945\n",
      "Epoch: 1169 Loss: 0.532646119594574\n",
      "Epoch: 1170 Loss: 0.5315454006195068\n",
      "Epoch: 1171 Loss: 0.5309368371963501\n",
      "Epoch: 1172 Loss: 0.5300069451332092\n",
      "Epoch: 1173 Loss: 0.5290024280548096\n",
      "Epoch: 1174 Loss: 0.5279905200004578\n",
      "Epoch: 1175 Loss: 0.5271733999252319\n",
      "Epoch: 1176 Loss: 0.5267869830131531\n",
      "Epoch: 1177 Loss: 0.5262870788574219\n",
      "Epoch: 1178 Loss: 0.5249212384223938\n",
      "Epoch: 1179 Loss: 0.523727297782898\n",
      "Epoch: 1180 Loss: 0.5226756930351257\n",
      "Epoch: 1181 Loss: 0.5221984386444092\n",
      "Epoch: 1182 Loss: 0.5215306878089905\n",
      "Epoch: 1183 Loss: 0.5209425091743469\n",
      "Epoch: 1184 Loss: 0.519711971282959\n",
      "Epoch: 1185 Loss: 0.5186015963554382\n",
      "Epoch: 1186 Loss: 0.5182257890701294\n",
      "Epoch: 1187 Loss: 0.5170776844024658\n",
      "Epoch: 1188 Loss: 0.5162286758422852\n",
      "Epoch: 1189 Loss: 0.5153788328170776\n",
      "Epoch: 1190 Loss: 0.5148975253105164\n",
      "Epoch: 1191 Loss: 0.5145792961120605\n",
      "Epoch: 1192 Loss: 0.5130531191825867\n",
      "Epoch: 1193 Loss: 0.5123216509819031\n",
      "Epoch: 1194 Loss: 0.5110583305358887\n",
      "Epoch: 1195 Loss: 0.509972333908081\n",
      "Epoch: 1196 Loss: 0.5093833208084106\n",
      "Epoch: 1197 Loss: 0.5086772441864014\n",
      "Epoch: 1198 Loss: 0.5081235766410828\n",
      "Epoch: 1199 Loss: 0.5073111057281494\n",
      "Epoch: 1200 Loss: 0.5059940814971924\n",
      "Epoch: 1201 Loss: 0.5052796006202698\n",
      "Epoch: 1202 Loss: 0.5047211050987244\n",
      "Epoch: 1203 Loss: 0.5038405656814575\n",
      "Epoch: 1204 Loss: 0.5022789835929871\n",
      "Epoch: 1205 Loss: 0.50248122215271\n",
      "Epoch: 1206 Loss: 0.5009129047393799\n",
      "Epoch: 1207 Loss: 0.5000367164611816\n",
      "Epoch: 1208 Loss: 0.499600350856781\n",
      "Epoch: 1209 Loss: 0.49894848465919495\n",
      "Epoch: 1210 Loss: 0.49822068214416504\n",
      "Epoch: 1211 Loss: 0.4974333941936493\n",
      "Epoch: 1212 Loss: 0.4960220158100128\n",
      "Epoch: 1213 Loss: 0.49497389793395996\n",
      "Epoch: 1214 Loss: 0.4946848154067993\n",
      "Epoch: 1215 Loss: 0.49401065707206726\n",
      "Epoch: 1216 Loss: 0.4930734634399414\n",
      "Epoch: 1217 Loss: 0.492515504360199\n",
      "Epoch: 1218 Loss: 0.49093395471572876\n",
      "Epoch: 1219 Loss: 0.49025583267211914\n",
      "Epoch: 1220 Loss: 0.48919668793678284\n",
      "Epoch: 1221 Loss: 0.4886101186275482\n",
      "Epoch: 1222 Loss: 0.48803749680519104\n",
      "Epoch: 1223 Loss: 0.4872581958770752\n",
      "Epoch: 1224 Loss: 0.486362099647522\n",
      "Epoch: 1225 Loss: 0.48551908135414124\n",
      "Epoch: 1226 Loss: 0.4845135807991028\n",
      "Epoch: 1227 Loss: 0.4845229983329773\n",
      "Epoch: 1228 Loss: 0.483210027217865\n",
      "Epoch: 1229 Loss: 0.48198163509368896\n",
      "Epoch: 1230 Loss: 0.4815472364425659\n",
      "Epoch: 1231 Loss: 0.4804098904132843\n",
      "Epoch: 1232 Loss: 0.4794468581676483\n",
      "Epoch: 1233 Loss: 0.4791591763496399\n",
      "Epoch: 1234 Loss: 0.4785693287849426\n",
      "Epoch: 1235 Loss: 0.47727081179618835\n",
      "Epoch: 1236 Loss: 0.4770786464214325\n",
      "Epoch: 1237 Loss: 0.47568726539611816\n",
      "Epoch: 1238 Loss: 0.4751374423503876\n",
      "Epoch: 1239 Loss: 0.4737444818019867\n",
      "Epoch: 1240 Loss: 0.4735378324985504\n",
      "Epoch: 1241 Loss: 0.47226986289024353\n",
      "Epoch: 1242 Loss: 0.47212299704551697\n",
      "Epoch: 1243 Loss: 0.4715515971183777\n",
      "Epoch: 1244 Loss: 0.47021716833114624\n",
      "Epoch: 1245 Loss: 0.4694867730140686\n",
      "Epoch: 1246 Loss: 0.4683587849140167\n",
      "Epoch: 1247 Loss: 0.46752166748046875\n",
      "Epoch: 1248 Loss: 0.46649330854415894\n",
      "Epoch: 1249 Loss: 0.4675087630748749\n",
      "Epoch: 1250 Loss: 0.46580106019973755\n",
      "Epoch: 1251 Loss: 0.46517497301101685\n",
      "Epoch: 1252 Loss: 0.4634028971195221\n",
      "Epoch: 1253 Loss: 0.4630957841873169\n",
      "Epoch: 1254 Loss: 0.4621691107749939\n",
      "Epoch: 1255 Loss: 0.4620511829853058\n",
      "Epoch: 1256 Loss: 0.4603443145751953\n",
      "Epoch: 1257 Loss: 0.4603036642074585\n",
      "Epoch: 1258 Loss: 0.4588949382305145\n",
      "Epoch: 1259 Loss: 0.45816633105278015\n",
      "Epoch: 1260 Loss: 0.4577222168445587\n",
      "Epoch: 1261 Loss: 0.45716631412506104\n",
      "Epoch: 1262 Loss: 0.45560067892074585\n",
      "Epoch: 1263 Loss: 0.4554513990879059\n",
      "Epoch: 1264 Loss: 0.45397916436195374\n",
      "Epoch: 1265 Loss: 0.4532412588596344\n",
      "Epoch: 1266 Loss: 0.45235684514045715\n",
      "Epoch: 1267 Loss: 0.4520372748374939\n",
      "Epoch: 1268 Loss: 0.4508110582828522\n",
      "Epoch: 1269 Loss: 0.45039883255958557\n",
      "Epoch: 1270 Loss: 0.4493947923183441\n",
      "Epoch: 1271 Loss: 0.4489597976207733\n",
      "Epoch: 1272 Loss: 0.44888707995414734\n",
      "Epoch: 1273 Loss: 0.4474131762981415\n",
      "Epoch: 1274 Loss: 0.44680124521255493\n",
      "Epoch: 1275 Loss: 0.44577276706695557\n",
      "Epoch: 1276 Loss: 0.44483622908592224\n",
      "Epoch: 1277 Loss: 0.4445202946662903\n",
      "Epoch: 1278 Loss: 0.4432539939880371\n",
      "Epoch: 1279 Loss: 0.4428783357143402\n",
      "Epoch: 1280 Loss: 0.4415542185306549\n",
      "Epoch: 1281 Loss: 0.4415321350097656\n",
      "Epoch: 1282 Loss: 0.4400580823421478\n",
      "Epoch: 1283 Loss: 0.4396441578865051\n",
      "Epoch: 1284 Loss: 0.43910762667655945\n",
      "Epoch: 1285 Loss: 0.4377966821193695\n",
      "Epoch: 1286 Loss: 0.43702253699302673\n",
      "Epoch: 1287 Loss: 0.43658819794654846\n",
      "Epoch: 1288 Loss: 0.4355488717556\n",
      "Epoch: 1289 Loss: 0.4347716271877289\n",
      "Epoch: 1290 Loss: 0.434161901473999\n",
      "Epoch: 1291 Loss: 0.43359142541885376\n",
      "Epoch: 1292 Loss: 0.43235522508621216\n",
      "Epoch: 1293 Loss: 0.43244683742523193\n",
      "Epoch: 1294 Loss: 0.43101105093955994\n",
      "Epoch: 1295 Loss: 0.43009474873542786\n",
      "Epoch: 1296 Loss: 0.4295318126678467\n",
      "Epoch: 1297 Loss: 0.4295131266117096\n",
      "Epoch: 1298 Loss: 0.42819473147392273\n",
      "Epoch: 1299 Loss: 0.42728981375694275\n",
      "Epoch: 1300 Loss: 0.4268580377101898\n",
      "Epoch: 1301 Loss: 0.42649197578430176\n",
      "Epoch: 1302 Loss: 0.42574435472488403\n",
      "Epoch: 1303 Loss: 0.4240735173225403\n",
      "Epoch: 1304 Loss: 0.4234987199306488\n",
      "Epoch: 1305 Loss: 0.4227777123451233\n",
      "Epoch: 1306 Loss: 0.42219868302345276\n",
      "Epoch: 1307 Loss: 0.4223269522190094\n",
      "Epoch: 1308 Loss: 0.42045730352401733\n",
      "Epoch: 1309 Loss: 0.41971448063850403\n",
      "Epoch: 1310 Loss: 0.4187546372413635\n",
      "Epoch: 1311 Loss: 0.41840773820877075\n",
      "Epoch: 1312 Loss: 0.41788357496261597\n",
      "Epoch: 1313 Loss: 0.41664403676986694\n",
      "Epoch: 1314 Loss: 0.4158835709095001\n",
      "Epoch: 1315 Loss: 0.4151541292667389\n",
      "Epoch: 1316 Loss: 0.4146738350391388\n",
      "Epoch: 1317 Loss: 0.413735955953598\n",
      "Epoch: 1318 Loss: 0.4131512939929962\n",
      "Epoch: 1319 Loss: 0.41223809123039246\n",
      "Epoch: 1320 Loss: 0.4121040105819702\n",
      "Epoch: 1321 Loss: 0.4106632471084595\n",
      "Epoch: 1322 Loss: 0.4107445776462555\n",
      "Epoch: 1323 Loss: 0.4092038869857788\n",
      "Epoch: 1324 Loss: 0.40893611311912537\n",
      "Epoch: 1325 Loss: 0.4079252779483795\n",
      "Epoch: 1326 Loss: 0.40716856718063354\n",
      "Epoch: 1327 Loss: 0.4059240221977234\n",
      "Epoch: 1328 Loss: 0.4056626260280609\n",
      "Epoch: 1329 Loss: 0.4045696556568146\n",
      "Epoch: 1330 Loss: 0.4038563370704651\n",
      "Epoch: 1331 Loss: 0.4028162956237793\n",
      "Epoch: 1332 Loss: 0.40214774012565613\n",
      "Epoch: 1333 Loss: 0.4011855721473694\n",
      "Epoch: 1334 Loss: 0.4016108214855194\n",
      "Epoch: 1335 Loss: 0.3999597132205963\n",
      "Epoch: 1336 Loss: 0.39987415075302124\n",
      "Epoch: 1337 Loss: 0.39826881885528564\n",
      "Epoch: 1338 Loss: 0.3979974389076233\n",
      "Epoch: 1339 Loss: 0.3973964750766754\n",
      "Epoch: 1340 Loss: 0.3970447778701782\n",
      "Epoch: 1341 Loss: 0.39600852131843567\n",
      "Epoch: 1342 Loss: 0.3946666717529297\n",
      "Epoch: 1343 Loss: 0.3937780559062958\n",
      "Epoch: 1344 Loss: 0.39409106969833374\n",
      "Epoch: 1345 Loss: 0.392537385225296\n",
      "Epoch: 1346 Loss: 0.39273402094841003\n",
      "Epoch: 1347 Loss: 0.39188244938850403\n",
      "Epoch: 1348 Loss: 0.39045143127441406\n",
      "Epoch: 1349 Loss: 0.38963738083839417\n",
      "Epoch: 1350 Loss: 0.38891860842704773\n",
      "Epoch: 1351 Loss: 0.3885463774204254\n",
      "Epoch: 1352 Loss: 0.38753390312194824\n",
      "Epoch: 1353 Loss: 0.3877541422843933\n",
      "Epoch: 1354 Loss: 0.3860374689102173\n",
      "Epoch: 1355 Loss: 0.3852018713951111\n",
      "Epoch: 1356 Loss: 0.38512176275253296\n",
      "Epoch: 1357 Loss: 0.3836255371570587\n",
      "Epoch: 1358 Loss: 0.383975625038147\n",
      "Epoch: 1359 Loss: 0.38324180245399475\n",
      "Epoch: 1360 Loss: 0.38173022866249084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1361 Loss: 0.3813348710536957\n",
      "Epoch: 1362 Loss: 0.3804241716861725\n",
      "Epoch: 1363 Loss: 0.38091710209846497\n",
      "Epoch: 1364 Loss: 0.3790685534477234\n",
      "Epoch: 1365 Loss: 0.37828388810157776\n",
      "Epoch: 1366 Loss: 0.37794965505599976\n",
      "Epoch: 1367 Loss: 0.37711581587791443\n",
      "Epoch: 1368 Loss: 0.376871794462204\n",
      "Epoch: 1369 Loss: 0.3755810260772705\n",
      "Epoch: 1370 Loss: 0.3763425052165985\n",
      "Epoch: 1371 Loss: 0.375156044960022\n",
      "Epoch: 1372 Loss: 0.374043345451355\n",
      "Epoch: 1373 Loss: 0.37314683198928833\n",
      "Epoch: 1374 Loss: 0.3726581931114197\n",
      "Epoch: 1375 Loss: 0.37171319127082825\n",
      "Epoch: 1376 Loss: 0.3712460994720459\n",
      "Epoch: 1377 Loss: 0.37088415026664734\n",
      "Epoch: 1378 Loss: 0.3695302903652191\n",
      "Epoch: 1379 Loss: 0.3689679801464081\n",
      "Epoch: 1380 Loss: 0.368332177400589\n",
      "Epoch: 1381 Loss: 0.367782324552536\n",
      "Epoch: 1382 Loss: 0.3667169511318207\n",
      "Epoch: 1383 Loss: 0.3672838509082794\n",
      "Epoch: 1384 Loss: 0.36589735746383667\n",
      "Epoch: 1385 Loss: 0.3650367558002472\n",
      "Epoch: 1386 Loss: 0.3644337058067322\n",
      "Epoch: 1387 Loss: 0.36341482400894165\n",
      "Epoch: 1388 Loss: 0.36280596256256104\n",
      "Epoch: 1389 Loss: 0.3620600402355194\n",
      "Epoch: 1390 Loss: 0.36166059970855713\n",
      "Epoch: 1391 Loss: 0.36099472641944885\n",
      "Epoch: 1392 Loss: 0.36019226908683777\n",
      "Epoch: 1393 Loss: 0.35926803946495056\n",
      "Epoch: 1394 Loss: 0.35879626870155334\n",
      "Epoch: 1395 Loss: 0.3579535484313965\n",
      "Epoch: 1396 Loss: 0.35780590772628784\n",
      "Epoch: 1397 Loss: 0.3565632104873657\n",
      "Epoch: 1398 Loss: 0.35699859261512756\n",
      "Epoch: 1399 Loss: 0.3552163243293762\n",
      "Epoch: 1400 Loss: 0.35520225763320923\n",
      "Epoch: 1401 Loss: 0.35463300347328186\n",
      "Epoch: 1402 Loss: 0.3540121614933014\n",
      "Epoch: 1403 Loss: 0.3534247875213623\n",
      "Epoch: 1404 Loss: 0.3531584143638611\n",
      "Epoch: 1405 Loss: 0.35232916474342346\n",
      "Epoch: 1406 Loss: 0.3511783480644226\n",
      "Epoch: 1407 Loss: 0.3507532477378845\n",
      "Epoch: 1408 Loss: 0.34938737750053406\n",
      "Epoch: 1409 Loss: 0.34904778003692627\n",
      "Epoch: 1410 Loss: 0.34814125299453735\n",
      "Epoch: 1411 Loss: 0.3487619161605835\n",
      "Epoch: 1412 Loss: 0.3470165729522705\n",
      "Epoch: 1413 Loss: 0.3464027941226959\n",
      "Epoch: 1414 Loss: 0.34606000781059265\n",
      "Epoch: 1415 Loss: 0.34496790170669556\n",
      "Epoch: 1416 Loss: 0.3448706865310669\n",
      "Epoch: 1417 Loss: 0.34356027841567993\n",
      "Epoch: 1418 Loss: 0.34423568844795227\n",
      "Epoch: 1419 Loss: 0.3425406813621521\n",
      "Epoch: 1420 Loss: 0.3423672914505005\n",
      "Epoch: 1421 Loss: 0.3414202034473419\n",
      "Epoch: 1422 Loss: 0.3412080407142639\n",
      "Epoch: 1423 Loss: 0.34028497338294983\n",
      "Epoch: 1424 Loss: 0.3392421305179596\n",
      "Epoch: 1425 Loss: 0.3385952115058899\n",
      "Epoch: 1426 Loss: 0.3390297591686249\n",
      "Epoch: 1427 Loss: 0.33764660358428955\n",
      "Epoch: 1428 Loss: 0.337808758020401\n",
      "Epoch: 1429 Loss: 0.3368358612060547\n",
      "Epoch: 1430 Loss: 0.335947722196579\n",
      "Epoch: 1431 Loss: 0.33495062589645386\n",
      "Epoch: 1432 Loss: 0.3345052897930145\n",
      "Epoch: 1433 Loss: 0.33362245559692383\n",
      "Epoch: 1434 Loss: 0.3327188491821289\n",
      "Epoch: 1435 Loss: 0.3323470652103424\n",
      "Epoch: 1436 Loss: 0.33157891035079956\n",
      "Epoch: 1437 Loss: 0.3306775391101837\n",
      "Epoch: 1438 Loss: 0.3309535086154938\n",
      "Epoch: 1439 Loss: 0.3310590386390686\n",
      "Epoch: 1440 Loss: 0.3297260105609894\n",
      "Epoch: 1441 Loss: 0.32840368151664734\n",
      "Epoch: 1442 Loss: 0.3290311396121979\n",
      "Epoch: 1443 Loss: 0.3273460566997528\n",
      "Epoch: 1444 Loss: 0.32755523920059204\n",
      "Epoch: 1445 Loss: 0.32609933614730835\n",
      "Epoch: 1446 Loss: 0.3252551555633545\n",
      "Epoch: 1447 Loss: 0.3248654901981354\n",
      "Epoch: 1448 Loss: 0.3241529166698456\n",
      "Epoch: 1449 Loss: 0.32412800192832947\n",
      "Epoch: 1450 Loss: 0.32257401943206787\n",
      "Epoch: 1451 Loss: 0.3223940432071686\n",
      "Epoch: 1452 Loss: 0.32185500860214233\n",
      "Epoch: 1453 Loss: 0.32118359208106995\n",
      "Epoch: 1454 Loss: 0.3208358585834503\n",
      "Epoch: 1455 Loss: 0.3197160065174103\n",
      "Epoch: 1456 Loss: 0.3201580047607422\n",
      "Epoch: 1457 Loss: 0.31856489181518555\n",
      "Epoch: 1458 Loss: 0.319013774394989\n",
      "Epoch: 1459 Loss: 0.31766384840011597\n",
      "Epoch: 1460 Loss: 0.31762707233428955\n",
      "Epoch: 1461 Loss: 0.3165079653263092\n",
      "Epoch: 1462 Loss: 0.31590577960014343\n",
      "Epoch: 1463 Loss: 0.3159792125225067\n",
      "Epoch: 1464 Loss: 0.3146829605102539\n",
      "Epoch: 1465 Loss: 0.3142942488193512\n",
      "Epoch: 1466 Loss: 0.31357553601264954\n",
      "Epoch: 1467 Loss: 0.31332311034202576\n",
      "Epoch: 1468 Loss: 0.3127457797527313\n",
      "Epoch: 1469 Loss: 0.31177186965942383\n",
      "Epoch: 1470 Loss: 0.31147193908691406\n",
      "Epoch: 1471 Loss: 0.31052565574645996\n",
      "Epoch: 1472 Loss: 0.31124308705329895\n",
      "Epoch: 1473 Loss: 0.30929866433143616\n",
      "Epoch: 1474 Loss: 0.30903029441833496\n",
      "Epoch: 1475 Loss: 0.30887317657470703\n",
      "Epoch: 1476 Loss: 0.30747655034065247\n",
      "Epoch: 1477 Loss: 0.3076903522014618\n",
      "Epoch: 1478 Loss: 0.3064521551132202\n",
      "Epoch: 1479 Loss: 0.30602672696113586\n",
      "Epoch: 1480 Loss: 0.3051794171333313\n",
      "Epoch: 1481 Loss: 0.304720401763916\n",
      "Epoch: 1482 Loss: 0.30429714918136597\n",
      "Epoch: 1483 Loss: 0.30382826924324036\n",
      "Epoch: 1484 Loss: 0.30304375290870667\n",
      "Epoch: 1485 Loss: 0.30218270421028137\n",
      "Epoch: 1486 Loss: 0.3023998439311981\n",
      "Epoch: 1487 Loss: 0.3009811043739319\n",
      "Epoch: 1488 Loss: 0.3010730743408203\n",
      "Epoch: 1489 Loss: 0.30001795291900635\n",
      "Epoch: 1490 Loss: 0.2999104857444763\n",
      "Epoch: 1491 Loss: 0.2991967797279358\n",
      "Epoch: 1492 Loss: 0.29854926466941833\n",
      "Epoch: 1493 Loss: 0.2983247637748718\n",
      "Epoch: 1494 Loss: 0.2972276508808136\n",
      "Epoch: 1495 Loss: 0.2971998155117035\n",
      "Epoch: 1496 Loss: 0.296241819858551\n",
      "Epoch: 1497 Loss: 0.29605868458747864\n",
      "Epoch: 1498 Loss: 0.29587751626968384\n",
      "Epoch: 1499 Loss: 0.2949411869049072\n",
      "Epoch: 1500 Loss: 0.29400840401649475\n",
      "Epoch: 1501 Loss: 0.2938755750656128\n",
      "Epoch: 1502 Loss: 0.293173223733902\n",
      "Epoch: 1503 Loss: 0.29275137186050415\n",
      "Epoch: 1504 Loss: 0.2923729717731476\n",
      "Epoch: 1505 Loss: 0.2917749583721161\n",
      "Epoch: 1506 Loss: 0.29095587134361267\n",
      "Epoch: 1507 Loss: 0.29042091965675354\n",
      "Epoch: 1508 Loss: 0.29033470153808594\n",
      "Epoch: 1509 Loss: 0.2893165946006775\n",
      "Epoch: 1510 Loss: 0.28950533270835876\n",
      "Epoch: 1511 Loss: 0.2885478138923645\n",
      "Epoch: 1512 Loss: 0.2877632975578308\n",
      "Epoch: 1513 Loss: 0.2871793806552887\n",
      "Epoch: 1514 Loss: 0.2869214117527008\n",
      "Epoch: 1515 Loss: 0.28712308406829834\n",
      "Epoch: 1516 Loss: 0.28665727376937866\n",
      "Epoch: 1517 Loss: 0.28524044156074524\n",
      "Epoch: 1518 Loss: 0.28533992171287537\n",
      "Epoch: 1519 Loss: 0.2843470871448517\n",
      "Epoch: 1520 Loss: 0.28396162390708923\n",
      "Epoch: 1521 Loss: 0.2835128903388977\n",
      "Epoch: 1522 Loss: 0.28267425298690796\n",
      "Epoch: 1523 Loss: 0.2828516364097595\n",
      "Epoch: 1524 Loss: 0.28153759241104126\n",
      "Epoch: 1525 Loss: 0.2812453806400299\n",
      "Epoch: 1526 Loss: 0.2812090218067169\n",
      "Epoch: 1527 Loss: 0.28015798330307007\n",
      "Epoch: 1528 Loss: 0.2797752618789673\n",
      "Epoch: 1529 Loss: 0.27939242124557495\n",
      "Epoch: 1530 Loss: 0.2785375714302063\n",
      "Epoch: 1531 Loss: 0.2785986661911011\n",
      "Epoch: 1532 Loss: 0.2773568034172058\n",
      "Epoch: 1533 Loss: 0.2768070101737976\n",
      "Epoch: 1534 Loss: 0.2764965891838074\n",
      "Epoch: 1535 Loss: 0.2759000360965729\n",
      "Epoch: 1536 Loss: 0.2751617133617401\n",
      "Epoch: 1537 Loss: 0.27539145946502686\n",
      "Epoch: 1538 Loss: 0.27455586194992065\n",
      "Epoch: 1539 Loss: 0.27404147386550903\n",
      "Epoch: 1540 Loss: 0.27391424775123596\n",
      "Epoch: 1541 Loss: 0.2737753987312317\n",
      "Epoch: 1542 Loss: 0.2727324962615967\n",
      "Epoch: 1543 Loss: 0.2725326716899872\n",
      "Epoch: 1544 Loss: 0.27143457531929016\n",
      "Epoch: 1545 Loss: 0.27128568291664124\n",
      "Epoch: 1546 Loss: 0.2709152102470398\n",
      "Epoch: 1547 Loss: 0.269915908575058\n",
      "Epoch: 1548 Loss: 0.27018457651138306\n",
      "Epoch: 1549 Loss: 0.26897308230400085\n",
      "Epoch: 1550 Loss: 0.26872581243515015\n",
      "Epoch: 1551 Loss: 0.26860111951828003\n",
      "Epoch: 1552 Loss: 0.26774558424949646\n",
      "Epoch: 1553 Loss: 0.2672189474105835\n",
      "Epoch: 1554 Loss: 0.26682618260383606\n",
      "Epoch: 1555 Loss: 0.2672698199748993\n",
      "Epoch: 1556 Loss: 0.2658971846103668\n",
      "Epoch: 1557 Loss: 0.26536017656326294\n",
      "Epoch: 1558 Loss: 0.26502567529678345\n",
      "Epoch: 1559 Loss: 0.2643665075302124\n",
      "Epoch: 1560 Loss: 0.26394766569137573\n",
      "Epoch: 1561 Loss: 0.2633238732814789\n",
      "Epoch: 1562 Loss: 0.2625529170036316\n",
      "Epoch: 1563 Loss: 0.2628799080848694\n",
      "Epoch: 1564 Loss: 0.2615247368812561\n",
      "Epoch: 1565 Loss: 0.26138705015182495\n",
      "Epoch: 1566 Loss: 0.2608243525028229\n",
      "Epoch: 1567 Loss: 0.26006343960762024\n",
      "Epoch: 1568 Loss: 0.2600342333316803\n",
      "Epoch: 1569 Loss: 0.2594932019710541\n",
      "Epoch: 1570 Loss: 0.25872868299484253\n",
      "Epoch: 1571 Loss: 0.25839242339134216\n",
      "Epoch: 1572 Loss: 0.2583055794239044\n",
      "Epoch: 1573 Loss: 0.2575106918811798\n",
      "Epoch: 1574 Loss: 0.25680193305015564\n",
      "Epoch: 1575 Loss: 0.25674745440483093\n",
      "Epoch: 1576 Loss: 0.256476491689682\n",
      "Epoch: 1577 Loss: 0.255452036857605\n",
      "Epoch: 1578 Loss: 0.25538215041160583\n",
      "Epoch: 1579 Loss: 0.2547231614589691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1580 Loss: 0.25483015179634094\n",
      "Epoch: 1581 Loss: 0.25377357006073\n",
      "Epoch: 1582 Loss: 0.2532642185688019\n",
      "Epoch: 1583 Loss: 0.25255560874938965\n",
      "Epoch: 1584 Loss: 0.25359776616096497\n",
      "Epoch: 1585 Loss: 0.25196704268455505\n",
      "Epoch: 1586 Loss: 0.251701682806015\n",
      "Epoch: 1587 Loss: 0.2513778507709503\n",
      "Epoch: 1588 Loss: 0.2506248950958252\n",
      "Epoch: 1589 Loss: 0.2500211000442505\n",
      "Epoch: 1590 Loss: 0.24985864758491516\n",
      "Epoch: 1591 Loss: 0.24937964975833893\n",
      "Epoch: 1592 Loss: 0.24945852160453796\n",
      "Epoch: 1593 Loss: 0.24892711639404297\n",
      "Epoch: 1594 Loss: 0.24874241650104523\n",
      "Epoch: 1595 Loss: 0.24771364033222198\n",
      "Epoch: 1596 Loss: 0.2481001615524292\n",
      "Epoch: 1597 Loss: 0.2468033730983734\n",
      "Epoch: 1598 Loss: 0.24642738699913025\n",
      "Epoch: 1599 Loss: 0.2458091676235199\n",
      "Epoch: 1600 Loss: 0.245590940117836\n",
      "Epoch: 1601 Loss: 0.24502046406269073\n",
      "Epoch: 1602 Loss: 0.24440829455852509\n",
      "Epoch: 1603 Loss: 0.2440701723098755\n",
      "Epoch: 1604 Loss: 0.24364666640758514\n",
      "Epoch: 1605 Loss: 0.24319373071193695\n",
      "Epoch: 1606 Loss: 0.2425256073474884\n",
      "Epoch: 1607 Loss: 0.24213790893554688\n",
      "Epoch: 1608 Loss: 0.24168778955936432\n",
      "Epoch: 1609 Loss: 0.24127987027168274\n",
      "Epoch: 1610 Loss: 0.24074004590511322\n",
      "Epoch: 1611 Loss: 0.24040231108665466\n",
      "Epoch: 1612 Loss: 0.24034090340137482\n",
      "Epoch: 1613 Loss: 0.2395055890083313\n",
      "Epoch: 1614 Loss: 0.23913849890232086\n",
      "Epoch: 1615 Loss: 0.2388429343700409\n",
      "Epoch: 1616 Loss: 0.2380271703004837\n",
      "Epoch: 1617 Loss: 0.23815694451332092\n",
      "Epoch: 1618 Loss: 0.2377462387084961\n",
      "Epoch: 1619 Loss: 0.2369002252817154\n",
      "Epoch: 1620 Loss: 0.23676428198814392\n",
      "Epoch: 1621 Loss: 0.2366703450679779\n",
      "Epoch: 1622 Loss: 0.2370130717754364\n",
      "Epoch: 1623 Loss: 0.23581379652023315\n",
      "Epoch: 1624 Loss: 0.23513485491275787\n",
      "Epoch: 1625 Loss: 0.23472416400909424\n",
      "Epoch: 1626 Loss: 0.23422876000404358\n",
      "Epoch: 1627 Loss: 0.23364242911338806\n",
      "Epoch: 1628 Loss: 0.2335117608308792\n",
      "Epoch: 1629 Loss: 0.23321062326431274\n",
      "Epoch: 1630 Loss: 0.23237311840057373\n",
      "Epoch: 1631 Loss: 0.23243120312690735\n",
      "Epoch: 1632 Loss: 0.23181964457035065\n",
      "Epoch: 1633 Loss: 0.23133470118045807\n",
      "Epoch: 1634 Loss: 0.23062211275100708\n",
      "Epoch: 1635 Loss: 0.23110076785087585\n",
      "Epoch: 1636 Loss: 0.23004676401615143\n",
      "Epoch: 1637 Loss: 0.2297435849905014\n",
      "Epoch: 1638 Loss: 0.22960418462753296\n",
      "Epoch: 1639 Loss: 0.229945570230484\n",
      "Epoch: 1640 Loss: 0.2285729944705963\n",
      "Epoch: 1641 Loss: 0.22805267572402954\n",
      "Epoch: 1642 Loss: 0.22846685349941254\n",
      "Epoch: 1643 Loss: 0.22725801169872284\n",
      "Epoch: 1644 Loss: 0.22792492806911469\n",
      "Epoch: 1645 Loss: 0.2269151210784912\n",
      "Epoch: 1646 Loss: 0.2261970043182373\n",
      "Epoch: 1647 Loss: 0.2255924642086029\n",
      "Epoch: 1648 Loss: 0.22563527524471283\n",
      "Epoch: 1649 Loss: 0.22483141720294952\n",
      "Epoch: 1650 Loss: 0.22460143268108368\n",
      "Epoch: 1651 Loss: 0.2241228073835373\n",
      "Epoch: 1652 Loss: 0.22371697425842285\n",
      "Epoch: 1653 Loss: 0.22349093854427338\n",
      "Epoch: 1654 Loss: 0.2230059802532196\n",
      "Epoch: 1655 Loss: 0.22256585955619812\n",
      "Epoch: 1656 Loss: 0.22205069661140442\n",
      "Epoch: 1657 Loss: 0.2218315452337265\n",
      "Epoch: 1658 Loss: 0.2212013453245163\n",
      "Epoch: 1659 Loss: 0.22154104709625244\n",
      "Epoch: 1660 Loss: 0.22054746747016907\n",
      "Epoch: 1661 Loss: 0.22041884064674377\n",
      "Epoch: 1662 Loss: 0.22050002217292786\n",
      "Epoch: 1663 Loss: 0.2197721004486084\n",
      "Epoch: 1664 Loss: 0.21953518688678741\n",
      "Epoch: 1665 Loss: 0.21881446242332458\n",
      "Epoch: 1666 Loss: 0.21835941076278687\n",
      "Epoch: 1667 Loss: 0.2182835340499878\n",
      "Epoch: 1668 Loss: 0.21798694133758545\n",
      "Epoch: 1669 Loss: 0.21724435687065125\n",
      "Epoch: 1670 Loss: 0.216868594288826\n",
      "Epoch: 1671 Loss: 0.21679119765758514\n",
      "Epoch: 1672 Loss: 0.2162727266550064\n",
      "Epoch: 1673 Loss: 0.21593144536018372\n",
      "Epoch: 1674 Loss: 0.21541723608970642\n",
      "Epoch: 1675 Loss: 0.21500344574451447\n",
      "Epoch: 1676 Loss: 0.2153397649526596\n",
      "Epoch: 1677 Loss: 0.21473918855190277\n",
      "Epoch: 1678 Loss: 0.21455593407154083\n",
      "Epoch: 1679 Loss: 0.21363088488578796\n",
      "Epoch: 1680 Loss: 0.21378090977668762\n",
      "Epoch: 1681 Loss: 0.21302694082260132\n",
      "Epoch: 1682 Loss: 0.21274755895137787\n",
      "Epoch: 1683 Loss: 0.2123280167579651\n",
      "Epoch: 1684 Loss: 0.21185149252414703\n",
      "Epoch: 1685 Loss: 0.21153034269809723\n",
      "Epoch: 1686 Loss: 0.2121301144361496\n",
      "Epoch: 1687 Loss: 0.21073052287101746\n",
      "Epoch: 1688 Loss: 0.2115931659936905\n",
      "Epoch: 1689 Loss: 0.210484117269516\n",
      "Epoch: 1690 Loss: 0.2098853588104248\n",
      "Epoch: 1691 Loss: 0.20944921672344208\n",
      "Epoch: 1692 Loss: 0.20932462811470032\n",
      "Epoch: 1693 Loss: 0.20865881443023682\n",
      "Epoch: 1694 Loss: 0.20918846130371094\n",
      "Epoch: 1695 Loss: 0.20821179449558258\n",
      "Epoch: 1696 Loss: 0.20796650648117065\n",
      "Epoch: 1697 Loss: 0.20757031440734863\n",
      "Epoch: 1698 Loss: 0.2072240561246872\n",
      "Epoch: 1699 Loss: 0.20675677061080933\n",
      "Epoch: 1700 Loss: 0.2065221667289734\n",
      "Epoch: 1701 Loss: 0.20627641677856445\n",
      "Epoch: 1702 Loss: 0.20577667653560638\n",
      "Epoch: 1703 Loss: 0.2054780125617981\n",
      "Epoch: 1704 Loss: 0.2051585465669632\n",
      "Epoch: 1705 Loss: 0.20477639138698578\n",
      "Epoch: 1706 Loss: 0.20446805655956268\n",
      "Epoch: 1707 Loss: 0.20400677621364594\n",
      "Epoch: 1708 Loss: 0.20469848811626434\n",
      "Epoch: 1709 Loss: 0.20331989228725433\n",
      "Epoch: 1710 Loss: 0.20338653028011322\n",
      "Epoch: 1711 Loss: 0.20276585221290588\n",
      "Epoch: 1712 Loss: 0.2027340978384018\n",
      "Epoch: 1713 Loss: 0.20203621685504913\n",
      "Epoch: 1714 Loss: 0.20215517282485962\n",
      "Epoch: 1715 Loss: 0.20174799859523773\n",
      "Epoch: 1716 Loss: 0.20117919147014618\n",
      "Epoch: 1717 Loss: 0.20086444914340973\n",
      "Epoch: 1718 Loss: 0.20073355734348297\n",
      "Epoch: 1719 Loss: 0.2004031091928482\n",
      "Epoch: 1720 Loss: 0.20011122524738312\n",
      "Epoch: 1721 Loss: 0.19975483417510986\n",
      "Epoch: 1722 Loss: 0.19943805038928986\n",
      "Epoch: 1723 Loss: 0.1992008090019226\n",
      "Epoch: 1724 Loss: 0.19882017374038696\n",
      "Epoch: 1725 Loss: 0.19830214977264404\n",
      "Epoch: 1726 Loss: 0.19796155393123627\n",
      "Epoch: 1727 Loss: 0.19796501100063324\n",
      "Epoch: 1728 Loss: 0.19749023020267487\n",
      "Epoch: 1729 Loss: 0.19735579192638397\n",
      "Epoch: 1730 Loss: 0.1969437301158905\n",
      "Epoch: 1731 Loss: 0.1965748518705368\n",
      "Epoch: 1732 Loss: 0.19636844098567963\n",
      "Epoch: 1733 Loss: 0.1958048790693283\n",
      "Epoch: 1734 Loss: 0.19636771082878113\n",
      "Epoch: 1735 Loss: 0.19528871774673462\n",
      "Epoch: 1736 Loss: 0.1954069286584854\n",
      "Epoch: 1737 Loss: 0.19473519921302795\n",
      "Epoch: 1738 Loss: 0.1949024349451065\n",
      "Epoch: 1739 Loss: 0.19418558478355408\n",
      "Epoch: 1740 Loss: 0.19402039051055908\n",
      "Epoch: 1741 Loss: 0.19348131120204926\n",
      "Epoch: 1742 Loss: 0.193303644657135\n",
      "Epoch: 1743 Loss: 0.1929575353860855\n",
      "Epoch: 1744 Loss: 0.19268392026424408\n",
      "Epoch: 1745 Loss: 0.1925491839647293\n",
      "Epoch: 1746 Loss: 0.19203142821788788\n",
      "Epoch: 1747 Loss: 0.1917756050825119\n",
      "Epoch: 1748 Loss: 0.191522479057312\n",
      "Epoch: 1749 Loss: 0.19157397747039795\n",
      "Epoch: 1750 Loss: 0.190838024020195\n",
      "Epoch: 1751 Loss: 0.1905730962753296\n",
      "Epoch: 1752 Loss: 0.1902923882007599\n",
      "Epoch: 1753 Loss: 0.19033318758010864\n",
      "Epoch: 1754 Loss: 0.19034172594547272\n",
      "Epoch: 1755 Loss: 0.18942195177078247\n",
      "Epoch: 1756 Loss: 0.18933434784412384\n",
      "Epoch: 1757 Loss: 0.18883289396762848\n",
      "Epoch: 1758 Loss: 0.18895941972732544\n",
      "Epoch: 1759 Loss: 0.1883920133113861\n",
      "Epoch: 1760 Loss: 0.18803541362285614\n",
      "Epoch: 1761 Loss: 0.1878025084733963\n",
      "Epoch: 1762 Loss: 0.18788571655750275\n",
      "Epoch: 1763 Loss: 0.18725436925888062\n",
      "Epoch: 1764 Loss: 0.1870800256729126\n",
      "Epoch: 1765 Loss: 0.18663209676742554\n",
      "Epoch: 1766 Loss: 0.18637138605117798\n",
      "Epoch: 1767 Loss: 0.1861761212348938\n",
      "Epoch: 1768 Loss: 0.18597988784313202\n",
      "Epoch: 1769 Loss: 0.18555165827274323\n",
      "Epoch: 1770 Loss: 0.18522359430789948\n",
      "Epoch: 1771 Loss: 0.18511024117469788\n",
      "Epoch: 1772 Loss: 0.18484985828399658\n",
      "Epoch: 1773 Loss: 0.1846056431531906\n",
      "Epoch: 1774 Loss: 0.18425004184246063\n",
      "Epoch: 1775 Loss: 0.1838567703962326\n",
      "Epoch: 1776 Loss: 0.18369027972221375\n",
      "Epoch: 1777 Loss: 0.18343231081962585\n",
      "Epoch: 1778 Loss: 0.18307067453861237\n",
      "Epoch: 1779 Loss: 0.18277953565120697\n",
      "Epoch: 1780 Loss: 0.18281258642673492\n",
      "Epoch: 1781 Loss: 0.1822335422039032\n",
      "Epoch: 1782 Loss: 0.18235823512077332\n",
      "Epoch: 1783 Loss: 0.18172794580459595\n",
      "Epoch: 1784 Loss: 0.1814359724521637\n",
      "Epoch: 1785 Loss: 0.1811717450618744\n",
      "Epoch: 1786 Loss: 0.1810033917427063\n",
      "Epoch: 1787 Loss: 0.18065910041332245\n",
      "Epoch: 1788 Loss: 0.18038363754749298\n",
      "Epoch: 1789 Loss: 0.18008635938167572\n",
      "Epoch: 1790 Loss: 0.18015974760055542\n",
      "Epoch: 1791 Loss: 0.17952647805213928\n",
      "Epoch: 1792 Loss: 0.17951996624469757\n",
      "Epoch: 1793 Loss: 0.1793850213289261\n",
      "Epoch: 1794 Loss: 0.1786508411169052\n",
      "Epoch: 1795 Loss: 0.17855952680110931\n",
      "Epoch: 1796 Loss: 0.1781708300113678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1797 Loss: 0.1782175749540329\n",
      "Epoch: 1798 Loss: 0.17774489521980286\n",
      "Epoch: 1799 Loss: 0.17766305804252625\n",
      "Epoch: 1800 Loss: 0.1773190200328827\n",
      "Epoch: 1801 Loss: 0.17686007916927338\n",
      "Epoch: 1802 Loss: 0.17690642178058624\n",
      "Epoch: 1803 Loss: 0.17646771669387817\n",
      "Epoch: 1804 Loss: 0.17642800509929657\n",
      "Epoch: 1805 Loss: 0.17585347592830658\n",
      "Epoch: 1806 Loss: 0.17583943903446198\n",
      "Epoch: 1807 Loss: 0.17536661028862\n",
      "Epoch: 1808 Loss: 0.17530374228954315\n",
      "Epoch: 1809 Loss: 0.17478276789188385\n",
      "Epoch: 1810 Loss: 0.17495375871658325\n",
      "Epoch: 1811 Loss: 0.17449894547462463\n",
      "Epoch: 1812 Loss: 0.1740904003381729\n",
      "Epoch: 1813 Loss: 0.17379769682884216\n",
      "Epoch: 1814 Loss: 0.17366880178451538\n",
      "Epoch: 1815 Loss: 0.17384852468967438\n",
      "Epoch: 1816 Loss: 0.17306627333164215\n",
      "Epoch: 1817 Loss: 0.17292238771915436\n",
      "Epoch: 1818 Loss: 0.17275463044643402\n",
      "Epoch: 1819 Loss: 0.17227086424827576\n",
      "Epoch: 1820 Loss: 0.17200851440429688\n",
      "Epoch: 1821 Loss: 0.17191989719867706\n",
      "Epoch: 1822 Loss: 0.17207300662994385\n",
      "Epoch: 1823 Loss: 0.17142032086849213\n",
      "Epoch: 1824 Loss: 0.17119453847408295\n",
      "Epoch: 1825 Loss: 0.17096006870269775\n",
      "Epoch: 1826 Loss: 0.17069874703884125\n",
      "Epoch: 1827 Loss: 0.17052552103996277\n",
      "Epoch: 1828 Loss: 0.17018109560012817\n",
      "Epoch: 1829 Loss: 0.17000387609004974\n",
      "Epoch: 1830 Loss: 0.17030905187129974\n",
      "Epoch: 1831 Loss: 0.16934341192245483\n",
      "Epoch: 1832 Loss: 0.16932490468025208\n",
      "Epoch: 1833 Loss: 0.16918347775936127\n",
      "Epoch: 1834 Loss: 0.16893695294857025\n",
      "Epoch: 1835 Loss: 0.16855792701244354\n",
      "Epoch: 1836 Loss: 0.16846410930156708\n",
      "Epoch: 1837 Loss: 0.16798190772533417\n",
      "Epoch: 1838 Loss: 0.16782589256763458\n",
      "Epoch: 1839 Loss: 0.16751082241535187\n",
      "Epoch: 1840 Loss: 0.16743288934230804\n",
      "Epoch: 1841 Loss: 0.1672966182231903\n",
      "Epoch: 1842 Loss: 0.16695326566696167\n",
      "Epoch: 1843 Loss: 0.16664309799671173\n",
      "Epoch: 1844 Loss: 0.16647009551525116\n",
      "Epoch: 1845 Loss: 0.16613851487636566\n",
      "Epoch: 1846 Loss: 0.1659165322780609\n",
      "Epoch: 1847 Loss: 0.16595561802387238\n",
      "Epoch: 1848 Loss: 0.16568174958229065\n",
      "Epoch: 1849 Loss: 0.16538546979427338\n",
      "Epoch: 1850 Loss: 0.16506414115428925\n",
      "Epoch: 1851 Loss: 0.1647864133119583\n",
      "Epoch: 1852 Loss: 0.16483920812606812\n",
      "Epoch: 1853 Loss: 0.164323091506958\n",
      "Epoch: 1854 Loss: 0.16414791345596313\n",
      "Epoch: 1855 Loss: 0.16393740475177765\n",
      "Epoch: 1856 Loss: 0.16358840465545654\n",
      "Epoch: 1857 Loss: 0.16332614421844482\n",
      "Epoch: 1858 Loss: 0.16327814757823944\n",
      "Epoch: 1859 Loss: 0.16295889019966125\n",
      "Epoch: 1860 Loss: 0.1629469245672226\n",
      "Epoch: 1861 Loss: 0.162601500749588\n",
      "Epoch: 1862 Loss: 0.16237184405326843\n",
      "Epoch: 1863 Loss: 0.16206109523773193\n",
      "Epoch: 1864 Loss: 0.16208602488040924\n",
      "Epoch: 1865 Loss: 0.16196754574775696\n",
      "Epoch: 1866 Loss: 0.16144302487373352\n",
      "Epoch: 1867 Loss: 0.16128817200660706\n",
      "Epoch: 1868 Loss: 0.16098293662071228\n",
      "Epoch: 1869 Loss: 0.16081781685352325\n",
      "Epoch: 1870 Loss: 0.1605905443429947\n",
      "Epoch: 1871 Loss: 0.16031409800052643\n",
      "Epoch: 1872 Loss: 0.16025319695472717\n",
      "Epoch: 1873 Loss: 0.15989893674850464\n",
      "Epoch: 1874 Loss: 0.15962176024913788\n",
      "Epoch: 1875 Loss: 0.15947863459587097\n",
      "Epoch: 1876 Loss: 0.1592170149087906\n",
      "Epoch: 1877 Loss: 0.1592562347650528\n",
      "Epoch: 1878 Loss: 0.15895172953605652\n",
      "Epoch: 1879 Loss: 0.1587412804365158\n",
      "Epoch: 1880 Loss: 0.15842655301094055\n",
      "Epoch: 1881 Loss: 0.15828140079975128\n",
      "Epoch: 1882 Loss: 0.1579512655735016\n",
      "Epoch: 1883 Loss: 0.15779250860214233\n",
      "Epoch: 1884 Loss: 0.1574840098619461\n",
      "Epoch: 1885 Loss: 0.15737324953079224\n",
      "Epoch: 1886 Loss: 0.15725712478160858\n",
      "Epoch: 1887 Loss: 0.15708167850971222\n",
      "Epoch: 1888 Loss: 0.15675033628940582\n",
      "Epoch: 1889 Loss: 0.1564362496137619\n",
      "Epoch: 1890 Loss: 0.1563490629196167\n",
      "Epoch: 1891 Loss: 0.1561286449432373\n",
      "Epoch: 1892 Loss: 0.15595273673534393\n",
      "Epoch: 1893 Loss: 0.15577563643455505\n",
      "Epoch: 1894 Loss: 0.15541833639144897\n",
      "Epoch: 1895 Loss: 0.1553766131401062\n",
      "Epoch: 1896 Loss: 0.15524142980575562\n",
      "Epoch: 1897 Loss: 0.15499620139598846\n",
      "Epoch: 1898 Loss: 0.1545998752117157\n",
      "Epoch: 1899 Loss: 0.15447713434696198\n",
      "Epoch: 1900 Loss: 0.15417060256004333\n",
      "Epoch: 1901 Loss: 0.15404316782951355\n",
      "Epoch: 1902 Loss: 0.1537862867116928\n",
      "Epoch: 1903 Loss: 0.1540158987045288\n",
      "Epoch: 1904 Loss: 0.15339751541614532\n",
      "Epoch: 1905 Loss: 0.1532921940088272\n",
      "Epoch: 1906 Loss: 0.15308529138565063\n",
      "Epoch: 1907 Loss: 0.15297278761863708\n",
      "Epoch: 1908 Loss: 0.15267150104045868\n",
      "Epoch: 1909 Loss: 0.1524106115102768\n",
      "Epoch: 1910 Loss: 0.15243378281593323\n",
      "Epoch: 1911 Loss: 0.15211226046085358\n",
      "Epoch: 1912 Loss: 0.1517564058303833\n",
      "Epoch: 1913 Loss: 0.15168847143650055\n",
      "Epoch: 1914 Loss: 0.151448592543602\n",
      "Epoch: 1915 Loss: 0.1512385606765747\n",
      "Epoch: 1916 Loss: 0.15111805498600006\n",
      "Epoch: 1917 Loss: 0.1509411334991455\n",
      "Epoch: 1918 Loss: 0.15083228051662445\n",
      "Epoch: 1919 Loss: 0.15048383176326752\n",
      "Epoch: 1920 Loss: 0.1503652185201645\n",
      "Epoch: 1921 Loss: 0.1502128392457962\n",
      "Epoch: 1922 Loss: 0.1497998833656311\n",
      "Epoch: 1923 Loss: 0.14982487261295319\n",
      "Epoch: 1924 Loss: 0.14946478605270386\n",
      "Epoch: 1925 Loss: 0.14938023686408997\n",
      "Epoch: 1926 Loss: 0.14911949634552002\n",
      "Epoch: 1927 Loss: 0.14896616339683533\n",
      "Epoch: 1928 Loss: 0.14885658025741577\n",
      "Epoch: 1929 Loss: 0.14854088425636292\n",
      "Epoch: 1930 Loss: 0.1486082673072815\n",
      "Epoch: 1931 Loss: 0.14827421307563782\n",
      "Epoch: 1932 Loss: 0.14801979064941406\n",
      "Epoch: 1933 Loss: 0.14788727462291718\n",
      "Epoch: 1934 Loss: 0.14748840034008026\n",
      "Epoch: 1935 Loss: 0.14749987423419952\n",
      "Epoch: 1936 Loss: 0.14726965129375458\n",
      "Epoch: 1937 Loss: 0.14715754985809326\n",
      "Epoch: 1938 Loss: 0.14678055047988892\n",
      "Epoch: 1939 Loss: 0.14662881195545197\n",
      "Epoch: 1940 Loss: 0.14650146663188934\n",
      "Epoch: 1941 Loss: 0.14662908017635345\n",
      "Epoch: 1942 Loss: 0.14622144401073456\n",
      "Epoch: 1943 Loss: 0.14606086909770966\n",
      "Epoch: 1944 Loss: 0.14587581157684326\n",
      "Epoch: 1945 Loss: 0.14558950066566467\n",
      "Epoch: 1946 Loss: 0.14549507200717926\n",
      "Epoch: 1947 Loss: 0.14526216685771942\n",
      "Epoch: 1948 Loss: 0.14504244923591614\n",
      "Epoch: 1949 Loss: 0.14484262466430664\n",
      "Epoch: 1950 Loss: 0.14477577805519104\n",
      "Epoch: 1951 Loss: 0.14455915987491608\n",
      "Epoch: 1952 Loss: 0.14429090917110443\n",
      "Epoch: 1953 Loss: 0.14442691206932068\n",
      "Epoch: 1954 Loss: 0.14399567246437073\n",
      "Epoch: 1955 Loss: 0.14382754266262054\n",
      "Epoch: 1956 Loss: 0.1435914933681488\n",
      "Epoch: 1957 Loss: 0.14355827867984772\n",
      "Epoch: 1958 Loss: 0.14330193400382996\n",
      "Epoch: 1959 Loss: 0.14308272302150726\n",
      "Epoch: 1960 Loss: 0.14288191497325897\n",
      "Epoch: 1961 Loss: 0.14278055727481842\n",
      "Epoch: 1962 Loss: 0.14250648021697998\n",
      "Epoch: 1963 Loss: 0.14241540431976318\n",
      "Epoch: 1964 Loss: 0.14218033850193024\n",
      "Epoch: 1965 Loss: 0.14204798638820648\n",
      "Epoch: 1966 Loss: 0.14200332760810852\n",
      "Epoch: 1967 Loss: 0.14164434373378754\n",
      "Epoch: 1968 Loss: 0.14146634936332703\n",
      "Epoch: 1969 Loss: 0.14139196276664734\n",
      "Epoch: 1970 Loss: 0.14116829633712769\n",
      "Epoch: 1971 Loss: 0.14096969366073608\n",
      "Epoch: 1972 Loss: 0.14081428945064545\n",
      "Epoch: 1973 Loss: 0.14065676927566528\n",
      "Epoch: 1974 Loss: 0.14054657518863678\n",
      "Epoch: 1975 Loss: 0.14025157690048218\n",
      "Epoch: 1976 Loss: 0.14009277522563934\n",
      "Epoch: 1977 Loss: 0.13990437984466553\n",
      "Epoch: 1978 Loss: 0.13974258303642273\n",
      "Epoch: 1979 Loss: 0.13971887528896332\n",
      "Epoch: 1980 Loss: 0.13943475484848022\n",
      "Epoch: 1981 Loss: 0.1393870860338211\n",
      "Epoch: 1982 Loss: 0.1391451507806778\n",
      "Epoch: 1983 Loss: 0.1390002816915512\n",
      "Epoch: 1984 Loss: 0.13881544768810272\n",
      "Epoch: 1985 Loss: 0.1385616958141327\n",
      "Epoch: 1986 Loss: 0.13871599733829498\n",
      "Epoch: 1987 Loss: 0.13834166526794434\n",
      "Epoch: 1988 Loss: 0.13812649250030518\n",
      "Epoch: 1989 Loss: 0.1379702240228653\n",
      "Epoch: 1990 Loss: 0.1377795934677124\n",
      "Epoch: 1991 Loss: 0.13765569031238556\n",
      "Epoch: 1992 Loss: 0.13753370940685272\n",
      "Epoch: 1993 Loss: 0.13719940185546875\n",
      "Epoch: 1994 Loss: 0.1371912658214569\n",
      "Epoch: 1995 Loss: 0.13694816827774048\n",
      "Epoch: 1996 Loss: 0.13680914044380188\n",
      "Epoch: 1997 Loss: 0.13661301136016846\n",
      "Epoch: 1998 Loss: 0.13652963936328888\n",
      "Epoch: 1999 Loss: 0.1363096684217453\n",
      "Epoch: 2000 Loss: 0.13614344596862793\n",
      "Epoch: 2001 Loss: 0.13603144884109497\n",
      "Epoch: 2002 Loss: 0.13580362498760223\n",
      "Epoch: 2003 Loss: 0.13570722937583923\n",
      "Epoch: 2004 Loss: 0.13556592166423798\n",
      "Epoch: 2005 Loss: 0.13533280789852142\n",
      "Epoch: 2006 Loss: 0.13523565232753754\n",
      "Epoch: 2007 Loss: 0.13507598638534546\n",
      "Epoch: 2008 Loss: 0.1348782330751419\n",
      "Epoch: 2009 Loss: 0.13472895324230194\n",
      "Epoch: 2010 Loss: 0.13462607562541962\n",
      "Epoch: 2011 Loss: 0.1344473958015442\n",
      "Epoch: 2012 Loss: 0.13427244126796722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2013 Loss: 0.134088397026062\n",
      "Epoch: 2014 Loss: 0.13401709496974945\n",
      "Epoch: 2015 Loss: 0.1337732970714569\n",
      "Epoch: 2016 Loss: 0.13364332914352417\n",
      "Epoch: 2017 Loss: 0.13344885408878326\n",
      "Epoch: 2018 Loss: 0.13342343270778656\n",
      "Epoch: 2019 Loss: 0.13308849930763245\n",
      "Epoch: 2020 Loss: 0.1330573856830597\n",
      "Epoch: 2021 Loss: 0.13291144371032715\n",
      "Epoch: 2022 Loss: 0.13264153897762299\n",
      "Epoch: 2023 Loss: 0.1325129121541977\n",
      "Epoch: 2024 Loss: 0.13241155445575714\n",
      "Epoch: 2025 Loss: 0.13228698074817657\n",
      "Epoch: 2026 Loss: 0.13211336731910706\n",
      "Epoch: 2027 Loss: 0.1320229321718216\n",
      "Epoch: 2028 Loss: 0.13181649148464203\n",
      "Epoch: 2029 Loss: 0.13162218034267426\n",
      "Epoch: 2030 Loss: 0.13148058950901031\n",
      "Epoch: 2031 Loss: 0.13129925727844238\n",
      "Epoch: 2032 Loss: 0.13116848468780518\n",
      "Epoch: 2033 Loss: 0.1310192346572876\n",
      "Epoch: 2034 Loss: 0.13089904189109802\n",
      "Epoch: 2035 Loss: 0.13075819611549377\n",
      "Epoch: 2036 Loss: 0.13060802221298218\n",
      "Epoch: 2037 Loss: 0.1304006427526474\n",
      "Epoch: 2038 Loss: 0.1302492767572403\n",
      "Epoch: 2039 Loss: 0.13019102811813354\n",
      "Epoch: 2040 Loss: 0.12994031608104706\n",
      "Epoch: 2041 Loss: 0.12983761727809906\n",
      "Epoch: 2042 Loss: 0.12964121997356415\n",
      "Epoch: 2043 Loss: 0.1295517534017563\n",
      "Epoch: 2044 Loss: 0.1294669806957245\n",
      "Epoch: 2045 Loss: 0.1292426586151123\n",
      "Epoch: 2046 Loss: 0.129024475812912\n",
      "Epoch: 2047 Loss: 0.1289907991886139\n",
      "Epoch: 2048 Loss: 0.12883758544921875\n",
      "Epoch: 2049 Loss: 0.12860415875911713\n",
      "Epoch: 2050 Loss: 0.12848283350467682\n",
      "Epoch: 2051 Loss: 0.12839442491531372\n",
      "Epoch: 2052 Loss: 0.12827269732952118\n",
      "Epoch: 2053 Loss: 0.1279842108488083\n",
      "Epoch: 2054 Loss: 0.12824493646621704\n",
      "Epoch: 2055 Loss: 0.12777115404605865\n",
      "Epoch: 2056 Loss: 0.1276274025440216\n",
      "Epoch: 2057 Loss: 0.1274784803390503\n",
      "Epoch: 2058 Loss: 0.12739326059818268\n",
      "Epoch: 2059 Loss: 0.1272342950105667\n",
      "Epoch: 2060 Loss: 0.12705780565738678\n",
      "Epoch: 2061 Loss: 0.1269637495279312\n",
      "Epoch: 2062 Loss: 0.12681476771831512\n",
      "Epoch: 2063 Loss: 0.12655988335609436\n",
      "Epoch: 2064 Loss: 0.12651458382606506\n",
      "Epoch: 2065 Loss: 0.1262664943933487\n",
      "Epoch: 2066 Loss: 0.12624286115169525\n",
      "Epoch: 2067 Loss: 0.1260078251361847\n",
      "Epoch: 2068 Loss: 0.12586921453475952\n",
      "Epoch: 2069 Loss: 0.12583371996879578\n",
      "Epoch: 2070 Loss: 0.12561829388141632\n",
      "Epoch: 2071 Loss: 0.1256026327610016\n",
      "Epoch: 2072 Loss: 0.12548048794269562\n",
      "Epoch: 2073 Loss: 0.12525080144405365\n",
      "Epoch: 2074 Loss: 0.12510110437870026\n",
      "Epoch: 2075 Loss: 0.12496835738420486\n",
      "Epoch: 2076 Loss: 0.12480728328227997\n",
      "Epoch: 2077 Loss: 0.12469495087862015\n",
      "Epoch: 2078 Loss: 0.12457028031349182\n",
      "Epoch: 2079 Loss: 0.12438010424375534\n",
      "Epoch: 2080 Loss: 0.1244124099612236\n",
      "Epoch: 2081 Loss: 0.12414852529764175\n",
      "Epoch: 2082 Loss: 0.12399996072053909\n",
      "Epoch: 2083 Loss: 0.12383843958377838\n",
      "Epoch: 2084 Loss: 0.12377278506755829\n",
      "Epoch: 2085 Loss: 0.12362122535705566\n",
      "Epoch: 2086 Loss: 0.12342493236064911\n",
      "Epoch: 2087 Loss: 0.12340699136257172\n",
      "Epoch: 2088 Loss: 0.12319089472293854\n",
      "Epoch: 2089 Loss: 0.12303651869297028\n",
      "Epoch: 2090 Loss: 0.12284310162067413\n",
      "Epoch: 2091 Loss: 0.12278486043214798\n",
      "Epoch: 2092 Loss: 0.12269335240125656\n",
      "Epoch: 2093 Loss: 0.12253746390342712\n",
      "Epoch: 2094 Loss: 0.12240023910999298\n",
      "Epoch: 2095 Loss: 0.12231221795082092\n",
      "Epoch: 2096 Loss: 0.12207020819187164\n",
      "Epoch: 2097 Loss: 0.12198659032583237\n",
      "Epoch: 2098 Loss: 0.12186823040246964\n",
      "Epoch: 2099 Loss: 0.12166116386651993\n",
      "Epoch: 2100 Loss: 0.12152434140443802\n",
      "Epoch: 2101 Loss: 0.12144825607538223\n",
      "Epoch: 2102 Loss: 0.12123719602823257\n",
      "Epoch: 2103 Loss: 0.12119422852993011\n",
      "Epoch: 2104 Loss: 0.12104164808988571\n",
      "Epoch: 2105 Loss: 0.1208825558423996\n",
      "Epoch: 2106 Loss: 0.1207725778222084\n",
      "Epoch: 2107 Loss: 0.12065111845731735\n",
      "Epoch: 2108 Loss: 0.12049878388643265\n",
      "Epoch: 2109 Loss: 0.12044794112443924\n",
      "Epoch: 2110 Loss: 0.1202353984117508\n",
      "Epoch: 2111 Loss: 0.12008259445428848\n",
      "Epoch: 2112 Loss: 0.11996519565582275\n",
      "Epoch: 2113 Loss: 0.11979549378156662\n",
      "Epoch: 2114 Loss: 0.11975747346878052\n",
      "Epoch: 2115 Loss: 0.11972243338823318\n",
      "Epoch: 2116 Loss: 0.11946440488100052\n",
      "Epoch: 2117 Loss: 0.11934599280357361\n",
      "Epoch: 2118 Loss: 0.11926618218421936\n",
      "Epoch: 2119 Loss: 0.11903591454029083\n",
      "Epoch: 2120 Loss: 0.11893562972545624\n",
      "Epoch: 2121 Loss: 0.11894778162240982\n",
      "Epoch: 2122 Loss: 0.11874745041131973\n",
      "Epoch: 2123 Loss: 0.11859827488660812\n",
      "Epoch: 2124 Loss: 0.11842517554759979\n",
      "Epoch: 2125 Loss: 0.11834248900413513\n",
      "Epoch: 2126 Loss: 0.1181781142950058\n",
      "Epoch: 2127 Loss: 0.11802537739276886\n",
      "Epoch: 2128 Loss: 0.11808263510465622\n",
      "Epoch: 2129 Loss: 0.11779608577489853\n",
      "Epoch: 2130 Loss: 0.11767621338367462\n",
      "Epoch: 2131 Loss: 0.1176118329167366\n",
      "Epoch: 2132 Loss: 0.11750015616416931\n",
      "Epoch: 2133 Loss: 0.11736743152141571\n",
      "Epoch: 2134 Loss: 0.11719036102294922\n",
      "Epoch: 2135 Loss: 0.11704989522695541\n",
      "Epoch: 2136 Loss: 0.11695161461830139\n",
      "Epoch: 2137 Loss: 0.11686587333679199\n",
      "Epoch: 2138 Loss: 0.11675814539194107\n",
      "Epoch: 2139 Loss: 0.11661837249994278\n",
      "Epoch: 2140 Loss: 0.11651314049959183\n",
      "Epoch: 2141 Loss: 0.11639203131198883\n",
      "Epoch: 2142 Loss: 0.116228386759758\n",
      "Epoch: 2143 Loss: 0.1161111444234848\n",
      "Epoch: 2144 Loss: 0.11599013954401016\n",
      "Epoch: 2145 Loss: 0.11587236821651459\n",
      "Epoch: 2146 Loss: 0.11577325314283371\n",
      "Epoch: 2147 Loss: 0.11555536091327667\n",
      "Epoch: 2148 Loss: 0.11548297852277756\n",
      "Epoch: 2149 Loss: 0.11535076051950455\n",
      "Epoch: 2150 Loss: 0.11529573053121567\n",
      "Epoch: 2151 Loss: 0.11509976536035538\n",
      "Epoch: 2152 Loss: 0.1150527372956276\n",
      "Epoch: 2153 Loss: 0.11486245691776276\n",
      "Epoch: 2154 Loss: 0.11482666432857513\n",
      "Epoch: 2155 Loss: 0.11470022052526474\n",
      "Epoch: 2156 Loss: 0.11451864242553711\n",
      "Epoch: 2157 Loss: 0.11444466561079025\n",
      "Epoch: 2158 Loss: 0.11429829150438309\n",
      "Epoch: 2159 Loss: 0.11420907080173492\n",
      "Epoch: 2160 Loss: 0.1141137108206749\n",
      "Epoch: 2161 Loss: 0.11402729153633118\n",
      "Epoch: 2162 Loss: 0.1138564869761467\n",
      "Epoch: 2163 Loss: 0.1137571856379509\n",
      "Epoch: 2164 Loss: 0.1136123314499855\n",
      "Epoch: 2165 Loss: 0.1134558916091919\n",
      "Epoch: 2166 Loss: 0.11346760392189026\n",
      "Epoch: 2167 Loss: 0.11328113079071045\n",
      "Epoch: 2168 Loss: 0.11310946196317673\n",
      "Epoch: 2169 Loss: 0.11298511922359467\n",
      "Epoch: 2170 Loss: 0.11305703967809677\n",
      "Epoch: 2171 Loss: 0.11282164603471756\n",
      "Epoch: 2172 Loss: 0.11266246438026428\n",
      "Epoch: 2173 Loss: 0.11257229000329971\n",
      "Epoch: 2174 Loss: 0.11247366666793823\n",
      "Epoch: 2175 Loss: 0.11233323067426682\n",
      "Epoch: 2176 Loss: 0.11224808543920517\n",
      "Epoch: 2177 Loss: 0.11212991178035736\n",
      "Epoch: 2178 Loss: 0.11200843751430511\n",
      "Epoch: 2179 Loss: 0.11188307404518127\n",
      "Epoch: 2180 Loss: 0.11172480881214142\n",
      "Epoch: 2181 Loss: 0.11165273189544678\n",
      "Epoch: 2182 Loss: 0.11162128299474716\n",
      "Epoch: 2183 Loss: 0.11140868067741394\n",
      "Epoch: 2184 Loss: 0.11132615059614182\n",
      "Epoch: 2185 Loss: 0.11121471971273422\n",
      "Epoch: 2186 Loss: 0.11107862740755081\n",
      "Epoch: 2187 Loss: 0.11094612628221512\n",
      "Epoch: 2188 Loss: 0.11089543998241425\n",
      "Epoch: 2189 Loss: 0.11080123484134674\n",
      "Epoch: 2190 Loss: 0.1106707751750946\n",
      "Epoch: 2191 Loss: 0.11060425639152527\n",
      "Epoch: 2192 Loss: 0.11043544113636017\n",
      "Epoch: 2193 Loss: 0.11032174527645111\n",
      "Epoch: 2194 Loss: 0.11025391519069672\n",
      "Epoch: 2195 Loss: 0.11010054498910904\n",
      "Epoch: 2196 Loss: 0.11001608520746231\n",
      "Epoch: 2197 Loss: 0.10990891605615616\n",
      "Epoch: 2198 Loss: 0.10976722836494446\n",
      "Epoch: 2199 Loss: 0.10965856909751892\n",
      "Epoch: 2200 Loss: 0.10957342386245728\n",
      "Epoch: 2201 Loss: 0.10942868888378143\n",
      "Epoch: 2202 Loss: 0.1093384250998497\n",
      "Epoch: 2203 Loss: 0.10925083607435226\n",
      "Epoch: 2204 Loss: 0.10901673138141632\n",
      "Epoch: 2205 Loss: 0.10902809351682663\n",
      "Epoch: 2206 Loss: 0.10891249775886536\n",
      "Epoch: 2207 Loss: 0.10880643874406815\n",
      "Epoch: 2208 Loss: 0.10875054448843002\n",
      "Epoch: 2209 Loss: 0.10871884971857071\n",
      "Epoch: 2210 Loss: 0.108414426445961\n",
      "Epoch: 2211 Loss: 0.10841215401887894\n",
      "Epoch: 2212 Loss: 0.10827114433050156\n",
      "Epoch: 2213 Loss: 0.10830368101596832\n",
      "Epoch: 2214 Loss: 0.1080850213766098\n",
      "Epoch: 2215 Loss: 0.10792579501867294\n",
      "Epoch: 2216 Loss: 0.10775917768478394\n",
      "Epoch: 2217 Loss: 0.10777954012155533\n",
      "Epoch: 2218 Loss: 0.10766571015119553\n",
      "Epoch: 2219 Loss: 0.1075223907828331\n",
      "Epoch: 2220 Loss: 0.10754581540822983\n",
      "Epoch: 2221 Loss: 0.1073000431060791\n",
      "Epoch: 2222 Loss: 0.107195183634758\n",
      "Epoch: 2223 Loss: 0.10706138610839844\n",
      "Epoch: 2224 Loss: 0.10701512545347214\n",
      "Epoch: 2225 Loss: 0.10694374889135361\n",
      "Epoch: 2226 Loss: 0.10670989751815796\n",
      "Epoch: 2227 Loss: 0.1066877469420433\n",
      "Epoch: 2228 Loss: 0.10658203065395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2229 Loss: 0.10650036484003067\n",
      "Epoch: 2230 Loss: 0.1063622385263443\n",
      "Epoch: 2231 Loss: 0.1062159538269043\n",
      "Epoch: 2232 Loss: 0.10617890954017639\n",
      "Epoch: 2233 Loss: 0.10606302320957184\n",
      "Epoch: 2234 Loss: 0.10593526065349579\n",
      "Epoch: 2235 Loss: 0.1058071106672287\n",
      "Epoch: 2236 Loss: 0.10571444779634476\n",
      "Epoch: 2237 Loss: 0.10560999810695648\n",
      "Epoch: 2238 Loss: 0.10556701570749283\n",
      "Epoch: 2239 Loss: 0.10543933510780334\n",
      "Epoch: 2240 Loss: 0.10537666827440262\n",
      "Epoch: 2241 Loss: 0.10525594651699066\n",
      "Epoch: 2242 Loss: 0.10512358695268631\n",
      "Epoch: 2243 Loss: 0.105152927339077\n",
      "Epoch: 2244 Loss: 0.10492606461048126\n",
      "Epoch: 2245 Loss: 0.10481537133455276\n",
      "Epoch: 2246 Loss: 0.10470451414585114\n",
      "Epoch: 2247 Loss: 0.1045757308602333\n",
      "Epoch: 2248 Loss: 0.10452643781900406\n",
      "Epoch: 2249 Loss: 0.10438501089811325\n",
      "Epoch: 2250 Loss: 0.10435175895690918\n",
      "Epoch: 2251 Loss: 0.10421611368656158\n",
      "Epoch: 2252 Loss: 0.10409204661846161\n",
      "Epoch: 2253 Loss: 0.1039891466498375\n",
      "Epoch: 2254 Loss: 0.10393382608890533\n",
      "Epoch: 2255 Loss: 0.10396304726600647\n",
      "Epoch: 2256 Loss: 0.10374928265810013\n",
      "Epoch: 2257 Loss: 0.10372181981801987\n",
      "Epoch: 2258 Loss: 0.10356620699167252\n",
      "Epoch: 2259 Loss: 0.10342961549758911\n",
      "Epoch: 2260 Loss: 0.10335306823253632\n",
      "Epoch: 2261 Loss: 0.10324247181415558\n",
      "Epoch: 2262 Loss: 0.10309824347496033\n",
      "Epoch: 2263 Loss: 0.10303997248411179\n",
      "Epoch: 2264 Loss: 0.10293195396661758\n",
      "Epoch: 2265 Loss: 0.10287194699048996\n",
      "Epoch: 2266 Loss: 0.10281571745872498\n",
      "Epoch: 2267 Loss: 0.10260951519012451\n",
      "Epoch: 2268 Loss: 0.10257263481616974\n",
      "Epoch: 2269 Loss: 0.10241999477148056\n",
      "Epoch: 2270 Loss: 0.10232129693031311\n",
      "Epoch: 2271 Loss: 0.10231493413448334\n",
      "Epoch: 2272 Loss: 0.10213398188352585\n",
      "Epoch: 2273 Loss: 0.10204306244850159\n",
      "Epoch: 2274 Loss: 0.10191892087459564\n",
      "Epoch: 2275 Loss: 0.10191282629966736\n",
      "Epoch: 2276 Loss: 0.10178221762180328\n",
      "Epoch: 2277 Loss: 0.10178916156291962\n",
      "Epoch: 2278 Loss: 0.10152878612279892\n",
      "Epoch: 2279 Loss: 0.10144135355949402\n",
      "Epoch: 2280 Loss: 0.1013818308711052\n",
      "Epoch: 2281 Loss: 0.10129120945930481\n",
      "Epoch: 2282 Loss: 0.10129516571760178\n",
      "Epoch: 2283 Loss: 0.10109210014343262\n",
      "Epoch: 2284 Loss: 0.10097207129001617\n",
      "Epoch: 2285 Loss: 0.10089677572250366\n",
      "Epoch: 2286 Loss: 0.10090656578540802\n",
      "Epoch: 2287 Loss: 0.10064025968313217\n",
      "Epoch: 2288 Loss: 0.1006733849644661\n",
      "Epoch: 2289 Loss: 0.10054438561201096\n",
      "Epoch: 2290 Loss: 0.10042238980531693\n",
      "Epoch: 2291 Loss: 0.1002809926867485\n",
      "Epoch: 2292 Loss: 0.10022053867578506\n",
      "Epoch: 2293 Loss: 0.10020580142736435\n",
      "Epoch: 2294 Loss: 0.10010777413845062\n",
      "Epoch: 2295 Loss: 0.09997544437646866\n",
      "Epoch: 2296 Loss: 0.09984668344259262\n",
      "Epoch: 2297 Loss: 0.0997842326760292\n",
      "Epoch: 2298 Loss: 0.09975060820579529\n",
      "Epoch: 2299 Loss: 0.09959284216165543\n",
      "Epoch: 2300 Loss: 0.09943472594022751\n",
      "Epoch: 2301 Loss: 0.09941600263118744\n",
      "Epoch: 2302 Loss: 0.09934939444065094\n",
      "Epoch: 2303 Loss: 0.09914092719554901\n",
      "Epoch: 2304 Loss: 0.0992191880941391\n",
      "Epoch: 2305 Loss: 0.09916717559099197\n",
      "Epoch: 2306 Loss: 0.09897727519273758\n",
      "Epoch: 2307 Loss: 0.09887944161891937\n",
      "Epoch: 2308 Loss: 0.09872814267873764\n",
      "Epoch: 2309 Loss: 0.09877718240022659\n",
      "Epoch: 2310 Loss: 0.09861572086811066\n",
      "Epoch: 2311 Loss: 0.09846368432044983\n",
      "Epoch: 2312 Loss: 0.09837830066680908\n",
      "Epoch: 2313 Loss: 0.09840196371078491\n",
      "Epoch: 2314 Loss: 0.09831880033016205\n",
      "Epoch: 2315 Loss: 0.09822873026132584\n",
      "Epoch: 2316 Loss: 0.09804602712392807\n",
      "Epoch: 2317 Loss: 0.09791310131549835\n",
      "Epoch: 2318 Loss: 0.09788975119590759\n",
      "Epoch: 2319 Loss: 0.09771484136581421\n",
      "Epoch: 2320 Loss: 0.09768518805503845\n",
      "Epoch: 2321 Loss: 0.09769794344902039\n",
      "Epoch: 2322 Loss: 0.09749505668878555\n",
      "Epoch: 2323 Loss: 0.09741248935461044\n",
      "Epoch: 2324 Loss: 0.0973108559846878\n",
      "Epoch: 2325 Loss: 0.09721795469522476\n",
      "Epoch: 2326 Loss: 0.09723547101020813\n",
      "Epoch: 2327 Loss: 0.09707916527986526\n",
      "Epoch: 2328 Loss: 0.09701622277498245\n",
      "Epoch: 2329 Loss: 0.09689045697450638\n",
      "Epoch: 2330 Loss: 0.09681545197963715\n",
      "Epoch: 2331 Loss: 0.09672772884368896\n",
      "Epoch: 2332 Loss: 0.0966663807630539\n",
      "Epoch: 2333 Loss: 0.09653286635875702\n",
      "Epoch: 2334 Loss: 0.0964580625295639\n",
      "Epoch: 2335 Loss: 0.09633769094944\n",
      "Epoch: 2336 Loss: 0.09622381627559662\n",
      "Epoch: 2337 Loss: 0.0962538942694664\n",
      "Epoch: 2338 Loss: 0.09618297964334488\n",
      "Epoch: 2339 Loss: 0.09619306027889252\n",
      "Epoch: 2340 Loss: 0.09592120349407196\n",
      "Epoch: 2341 Loss: 0.09582336992025375\n",
      "Epoch: 2342 Loss: 0.09585347771644592\n",
      "Epoch: 2343 Loss: 0.09573283046483994\n",
      "Epoch: 2344 Loss: 0.09562519192695618\n",
      "Epoch: 2345 Loss: 0.09548313170671463\n",
      "Epoch: 2346 Loss: 0.09542769938707352\n",
      "Epoch: 2347 Loss: 0.09535658359527588\n",
      "Epoch: 2348 Loss: 0.09535064548254013\n",
      "Epoch: 2349 Loss: 0.09522922337055206\n",
      "Epoch: 2350 Loss: 0.09508006274700165\n",
      "Epoch: 2351 Loss: 0.09499777108430862\n",
      "Epoch: 2352 Loss: 0.09493017196655273\n",
      "Epoch: 2353 Loss: 0.09489693492650986\n",
      "Epoch: 2354 Loss: 0.09480557590723038\n",
      "Epoch: 2355 Loss: 0.09463082998991013\n",
      "Epoch: 2356 Loss: 0.09462018311023712\n",
      "Epoch: 2357 Loss: 0.09451316297054291\n",
      "Epoch: 2358 Loss: 0.09443187713623047\n",
      "Epoch: 2359 Loss: 0.0943259671330452\n",
      "Epoch: 2360 Loss: 0.09429508447647095\n",
      "Epoch: 2361 Loss: 0.09420870244503021\n",
      "Epoch: 2362 Loss: 0.0941375121474266\n",
      "Epoch: 2363 Loss: 0.09403938800096512\n",
      "Epoch: 2364 Loss: 0.09395613521337509\n",
      "Epoch: 2365 Loss: 0.09384462237358093\n",
      "Epoch: 2366 Loss: 0.09381089359521866\n",
      "Epoch: 2367 Loss: 0.09369724988937378\n",
      "Epoch: 2368 Loss: 0.09358354657888412\n",
      "Epoch: 2369 Loss: 0.09353464096784592\n",
      "Epoch: 2370 Loss: 0.09342792630195618\n",
      "Epoch: 2371 Loss: 0.0934317335486412\n",
      "Epoch: 2372 Loss: 0.09325146675109863\n",
      "Epoch: 2373 Loss: 0.09321480989456177\n",
      "Epoch: 2374 Loss: 0.09312561899423599\n",
      "Epoch: 2375 Loss: 0.09315531700849533\n",
      "Epoch: 2376 Loss: 0.09295948594808578\n",
      "Epoch: 2377 Loss: 0.09283560514450073\n",
      "Epoch: 2378 Loss: 0.0928870365023613\n",
      "Epoch: 2379 Loss: 0.09271499514579773\n",
      "Epoch: 2380 Loss: 0.09266993403434753\n",
      "Epoch: 2381 Loss: 0.09264427423477173\n",
      "Epoch: 2382 Loss: 0.09246916323900223\n",
      "Epoch: 2383 Loss: 0.09236785024404526\n",
      "Epoch: 2384 Loss: 0.09231673926115036\n",
      "Epoch: 2385 Loss: 0.09221629053354263\n",
      "Epoch: 2386 Loss: 0.09209335595369339\n",
      "Epoch: 2387 Loss: 0.09205814450979233\n",
      "Epoch: 2388 Loss: 0.09208446741104126\n",
      "Epoch: 2389 Loss: 0.09196752309799194\n",
      "Epoch: 2390 Loss: 0.09186048060655594\n",
      "Epoch: 2391 Loss: 0.09180095046758652\n",
      "Epoch: 2392 Loss: 0.09173053503036499\n",
      "Epoch: 2393 Loss: 0.0916147381067276\n",
      "Epoch: 2394 Loss: 0.09152434766292572\n",
      "Epoch: 2395 Loss: 0.09147854149341583\n",
      "Epoch: 2396 Loss: 0.09138019382953644\n",
      "Epoch: 2397 Loss: 0.09129419922828674\n",
      "Epoch: 2398 Loss: 0.09121453762054443\n",
      "Epoch: 2399 Loss: 0.09121713787317276\n",
      "Epoch: 2400 Loss: 0.09108831733465195\n",
      "Epoch: 2401 Loss: 0.09094487875699997\n",
      "Epoch: 2402 Loss: 0.0909561812877655\n",
      "Epoch: 2403 Loss: 0.09082932025194168\n",
      "Epoch: 2404 Loss: 0.09077852219343185\n",
      "Epoch: 2405 Loss: 0.09070644527673721\n",
      "Epoch: 2406 Loss: 0.09065154939889908\n",
      "Epoch: 2407 Loss: 0.09054713696241379\n",
      "Epoch: 2408 Loss: 0.09045426547527313\n",
      "Epoch: 2409 Loss: 0.0903451219201088\n",
      "Epoch: 2410 Loss: 0.09027969092130661\n",
      "Epoch: 2411 Loss: 0.09029952436685562\n",
      "Epoch: 2412 Loss: 0.09022179245948792\n",
      "Epoch: 2413 Loss: 0.0900350883603096\n",
      "Epoch: 2414 Loss: 0.08999330550432205\n",
      "Epoch: 2415 Loss: 0.08988386392593384\n",
      "Epoch: 2416 Loss: 0.0899360403418541\n",
      "Epoch: 2417 Loss: 0.08971905708312988\n",
      "Epoch: 2418 Loss: 0.08967655152082443\n",
      "Epoch: 2419 Loss: 0.08959528803825378\n",
      "Epoch: 2420 Loss: 0.08950479328632355\n",
      "Epoch: 2421 Loss: 0.08948399126529694\n",
      "Epoch: 2422 Loss: 0.08934447169303894\n",
      "Epoch: 2423 Loss: 0.0894351601600647\n",
      "Epoch: 2424 Loss: 0.08933453261852264\n",
      "Epoch: 2425 Loss: 0.08915285021066666\n",
      "Epoch: 2426 Loss: 0.08906105160713196\n",
      "Epoch: 2427 Loss: 0.0890037789940834\n",
      "Epoch: 2428 Loss: 0.08892975002527237\n",
      "Epoch: 2429 Loss: 0.08881252259016037\n",
      "Epoch: 2430 Loss: 0.08873733878135681\n",
      "Epoch: 2431 Loss: 0.08877958357334137\n",
      "Epoch: 2432 Loss: 0.08862058073282242\n",
      "Epoch: 2433 Loss: 0.08857554942369461\n",
      "Epoch: 2434 Loss: 0.08846352249383926\n",
      "Epoch: 2435 Loss: 0.08837243914604187\n",
      "Epoch: 2436 Loss: 0.08832766115665436\n",
      "Epoch: 2437 Loss: 0.0882311537861824\n",
      "Epoch: 2438 Loss: 0.08824564516544342\n",
      "Epoch: 2439 Loss: 0.08811184763908386\n",
      "Epoch: 2440 Loss: 0.08809001743793488\n",
      "Epoch: 2441 Loss: 0.08797767758369446\n",
      "Epoch: 2442 Loss: 0.08785616606473923\n",
      "Epoch: 2443 Loss: 0.08782122284173965\n",
      "Epoch: 2444 Loss: 0.08769472688436508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2445 Loss: 0.0876474604010582\n",
      "Epoch: 2446 Loss: 0.08762016892433167\n",
      "Epoch: 2447 Loss: 0.08747073262929916\n",
      "Epoch: 2448 Loss: 0.08747440576553345\n",
      "Epoch: 2449 Loss: 0.08735126256942749\n",
      "Epoch: 2450 Loss: 0.08744354546070099\n",
      "Epoch: 2451 Loss: 0.08726350963115692\n",
      "Epoch: 2452 Loss: 0.08713896572589874\n",
      "Epoch: 2453 Loss: 0.08712287992238998\n",
      "Epoch: 2454 Loss: 0.08701343834400177\n",
      "Epoch: 2455 Loss: 0.08688829094171524\n",
      "Epoch: 2456 Loss: 0.08687110245227814\n",
      "Epoch: 2457 Loss: 0.08676072210073471\n",
      "Epoch: 2458 Loss: 0.08675374835729599\n",
      "Epoch: 2459 Loss: 0.08679033815860748\n",
      "Epoch: 2460 Loss: 0.08658914268016815\n",
      "Epoch: 2461 Loss: 0.08649464696645737\n",
      "Epoch: 2462 Loss: 0.0865168496966362\n",
      "Epoch: 2463 Loss: 0.08637602627277374\n",
      "Epoch: 2464 Loss: 0.08626803755760193\n",
      "Epoch: 2465 Loss: 0.0862186849117279\n",
      "Epoch: 2466 Loss: 0.08617985248565674\n",
      "Epoch: 2467 Loss: 0.08611767739057541\n",
      "Epoch: 2468 Loss: 0.08598871529102325\n",
      "Epoch: 2469 Loss: 0.08607611805200577\n",
      "Epoch: 2470 Loss: 0.08585193753242493\n",
      "Epoch: 2471 Loss: 0.08580554276704788\n",
      "Epoch: 2472 Loss: 0.08571819216012955\n",
      "Epoch: 2473 Loss: 0.08565246313810349\n",
      "Epoch: 2474 Loss: 0.08567292243242264\n",
      "Epoch: 2475 Loss: 0.08559948205947876\n",
      "Epoch: 2476 Loss: 0.08542069792747498\n",
      "Epoch: 2477 Loss: 0.08544830232858658\n",
      "Epoch: 2478 Loss: 0.08529023081064224\n",
      "Epoch: 2479 Loss: 0.08523967117071152\n",
      "Epoch: 2480 Loss: 0.0851932168006897\n",
      "Epoch: 2481 Loss: 0.0851217657327652\n",
      "Epoch: 2482 Loss: 0.08502403646707535\n",
      "Epoch: 2483 Loss: 0.0850040465593338\n",
      "Epoch: 2484 Loss: 0.08488281816244125\n",
      "Epoch: 2485 Loss: 0.08482854068279266\n",
      "Epoch: 2486 Loss: 0.08483342081308365\n",
      "Epoch: 2487 Loss: 0.08466959744691849\n",
      "Epoch: 2488 Loss: 0.08478689193725586\n",
      "Epoch: 2489 Loss: 0.0845550000667572\n",
      "Epoch: 2490 Loss: 0.084488146007061\n",
      "Epoch: 2491 Loss: 0.08444614708423615\n",
      "Epoch: 2492 Loss: 0.08438950777053833\n",
      "Epoch: 2493 Loss: 0.08437533676624298\n",
      "Epoch: 2494 Loss: 0.08423428982496262\n",
      "Epoch: 2495 Loss: 0.08415533602237701\n",
      "Epoch: 2496 Loss: 0.08415482193231583\n",
      "Epoch: 2497 Loss: 0.08401166647672653\n",
      "Epoch: 2498 Loss: 0.08398430794477463\n",
      "Epoch: 2499 Loss: 0.083824023604393\n",
      "Epoch: 2500 Loss: 0.08382975310087204\n",
      "Epoch: 2501 Loss: 0.08376500755548477\n",
      "Epoch: 2502 Loss: 0.08369182795286179\n",
      "Epoch: 2503 Loss: 0.08362803608179092\n",
      "Epoch: 2504 Loss: 0.08355249464511871\n",
      "Epoch: 2505 Loss: 0.08358951658010483\n",
      "Epoch: 2506 Loss: 0.08339086920022964\n",
      "Epoch: 2507 Loss: 0.08335204422473907\n",
      "Epoch: 2508 Loss: 0.08328723162412643\n",
      "Epoch: 2509 Loss: 0.08319143950939178\n",
      "Epoch: 2510 Loss: 0.0831340104341507\n",
      "Epoch: 2511 Loss: 0.08313808590173721\n",
      "Epoch: 2512 Loss: 0.08301348984241486\n",
      "Epoch: 2513 Loss: 0.08290143311023712\n",
      "Epoch: 2514 Loss: 0.0829780176281929\n",
      "Epoch: 2515 Loss: 0.08277282118797302\n",
      "Epoch: 2516 Loss: 0.08273729681968689\n",
      "Epoch: 2517 Loss: 0.08275312930345535\n",
      "Epoch: 2518 Loss: 0.08266127109527588\n",
      "Epoch: 2519 Loss: 0.08253297954797745\n",
      "Epoch: 2520 Loss: 0.08251119405031204\n",
      "Epoch: 2521 Loss: 0.0824664756655693\n",
      "Epoch: 2522 Loss: 0.08236420899629593\n",
      "Epoch: 2523 Loss: 0.0822664126753807\n",
      "Epoch: 2524 Loss: 0.08225000649690628\n",
      "Epoch: 2525 Loss: 0.08214923739433289\n",
      "Epoch: 2526 Loss: 0.08210926502943039\n",
      "Epoch: 2527 Loss: 0.08204897493124008\n",
      "Epoch: 2528 Loss: 0.08197510987520218\n",
      "Epoch: 2529 Loss: 0.08197400718927383\n",
      "Epoch: 2530 Loss: 0.08180053532123566\n",
      "Epoch: 2531 Loss: 0.08185900747776031\n",
      "Epoch: 2532 Loss: 0.08173901587724686\n",
      "Epoch: 2533 Loss: 0.08160243183374405\n",
      "Epoch: 2534 Loss: 0.0816587582230568\n",
      "Epoch: 2535 Loss: 0.08146385848522186\n",
      "Epoch: 2536 Loss: 0.08144210278987885\n",
      "Epoch: 2537 Loss: 0.08139397948980331\n",
      "Epoch: 2538 Loss: 0.0813203677535057\n",
      "Epoch: 2539 Loss: 0.08130530267953873\n",
      "Epoch: 2540 Loss: 0.08129164576530457\n",
      "Epoch: 2541 Loss: 0.08112774789333344\n",
      "Epoch: 2542 Loss: 0.08106362819671631\n",
      "Epoch: 2543 Loss: 0.08101391792297363\n",
      "Epoch: 2544 Loss: 0.08089752495288849\n",
      "Epoch: 2545 Loss: 0.08094487339258194\n",
      "Epoch: 2546 Loss: 0.0807821974158287\n",
      "Epoch: 2547 Loss: 0.08081719279289246\n",
      "Epoch: 2548 Loss: 0.08070658147335052\n",
      "Epoch: 2549 Loss: 0.08061064779758453\n",
      "Epoch: 2550 Loss: 0.08063600212335587\n",
      "Epoch: 2551 Loss: 0.08051839470863342\n",
      "Epoch: 2552 Loss: 0.08040717244148254\n",
      "Epoch: 2553 Loss: 0.08038224279880524\n",
      "Epoch: 2554 Loss: 0.08037219941616058\n",
      "Epoch: 2555 Loss: 0.08032042533159256\n",
      "Epoch: 2556 Loss: 0.08017198741436005\n",
      "Epoch: 2557 Loss: 0.08016730844974518\n",
      "Epoch: 2558 Loss: 0.08004111796617508\n",
      "Epoch: 2559 Loss: 0.08002067357301712\n",
      "Epoch: 2560 Loss: 0.07994024455547333\n",
      "Epoch: 2561 Loss: 0.07995935529470444\n",
      "Epoch: 2562 Loss: 0.07988723367452621\n",
      "Epoch: 2563 Loss: 0.07973047345876694\n",
      "Epoch: 2564 Loss: 0.07973834127187729\n",
      "Epoch: 2565 Loss: 0.07960739731788635\n",
      "Epoch: 2566 Loss: 0.07957383990287781\n",
      "Epoch: 2567 Loss: 0.07956383377313614\n",
      "Epoch: 2568 Loss: 0.07939372956752777\n",
      "Epoch: 2569 Loss: 0.07937471568584442\n",
      "Epoch: 2570 Loss: 0.07939784228801727\n",
      "Epoch: 2571 Loss: 0.07926668226718903\n",
      "Epoch: 2572 Loss: 0.07919377088546753\n",
      "Epoch: 2573 Loss: 0.0791710689663887\n",
      "Epoch: 2574 Loss: 0.07905813306570053\n",
      "Epoch: 2575 Loss: 0.07910637557506561\n",
      "Epoch: 2576 Loss: 0.07897075265645981\n",
      "Epoch: 2577 Loss: 0.07889733463525772\n",
      "Epoch: 2578 Loss: 0.0789298415184021\n",
      "Epoch: 2579 Loss: 0.07875693589448929\n",
      "Epoch: 2580 Loss: 0.07875178754329681\n",
      "Epoch: 2581 Loss: 0.07863949984312057\n",
      "Epoch: 2582 Loss: 0.0786772295832634\n",
      "Epoch: 2583 Loss: 0.07855354994535446\n",
      "Epoch: 2584 Loss: 0.0784829705953598\n",
      "Epoch: 2585 Loss: 0.07841534167528152\n",
      "Epoch: 2586 Loss: 0.07845853269100189\n",
      "Epoch: 2587 Loss: 0.0783371552824974\n",
      "Epoch: 2588 Loss: 0.07824201136827469\n",
      "Epoch: 2589 Loss: 0.0782056674361229\n",
      "Epoch: 2590 Loss: 0.07807787507772446\n",
      "Epoch: 2591 Loss: 0.07816906273365021\n",
      "Epoch: 2592 Loss: 0.07800519466400146\n",
      "Epoch: 2593 Loss: 0.07793647050857544\n",
      "Epoch: 2594 Loss: 0.07788950204849243\n",
      "Epoch: 2595 Loss: 0.07786644995212555\n",
      "Epoch: 2596 Loss: 0.0778251588344574\n",
      "Epoch: 2597 Loss: 0.07770521938800812\n",
      "Epoch: 2598 Loss: 0.07765960693359375\n",
      "Epoch: 2599 Loss: 0.07759903371334076\n",
      "Epoch: 2600 Loss: 0.07757285982370377\n",
      "Epoch: 2601 Loss: 0.07748110592365265\n",
      "Epoch: 2602 Loss: 0.07743175327777863\n",
      "Epoch: 2603 Loss: 0.07742221653461456\n",
      "Epoch: 2604 Loss: 0.07729151844978333\n",
      "Epoch: 2605 Loss: 0.07725067436695099\n",
      "Epoch: 2606 Loss: 0.07717746496200562\n",
      "Epoch: 2607 Loss: 0.07712620496749878\n",
      "Epoch: 2608 Loss: 0.07709957659244537\n",
      "Epoch: 2609 Loss: 0.07704983651638031\n",
      "Epoch: 2610 Loss: 0.07698369771242142\n",
      "Epoch: 2611 Loss: 0.07691293209791183\n",
      "Epoch: 2612 Loss: 0.07683245092630386\n",
      "Epoch: 2613 Loss: 0.07677540928125381\n",
      "Epoch: 2614 Loss: 0.07670541852712631\n",
      "Epoch: 2615 Loss: 0.07672233879566193\n",
      "Epoch: 2616 Loss: 0.07653293013572693\n",
      "Epoch: 2617 Loss: 0.0765928402543068\n",
      "Epoch: 2618 Loss: 0.07650924474000931\n",
      "Epoch: 2619 Loss: 0.07638034969568253\n",
      "Epoch: 2620 Loss: 0.07636655122041702\n",
      "Epoch: 2621 Loss: 0.07630360871553421\n",
      "Epoch: 2622 Loss: 0.07624709606170654\n",
      "Epoch: 2623 Loss: 0.07618004828691483\n",
      "Epoch: 2624 Loss: 0.07617444545030594\n",
      "Epoch: 2625 Loss: 0.07603190839290619\n",
      "Epoch: 2626 Loss: 0.07603622227907181\n",
      "Epoch: 2627 Loss: 0.07598286122083664\n",
      "Epoch: 2628 Loss: 0.07587316632270813\n",
      "Epoch: 2629 Loss: 0.07584153860807419\n",
      "Epoch: 2630 Loss: 0.07575982809066772\n",
      "Epoch: 2631 Loss: 0.07568128407001495\n",
      "Epoch: 2632 Loss: 0.07568949460983276\n",
      "Epoch: 2633 Loss: 0.07559085637331009\n",
      "Epoch: 2634 Loss: 0.07555276155471802\n",
      "Epoch: 2635 Loss: 0.07546741515398026\n",
      "Epoch: 2636 Loss: 0.07540293782949448\n",
      "Epoch: 2637 Loss: 0.0753851905465126\n",
      "Epoch: 2638 Loss: 0.07531382888555527\n",
      "Epoch: 2639 Loss: 0.07535683363676071\n",
      "Epoch: 2640 Loss: 0.07521502673625946\n",
      "Epoch: 2641 Loss: 0.07513818144798279\n",
      "Epoch: 2642 Loss: 0.07506410777568817\n",
      "Epoch: 2643 Loss: 0.07502583414316177\n",
      "Epoch: 2644 Loss: 0.07499881088733673\n",
      "Epoch: 2645 Loss: 0.07490290701389313\n",
      "Epoch: 2646 Loss: 0.07488803565502167\n",
      "Epoch: 2647 Loss: 0.07478099316358566\n",
      "Epoch: 2648 Loss: 0.07474374026060104\n",
      "Epoch: 2649 Loss: 0.07468339055776596\n",
      "Epoch: 2650 Loss: 0.0746207907795906\n",
      "Epoch: 2651 Loss: 0.07459357380867004\n",
      "Epoch: 2652 Loss: 0.07450942695140839\n",
      "Epoch: 2653 Loss: 0.07442320138216019\n",
      "Epoch: 2654 Loss: 0.07438093423843384\n",
      "Epoch: 2655 Loss: 0.07434913516044617\n",
      "Epoch: 2656 Loss: 0.074330173432827\n",
      "Epoch: 2657 Loss: 0.0742131695151329\n",
      "Epoch: 2658 Loss: 0.07414586842060089\n",
      "Epoch: 2659 Loss: 0.07409639656543732\n",
      "Epoch: 2660 Loss: 0.07407543808221817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2661 Loss: 0.0740671157836914\n",
      "Epoch: 2662 Loss: 0.07396484911441803\n",
      "Epoch: 2663 Loss: 0.07387436926364899\n",
      "Epoch: 2664 Loss: 0.07390188425779343\n",
      "Epoch: 2665 Loss: 0.07376675307750702\n",
      "Epoch: 2666 Loss: 0.0737120658159256\n",
      "Epoch: 2667 Loss: 0.07372020184993744\n",
      "Epoch: 2668 Loss: 0.07360817492008209\n",
      "Epoch: 2669 Loss: 0.07362392544746399\n",
      "Epoch: 2670 Loss: 0.07347884774208069\n",
      "Epoch: 2671 Loss: 0.07349720597267151\n",
      "Epoch: 2672 Loss: 0.07339026778936386\n",
      "Epoch: 2673 Loss: 0.07331346720457077\n",
      "Epoch: 2674 Loss: 0.07327642291784286\n",
      "Epoch: 2675 Loss: 0.07323070615530014\n",
      "Epoch: 2676 Loss: 0.07315930724143982\n",
      "Epoch: 2677 Loss: 0.0731341689825058\n",
      "Epoch: 2678 Loss: 0.07303822785615921\n",
      "Epoch: 2679 Loss: 0.07300972938537598\n",
      "Epoch: 2680 Loss: 0.07297687977552414\n",
      "Epoch: 2681 Loss: 0.0728595182299614\n",
      "Epoch: 2682 Loss: 0.07283385097980499\n",
      "Epoch: 2683 Loss: 0.0727756917476654\n",
      "Epoch: 2684 Loss: 0.07270215451717377\n",
      "Epoch: 2685 Loss: 0.0727299153804779\n",
      "Epoch: 2686 Loss: 0.0726659819483757\n",
      "Epoch: 2687 Loss: 0.07257802039384842\n",
      "Epoch: 2688 Loss: 0.07251069694757462\n",
      "Epoch: 2689 Loss: 0.07248716801404953\n",
      "Epoch: 2690 Loss: 0.07239805161952972\n",
      "Epoch: 2691 Loss: 0.07234251499176025\n",
      "Epoch: 2692 Loss: 0.0722997710108757\n",
      "Epoch: 2693 Loss: 0.07228600233793259\n",
      "Epoch: 2694 Loss: 0.0721665695309639\n",
      "Epoch: 2695 Loss: 0.07211053371429443\n",
      "Epoch: 2696 Loss: 0.0720662847161293\n",
      "Epoch: 2697 Loss: 0.07207541167736053\n",
      "Epoch: 2698 Loss: 0.07196871191263199\n",
      "Epoch: 2699 Loss: 0.07192343473434448\n",
      "Epoch: 2700 Loss: 0.07185519486665726\n",
      "Epoch: 2701 Loss: 0.07183025032281876\n",
      "Epoch: 2702 Loss: 0.07175060361623764\n",
      "Epoch: 2703 Loss: 0.07169751077890396\n",
      "Epoch: 2704 Loss: 0.07170753180980682\n",
      "Epoch: 2705 Loss: 0.07160080969333649\n",
      "Epoch: 2706 Loss: 0.0715581476688385\n",
      "Epoch: 2707 Loss: 0.07149158418178558\n",
      "Epoch: 2708 Loss: 0.07144726812839508\n",
      "Epoch: 2709 Loss: 0.07140740007162094\n",
      "Epoch: 2710 Loss: 0.07132983952760696\n",
      "Epoch: 2711 Loss: 0.0713486596941948\n",
      "Epoch: 2712 Loss: 0.07123738527297974\n",
      "Epoch: 2713 Loss: 0.07118015736341476\n",
      "Epoch: 2714 Loss: 0.07115170359611511\n",
      "Epoch: 2715 Loss: 0.07111626118421555\n",
      "Epoch: 2716 Loss: 0.07099301367998123\n",
      "Epoch: 2717 Loss: 0.07111795246601105\n",
      "Epoch: 2718 Loss: 0.07091519981622696\n",
      "Epoch: 2719 Loss: 0.07090818881988525\n",
      "Epoch: 2720 Loss: 0.07093002647161484\n",
      "Epoch: 2721 Loss: 0.07078925520181656\n",
      "Epoch: 2722 Loss: 0.07073734700679779\n",
      "Epoch: 2723 Loss: 0.07067745923995972\n",
      "Epoch: 2724 Loss: 0.07063417136669159\n",
      "Epoch: 2725 Loss: 0.0705859363079071\n",
      "Epoch: 2726 Loss: 0.07052415609359741\n",
      "Epoch: 2727 Loss: 0.07048206031322479\n",
      "Epoch: 2728 Loss: 0.07048293948173523\n",
      "Epoch: 2729 Loss: 0.07038717716932297\n",
      "Epoch: 2730 Loss: 0.07030986249446869\n",
      "Epoch: 2731 Loss: 0.07027819007635117\n",
      "Epoch: 2732 Loss: 0.07026787102222443\n",
      "Epoch: 2733 Loss: 0.07019023597240448\n",
      "Epoch: 2734 Loss: 0.07013292610645294\n",
      "Epoch: 2735 Loss: 0.07011044770479202\n",
      "Epoch: 2736 Loss: 0.07006135582923889\n",
      "Epoch: 2737 Loss: 0.06999024748802185\n",
      "Epoch: 2738 Loss: 0.06999965012073517\n",
      "Epoch: 2739 Loss: 0.06988141685724258\n",
      "Epoch: 2740 Loss: 0.06983505189418793\n",
      "Epoch: 2741 Loss: 0.0697934553027153\n",
      "Epoch: 2742 Loss: 0.06972793489694595\n",
      "Epoch: 2743 Loss: 0.06966393440961838\n",
      "Epoch: 2744 Loss: 0.06966046243906021\n",
      "Epoch: 2745 Loss: 0.0695616751909256\n",
      "Epoch: 2746 Loss: 0.06952261924743652\n",
      "Epoch: 2747 Loss: 0.06949502229690552\n",
      "Epoch: 2748 Loss: 0.06942226737737656\n",
      "Epoch: 2749 Loss: 0.06941042840480804\n",
      "Epoch: 2750 Loss: 0.06936527788639069\n",
      "Epoch: 2751 Loss: 0.06934499740600586\n",
      "Epoch: 2752 Loss: 0.06925112009048462\n",
      "Epoch: 2753 Loss: 0.0691743940114975\n",
      "Epoch: 2754 Loss: 0.06912314146757126\n",
      "Epoch: 2755 Loss: 0.06906543672084808\n",
      "Epoch: 2756 Loss: 0.06903911381959915\n",
      "Epoch: 2757 Loss: 0.06911595910787582\n",
      "Epoch: 2758 Loss: 0.06895802170038223\n",
      "Epoch: 2759 Loss: 0.06891404837369919\n",
      "Epoch: 2760 Loss: 0.06891708821058273\n",
      "Epoch: 2761 Loss: 0.06879572570323944\n",
      "Epoch: 2762 Loss: 0.06876182556152344\n",
      "Epoch: 2763 Loss: 0.06869013607501984\n",
      "Epoch: 2764 Loss: 0.06865230947732925\n",
      "Epoch: 2765 Loss: 0.06867198646068573\n",
      "Epoch: 2766 Loss: 0.0685688927769661\n",
      "Epoch: 2767 Loss: 0.06851118057966232\n",
      "Epoch: 2768 Loss: 0.06846262514591217\n",
      "Epoch: 2769 Loss: 0.06839267164468765\n",
      "Epoch: 2770 Loss: 0.06836123764514923\n",
      "Epoch: 2771 Loss: 0.06831985712051392\n",
      "Epoch: 2772 Loss: 0.06843271106481552\n",
      "Epoch: 2773 Loss: 0.06821218878030777\n",
      "Epoch: 2774 Loss: 0.0682016983628273\n",
      "Epoch: 2775 Loss: 0.06817466020584106\n",
      "Epoch: 2776 Loss: 0.06808942556381226\n",
      "Epoch: 2777 Loss: 0.06805402785539627\n",
      "Epoch: 2778 Loss: 0.06803158670663834\n",
      "Epoch: 2779 Loss: 0.06793911755084991\n",
      "Epoch: 2780 Loss: 0.06792844086885452\n",
      "Epoch: 2781 Loss: 0.0678233727812767\n",
      "Epoch: 2782 Loss: 0.06786002218723297\n",
      "Epoch: 2783 Loss: 0.06774050742387772\n",
      "Epoch: 2784 Loss: 0.06770706921815872\n",
      "Epoch: 2785 Loss: 0.06767582148313522\n",
      "Epoch: 2786 Loss: 0.06768889725208282\n",
      "Epoch: 2787 Loss: 0.06759653240442276\n",
      "Epoch: 2788 Loss: 0.06754505634307861\n",
      "Epoch: 2789 Loss: 0.0675128772854805\n",
      "Epoch: 2790 Loss: 0.06745564937591553\n",
      "Epoch: 2791 Loss: 0.0674058347940445\n",
      "Epoch: 2792 Loss: 0.0673280581831932\n",
      "Epoch: 2793 Loss: 0.06733931601047516\n",
      "Epoch: 2794 Loss: 0.06722883135080338\n",
      "Epoch: 2795 Loss: 0.06721826642751694\n",
      "Epoch: 2796 Loss: 0.06723333150148392\n",
      "Epoch: 2797 Loss: 0.06711594015359879\n",
      "Epoch: 2798 Loss: 0.06708648055791855\n",
      "Epoch: 2799 Loss: 0.06701140850782394\n",
      "Epoch: 2800 Loss: 0.06696248054504395\n",
      "Epoch: 2801 Loss: 0.06695304065942764\n",
      "Epoch: 2802 Loss: 0.06688034534454346\n",
      "Epoch: 2803 Loss: 0.06682655960321426\n",
      "Epoch: 2804 Loss: 0.06675469875335693\n",
      "Epoch: 2805 Loss: 0.06676965951919556\n",
      "Epoch: 2806 Loss: 0.06670461595058441\n",
      "Epoch: 2807 Loss: 0.06666460633277893\n",
      "Epoch: 2808 Loss: 0.06660284101963043\n",
      "Epoch: 2809 Loss: 0.06662847101688385\n",
      "Epoch: 2810 Loss: 0.06656231731176376\n",
      "Epoch: 2811 Loss: 0.0664917379617691\n",
      "Epoch: 2812 Loss: 0.06642739474773407\n",
      "Epoch: 2813 Loss: 0.0663672462105751\n",
      "Epoch: 2814 Loss: 0.06630609929561615\n",
      "Epoch: 2815 Loss: 0.06630432605743408\n",
      "Epoch: 2816 Loss: 0.0663287416100502\n",
      "Epoch: 2817 Loss: 0.06619809567928314\n",
      "Epoch: 2818 Loss: 0.0661458969116211\n",
      "Epoch: 2819 Loss: 0.06615947186946869\n",
      "Epoch: 2820 Loss: 0.06606558710336685\n",
      "Epoch: 2821 Loss: 0.0660131648182869\n",
      "Epoch: 2822 Loss: 0.06599332392215729\n",
      "Epoch: 2823 Loss: 0.06595954298973083\n",
      "Epoch: 2824 Loss: 0.06589226424694061\n",
      "Epoch: 2825 Loss: 0.06584244221448898\n",
      "Epoch: 2826 Loss: 0.06575606018304825\n",
      "Epoch: 2827 Loss: 0.06575973331928253\n",
      "Epoch: 2828 Loss: 0.06571078300476074\n",
      "Epoch: 2829 Loss: 0.06564787775278091\n",
      "Epoch: 2830 Loss: 0.06560192257165909\n",
      "Epoch: 2831 Loss: 0.06561105698347092\n",
      "Epoch: 2832 Loss: 0.06551635265350342\n",
      "Epoch: 2833 Loss: 0.06547003984451294\n",
      "Epoch: 2834 Loss: 0.06543669104576111\n",
      "Epoch: 2835 Loss: 0.06544357538223267\n",
      "Epoch: 2836 Loss: 0.06534949690103531\n",
      "Epoch: 2837 Loss: 0.06529782712459564\n",
      "Epoch: 2838 Loss: 0.06529814749956131\n",
      "Epoch: 2839 Loss: 0.06518041342496872\n",
      "Epoch: 2840 Loss: 0.06526027619838715\n",
      "Epoch: 2841 Loss: 0.06510445475578308\n",
      "Epoch: 2842 Loss: 0.06509239226579666\n",
      "Epoch: 2843 Loss: 0.06504332274198532\n",
      "Epoch: 2844 Loss: 0.06503350287675858\n",
      "Epoch: 2845 Loss: 0.0649244412779808\n",
      "Epoch: 2846 Loss: 0.06489060819149017\n",
      "Epoch: 2847 Loss: 0.06485109776258469\n",
      "Epoch: 2848 Loss: 0.06482233852148056\n",
      "Epoch: 2849 Loss: 0.06478127092123032\n",
      "Epoch: 2850 Loss: 0.06473274528980255\n",
      "Epoch: 2851 Loss: 0.06467624008655548\n",
      "Epoch: 2852 Loss: 0.06463958323001862\n",
      "Epoch: 2853 Loss: 0.06468615680932999\n",
      "Epoch: 2854 Loss: 0.06456097960472107\n",
      "Epoch: 2855 Loss: 0.06451977789402008\n",
      "Epoch: 2856 Loss: 0.06447456032037735\n",
      "Epoch: 2857 Loss: 0.06440739333629608\n",
      "Epoch: 2858 Loss: 0.06437039375305176\n",
      "Epoch: 2859 Loss: 0.06436891853809357\n",
      "Epoch: 2860 Loss: 0.06433972716331482\n",
      "Epoch: 2861 Loss: 0.06427877396345139\n",
      "Epoch: 2862 Loss: 0.0642063170671463\n",
      "Epoch: 2863 Loss: 0.06418073922395706\n",
      "Epoch: 2864 Loss: 0.06413248181343079\n",
      "Epoch: 2865 Loss: 0.06410928815603256\n",
      "Epoch: 2866 Loss: 0.06402013450860977\n",
      "Epoch: 2867 Loss: 0.06402769684791565\n",
      "Epoch: 2868 Loss: 0.06394094228744507\n",
      "Epoch: 2869 Loss: 0.06393913179636002\n",
      "Epoch: 2870 Loss: 0.06386427581310272\n",
      "Epoch: 2871 Loss: 0.06384403258562088\n",
      "Epoch: 2872 Loss: 0.06381205469369888\n",
      "Epoch: 2873 Loss: 0.06375713646411896\n",
      "Epoch: 2874 Loss: 0.06369338929653168\n",
      "Epoch: 2875 Loss: 0.06367333978414536\n",
      "Epoch: 2876 Loss: 0.06361059099435806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2877 Loss: 0.06360799819231033\n",
      "Epoch: 2878 Loss: 0.06356651335954666\n",
      "Epoch: 2879 Loss: 0.06348317861557007\n",
      "Epoch: 2880 Loss: 0.06342194229364395\n",
      "Epoch: 2881 Loss: 0.06345760822296143\n",
      "Epoch: 2882 Loss: 0.0633319616317749\n",
      "Epoch: 2883 Loss: 0.06330428272485733\n",
      "Epoch: 2884 Loss: 0.0632735937833786\n",
      "Epoch: 2885 Loss: 0.06320297718048096\n",
      "Epoch: 2886 Loss: 0.06327451020479202\n",
      "Epoch: 2887 Loss: 0.06317539513111115\n",
      "Epoch: 2888 Loss: 0.06311025470495224\n",
      "Epoch: 2889 Loss: 0.06308712065219879\n",
      "Epoch: 2890 Loss: 0.06301146745681763\n",
      "Epoch: 2891 Loss: 0.06299193203449249\n",
      "Epoch: 2892 Loss: 0.06292460858821869\n",
      "Epoch: 2893 Loss: 0.06289585679769516\n",
      "Epoch: 2894 Loss: 0.06285305321216583\n",
      "Epoch: 2895 Loss: 0.06281646341085434\n",
      "Epoch: 2896 Loss: 0.0628601610660553\n",
      "Epoch: 2897 Loss: 0.06273584067821503\n",
      "Epoch: 2898 Loss: 0.06269146502017975\n",
      "Epoch: 2899 Loss: 0.06267240643501282\n",
      "Epoch: 2900 Loss: 0.0626172199845314\n",
      "Epoch: 2901 Loss: 0.06256529688835144\n",
      "Epoch: 2902 Loss: 0.06254670023918152\n",
      "Epoch: 2903 Loss: 0.06246071308851242\n",
      "Epoch: 2904 Loss: 0.062437500804662704\n",
      "Epoch: 2905 Loss: 0.06247715279459953\n",
      "Epoch: 2906 Loss: 0.062346626073122025\n",
      "Epoch: 2907 Loss: 0.06230732426047325\n",
      "Epoch: 2908 Loss: 0.062295813113451004\n",
      "Epoch: 2909 Loss: 0.062227774411439896\n",
      "Epoch: 2910 Loss: 0.062267374247312546\n",
      "Epoch: 2911 Loss: 0.06217901408672333\n",
      "Epoch: 2912 Loss: 0.062133610248565674\n",
      "Epoch: 2913 Loss: 0.062062665820121765\n",
      "Epoch: 2914 Loss: 0.06201888248324394\n",
      "Epoch: 2915 Loss: 0.06197645515203476\n",
      "Epoch: 2916 Loss: 0.061985280364751816\n",
      "Epoch: 2917 Loss: 0.06190206855535507\n",
      "Epoch: 2918 Loss: 0.06188729777932167\n",
      "Epoch: 2919 Loss: 0.06182287260890007\n",
      "Epoch: 2920 Loss: 0.06176454946398735\n",
      "Epoch: 2921 Loss: 0.061737604439258575\n",
      "Epoch: 2922 Loss: 0.061716508120298386\n",
      "Epoch: 2923 Loss: 0.06172532960772514\n",
      "Epoch: 2924 Loss: 0.061621423810720444\n",
      "Epoch: 2925 Loss: 0.06156573072075844\n",
      "Epoch: 2926 Loss: 0.061572860926389694\n",
      "Epoch: 2927 Loss: 0.06151198968291283\n",
      "Epoch: 2928 Loss: 0.06159190461039543\n",
      "Epoch: 2929 Loss: 0.061431627720594406\n",
      "Epoch: 2930 Loss: 0.061394184827804565\n",
      "Epoch: 2931 Loss: 0.06133449450135231\n",
      "Epoch: 2932 Loss: 0.06132599338889122\n",
      "Epoch: 2933 Loss: 0.06125546619296074\n",
      "Epoch: 2934 Loss: 0.061203960329294205\n",
      "Epoch: 2935 Loss: 0.06118744611740112\n",
      "Epoch: 2936 Loss: 0.061147429049015045\n",
      "Epoch: 2937 Loss: 0.06107411906123161\n",
      "Epoch: 2938 Loss: 0.06107470393180847\n",
      "Epoch: 2939 Loss: 0.061011724174022675\n",
      "Epoch: 2940 Loss: 0.061048705130815506\n",
      "Epoch: 2941 Loss: 0.06093394756317139\n",
      "Epoch: 2942 Loss: 0.060949232429265976\n",
      "Epoch: 2943 Loss: 0.06084008514881134\n",
      "Epoch: 2944 Loss: 0.06085297092795372\n",
      "Epoch: 2945 Loss: 0.06078231707215309\n",
      "Epoch: 2946 Loss: 0.06074083223938942\n",
      "Epoch: 2947 Loss: 0.06068352237343788\n",
      "Epoch: 2948 Loss: 0.060649510473012924\n",
      "Epoch: 2949 Loss: 0.06062255799770355\n",
      "Epoch: 2950 Loss: 0.0605764240026474\n",
      "Epoch: 2951 Loss: 0.06053848937153816\n",
      "Epoch: 2952 Loss: 0.060483675450086594\n",
      "Epoch: 2953 Loss: 0.06050139665603638\n",
      "Epoch: 2954 Loss: 0.06040194258093834\n",
      "Epoch: 2955 Loss: 0.0603974349796772\n",
      "Epoch: 2956 Loss: 0.06034296751022339\n",
      "Epoch: 2957 Loss: 0.060304876416921616\n",
      "Epoch: 2958 Loss: 0.06027986854314804\n",
      "Epoch: 2959 Loss: 0.06020664796233177\n",
      "Epoch: 2960 Loss: 0.060175444930791855\n",
      "Epoch: 2961 Loss: 0.06022694706916809\n",
      "Epoch: 2962 Loss: 0.060143738985061646\n",
      "Epoch: 2963 Loss: 0.06007268279790878\n",
      "Epoch: 2964 Loss: 0.06002751365303993\n",
      "Epoch: 2965 Loss: 0.05997418612241745\n",
      "Epoch: 2966 Loss: 0.05999535322189331\n",
      "Epoch: 2967 Loss: 0.059869375079870224\n",
      "Epoch: 2968 Loss: 0.05988551303744316\n",
      "Epoch: 2969 Loss: 0.05982241407036781\n",
      "Epoch: 2970 Loss: 0.05979067459702492\n",
      "Epoch: 2971 Loss: 0.059784743934869766\n",
      "Epoch: 2972 Loss: 0.05970410630106926\n",
      "Epoch: 2973 Loss: 0.0597410686314106\n",
      "Epoch: 2974 Loss: 0.059643521904945374\n",
      "Epoch: 2975 Loss: 0.05963549390435219\n",
      "Epoch: 2976 Loss: 0.059557389467954636\n",
      "Epoch: 2977 Loss: 0.059522271156311035\n",
      "Epoch: 2978 Loss: 0.05946727469563484\n",
      "Epoch: 2979 Loss: 0.05943166837096214\n",
      "Epoch: 2980 Loss: 0.05945387855172157\n",
      "Epoch: 2981 Loss: 0.05937139689922333\n",
      "Epoch: 2982 Loss: 0.05936015769839287\n",
      "Epoch: 2983 Loss: 0.059280723333358765\n",
      "Epoch: 2984 Loss: 0.059238217771053314\n",
      "Epoch: 2985 Loss: 0.05921729654073715\n",
      "Epoch: 2986 Loss: 0.05921463295817375\n",
      "Epoch: 2987 Loss: 0.059174858033657074\n",
      "Epoch: 2988 Loss: 0.05910491198301315\n",
      "Epoch: 2989 Loss: 0.05905848741531372\n",
      "Epoch: 2990 Loss: 0.05907495692372322\n",
      "Epoch: 2991 Loss: 0.05899359658360481\n",
      "Epoch: 2992 Loss: 0.058944933116436005\n",
      "Epoch: 2993 Loss: 0.05893230065703392\n",
      "Epoch: 2994 Loss: 0.0588383674621582\n",
      "Epoch: 2995 Loss: 0.058830611407756805\n",
      "Epoch: 2996 Loss: 0.05878902226686478\n",
      "Epoch: 2997 Loss: 0.05883282795548439\n",
      "Epoch: 2998 Loss: 0.05872711166739464\n",
      "Epoch: 2999 Loss: 0.058664415031671524\n",
      "Epoch: 3000 Loss: 0.058627087622880936\n",
      "Epoch: 3001 Loss: 0.05857263505458832\n",
      "Epoch: 3002 Loss: 0.05857427790760994\n",
      "Epoch: 3003 Loss: 0.05851228907704353\n",
      "Epoch: 3004 Loss: 0.05848391726613045\n",
      "Epoch: 3005 Loss: 0.05843237414956093\n",
      "Epoch: 3006 Loss: 0.05840112641453743\n",
      "Epoch: 3007 Loss: 0.05834931507706642\n",
      "Epoch: 3008 Loss: 0.05836279317736626\n",
      "Epoch: 3009 Loss: 0.05826680362224579\n",
      "Epoch: 3010 Loss: 0.05833609774708748\n",
      "Epoch: 3011 Loss: 0.05819574370980263\n",
      "Epoch: 3012 Loss: 0.0581778809428215\n",
      "Epoch: 3013 Loss: 0.05813654139637947\n",
      "Epoch: 3014 Loss: 0.05808677896857262\n",
      "Epoch: 3015 Loss: 0.05805891007184982\n",
      "Epoch: 3016 Loss: 0.05801885202527046\n",
      "Epoch: 3017 Loss: 0.05797435715794563\n",
      "Epoch: 3018 Loss: 0.05794169008731842\n",
      "Epoch: 3019 Loss: 0.057914357632398605\n",
      "Epoch: 3020 Loss: 0.05791543796658516\n",
      "Epoch: 3021 Loss: 0.057876184582710266\n",
      "Epoch: 3022 Loss: 0.05780895799398422\n",
      "Epoch: 3023 Loss: 0.0577501580119133\n",
      "Epoch: 3024 Loss: 0.05773762986063957\n",
      "Epoch: 3025 Loss: 0.0576818510890007\n",
      "Epoch: 3026 Loss: 0.05766555666923523\n",
      "Epoch: 3027 Loss: 0.057598091661930084\n",
      "Epoch: 3028 Loss: 0.05756919085979462\n",
      "Epoch: 3029 Loss: 0.05751216411590576\n",
      "Epoch: 3030 Loss: 0.057499464601278305\n",
      "Epoch: 3031 Loss: 0.057490989565849304\n",
      "Epoch: 3032 Loss: 0.05748532712459564\n",
      "Epoch: 3033 Loss: 0.0574006512761116\n",
      "Epoch: 3034 Loss: 0.05734656751155853\n",
      "Epoch: 3035 Loss: 0.057317640632390976\n",
      "Epoch: 3036 Loss: 0.05727376788854599\n",
      "Epoch: 3037 Loss: 0.057252414524555206\n",
      "Epoch: 3038 Loss: 0.057230520993471146\n",
      "Epoch: 3039 Loss: 0.057134222239255905\n",
      "Epoch: 3040 Loss: 0.057134803384542465\n",
      "Epoch: 3041 Loss: 0.057093311101198196\n",
      "Epoch: 3042 Loss: 0.057063378393650055\n",
      "Epoch: 3043 Loss: 0.05705450102686882\n",
      "Epoch: 3044 Loss: 0.056996043771505356\n",
      "Epoch: 3045 Loss: 0.05696719512343407\n",
      "Epoch: 3046 Loss: 0.056940171867609024\n",
      "Epoch: 3047 Loss: 0.05685052275657654\n",
      "Epoch: 3048 Loss: 0.05686056986451149\n",
      "Epoch: 3049 Loss: 0.056794650852680206\n",
      "Epoch: 3050 Loss: 0.05677925422787666\n",
      "Epoch: 3051 Loss: 0.056709568947553635\n",
      "Epoch: 3052 Loss: 0.05668621510267258\n",
      "Epoch: 3053 Loss: 0.05664354935288429\n",
      "Epoch: 3054 Loss: 0.05661590024828911\n",
      "Epoch: 3055 Loss: 0.0566437765955925\n",
      "Epoch: 3056 Loss: 0.0565689280629158\n",
      "Epoch: 3057 Loss: 0.05649929121136665\n",
      "Epoch: 3058 Loss: 0.05648667737841606\n",
      "Epoch: 3059 Loss: 0.056414682418107986\n",
      "Epoch: 3060 Loss: 0.05638689175248146\n",
      "Epoch: 3061 Loss: 0.056368980556726456\n",
      "Epoch: 3062 Loss: 0.05634942278265953\n",
      "Epoch: 3063 Loss: 0.056287288665771484\n",
      "Epoch: 3064 Loss: 0.05627859756350517\n",
      "Epoch: 3065 Loss: 0.056217074394226074\n",
      "Epoch: 3066 Loss: 0.05624064430594444\n",
      "Epoch: 3067 Loss: 0.05615031719207764\n",
      "Epoch: 3068 Loss: 0.05611448362469673\n",
      "Epoch: 3069 Loss: 0.05607905611395836\n",
      "Epoch: 3070 Loss: 0.05604349449276924\n",
      "Epoch: 3071 Loss: 0.055997084826231\n",
      "Epoch: 3072 Loss: 0.05597597360610962\n",
      "Epoch: 3073 Loss: 0.0559416264295578\n",
      "Epoch: 3074 Loss: 0.05588150769472122\n",
      "Epoch: 3075 Loss: 0.05586518347263336\n",
      "Epoch: 3076 Loss: 0.055823154747486115\n",
      "Epoch: 3077 Loss: 0.05579596757888794\n",
      "Epoch: 3078 Loss: 0.055764518678188324\n",
      "Epoch: 3079 Loss: 0.055698588490486145\n",
      "Epoch: 3080 Loss: 0.05570783093571663\n",
      "Epoch: 3081 Loss: 0.055655863136053085\n",
      "Epoch: 3082 Loss: 0.055612288415431976\n",
      "Epoch: 3083 Loss: 0.05557538568973541\n",
      "Epoch: 3084 Loss: 0.05553371086716652\n",
      "Epoch: 3085 Loss: 0.05550358444452286\n",
      "Epoch: 3086 Loss: 0.05550185218453407\n",
      "Epoch: 3087 Loss: 0.05542375147342682\n",
      "Epoch: 3088 Loss: 0.05543026328086853\n",
      "Epoch: 3089 Loss: 0.055432990193367004\n",
      "Epoch: 3090 Loss: 0.055334750562906265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3091 Loss: 0.05529477074742317\n",
      "Epoch: 3092 Loss: 0.05525246635079384\n",
      "Epoch: 3093 Loss: 0.05526745691895485\n",
      "Epoch: 3094 Loss: 0.05518920347094536\n",
      "Epoch: 3095 Loss: 0.055153556168079376\n",
      "Epoch: 3096 Loss: 0.05513948202133179\n",
      "Epoch: 3097 Loss: 0.055093973875045776\n",
      "Epoch: 3098 Loss: 0.055090487003326416\n",
      "Epoch: 3099 Loss: 0.055023182183504105\n",
      "Epoch: 3100 Loss: 0.05499022454023361\n",
      "Epoch: 3101 Loss: 0.054966818541288376\n",
      "Epoch: 3102 Loss: 0.05492798238992691\n",
      "Epoch: 3103 Loss: 0.05487947165966034\n",
      "Epoch: 3104 Loss: 0.054848767817020416\n",
      "Epoch: 3105 Loss: 0.054788876324892044\n",
      "Epoch: 3106 Loss: 0.05477519333362579\n",
      "Epoch: 3107 Loss: 0.05473906919360161\n",
      "Epoch: 3108 Loss: 0.05473509058356285\n",
      "Epoch: 3109 Loss: 0.05466680973768234\n",
      "Epoch: 3110 Loss: 0.05461501330137253\n",
      "Epoch: 3111 Loss: 0.0546061210334301\n",
      "Epoch: 3112 Loss: 0.05457378923892975\n",
      "Epoch: 3113 Loss: 0.054580289870500565\n",
      "Epoch: 3114 Loss: 0.054497528821229935\n",
      "Epoch: 3115 Loss: 0.05446775257587433\n",
      "Epoch: 3116 Loss: 0.05442870035767555\n",
      "Epoch: 3117 Loss: 0.054393768310546875\n",
      "Epoch: 3118 Loss: 0.054360974580049515\n",
      "Epoch: 3119 Loss: 0.05434674769639969\n",
      "Epoch: 3120 Loss: 0.054341770708560944\n",
      "Epoch: 3121 Loss: 0.054271623492240906\n",
      "Epoch: 3122 Loss: 0.054249413311481476\n",
      "Epoch: 3123 Loss: 0.05419350787997246\n",
      "Epoch: 3124 Loss: 0.054159533232450485\n",
      "Epoch: 3125 Loss: 0.05414678528904915\n",
      "Epoch: 3126 Loss: 0.05409086495637894\n",
      "Epoch: 3127 Loss: 0.05407452583312988\n",
      "Epoch: 3128 Loss: 0.05402427166700363\n",
      "Epoch: 3129 Loss: 0.05404987186193466\n",
      "Epoch: 3130 Loss: 0.05398089066147804\n",
      "Epoch: 3131 Loss: 0.05394359305500984\n",
      "Epoch: 3132 Loss: 0.05389484018087387\n",
      "Epoch: 3133 Loss: 0.05386810377240181\n",
      "Epoch: 3134 Loss: 0.053809624165296555\n",
      "Epoch: 3135 Loss: 0.0538448728621006\n",
      "Epoch: 3136 Loss: 0.05375876650214195\n",
      "Epoch: 3137 Loss: 0.053734079003334045\n",
      "Epoch: 3138 Loss: 0.05369673669338226\n",
      "Epoch: 3139 Loss: 0.05369240418076515\n",
      "Epoch: 3140 Loss: 0.0536215677857399\n",
      "Epoch: 3141 Loss: 0.05360725522041321\n",
      "Epoch: 3142 Loss: 0.053608935326337814\n",
      "Epoch: 3143 Loss: 0.0535762645304203\n",
      "Epoch: 3144 Loss: 0.053515709936618805\n",
      "Epoch: 3145 Loss: 0.05347560718655586\n",
      "Epoch: 3146 Loss: 0.05345495417714119\n",
      "Epoch: 3147 Loss: 0.05340583249926567\n",
      "Epoch: 3148 Loss: 0.0534440353512764\n",
      "Epoch: 3149 Loss: 0.05333970859646797\n",
      "Epoch: 3150 Loss: 0.05332695320248604\n",
      "Epoch: 3151 Loss: 0.053262755274772644\n",
      "Epoch: 3152 Loss: 0.05324903503060341\n",
      "Epoch: 3153 Loss: 0.05320366844534874\n",
      "Epoch: 3154 Loss: 0.05317317321896553\n",
      "Epoch: 3155 Loss: 0.053144656121730804\n",
      "Epoch: 3156 Loss: 0.05312478542327881\n",
      "Epoch: 3157 Loss: 0.05308998003602028\n",
      "Epoch: 3158 Loss: 0.05305122956633568\n",
      "Epoch: 3159 Loss: 0.05302007496356964\n",
      "Epoch: 3160 Loss: 0.052972592413425446\n",
      "Epoch: 3161 Loss: 0.05295407399535179\n",
      "Epoch: 3162 Loss: 0.052909672260284424\n",
      "Epoch: 3163 Loss: 0.05295374244451523\n",
      "Epoch: 3164 Loss: 0.05285600200295448\n",
      "Epoch: 3165 Loss: 0.05283217504620552\n",
      "Epoch: 3166 Loss: 0.05278448387980461\n",
      "Epoch: 3167 Loss: 0.052780114114284515\n",
      "Epoch: 3168 Loss: 0.05270029604434967\n",
      "Epoch: 3169 Loss: 0.052692972123622894\n",
      "Epoch: 3170 Loss: 0.052673354744911194\n",
      "Epoch: 3171 Loss: 0.05262181535363197\n",
      "Epoch: 3172 Loss: 0.05257491394877434\n",
      "Epoch: 3173 Loss: 0.052569251507520676\n",
      "Epoch: 3174 Loss: 0.052568864077329636\n",
      "Epoch: 3175 Loss: 0.05249593406915665\n",
      "Epoch: 3176 Loss: 0.0524769127368927\n",
      "Epoch: 3177 Loss: 0.05243505910038948\n",
      "Epoch: 3178 Loss: 0.05240393057465553\n",
      "Epoch: 3179 Loss: 0.052375808358192444\n",
      "Epoch: 3180 Loss: 0.052382439374923706\n",
      "Epoch: 3181 Loss: 0.05230947583913803\n",
      "Epoch: 3182 Loss: 0.052268415689468384\n",
      "Epoch: 3183 Loss: 0.052235204726457596\n",
      "Epoch: 3184 Loss: 0.05222081393003464\n",
      "Epoch: 3185 Loss: 0.05218333378434181\n",
      "Epoch: 3186 Loss: 0.05212961137294769\n",
      "Epoch: 3187 Loss: 0.052129462361335754\n",
      "Epoch: 3188 Loss: 0.05208596587181091\n",
      "Epoch: 3189 Loss: 0.05204296112060547\n",
      "Epoch: 3190 Loss: 0.05201074853539467\n",
      "Epoch: 3191 Loss: 0.05199424922466278\n",
      "Epoch: 3192 Loss: 0.05193490535020828\n",
      "Epoch: 3193 Loss: 0.05194598063826561\n",
      "Epoch: 3194 Loss: 0.05189087241888046\n",
      "Epoch: 3195 Loss: 0.051865462213754654\n",
      "Epoch: 3196 Loss: 0.05183551460504532\n",
      "Epoch: 3197 Loss: 0.05180469900369644\n",
      "Epoch: 3198 Loss: 0.05175954848527908\n",
      "Epoch: 3199 Loss: 0.05173998698592186\n",
      "Epoch: 3200 Loss: 0.051692888140678406\n",
      "Epoch: 3201 Loss: 0.05168011784553528\n",
      "Epoch: 3202 Loss: 0.05162854492664337\n",
      "Epoch: 3203 Loss: 0.05160827934741974\n",
      "Epoch: 3204 Loss: 0.05159592255949974\n",
      "Epoch: 3205 Loss: 0.05154382437467575\n",
      "Epoch: 3206 Loss: 0.05152329057455063\n",
      "Epoch: 3207 Loss: 0.05154184252023697\n",
      "Epoch: 3208 Loss: 0.051517389714717865\n",
      "Epoch: 3209 Loss: 0.05146824195981026\n",
      "Epoch: 3210 Loss: 0.05140708386898041\n",
      "Epoch: 3211 Loss: 0.05139278620481491\n",
      "Epoch: 3212 Loss: 0.05135394260287285\n",
      "Epoch: 3213 Loss: 0.0513482466340065\n",
      "Epoch: 3214 Loss: 0.05128388851881027\n",
      "Epoch: 3215 Loss: 0.05125267058610916\n",
      "Epoch: 3216 Loss: 0.05120920389890671\n",
      "Epoch: 3217 Loss: 0.05122356116771698\n",
      "Epoch: 3218 Loss: 0.051138006150722504\n",
      "Epoch: 3219 Loss: 0.051108215004205704\n",
      "Epoch: 3220 Loss: 0.051082585006952286\n",
      "Epoch: 3221 Loss: 0.05112641677260399\n",
      "Epoch: 3222 Loss: 0.0510372593998909\n",
      "Epoch: 3223 Loss: 0.05099872127175331\n",
      "Epoch: 3224 Loss: 0.05097375810146332\n",
      "Epoch: 3225 Loss: 0.0509326197206974\n",
      "Epoch: 3226 Loss: 0.05091310665011406\n",
      "Epoch: 3227 Loss: 0.05087720602750778\n",
      "Epoch: 3228 Loss: 0.05082632228732109\n",
      "Epoch: 3229 Loss: 0.050806719809770584\n",
      "Epoch: 3230 Loss: 0.05079587921500206\n",
      "Epoch: 3231 Loss: 0.050738006830215454\n",
      "Epoch: 3232 Loss: 0.05074533075094223\n",
      "Epoch: 3233 Loss: 0.05071507394313812\n",
      "Epoch: 3234 Loss: 0.0506613664329052\n",
      "Epoch: 3235 Loss: 0.050646256655454636\n",
      "Epoch: 3236 Loss: 0.050592437386512756\n",
      "Epoch: 3237 Loss: 0.05058848112821579\n",
      "Epoch: 3238 Loss: 0.05052947625517845\n",
      "Epoch: 3239 Loss: 0.050511427223682404\n",
      "Epoch: 3240 Loss: 0.05047832429409027\n",
      "Epoch: 3241 Loss: 0.05045044422149658\n",
      "Epoch: 3242 Loss: 0.05041296035051346\n",
      "Epoch: 3243 Loss: 0.05038009211421013\n",
      "Epoch: 3244 Loss: 0.05036863312125206\n",
      "Epoch: 3245 Loss: 0.05033797770738602\n",
      "Epoch: 3246 Loss: 0.050299886614084244\n",
      "Epoch: 3247 Loss: 0.05026273801922798\n",
      "Epoch: 3248 Loss: 0.05025175213813782\n",
      "Epoch: 3249 Loss: 0.050211962312459946\n",
      "Epoch: 3250 Loss: 0.05017301067709923\n",
      "Epoch: 3251 Loss: 0.05013924837112427\n",
      "Epoch: 3252 Loss: 0.05013519898056984\n",
      "Epoch: 3253 Loss: 0.05008076876401901\n",
      "Epoch: 3254 Loss: 0.050062112510204315\n",
      "Epoch: 3255 Loss: 0.05007370933890343\n",
      "Epoch: 3256 Loss: 0.05000198632478714\n",
      "Epoch: 3257 Loss: 0.04998629912734032\n",
      "Epoch: 3258 Loss: 0.049948014318943024\n",
      "Epoch: 3259 Loss: 0.049912359565496445\n",
      "Epoch: 3260 Loss: 0.049882903695106506\n",
      "Epoch: 3261 Loss: 0.04985373467206955\n",
      "Epoch: 3262 Loss: 0.04981575533747673\n",
      "Epoch: 3263 Loss: 0.04979536309838295\n",
      "Epoch: 3264 Loss: 0.049797262996435165\n",
      "Epoch: 3265 Loss: 0.049750301986932755\n",
      "Epoch: 3266 Loss: 0.04973291978240013\n",
      "Epoch: 3267 Loss: 0.049687061458826065\n",
      "Epoch: 3268 Loss: 0.04965553805232048\n",
      "Epoch: 3269 Loss: 0.04961487278342247\n",
      "Epoch: 3270 Loss: 0.04960879310965538\n",
      "Epoch: 3271 Loss: 0.049555372446775436\n",
      "Epoch: 3272 Loss: 0.04951268807053566\n",
      "Epoch: 3273 Loss: 0.049517299979925156\n",
      "Epoch: 3274 Loss: 0.04946182295680046\n",
      "Epoch: 3275 Loss: 0.04944782704114914\n",
      "Epoch: 3276 Loss: 0.04940678924322128\n",
      "Epoch: 3277 Loss: 0.049396906048059464\n",
      "Epoch: 3278 Loss: 0.049362991005182266\n",
      "Epoch: 3279 Loss: 0.04938317835330963\n",
      "Epoch: 3280 Loss: 0.04928823933005333\n",
      "Epoch: 3281 Loss: 0.04929540306329727\n",
      "Epoch: 3282 Loss: 0.04923740029335022\n",
      "Epoch: 3283 Loss: 0.0492262989282608\n",
      "Epoch: 3284 Loss: 0.04918486624956131\n",
      "Epoch: 3285 Loss: 0.049160245805978775\n",
      "Epoch: 3286 Loss: 0.04911487549543381\n",
      "Epoch: 3287 Loss: 0.04910928010940552\n",
      "Epoch: 3288 Loss: 0.04905961826443672\n",
      "Epoch: 3289 Loss: 0.04910879582166672\n",
      "Epoch: 3290 Loss: 0.04902196303009987\n",
      "Epoch: 3291 Loss: 0.04899833723902702\n",
      "Epoch: 3292 Loss: 0.04896627366542816\n",
      "Epoch: 3293 Loss: 0.048926979303359985\n",
      "Epoch: 3294 Loss: 0.048902109265327454\n",
      "Epoch: 3295 Loss: 0.048882585018873215\n",
      "Epoch: 3296 Loss: 0.048842187970876694\n",
      "Epoch: 3297 Loss: 0.048819709569215775\n",
      "Epoch: 3298 Loss: 0.048784904181957245\n",
      "Epoch: 3299 Loss: 0.048736050724983215\n",
      "Epoch: 3300 Loss: 0.04870763048529625\n",
      "Epoch: 3301 Loss: 0.048700541257858276\n",
      "Epoch: 3302 Loss: 0.04868321120738983\n",
      "Epoch: 3303 Loss: 0.048628125339746475\n",
      "Epoch: 3304 Loss: 0.048628512769937515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3305 Loss: 0.04858308658003807\n",
      "Epoch: 3306 Loss: 0.0485985092818737\n",
      "Epoch: 3307 Loss: 0.048588771373033524\n",
      "Epoch: 3308 Loss: 0.04849693179130554\n",
      "Epoch: 3309 Loss: 0.04848721995949745\n",
      "Epoch: 3310 Loss: 0.04842355102300644\n",
      "Epoch: 3311 Loss: 0.04841632395982742\n",
      "Epoch: 3312 Loss: 0.048388198018074036\n",
      "Epoch: 3313 Loss: 0.04837508127093315\n",
      "Epoch: 3314 Loss: 0.048339053988456726\n",
      "Epoch: 3315 Loss: 0.048307813704013824\n",
      "Epoch: 3316 Loss: 0.04828929901123047\n",
      "Epoch: 3317 Loss: 0.04831169918179512\n",
      "Epoch: 3318 Loss: 0.04822473227977753\n",
      "Epoch: 3319 Loss: 0.0482025109231472\n",
      "Epoch: 3320 Loss: 0.048156023025512695\n",
      "Epoch: 3321 Loss: 0.04814111068844795\n",
      "Epoch: 3322 Loss: 0.04811404272913933\n",
      "Epoch: 3323 Loss: 0.04808041453361511\n",
      "Epoch: 3324 Loss: 0.0480370819568634\n",
      "Epoch: 3325 Loss: 0.04804364591836929\n",
      "Epoch: 3326 Loss: 0.048013053834438324\n",
      "Epoch: 3327 Loss: 0.0479828380048275\n",
      "Epoch: 3328 Loss: 0.04795282334089279\n",
      "Epoch: 3329 Loss: 0.04792524874210358\n",
      "Epoch: 3330 Loss: 0.047881271690130234\n",
      "Epoch: 3331 Loss: 0.047869566828012466\n",
      "Epoch: 3332 Loss: 0.04783538728952408\n",
      "Epoch: 3333 Loss: 0.04780099168419838\n",
      "Epoch: 3334 Loss: 0.04776938632130623\n",
      "Epoch: 3335 Loss: 0.04774943366646767\n",
      "Epoch: 3336 Loss: 0.047736458480358124\n",
      "Epoch: 3337 Loss: 0.04769403859972954\n",
      "Epoch: 3338 Loss: 0.04764929786324501\n",
      "Epoch: 3339 Loss: 0.04764712601900101\n",
      "Epoch: 3340 Loss: 0.04764147475361824\n",
      "Epoch: 3341 Loss: 0.04763190448284149\n",
      "Epoch: 3342 Loss: 0.04757687449455261\n",
      "Epoch: 3343 Loss: 0.04754362627863884\n",
      "Epoch: 3344 Loss: 0.04750014841556549\n",
      "Epoch: 3345 Loss: 0.04747176915407181\n",
      "Epoch: 3346 Loss: 0.04748460650444031\n",
      "Epoch: 3347 Loss: 0.04740680381655693\n",
      "Epoch: 3348 Loss: 0.04742177575826645\n",
      "Epoch: 3349 Loss: 0.047375407069921494\n",
      "Epoch: 3350 Loss: 0.04734412580728531\n",
      "Epoch: 3351 Loss: 0.04731396213173866\n",
      "Epoch: 3352 Loss: 0.04728608578443527\n",
      "Epoch: 3353 Loss: 0.04726681113243103\n",
      "Epoch: 3354 Loss: 0.04723774641752243\n",
      "Epoch: 3355 Loss: 0.04726048931479454\n",
      "Epoch: 3356 Loss: 0.04718569666147232\n",
      "Epoch: 3357 Loss: 0.047167349606752396\n",
      "Epoch: 3358 Loss: 0.04716004431247711\n",
      "Epoch: 3359 Loss: 0.04712335765361786\n",
      "Epoch: 3360 Loss: 0.04712880775332451\n",
      "Epoch: 3361 Loss: 0.04706060513854027\n",
      "Epoch: 3362 Loss: 0.047032296657562256\n",
      "Epoch: 3363 Loss: 0.04700259864330292\n",
      "Epoch: 3364 Loss: 0.04698604717850685\n",
      "Epoch: 3365 Loss: 0.046958163380622864\n",
      "Epoch: 3366 Loss: 0.04693074896931648\n",
      "Epoch: 3367 Loss: 0.046887900680303574\n",
      "Epoch: 3368 Loss: 0.04688740521669388\n",
      "Epoch: 3369 Loss: 0.0468277782201767\n",
      "Epoch: 3370 Loss: 0.046812012791633606\n",
      "Epoch: 3371 Loss: 0.046792853623628616\n",
      "Epoch: 3372 Loss: 0.04677043855190277\n",
      "Epoch: 3373 Loss: 0.04673309624195099\n",
      "Epoch: 3374 Loss: 0.046738654375076294\n",
      "Epoch: 3375 Loss: 0.04672388732433319\n",
      "Epoch: 3376 Loss: 0.04668295755982399\n",
      "Epoch: 3377 Loss: 0.04663950577378273\n",
      "Epoch: 3378 Loss: 0.04661741852760315\n",
      "Epoch: 3379 Loss: 0.04657070338726044\n",
      "Epoch: 3380 Loss: 0.04655514657497406\n",
      "Epoch: 3381 Loss: 0.04652758315205574\n",
      "Epoch: 3382 Loss: 0.04650137200951576\n",
      "Epoch: 3383 Loss: 0.04646635800600052\n",
      "Epoch: 3384 Loss: 0.04645652696490288\n",
      "Epoch: 3385 Loss: 0.04644036665558815\n",
      "Epoch: 3386 Loss: 0.04642653837800026\n",
      "Epoch: 3387 Loss: 0.04638650640845299\n",
      "Epoch: 3388 Loss: 0.04634253680706024\n",
      "Epoch: 3389 Loss: 0.04632951319217682\n",
      "Epoch: 3390 Loss: 0.046300940215587616\n",
      "Epoch: 3391 Loss: 0.04628908261656761\n",
      "Epoch: 3392 Loss: 0.04626242816448212\n",
      "Epoch: 3393 Loss: 0.04623372107744217\n",
      "Epoch: 3394 Loss: 0.046194855123758316\n",
      "Epoch: 3395 Loss: 0.046172134578228\n",
      "Epoch: 3396 Loss: 0.046142518520355225\n",
      "Epoch: 3397 Loss: 0.046115268021821976\n",
      "Epoch: 3398 Loss: 0.04610736295580864\n",
      "Epoch: 3399 Loss: 0.046069420874118805\n",
      "Epoch: 3400 Loss: 0.04607398435473442\n",
      "Epoch: 3401 Loss: 0.04605233296751976\n",
      "Epoch: 3402 Loss: 0.046013638377189636\n",
      "Epoch: 3403 Loss: 0.045964404940605164\n",
      "Epoch: 3404 Loss: 0.04594669118523598\n",
      "Epoch: 3405 Loss: 0.04592335596680641\n",
      "Epoch: 3406 Loss: 0.045885566622018814\n",
      "Epoch: 3407 Loss: 0.04586639627814293\n",
      "Epoch: 3408 Loss: 0.04583112895488739\n",
      "Epoch: 3409 Loss: 0.04581962153315544\n",
      "Epoch: 3410 Loss: 0.04578132554888725\n",
      "Epoch: 3411 Loss: 0.045754577964544296\n",
      "Epoch: 3412 Loss: 0.045776985585689545\n",
      "Epoch: 3413 Loss: 0.04571389779448509\n",
      "Epoch: 3414 Loss: 0.04571277275681496\n",
      "Epoch: 3415 Loss: 0.04565857723355293\n",
      "Epoch: 3416 Loss: 0.04563770815730095\n",
      "Epoch: 3417 Loss: 0.04561539739370346\n",
      "Epoch: 3418 Loss: 0.04559002071619034\n",
      "Epoch: 3419 Loss: 0.045569125562906265\n",
      "Epoch: 3420 Loss: 0.045562222599983215\n",
      "Epoch: 3421 Loss: 0.04550594463944435\n",
      "Epoch: 3422 Loss: 0.04547809064388275\n",
      "Epoch: 3423 Loss: 0.045473068952560425\n",
      "Epoch: 3424 Loss: 0.04544394835829735\n",
      "Epoch: 3425 Loss: 0.04540882259607315\n",
      "Epoch: 3426 Loss: 0.045377571135759354\n",
      "Epoch: 3427 Loss: 0.04536082595586777\n",
      "Epoch: 3428 Loss: 0.04534285515546799\n",
      "Epoch: 3429 Loss: 0.045367635786533356\n",
      "Epoch: 3430 Loss: 0.04528512433171272\n",
      "Epoch: 3431 Loss: 0.04526025429368019\n",
      "Epoch: 3432 Loss: 0.045237962156534195\n",
      "Epoch: 3433 Loss: 0.04521942883729935\n",
      "Epoch: 3434 Loss: 0.045209985226392746\n",
      "Epoch: 3435 Loss: 0.045151107013225555\n",
      "Epoch: 3436 Loss: 0.04514232650399208\n",
      "Epoch: 3437 Loss: 0.04511111602187157\n",
      "Epoch: 3438 Loss: 0.04509161040186882\n",
      "Epoch: 3439 Loss: 0.045053958892822266\n",
      "Epoch: 3440 Loss: 0.045047517865896225\n",
      "Epoch: 3441 Loss: 0.04500892385840416\n",
      "Epoch: 3442 Loss: 0.04499340057373047\n",
      "Epoch: 3443 Loss: 0.044965412467718124\n",
      "Epoch: 3444 Loss: 0.044932540506124496\n",
      "Epoch: 3445 Loss: 0.044913988560438156\n",
      "Epoch: 3446 Loss: 0.04489465802907944\n",
      "Epoch: 3447 Loss: 0.04486534744501114\n",
      "Epoch: 3448 Loss: 0.0448504202067852\n",
      "Epoch: 3449 Loss: 0.04479862377047539\n",
      "Epoch: 3450 Loss: 0.04478774964809418\n",
      "Epoch: 3451 Loss: 0.044768478721380234\n",
      "Epoch: 3452 Loss: 0.04473749175667763\n",
      "Epoch: 3453 Loss: 0.04471645876765251\n",
      "Epoch: 3454 Loss: 0.04469185322523117\n",
      "Epoch: 3455 Loss: 0.04466012865304947\n",
      "Epoch: 3456 Loss: 0.044640377163887024\n",
      "Epoch: 3457 Loss: 0.0446673221886158\n",
      "Epoch: 3458 Loss: 0.04464090242981911\n",
      "Epoch: 3459 Loss: 0.04458632320165634\n",
      "Epoch: 3460 Loss: 0.04455757886171341\n",
      "Epoch: 3461 Loss: 0.044533222913742065\n",
      "Epoch: 3462 Loss: 0.04450191557407379\n",
      "Epoch: 3463 Loss: 0.044474437832832336\n",
      "Epoch: 3464 Loss: 0.04444624111056328\n",
      "Epoch: 3465 Loss: 0.044458966702222824\n",
      "Epoch: 3466 Loss: 0.04441634565591812\n",
      "Epoch: 3467 Loss: 0.044376350939273834\n",
      "Epoch: 3468 Loss: 0.04435059055685997\n",
      "Epoch: 3469 Loss: 0.04433070868253708\n",
      "Epoch: 3470 Loss: 0.044306300580501556\n",
      "Epoch: 3471 Loss: 0.04428497701883316\n",
      "Epoch: 3472 Loss: 0.044244129210710526\n",
      "Epoch: 3473 Loss: 0.04422398656606674\n",
      "Epoch: 3474 Loss: 0.04422708600759506\n",
      "Epoch: 3475 Loss: 0.04419412463903427\n",
      "Epoch: 3476 Loss: 0.0441490076482296\n",
      "Epoch: 3477 Loss: 0.044139549136161804\n",
      "Epoch: 3478 Loss: 0.044136203825473785\n",
      "Epoch: 3479 Loss: 0.04408876970410347\n",
      "Epoch: 3480 Loss: 0.044053416699171066\n",
      "Epoch: 3481 Loss: 0.044044554233551025\n",
      "Epoch: 3482 Loss: 0.04401827231049538\n",
      "Epoch: 3483 Loss: 0.04398790001869202\n",
      "Epoch: 3484 Loss: 0.0439641997218132\n",
      "Epoch: 3485 Loss: 0.043995168060064316\n",
      "Epoch: 3486 Loss: 0.04391995444893837\n",
      "Epoch: 3487 Loss: 0.04391909018158913\n",
      "Epoch: 3488 Loss: 0.04389118030667305\n",
      "Epoch: 3489 Loss: 0.04384448379278183\n",
      "Epoch: 3490 Loss: 0.04382434859871864\n",
      "Epoch: 3491 Loss: 0.043819867074489594\n",
      "Epoch: 3492 Loss: 0.043778348714113235\n",
      "Epoch: 3493 Loss: 0.04375668242573738\n",
      "Epoch: 3494 Loss: 0.04371853917837143\n",
      "Epoch: 3495 Loss: 0.04370909929275513\n",
      "Epoch: 3496 Loss: 0.043691761791706085\n",
      "Epoch: 3497 Loss: 0.043648358434438705\n",
      "Epoch: 3498 Loss: 0.04363880679011345\n",
      "Epoch: 3499 Loss: 0.04364032670855522\n",
      "Epoch: 3500 Loss: 0.04365925118327141\n",
      "Epoch: 3501 Loss: 0.04357151687145233\n",
      "Epoch: 3502 Loss: 0.04356161132454872\n",
      "Epoch: 3503 Loss: 0.04352577403187752\n",
      "Epoch: 3504 Loss: 0.043509677052497864\n",
      "Epoch: 3505 Loss: 0.043479375541210175\n",
      "Epoch: 3506 Loss: 0.0434541255235672\n",
      "Epoch: 3507 Loss: 0.04342419281601906\n",
      "Epoch: 3508 Loss: 0.0434010811150074\n",
      "Epoch: 3509 Loss: 0.04340634122490883\n",
      "Epoch: 3510 Loss: 0.04334888607263565\n",
      "Epoch: 3511 Loss: 0.0433349609375\n",
      "Epoch: 3512 Loss: 0.04330888390541077\n",
      "Epoch: 3513 Loss: 0.04328944534063339\n",
      "Epoch: 3514 Loss: 0.043244369328022\n",
      "Epoch: 3515 Loss: 0.04323694854974747\n",
      "Epoch: 3516 Loss: 0.04326881840825081\n",
      "Epoch: 3517 Loss: 0.04319772869348526\n",
      "Epoch: 3518 Loss: 0.04319186881184578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3519 Loss: 0.04314957931637764\n",
      "Epoch: 3520 Loss: 0.04313018172979355\n",
      "Epoch: 3521 Loss: 0.043101776391267776\n",
      "Epoch: 3522 Loss: 0.04309447482228279\n",
      "Epoch: 3523 Loss: 0.04307859390974045\n",
      "Epoch: 3524 Loss: 0.043071117252111435\n",
      "Epoch: 3525 Loss: 0.04301359876990318\n",
      "Epoch: 3526 Loss: 0.042984578758478165\n",
      "Epoch: 3527 Loss: 0.04297308251261711\n",
      "Epoch: 3528 Loss: 0.0429404079914093\n",
      "Epoch: 3529 Loss: 0.04292804002761841\n",
      "Epoch: 3530 Loss: 0.042902871966362\n",
      "Epoch: 3531 Loss: 0.042886875569820404\n",
      "Epoch: 3532 Loss: 0.042831871658563614\n",
      "Epoch: 3533 Loss: 0.042847126722335815\n",
      "Epoch: 3534 Loss: 0.04279229789972305\n",
      "Epoch: 3535 Loss: 0.04278385266661644\n",
      "Epoch: 3536 Loss: 0.04275187849998474\n",
      "Epoch: 3537 Loss: 0.04277915880084038\n",
      "Epoch: 3538 Loss: 0.04273777827620506\n",
      "Epoch: 3539 Loss: 0.042712800204753876\n",
      "Epoch: 3540 Loss: 0.04267468303442001\n",
      "Epoch: 3541 Loss: 0.042635951191186905\n",
      "Epoch: 3542 Loss: 0.042645134031772614\n",
      "Epoch: 3543 Loss: 0.042598433792591095\n",
      "Epoch: 3544 Loss: 0.042578183114528656\n",
      "Epoch: 3545 Loss: 0.042563799768686295\n",
      "Epoch: 3546 Loss: 0.04254640266299248\n",
      "Epoch: 3547 Loss: 0.042508434504270554\n",
      "Epoch: 3548 Loss: 0.042490143328905106\n",
      "Epoch: 3549 Loss: 0.04245256632566452\n",
      "Epoch: 3550 Loss: 0.04246354103088379\n",
      "Epoch: 3551 Loss: 0.04240843653678894\n",
      "Epoch: 3552 Loss: 0.04238804057240486\n",
      "Epoch: 3553 Loss: 0.042424991726875305\n",
      "Epoch: 3554 Loss: 0.04237111657857895\n",
      "Epoch: 3555 Loss: 0.042333997786045074\n",
      "Epoch: 3556 Loss: 0.04231923446059227\n",
      "Epoch: 3557 Loss: 0.04229649901390076\n",
      "Epoch: 3558 Loss: 0.04227549210190773\n",
      "Epoch: 3559 Loss: 0.04224302992224693\n",
      "Epoch: 3560 Loss: 0.042218729853630066\n",
      "Epoch: 3561 Loss: 0.04219057783484459\n",
      "Epoch: 3562 Loss: 0.042178694158792496\n",
      "Epoch: 3563 Loss: 0.04213777184486389\n",
      "Epoch: 3564 Loss: 0.04214291274547577\n",
      "Epoch: 3565 Loss: 0.04211932420730591\n",
      "Epoch: 3566 Loss: 0.042104996740818024\n",
      "Epoch: 3567 Loss: 0.04206889495253563\n",
      "Epoch: 3568 Loss: 0.04204431548714638\n",
      "Epoch: 3569 Loss: 0.04200966656208038\n",
      "Epoch: 3570 Loss: 0.04203043505549431\n",
      "Epoch: 3571 Loss: 0.04197767376899719\n",
      "Epoch: 3572 Loss: 0.0419551283121109\n",
      "Epoch: 3573 Loss: 0.0419597290456295\n",
      "Epoch: 3574 Loss: 0.04193912073969841\n",
      "Epoch: 3575 Loss: 0.041885219514369965\n",
      "Epoch: 3576 Loss: 0.0418754480779171\n",
      "Epoch: 3577 Loss: 0.041847068816423416\n",
      "Epoch: 3578 Loss: 0.04184700921177864\n",
      "Epoch: 3579 Loss: 0.04179861396551132\n",
      "Epoch: 3580 Loss: 0.041785214096307755\n",
      "Epoch: 3581 Loss: 0.041748952120542526\n",
      "Epoch: 3582 Loss: 0.04174370691180229\n",
      "Epoch: 3583 Loss: 0.04171416535973549\n",
      "Epoch: 3584 Loss: 0.04169030487537384\n",
      "Epoch: 3585 Loss: 0.04165336862206459\n",
      "Epoch: 3586 Loss: 0.041660141199827194\n",
      "Epoch: 3587 Loss: 0.04161106422543526\n",
      "Epoch: 3588 Loss: 0.04160938411951065\n",
      "Epoch: 3589 Loss: 0.04157359153032303\n",
      "Epoch: 3590 Loss: 0.04157739877700806\n",
      "Epoch: 3591 Loss: 0.041535940021276474\n",
      "Epoch: 3592 Loss: 0.041506215929985046\n",
      "Epoch: 3593 Loss: 0.04149669036269188\n",
      "Epoch: 3594 Loss: 0.04147389158606529\n",
      "Epoch: 3595 Loss: 0.04145757108926773\n",
      "Epoch: 3596 Loss: 0.04141472280025482\n",
      "Epoch: 3597 Loss: 0.04142468795180321\n",
      "Epoch: 3598 Loss: 0.041388750076293945\n",
      "Epoch: 3599 Loss: 0.04135630652308464\n",
      "Epoch: 3600 Loss: 0.04134490340948105\n",
      "Epoch: 3601 Loss: 0.041357338428497314\n",
      "Epoch: 3602 Loss: 0.04134518280625343\n",
      "Epoch: 3603 Loss: 0.04128577932715416\n",
      "Epoch: 3604 Loss: 0.0412718802690506\n",
      "Epoch: 3605 Loss: 0.04123380407691002\n",
      "Epoch: 3606 Loss: 0.041227735579013824\n",
      "Epoch: 3607 Loss: 0.0411825105547905\n",
      "Epoch: 3608 Loss: 0.04118945449590683\n",
      "Epoch: 3609 Loss: 0.041137658059597015\n",
      "Epoch: 3610 Loss: 0.04114535450935364\n",
      "Epoch: 3611 Loss: 0.0411037839949131\n",
      "Epoch: 3612 Loss: 0.041090693324804306\n",
      "Epoch: 3613 Loss: 0.04105289652943611\n",
      "Epoch: 3614 Loss: 0.041044946759939194\n",
      "Epoch: 3615 Loss: 0.041041407734155655\n",
      "Epoch: 3616 Loss: 0.04103788733482361\n",
      "Epoch: 3617 Loss: 0.04097452759742737\n",
      "Epoch: 3618 Loss: 0.04096730798482895\n",
      "Epoch: 3619 Loss: 0.04093775898218155\n",
      "Epoch: 3620 Loss: 0.04094106703996658\n",
      "Epoch: 3621 Loss: 0.04088634252548218\n",
      "Epoch: 3622 Loss: 0.040878962725400925\n",
      "Epoch: 3623 Loss: 0.04087081924080849\n",
      "Epoch: 3624 Loss: 0.04086422175168991\n",
      "Epoch: 3625 Loss: 0.040817372500896454\n",
      "Epoch: 3626 Loss: 0.04080598056316376\n",
      "Epoch: 3627 Loss: 0.04076909273862839\n",
      "Epoch: 3628 Loss: 0.040748924016952515\n",
      "Epoch: 3629 Loss: 0.0407349094748497\n",
      "Epoch: 3630 Loss: 0.04069625213742256\n",
      "Epoch: 3631 Loss: 0.040688998997211456\n",
      "Epoch: 3632 Loss: 0.04064870625734329\n",
      "Epoch: 3633 Loss: 0.040659692138433456\n",
      "Epoch: 3634 Loss: 0.04065006598830223\n",
      "Epoch: 3635 Loss: 0.04060407727956772\n",
      "Epoch: 3636 Loss: 0.04058118164539337\n",
      "Epoch: 3637 Loss: 0.040553025901317596\n",
      "Epoch: 3638 Loss: 0.040546443313360214\n",
      "Epoch: 3639 Loss: 0.040518030524253845\n",
      "Epoch: 3640 Loss: 0.04049963131546974\n",
      "Epoch: 3641 Loss: 0.04047134891152382\n",
      "Epoch: 3642 Loss: 0.04046532139182091\n",
      "Epoch: 3643 Loss: 0.04042458161711693\n",
      "Epoch: 3644 Loss: 0.040414102375507355\n",
      "Epoch: 3645 Loss: 0.04038209095597267\n",
      "Epoch: 3646 Loss: 0.040373481810092926\n",
      "Epoch: 3647 Loss: 0.040338315069675446\n",
      "Epoch: 3648 Loss: 0.04032827168703079\n",
      "Epoch: 3649 Loss: 0.04031483829021454\n",
      "Epoch: 3650 Loss: 0.04028366506099701\n",
      "Epoch: 3651 Loss: 0.04027319699525833\n",
      "Epoch: 3652 Loss: 0.04024619609117508\n",
      "Epoch: 3653 Loss: 0.04022131487727165\n",
      "Epoch: 3654 Loss: 0.04021163657307625\n",
      "Epoch: 3655 Loss: 0.04018674045801163\n",
      "Epoch: 3656 Loss: 0.04016109183430672\n",
      "Epoch: 3657 Loss: 0.040152598172426224\n",
      "Epoch: 3658 Loss: 0.04011138156056404\n",
      "Epoch: 3659 Loss: 0.04009821638464928\n",
      "Epoch: 3660 Loss: 0.0401243232190609\n",
      "Epoch: 3661 Loss: 0.0401008166372776\n",
      "Epoch: 3662 Loss: 0.04006471857428551\n",
      "Epoch: 3663 Loss: 0.04003794491291046\n",
      "Epoch: 3664 Loss: 0.04001979902386665\n",
      "Epoch: 3665 Loss: 0.03999212756752968\n",
      "Epoch: 3666 Loss: 0.03995979577302933\n",
      "Epoch: 3667 Loss: 0.039968427270650864\n",
      "Epoch: 3668 Loss: 0.03992009535431862\n",
      "Epoch: 3669 Loss: 0.0399150624871254\n",
      "Epoch: 3670 Loss: 0.039898473769426346\n",
      "Epoch: 3671 Loss: 0.039863262325525284\n",
      "Epoch: 3672 Loss: 0.039832375943660736\n",
      "Epoch: 3673 Loss: 0.03983822837471962\n",
      "Epoch: 3674 Loss: 0.03980023413896561\n",
      "Epoch: 3675 Loss: 0.039783820509910583\n",
      "Epoch: 3676 Loss: 0.03975421190261841\n",
      "Epoch: 3677 Loss: 0.03974147140979767\n",
      "Epoch: 3678 Loss: 0.03972191363573074\n",
      "Epoch: 3679 Loss: 0.039688561111688614\n",
      "Epoch: 3680 Loss: 0.03967414051294327\n",
      "Epoch: 3681 Loss: 0.03966807574033737\n",
      "Epoch: 3682 Loss: 0.039639171212911606\n",
      "Epoch: 3683 Loss: 0.03962216526269913\n",
      "Epoch: 3684 Loss: 0.03958975523710251\n",
      "Epoch: 3685 Loss: 0.039571892470121384\n",
      "Epoch: 3686 Loss: 0.039547309279441833\n",
      "Epoch: 3687 Loss: 0.039533618837594986\n",
      "Epoch: 3688 Loss: 0.03950892388820648\n",
      "Epoch: 3689 Loss: 0.03950868174433708\n",
      "Epoch: 3690 Loss: 0.03947819769382477\n",
      "Epoch: 3691 Loss: 0.03949344903230667\n",
      "Epoch: 3692 Loss: 0.03948450833559036\n",
      "Epoch: 3693 Loss: 0.039442408829927444\n",
      "Epoch: 3694 Loss: 0.03941702842712402\n",
      "Epoch: 3695 Loss: 0.039391085505485535\n",
      "Epoch: 3696 Loss: 0.03935503214597702\n",
      "Epoch: 3697 Loss: 0.03934831544756889\n",
      "Epoch: 3698 Loss: 0.03932627663016319\n",
      "Epoch: 3699 Loss: 0.0393027737736702\n",
      "Epoch: 3700 Loss: 0.039303891360759735\n",
      "Epoch: 3701 Loss: 0.039273280650377274\n",
      "Epoch: 3702 Loss: 0.039258942008018494\n",
      "Epoch: 3703 Loss: 0.03921651095151901\n",
      "Epoch: 3704 Loss: 0.03920721635222435\n",
      "Epoch: 3705 Loss: 0.03917637839913368\n",
      "Epoch: 3706 Loss: 0.03915498033165932\n",
      "Epoch: 3707 Loss: 0.039157427847385406\n",
      "Epoch: 3708 Loss: 0.039110418409109116\n",
      "Epoch: 3709 Loss: 0.039099641144275665\n",
      "Epoch: 3710 Loss: 0.03908146545290947\n",
      "Epoch: 3711 Loss: 0.03907548636198044\n",
      "Epoch: 3712 Loss: 0.03904871642589569\n",
      "Epoch: 3713 Loss: 0.0390290729701519\n",
      "Epoch: 3714 Loss: 0.03900604695081711\n",
      "Epoch: 3715 Loss: 0.03898270055651665\n",
      "Epoch: 3716 Loss: 0.03896553814411163\n",
      "Epoch: 3717 Loss: 0.03893071040511131\n",
      "Epoch: 3718 Loss: 0.038927968591451645\n",
      "Epoch: 3719 Loss: 0.03890656307339668\n",
      "Epoch: 3720 Loss: 0.038888826966285706\n",
      "Epoch: 3721 Loss: 0.03886193037033081\n",
      "Epoch: 3722 Loss: 0.038867104798555374\n",
      "Epoch: 3723 Loss: 0.03883878514170647\n",
      "Epoch: 3724 Loss: 0.03880824148654938\n",
      "Epoch: 3725 Loss: 0.038783296942710876\n",
      "Epoch: 3726 Loss: 0.0388009212911129\n",
      "Epoch: 3727 Loss: 0.038785990327596664\n",
      "Epoch: 3728 Loss: 0.0387284941971302\n",
      "Epoch: 3729 Loss: 0.03872707486152649\n",
      "Epoch: 3730 Loss: 0.038711514323949814\n",
      "Epoch: 3731 Loss: 0.03867248445749283\n",
      "Epoch: 3732 Loss: 0.03866533190011978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3733 Loss: 0.03863080218434334\n",
      "Epoch: 3734 Loss: 0.03865200653672218\n",
      "Epoch: 3735 Loss: 0.0386202335357666\n",
      "Epoch: 3736 Loss: 0.038585685193538666\n",
      "Epoch: 3737 Loss: 0.038553424179553986\n",
      "Epoch: 3738 Loss: 0.038538843393325806\n",
      "Epoch: 3739 Loss: 0.03853343799710274\n",
      "Epoch: 3740 Loss: 0.03851146250963211\n",
      "Epoch: 3741 Loss: 0.03848296031355858\n",
      "Epoch: 3742 Loss: 0.038466718047857285\n",
      "Epoch: 3743 Loss: 0.03843557834625244\n",
      "Epoch: 3744 Loss: 0.03842293843626976\n",
      "Epoch: 3745 Loss: 0.038407906889915466\n",
      "Epoch: 3746 Loss: 0.03839730843901634\n",
      "Epoch: 3747 Loss: 0.0383693091571331\n",
      "Epoch: 3748 Loss: 0.038352251052856445\n",
      "Epoch: 3749 Loss: 0.03832171857357025\n",
      "Epoch: 3750 Loss: 0.03831395506858826\n",
      "Epoch: 3751 Loss: 0.03828231245279312\n",
      "Epoch: 3752 Loss: 0.03828957676887512\n",
      "Epoch: 3753 Loss: 0.038245826959609985\n",
      "Epoch: 3754 Loss: 0.03824087232351303\n",
      "Epoch: 3755 Loss: 0.03820888325572014\n",
      "Epoch: 3756 Loss: 0.03820405900478363\n",
      "Epoch: 3757 Loss: 0.038175296038389206\n",
      "Epoch: 3758 Loss: 0.03818564862012863\n",
      "Epoch: 3759 Loss: 0.03812969848513603\n",
      "Epoch: 3760 Loss: 0.03812837600708008\n",
      "Epoch: 3761 Loss: 0.038094524294137955\n",
      "Epoch: 3762 Loss: 0.038092613220214844\n",
      "Epoch: 3763 Loss: 0.03808975964784622\n",
      "Epoch: 3764 Loss: 0.038081541657447815\n",
      "Epoch: 3765 Loss: 0.03803669288754463\n",
      "Epoch: 3766 Loss: 0.038012776523828506\n",
      "Epoch: 3767 Loss: 0.03799613565206528\n",
      "Epoch: 3768 Loss: 0.03796415776014328\n",
      "Epoch: 3769 Loss: 0.037976279854774475\n",
      "Epoch: 3770 Loss: 0.037919383496046066\n",
      "Epoch: 3771 Loss: 0.037925463169813156\n",
      "Epoch: 3772 Loss: 0.037894170731306076\n",
      "Epoch: 3773 Loss: 0.03787519410252571\n",
      "Epoch: 3774 Loss: 0.03785436600446701\n",
      "Epoch: 3775 Loss: 0.03785282000899315\n",
      "Epoch: 3776 Loss: 0.03782171010971069\n",
      "Epoch: 3777 Loss: 0.03780152648687363\n",
      "Epoch: 3778 Loss: 0.037778809666633606\n",
      "Epoch: 3779 Loss: 0.03777642920613289\n",
      "Epoch: 3780 Loss: 0.03774704784154892\n",
      "Epoch: 3781 Loss: 0.03771919384598732\n",
      "Epoch: 3782 Loss: 0.03770389035344124\n",
      "Epoch: 3783 Loss: 0.03771146386861801\n",
      "Epoch: 3784 Loss: 0.037682872265577316\n",
      "Epoch: 3785 Loss: 0.03768032789230347\n",
      "Epoch: 3786 Loss: 0.037653833627700806\n",
      "Epoch: 3787 Loss: 0.037645742297172546\n",
      "Epoch: 3788 Loss: 0.03761215880513191\n",
      "Epoch: 3789 Loss: 0.037584155797958374\n",
      "Epoch: 3790 Loss: 0.03756535425782204\n",
      "Epoch: 3791 Loss: 0.037538014352321625\n",
      "Epoch: 3792 Loss: 0.037557173520326614\n",
      "Epoch: 3793 Loss: 0.037510357797145844\n",
      "Epoch: 3794 Loss: 0.0375095009803772\n",
      "Epoch: 3795 Loss: 0.037469349801540375\n",
      "Epoch: 3796 Loss: 0.03744819760322571\n",
      "Epoch: 3797 Loss: 0.03743467479944229\n",
      "Epoch: 3798 Loss: 0.037425119429826736\n",
      "Epoch: 3799 Loss: 0.03739248961210251\n",
      "Epoch: 3800 Loss: 0.03738245740532875\n",
      "Epoch: 3801 Loss: 0.03735733404755592\n",
      "Epoch: 3802 Loss: 0.037341389805078506\n",
      "Epoch: 3803 Loss: 0.03731860965490341\n",
      "Epoch: 3804 Loss: 0.037307851016521454\n",
      "Epoch: 3805 Loss: 0.0372811034321785\n",
      "Epoch: 3806 Loss: 0.037270210683345795\n",
      "Epoch: 3807 Loss: 0.03725568205118179\n",
      "Epoch: 3808 Loss: 0.03722725436091423\n",
      "Epoch: 3809 Loss: 0.03721120208501816\n",
      "Epoch: 3810 Loss: 0.03721558675169945\n",
      "Epoch: 3811 Loss: 0.03719143196940422\n",
      "Epoch: 3812 Loss: 0.037155915051698685\n",
      "Epoch: 3813 Loss: 0.03712773695588112\n",
      "Epoch: 3814 Loss: 0.03711502626538277\n",
      "Epoch: 3815 Loss: 0.037133317440748215\n",
      "Epoch: 3816 Loss: 0.03710927069187164\n",
      "Epoch: 3817 Loss: 0.03708009049296379\n",
      "Epoch: 3818 Loss: 0.037062715739011765\n",
      "Epoch: 3819 Loss: 0.03703919053077698\n",
      "Epoch: 3820 Loss: 0.03700427711009979\n",
      "Epoch: 3821 Loss: 0.036999814212322235\n",
      "Epoch: 3822 Loss: 0.036972712725400925\n",
      "Epoch: 3823 Loss: 0.03697299584746361\n",
      "Epoch: 3824 Loss: 0.03693491965532303\n",
      "Epoch: 3825 Loss: 0.03693590313196182\n",
      "Epoch: 3826 Loss: 0.03689482435584068\n",
      "Epoch: 3827 Loss: 0.03688505291938782\n",
      "Epoch: 3828 Loss: 0.036875542253255844\n",
      "Epoch: 3829 Loss: 0.03684880957007408\n",
      "Epoch: 3830 Loss: 0.03682717680931091\n",
      "Epoch: 3831 Loss: 0.036803681403398514\n",
      "Epoch: 3832 Loss: 0.036807332187891006\n",
      "Epoch: 3833 Loss: 0.036777447909116745\n",
      "Epoch: 3834 Loss: 0.03675210103392601\n",
      "Epoch: 3835 Loss: 0.03676661103963852\n",
      "Epoch: 3836 Loss: 0.03676373139023781\n",
      "Epoch: 3837 Loss: 0.03670213744044304\n",
      "Epoch: 3838 Loss: 0.03670552372932434\n",
      "Epoch: 3839 Loss: 0.036675259470939636\n",
      "Epoch: 3840 Loss: 0.03666406124830246\n",
      "Epoch: 3841 Loss: 0.036626413464546204\n",
      "Epoch: 3842 Loss: 0.03661692887544632\n",
      "Epoch: 3843 Loss: 0.03659730777144432\n",
      "Epoch: 3844 Loss: 0.03659079596400261\n",
      "Epoch: 3845 Loss: 0.03656572103500366\n",
      "Epoch: 3846 Loss: 0.03654458746314049\n",
      "Epoch: 3847 Loss: 0.036536525934934616\n",
      "Epoch: 3848 Loss: 0.03652779012918472\n",
      "Epoch: 3849 Loss: 0.03648221120238304\n",
      "Epoch: 3850 Loss: 0.03648105636239052\n",
      "Epoch: 3851 Loss: 0.03645991533994675\n",
      "Epoch: 3852 Loss: 0.03642965480685234\n",
      "Epoch: 3853 Loss: 0.036450933665037155\n",
      "Epoch: 3854 Loss: 0.03643325716257095\n",
      "Epoch: 3855 Loss: 0.03639109060168266\n",
      "Epoch: 3856 Loss: 0.03637247532606125\n",
      "Epoch: 3857 Loss: 0.03634723648428917\n",
      "Epoch: 3858 Loss: 0.03633476048707962\n",
      "Epoch: 3859 Loss: 0.036313630640506744\n",
      "Epoch: 3860 Loss: 0.036292001605033875\n",
      "Epoch: 3861 Loss: 0.03628331422805786\n",
      "Epoch: 3862 Loss: 0.03626229241490364\n",
      "Epoch: 3863 Loss: 0.03623570129275322\n",
      "Epoch: 3864 Loss: 0.03624245151877403\n",
      "Epoch: 3865 Loss: 0.03620940074324608\n",
      "Epoch: 3866 Loss: 0.036183521151542664\n",
      "Epoch: 3867 Loss: 0.03617957979440689\n",
      "Epoch: 3868 Loss: 0.03615199401974678\n",
      "Epoch: 3869 Loss: 0.036129485815763474\n",
      "Epoch: 3870 Loss: 0.03612551838159561\n",
      "Epoch: 3871 Loss: 0.0360899418592453\n",
      "Epoch: 3872 Loss: 0.036084823310375214\n",
      "Epoch: 3873 Loss: 0.03606029972434044\n",
      "Epoch: 3874 Loss: 0.03605922684073448\n",
      "Epoch: 3875 Loss: 0.03602642938494682\n",
      "Epoch: 3876 Loss: 0.03603387996554375\n",
      "Epoch: 3877 Loss: 0.036001816391944885\n",
      "Epoch: 3878 Loss: 0.035971127450466156\n",
      "Epoch: 3879 Loss: 0.03599170222878456\n",
      "Epoch: 3880 Loss: 0.03596331551671028\n",
      "Epoch: 3881 Loss: 0.03595473989844322\n",
      "Epoch: 3882 Loss: 0.035914383828639984\n",
      "Epoch: 3883 Loss: 0.03590517118573189\n",
      "Epoch: 3884 Loss: 0.035881951451301575\n",
      "Epoch: 3885 Loss: 0.03585305064916611\n",
      "Epoch: 3886 Loss: 0.03584626317024231\n",
      "Epoch: 3887 Loss: 0.0358169786632061\n",
      "Epoch: 3888 Loss: 0.03580251708626747\n",
      "Epoch: 3889 Loss: 0.03579419478774071\n",
      "Epoch: 3890 Loss: 0.03577112406492233\n",
      "Epoch: 3891 Loss: 0.035755984485149384\n",
      "Epoch: 3892 Loss: 0.03573291748762131\n",
      "Epoch: 3893 Loss: 0.03570752963423729\n",
      "Epoch: 3894 Loss: 0.035715218633413315\n",
      "Epoch: 3895 Loss: 0.03570873290300369\n",
      "Epoch: 3896 Loss: 0.035697583109140396\n",
      "Epoch: 3897 Loss: 0.03565837815403938\n",
      "Epoch: 3898 Loss: 0.035642631351947784\n",
      "Epoch: 3899 Loss: 0.03560710698366165\n",
      "Epoch: 3900 Loss: 0.03559398278594017\n",
      "Epoch: 3901 Loss: 0.035591576248407364\n",
      "Epoch: 3902 Loss: 0.03556551784276962\n",
      "Epoch: 3903 Loss: 0.035544805228710175\n",
      "Epoch: 3904 Loss: 0.03553852066397667\n",
      "Epoch: 3905 Loss: 0.035541754215955734\n",
      "Epoch: 3906 Loss: 0.03548664599657059\n",
      "Epoch: 3907 Loss: 0.03547307103872299\n",
      "Epoch: 3908 Loss: 0.035467226058244705\n",
      "Epoch: 3909 Loss: 0.03544597700238228\n",
      "Epoch: 3910 Loss: 0.03542175516486168\n",
      "Epoch: 3911 Loss: 0.035411302000284195\n",
      "Epoch: 3912 Loss: 0.03538444638252258\n",
      "Epoch: 3913 Loss: 0.03539910167455673\n",
      "Epoch: 3914 Loss: 0.03535846620798111\n",
      "Epoch: 3915 Loss: 0.035341911017894745\n",
      "Epoch: 3916 Loss: 0.035333652049303055\n",
      "Epoch: 3917 Loss: 0.035300757735967636\n",
      "Epoch: 3918 Loss: 0.03529341518878937\n",
      "Epoch: 3919 Loss: 0.035269271582365036\n",
      "Epoch: 3920 Loss: 0.03525723144412041\n",
      "Epoch: 3921 Loss: 0.035237301141023636\n",
      "Epoch: 3922 Loss: 0.03522550314664841\n",
      "Epoch: 3923 Loss: 0.035211242735385895\n",
      "Epoch: 3924 Loss: 0.035184942185878754\n",
      "Epoch: 3925 Loss: 0.035179004073143005\n",
      "Epoch: 3926 Loss: 0.03515824303030968\n",
      "Epoch: 3927 Loss: 0.035132911056280136\n",
      "Epoch: 3928 Loss: 0.03511951118707657\n",
      "Epoch: 3929 Loss: 0.03509930148720741\n",
      "Epoch: 3930 Loss: 0.035085003823041916\n",
      "Epoch: 3931 Loss: 0.035065796226263046\n",
      "Epoch: 3932 Loss: 0.035076893866062164\n",
      "Epoch: 3933 Loss: 0.035062894225120544\n",
      "Epoch: 3934 Loss: 0.03505195677280426\n",
      "Epoch: 3935 Loss: 0.035012196749448776\n",
      "Epoch: 3936 Loss: 0.03499217331409454\n",
      "Epoch: 3937 Loss: 0.03498014807701111\n",
      "Epoch: 3938 Loss: 0.03495071828365326\n",
      "Epoch: 3939 Loss: 0.034951627254486084\n",
      "Epoch: 3940 Loss: 0.034917138516902924\n",
      "Epoch: 3941 Loss: 0.03490670025348663\n",
      "Epoch: 3942 Loss: 0.034898411482572556\n",
      "Epoch: 3943 Loss: 0.034861184656620026\n",
      "Epoch: 3944 Loss: 0.034863993525505066\n",
      "Epoch: 3945 Loss: 0.034850992262363434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3946 Loss: 0.03480196371674538\n",
      "Epoch: 3947 Loss: 0.034811053425073624\n",
      "Epoch: 3948 Loss: 0.03478027880191803\n",
      "Epoch: 3949 Loss: 0.0347663052380085\n",
      "Epoch: 3950 Loss: 0.034769583493471146\n",
      "Epoch: 3951 Loss: 0.034731674939394\n",
      "Epoch: 3952 Loss: 0.034740149974823\n",
      "Epoch: 3953 Loss: 0.03470452129840851\n",
      "Epoch: 3954 Loss: 0.034696463495492935\n",
      "Epoch: 3955 Loss: 0.034682583063840866\n",
      "Epoch: 3956 Loss: 0.034650176763534546\n",
      "Epoch: 3957 Loss: 0.0346502885222435\n",
      "Epoch: 3958 Loss: 0.03461654111742973\n",
      "Epoch: 3959 Loss: 0.03460745885968208\n",
      "Epoch: 3960 Loss: 0.03458546847105026\n",
      "Epoch: 3961 Loss: 0.03457333520054817\n",
      "Epoch: 3962 Loss: 0.03459347411990166\n",
      "Epoch: 3963 Loss: 0.03455909341573715\n",
      "Epoch: 3964 Loss: 0.03452179580926895\n",
      "Epoch: 3965 Loss: 0.0345202274620533\n",
      "Epoch: 3966 Loss: 0.03450445458292961\n",
      "Epoch: 3967 Loss: 0.03448176383972168\n",
      "Epoch: 3968 Loss: 0.034482911229133606\n",
      "Epoch: 3969 Loss: 0.034443385899066925\n",
      "Epoch: 3970 Loss: 0.03443125635385513\n",
      "Epoch: 3971 Loss: 0.034398771822452545\n",
      "Epoch: 3972 Loss: 0.03440451622009277\n",
      "Epoch: 3973 Loss: 0.03437041863799095\n",
      "Epoch: 3974 Loss: 0.034361179918050766\n",
      "Epoch: 3975 Loss: 0.034351594746112823\n",
      "Epoch: 3976 Loss: 0.03433307632803917\n",
      "Epoch: 3977 Loss: 0.03430718183517456\n",
      "Epoch: 3978 Loss: 0.034296270459890366\n",
      "Epoch: 3979 Loss: 0.03427479788661003\n",
      "Epoch: 3980 Loss: 0.034271884709596634\n",
      "Epoch: 3981 Loss: 0.03425636887550354\n",
      "Epoch: 3982 Loss: 0.034268200397491455\n",
      "Epoch: 3983 Loss: 0.03423801809549332\n",
      "Epoch: 3984 Loss: 0.03421745449304581\n",
      "Epoch: 3985 Loss: 0.03419540822505951\n",
      "Epoch: 3986 Loss: 0.03418198600411415\n",
      "Epoch: 3987 Loss: 0.034151457250118256\n",
      "Epoch: 3988 Loss: 0.03415077179670334\n",
      "Epoch: 3989 Loss: 0.034135472029447556\n",
      "Epoch: 3990 Loss: 0.034096866846084595\n",
      "Epoch: 3991 Loss: 0.03408755734562874\n",
      "Epoch: 3992 Loss: 0.034095291048288345\n",
      "Epoch: 3993 Loss: 0.03405309095978737\n",
      "Epoch: 3994 Loss: 0.034040577709674835\n",
      "Epoch: 3995 Loss: 0.0340273380279541\n",
      "Epoch: 3996 Loss: 0.0340094268321991\n",
      "Epoch: 3997 Loss: 0.033995188772678375\n",
      "Epoch: 3998 Loss: 0.03397505730390549\n",
      "Epoch: 3999 Loss: 0.033968403935432434\n",
      "Epoch: 4000 Loss: 0.033945973962545395\n",
      "Epoch: 4001 Loss: 0.033951494842767715\n",
      "Epoch: 4002 Loss: 0.03390039876103401\n",
      "Epoch: 4003 Loss: 0.03390946984291077\n",
      "Epoch: 4004 Loss: 0.03387860581278801\n",
      "Epoch: 4005 Loss: 0.03386842459440231\n",
      "Epoch: 4006 Loss: 0.033851973712444305\n",
      "Epoch: 4007 Loss: 0.033835358917713165\n",
      "Epoch: 4008 Loss: 0.03385310620069504\n",
      "Epoch: 4009 Loss: 0.03382411599159241\n",
      "Epoch: 4010 Loss: 0.033807650208473206\n",
      "Epoch: 4011 Loss: 0.03377920016646385\n",
      "Epoch: 4012 Loss: 0.03377385064959526\n",
      "Epoch: 4013 Loss: 0.03373964875936508\n",
      "Epoch: 4014 Loss: 0.033724863082170486\n",
      "Epoch: 4015 Loss: 0.03371258080005646\n",
      "Epoch: 4016 Loss: 0.03370305523276329\n",
      "Epoch: 4017 Loss: 0.033681903034448624\n",
      "Epoch: 4018 Loss: 0.03366276994347572\n",
      "Epoch: 4019 Loss: 0.03363407030701637\n",
      "Epoch: 4020 Loss: 0.03365117311477661\n",
      "Epoch: 4021 Loss: 0.03361499682068825\n",
      "Epoch: 4022 Loss: 0.0336080938577652\n",
      "Epoch: 4023 Loss: 0.03357843682169914\n",
      "Epoch: 4024 Loss: 0.0335746668279171\n",
      "Epoch: 4025 Loss: 0.03355928882956505\n",
      "Epoch: 4026 Loss: 0.03353637456893921\n",
      "Epoch: 4027 Loss: 0.033530645072460175\n",
      "Epoch: 4028 Loss: 0.0335005521774292\n",
      "Epoch: 4029 Loss: 0.03348209708929062\n",
      "Epoch: 4030 Loss: 0.03348304703831673\n",
      "Epoch: 4031 Loss: 0.03346604108810425\n",
      "Epoch: 4032 Loss: 0.03343554586172104\n",
      "Epoch: 4033 Loss: 0.033432234078645706\n",
      "Epoch: 4034 Loss: 0.03343028202652931\n",
      "Epoch: 4035 Loss: 0.03338916227221489\n",
      "Epoch: 4036 Loss: 0.03339306265115738\n",
      "Epoch: 4037 Loss: 0.03339846804738045\n",
      "Epoch: 4038 Loss: 0.03338630124926567\n",
      "Epoch: 4039 Loss: 0.03335399180650711\n",
      "Epoch: 4040 Loss: 0.033338405191898346\n",
      "Epoch: 4041 Loss: 0.033317048102617264\n",
      "Epoch: 4042 Loss: 0.033293310552835464\n",
      "Epoch: 4043 Loss: 0.033281110227108\n",
      "Epoch: 4044 Loss: 0.03326549008488655\n",
      "Epoch: 4045 Loss: 0.03324340283870697\n",
      "Epoch: 4046 Loss: 0.03323589265346527\n",
      "Epoch: 4047 Loss: 0.03320808336138725\n",
      "Epoch: 4048 Loss: 0.03320203721523285\n",
      "Epoch: 4049 Loss: 0.03318234905600548\n",
      "Epoch: 4050 Loss: 0.03316907957196236\n",
      "Epoch: 4051 Loss: 0.0331510491669178\n",
      "Epoch: 4052 Loss: 0.033136606216430664\n",
      "Epoch: 4053 Loss: 0.033126089721918106\n",
      "Epoch: 4054 Loss: 0.03311358019709587\n",
      "Epoch: 4055 Loss: 0.033100634813308716\n",
      "Epoch: 4056 Loss: 0.033080700784921646\n",
      "Epoch: 4057 Loss: 0.03306102752685547\n",
      "Epoch: 4058 Loss: 0.033060140907764435\n",
      "Epoch: 4059 Loss: 0.033046185970306396\n",
      "Epoch: 4060 Loss: 0.03301594406366348\n",
      "Epoch: 4061 Loss: 0.03300461173057556\n",
      "Epoch: 4062 Loss: 0.03299110382795334\n",
      "Epoch: 4063 Loss: 0.03298031538724899\n",
      "Epoch: 4064 Loss: 0.03297918662428856\n",
      "Epoch: 4065 Loss: 0.03295473754405975\n",
      "Epoch: 4066 Loss: 0.032969310879707336\n",
      "Epoch: 4067 Loss: 0.03293705731630325\n",
      "Epoch: 4068 Loss: 0.032901398837566376\n",
      "Epoch: 4069 Loss: 0.032899897545576096\n",
      "Epoch: 4070 Loss: 0.03288240730762482\n",
      "Epoch: 4071 Loss: 0.032854773104190826\n",
      "Epoch: 4072 Loss: 0.032846804708242416\n",
      "Epoch: 4073 Loss: 0.03283503279089928\n",
      "Epoch: 4074 Loss: 0.0328136682510376\n",
      "Epoch: 4075 Loss: 0.03279297798871994\n",
      "Epoch: 4076 Loss: 0.03279513865709305\n",
      "Epoch: 4077 Loss: 0.032765600830316544\n",
      "Epoch: 4078 Loss: 0.03275204077363014\n",
      "Epoch: 4079 Loss: 0.032769087702035904\n",
      "Epoch: 4080 Loss: 0.03274187445640564\n",
      "Epoch: 4081 Loss: 0.03271498903632164\n",
      "Epoch: 4082 Loss: 0.03272200748324394\n",
      "Epoch: 4083 Loss: 0.032684411853551865\n",
      "Epoch: 4084 Loss: 0.0327073335647583\n",
      "Epoch: 4085 Loss: 0.03265826776623726\n",
      "Epoch: 4086 Loss: 0.03265165165066719\n",
      "Epoch: 4087 Loss: 0.03262088820338249\n",
      "Epoch: 4088 Loss: 0.03261375054717064\n",
      "Epoch: 4089 Loss: 0.032601889222860336\n",
      "Epoch: 4090 Loss: 0.032576244324445724\n",
      "Epoch: 4091 Loss: 0.03256434574723244\n",
      "Epoch: 4092 Loss: 0.032558172941207886\n",
      "Epoch: 4093 Loss: 0.03253265842795372\n",
      "Epoch: 4094 Loss: 0.032522521913051605\n",
      "Epoch: 4095 Loss: 0.03251199051737785\n",
      "Epoch: 4096 Loss: 0.03250283747911453\n",
      "Epoch: 4097 Loss: 0.032475925981998444\n",
      "Epoch: 4098 Loss: 0.03247056528925896\n",
      "Epoch: 4099 Loss: 0.032446496188640594\n",
      "Epoch: 4100 Loss: 0.03243393823504448\n",
      "Epoch: 4101 Loss: 0.03241803124547005\n",
      "Epoch: 4102 Loss: 0.032403893768787384\n",
      "Epoch: 4103 Loss: 0.03239341825246811\n",
      "Epoch: 4104 Loss: 0.03239770233631134\n",
      "Epoch: 4105 Loss: 0.032399021089076996\n",
      "Epoch: 4106 Loss: 0.03235092759132385\n",
      "Epoch: 4107 Loss: 0.032337941229343414\n",
      "Epoch: 4108 Loss: 0.032331835478544235\n",
      "Epoch: 4109 Loss: 0.03230547532439232\n",
      "Epoch: 4110 Loss: 0.03229707479476929\n",
      "Epoch: 4111 Loss: 0.03228098899126053\n",
      "Epoch: 4112 Loss: 0.032255321741104126\n",
      "Epoch: 4113 Loss: 0.03225531056523323\n",
      "Epoch: 4114 Loss: 0.03223632276058197\n",
      "Epoch: 4115 Loss: 0.03222591057419777\n",
      "Epoch: 4116 Loss: 0.032230135053396225\n",
      "Epoch: 4117 Loss: 0.032213617116212845\n",
      "Epoch: 4118 Loss: 0.0321897454559803\n",
      "Epoch: 4119 Loss: 0.032185666263103485\n",
      "Epoch: 4120 Loss: 0.03216511383652687\n",
      "Epoch: 4121 Loss: 0.03215363994240761\n",
      "Epoch: 4122 Loss: 0.032127998769283295\n",
      "Epoch: 4123 Loss: 0.032114412635564804\n",
      "Epoch: 4124 Loss: 0.032106224447488785\n",
      "Epoch: 4125 Loss: 0.03208904713392258\n",
      "Epoch: 4126 Loss: 0.032070092856884\n",
      "Epoch: 4127 Loss: 0.03207758814096451\n",
      "Epoch: 4128 Loss: 0.0320429690182209\n",
      "Epoch: 4129 Loss: 0.03202219307422638\n",
      "Epoch: 4130 Loss: 0.03201088309288025\n",
      "Epoch: 4131 Loss: 0.03199385851621628\n",
      "Epoch: 4132 Loss: 0.03199001029133797\n",
      "Epoch: 4133 Loss: 0.031981460750103\n",
      "Epoch: 4134 Loss: 0.03195077180862427\n",
      "Epoch: 4135 Loss: 0.0319472961127758\n",
      "Epoch: 4136 Loss: 0.03192352131009102\n",
      "Epoch: 4137 Loss: 0.0319109745323658\n",
      "Epoch: 4138 Loss: 0.03191167116165161\n",
      "Epoch: 4139 Loss: 0.03187398612499237\n",
      "Epoch: 4140 Loss: 0.03189195692539215\n",
      "Epoch: 4141 Loss: 0.03185427561402321\n",
      "Epoch: 4142 Loss: 0.031841475516557693\n",
      "Epoch: 4143 Loss: 0.03184010460972786\n",
      "Epoch: 4144 Loss: 0.03181391581892967\n",
      "Epoch: 4145 Loss: 0.03182603046298027\n",
      "Epoch: 4146 Loss: 0.03180501610040665\n",
      "Epoch: 4147 Loss: 0.03178281709551811\n",
      "Epoch: 4148 Loss: 0.03176938369870186\n",
      "Epoch: 4149 Loss: 0.03174373507499695\n",
      "Epoch: 4150 Loss: 0.03174491226673126\n",
      "Epoch: 4151 Loss: 0.03171766549348831\n",
      "Epoch: 4152 Loss: 0.031700845807790756\n",
      "Epoch: 4153 Loss: 0.03169230371713638\n",
      "Epoch: 4154 Loss: 0.0316808708012104\n",
      "Epoch: 4155 Loss: 0.031665243208408356\n",
      "Epoch: 4156 Loss: 0.03165443241596222\n",
      "Epoch: 4157 Loss: 0.031632062047719955\n",
      "Epoch: 4158 Loss: 0.03162182494997978\n",
      "Epoch: 4159 Loss: 0.03161008283495903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4160 Loss: 0.031588662415742874\n",
      "Epoch: 4161 Loss: 0.03158016875386238\n",
      "Epoch: 4162 Loss: 0.03156815469264984\n",
      "Epoch: 4163 Loss: 0.03155025467276573\n",
      "Epoch: 4164 Loss: 0.031543150544166565\n",
      "Epoch: 4165 Loss: 0.031523317098617554\n",
      "Epoch: 4166 Loss: 0.0315127857029438\n",
      "Epoch: 4167 Loss: 0.03148986026644707\n",
      "Epoch: 4168 Loss: 0.031485363841056824\n",
      "Epoch: 4169 Loss: 0.03146245703101158\n",
      "Epoch: 4170 Loss: 0.03144361823797226\n",
      "Epoch: 4171 Loss: 0.031446464359760284\n",
      "Epoch: 4172 Loss: 0.03142792731523514\n",
      "Epoch: 4173 Loss: 0.031410470604896545\n",
      "Epoch: 4174 Loss: 0.03139812499284744\n",
      "Epoch: 4175 Loss: 0.031393811106681824\n",
      "Epoch: 4176 Loss: 0.03137332946062088\n",
      "Epoch: 4177 Loss: 0.03135902062058449\n",
      "Epoch: 4178 Loss: 0.03135116025805473\n",
      "Epoch: 4179 Loss: 0.031320054084062576\n",
      "Epoch: 4180 Loss: 0.03132839873433113\n",
      "Epoch: 4181 Loss: 0.03132300823926926\n",
      "Epoch: 4182 Loss: 0.03131265565752983\n",
      "Epoch: 4183 Loss: 0.03127366676926613\n",
      "Epoch: 4184 Loss: 0.03127559274435043\n",
      "Epoch: 4185 Loss: 0.03124488890171051\n",
      "Epoch: 4186 Loss: 0.031233791261911392\n",
      "Epoch: 4187 Loss: 0.03122292272746563\n",
      "Epoch: 4188 Loss: 0.031210882589221\n",
      "Epoch: 4189 Loss: 0.031197961419820786\n",
      "Epoch: 4190 Loss: 0.031176351010799408\n",
      "Epoch: 4191 Loss: 0.03117649257183075\n",
      "Epoch: 4192 Loss: 0.031150514259934425\n",
      "Epoch: 4193 Loss: 0.031177498400211334\n",
      "Epoch: 4194 Loss: 0.031154127791523933\n",
      "Epoch: 4195 Loss: 0.031116869300603867\n",
      "Epoch: 4196 Loss: 0.031099488958716393\n",
      "Epoch: 4197 Loss: 0.03108973056077957\n",
      "Epoch: 4198 Loss: 0.031069539487361908\n",
      "Epoch: 4199 Loss: 0.031074535101652145\n",
      "Epoch: 4200 Loss: 0.03104471229016781\n",
      "Epoch: 4201 Loss: 0.0310380719602108\n",
      "Epoch: 4202 Loss: 0.031021589413285255\n",
      "Epoch: 4203 Loss: 0.03102554939687252\n",
      "Epoch: 4204 Loss: 0.030994011089205742\n",
      "Epoch: 4205 Loss: 0.030976643785834312\n",
      "Epoch: 4206 Loss: 0.030971843749284744\n",
      "Epoch: 4207 Loss: 0.030954919755458832\n",
      "Epoch: 4208 Loss: 0.030953610315918922\n",
      "Epoch: 4209 Loss: 0.03092273697257042\n",
      "Epoch: 4210 Loss: 0.030936451628804207\n",
      "Epoch: 4211 Loss: 0.030914820730686188\n",
      "Epoch: 4212 Loss: 0.030889548361301422\n",
      "Epoch: 4213 Loss: 0.030909018591046333\n",
      "Epoch: 4214 Loss: 0.03086024336516857\n",
      "Epoch: 4215 Loss: 0.030865168198943138\n",
      "Epoch: 4216 Loss: 0.030830975621938705\n",
      "Epoch: 4217 Loss: 0.03081641159951687\n",
      "Epoch: 4218 Loss: 0.030827244743704796\n",
      "Epoch: 4219 Loss: 0.03080548718571663\n",
      "Epoch: 4220 Loss: 0.030791323632001877\n",
      "Epoch: 4221 Loss: 0.030764814466238022\n",
      "Epoch: 4222 Loss: 0.03075551986694336\n",
      "Epoch: 4223 Loss: 0.030743161216378212\n",
      "Epoch: 4224 Loss: 0.030727701261639595\n",
      "Epoch: 4225 Loss: 0.030711017549037933\n",
      "Epoch: 4226 Loss: 0.030699914321303368\n",
      "Epoch: 4227 Loss: 0.030693000182509422\n",
      "Epoch: 4228 Loss: 0.030686402693390846\n",
      "Epoch: 4229 Loss: 0.030653933063149452\n",
      "Epoch: 4230 Loss: 0.030642053112387657\n",
      "Epoch: 4231 Loss: 0.03063567541539669\n",
      "Epoch: 4232 Loss: 0.03063063882291317\n",
      "Epoch: 4233 Loss: 0.03060508891940117\n",
      "Epoch: 4234 Loss: 0.030597131699323654\n",
      "Epoch: 4235 Loss: 0.030583519488573074\n",
      "Epoch: 4236 Loss: 0.03056713379919529\n",
      "Epoch: 4237 Loss: 0.0305830966681242\n",
      "Epoch: 4238 Loss: 0.03054586611688137\n",
      "Epoch: 4239 Loss: 0.030529486015439034\n",
      "Epoch: 4240 Loss: 0.030524635687470436\n",
      "Epoch: 4241 Loss: 0.030504995957016945\n",
      "Epoch: 4242 Loss: 0.03049526736140251\n",
      "Epoch: 4243 Loss: 0.030484138056635857\n",
      "Epoch: 4244 Loss: 0.030469687655568123\n",
      "Epoch: 4245 Loss: 0.03044736199080944\n",
      "Epoch: 4246 Loss: 0.0304371640086174\n",
      "Epoch: 4247 Loss: 0.03043912537395954\n",
      "Epoch: 4248 Loss: 0.030411943793296814\n",
      "Epoch: 4249 Loss: 0.030396992340683937\n",
      "Epoch: 4250 Loss: 0.03039298765361309\n",
      "Epoch: 4251 Loss: 0.03037997893989086\n",
      "Epoch: 4252 Loss: 0.03035687655210495\n",
      "Epoch: 4253 Loss: 0.030359888449311256\n",
      "Epoch: 4254 Loss: 0.030362319201231003\n",
      "Epoch: 4255 Loss: 0.030345028266310692\n",
      "Epoch: 4256 Loss: 0.030309418216347694\n",
      "Epoch: 4257 Loss: 0.03031993843615055\n",
      "Epoch: 4258 Loss: 0.03028712421655655\n",
      "Epoch: 4259 Loss: 0.03028285503387451\n",
      "Epoch: 4260 Loss: 0.030266599729657173\n",
      "Epoch: 4261 Loss: 0.030254513025283813\n",
      "Epoch: 4262 Loss: 0.030233139172196388\n",
      "Epoch: 4263 Loss: 0.030224071815609932\n",
      "Epoch: 4264 Loss: 0.03020251914858818\n",
      "Epoch: 4265 Loss: 0.030202344059944153\n",
      "Epoch: 4266 Loss: 0.03018343821167946\n",
      "Epoch: 4267 Loss: 0.030176648870110512\n",
      "Epoch: 4268 Loss: 0.030159929767251015\n",
      "Epoch: 4269 Loss: 0.03014613501727581\n",
      "Epoch: 4270 Loss: 0.0301354993134737\n",
      "Epoch: 4271 Loss: 0.030121324583888054\n",
      "Epoch: 4272 Loss: 0.030100880190730095\n",
      "Epoch: 4273 Loss: 0.030087634921073914\n",
      "Epoch: 4274 Loss: 0.030084295198321342\n",
      "Epoch: 4275 Loss: 0.030071917921304703\n",
      "Epoch: 4276 Loss: 0.030051030218601227\n",
      "Epoch: 4277 Loss: 0.03006819449365139\n",
      "Epoch: 4278 Loss: 0.030050188302993774\n",
      "Epoch: 4279 Loss: 0.030024880543351173\n",
      "Epoch: 4280 Loss: 0.0300030205398798\n",
      "Epoch: 4281 Loss: 0.029989803209900856\n",
      "Epoch: 4282 Loss: 0.029982537031173706\n",
      "Epoch: 4283 Loss: 0.02996346727013588\n",
      "Epoch: 4284 Loss: 0.029979541897773743\n",
      "Epoch: 4285 Loss: 0.029942119494080544\n",
      "Epoch: 4286 Loss: 0.029931243509054184\n",
      "Epoch: 4287 Loss: 0.029921071603894234\n",
      "Epoch: 4288 Loss: 0.029900312423706055\n",
      "Epoch: 4289 Loss: 0.029902352020144463\n",
      "Epoch: 4290 Loss: 0.02988363243639469\n",
      "Epoch: 4291 Loss: 0.029873009771108627\n",
      "Epoch: 4292 Loss: 0.02984631061553955\n",
      "Epoch: 4293 Loss: 0.029844209551811218\n",
      "Epoch: 4294 Loss: 0.029821885749697685\n",
      "Epoch: 4295 Loss: 0.029825426638126373\n",
      "Epoch: 4296 Loss: 0.029811786487698555\n",
      "Epoch: 4297 Loss: 0.02978624403476715\n",
      "Epoch: 4298 Loss: 0.02977786213159561\n",
      "Epoch: 4299 Loss: 0.02977130189538002\n",
      "Epoch: 4300 Loss: 0.029750822111964226\n",
      "Epoch: 4301 Loss: 0.029747067019343376\n",
      "Epoch: 4302 Loss: 0.02973238192498684\n",
      "Epoch: 4303 Loss: 0.029707958921790123\n",
      "Epoch: 4304 Loss: 0.029706882312893867\n",
      "Epoch: 4305 Loss: 0.029697565361857414\n",
      "Epoch: 4306 Loss: 0.029674064368009567\n",
      "Epoch: 4307 Loss: 0.0296877883374691\n",
      "Epoch: 4308 Loss: 0.02966109849512577\n",
      "Epoch: 4309 Loss: 0.029651639983057976\n",
      "Epoch: 4310 Loss: 0.029624298214912415\n",
      "Epoch: 4311 Loss: 0.029625840485095978\n",
      "Epoch: 4312 Loss: 0.029610397294163704\n",
      "Epoch: 4313 Loss: 0.029592106118798256\n",
      "Epoch: 4314 Loss: 0.029581762850284576\n",
      "Epoch: 4315 Loss: 0.02960614301264286\n",
      "Epoch: 4316 Loss: 0.029575619846582413\n",
      "Epoch: 4317 Loss: 0.02954876236617565\n",
      "Epoch: 4318 Loss: 0.029549822211265564\n",
      "Epoch: 4319 Loss: 0.02952135168015957\n",
      "Epoch: 4320 Loss: 0.02951248176395893\n",
      "Epoch: 4321 Loss: 0.0294913612306118\n",
      "Epoch: 4322 Loss: 0.02948141098022461\n",
      "Epoch: 4323 Loss: 0.029472069814801216\n",
      "Epoch: 4324 Loss: 0.029454810544848442\n",
      "Epoch: 4325 Loss: 0.029446439817547798\n",
      "Epoch: 4326 Loss: 0.02943342551589012\n",
      "Epoch: 4327 Loss: 0.029411863535642624\n",
      "Epoch: 4328 Loss: 0.02941278927028179\n",
      "Epoch: 4329 Loss: 0.029407130554318428\n",
      "Epoch: 4330 Loss: 0.029374562203884125\n",
      "Epoch: 4331 Loss: 0.029372524470090866\n",
      "Epoch: 4332 Loss: 0.029361849650740623\n",
      "Epoch: 4333 Loss: 0.029345085844397545\n",
      "Epoch: 4334 Loss: 0.02933923713862896\n",
      "Epoch: 4335 Loss: 0.029327480122447014\n",
      "Epoch: 4336 Loss: 0.029309792444109917\n",
      "Epoch: 4337 Loss: 0.029302755370736122\n",
      "Epoch: 4338 Loss: 0.02928677760064602\n",
      "Epoch: 4339 Loss: 0.029273735359311104\n",
      "Epoch: 4340 Loss: 0.02925565466284752\n",
      "Epoch: 4341 Loss: 0.02927292138338089\n",
      "Epoch: 4342 Loss: 0.02925419621169567\n",
      "Epoch: 4343 Loss: 0.029241813346743584\n",
      "Epoch: 4344 Loss: 0.029226064682006836\n",
      "Epoch: 4345 Loss: 0.029198504984378815\n",
      "Epoch: 4346 Loss: 0.02920379303395748\n",
      "Epoch: 4347 Loss: 0.02917788177728653\n",
      "Epoch: 4348 Loss: 0.029171172529459\n",
      "Epoch: 4349 Loss: 0.029151730239391327\n",
      "Epoch: 4350 Loss: 0.029161248356103897\n",
      "Epoch: 4351 Loss: 0.02912803925573826\n",
      "Epoch: 4352 Loss: 0.02911420166492462\n",
      "Epoch: 4353 Loss: 0.029102446511387825\n",
      "Epoch: 4354 Loss: 0.029084770008921623\n",
      "Epoch: 4355 Loss: 0.029087668284773827\n",
      "Epoch: 4356 Loss: 0.029071636497974396\n",
      "Epoch: 4357 Loss: 0.029048113152384758\n",
      "Epoch: 4358 Loss: 0.02903624065220356\n",
      "Epoch: 4359 Loss: 0.029036924242973328\n",
      "Epoch: 4360 Loss: 0.029009444639086723\n",
      "Epoch: 4361 Loss: 0.02900935523211956\n",
      "Epoch: 4362 Loss: 0.029005253687500954\n",
      "Epoch: 4363 Loss: 0.028978241607546806\n",
      "Epoch: 4364 Loss: 0.02897738106548786\n",
      "Epoch: 4365 Loss: 0.02896411344408989\n",
      "Epoch: 4366 Loss: 0.028968269005417824\n",
      "Epoch: 4367 Loss: 0.028958985581994057\n",
      "Epoch: 4368 Loss: 0.028930502012372017\n",
      "Epoch: 4369 Loss: 0.02892311103641987\n",
      "Epoch: 4370 Loss: 0.02890508621931076\n",
      "Epoch: 4371 Loss: 0.028884796425700188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4372 Loss: 0.028874104842543602\n",
      "Epoch: 4373 Loss: 0.02885342389345169\n",
      "Epoch: 4374 Loss: 0.02886348031461239\n",
      "Epoch: 4375 Loss: 0.028829989954829216\n",
      "Epoch: 4376 Loss: 0.02885289303958416\n",
      "Epoch: 4377 Loss: 0.028825094923377037\n",
      "Epoch: 4378 Loss: 0.028806529939174652\n",
      "Epoch: 4379 Loss: 0.028808800503611565\n",
      "Epoch: 4380 Loss: 0.02877996116876602\n",
      "Epoch: 4381 Loss: 0.02877817675471306\n",
      "Epoch: 4382 Loss: 0.028748977929353714\n",
      "Epoch: 4383 Loss: 0.02876213751733303\n",
      "Epoch: 4384 Loss: 0.028731053695082664\n",
      "Epoch: 4385 Loss: 0.02874632366001606\n",
      "Epoch: 4386 Loss: 0.02870936132967472\n",
      "Epoch: 4387 Loss: 0.028700949624180794\n",
      "Epoch: 4388 Loss: 0.028684353455901146\n",
      "Epoch: 4389 Loss: 0.028681935742497444\n",
      "Epoch: 4390 Loss: 0.028658859431743622\n",
      "Epoch: 4391 Loss: 0.028644489124417305\n",
      "Epoch: 4392 Loss: 0.02863495424389839\n",
      "Epoch: 4393 Loss: 0.028632666915655136\n",
      "Epoch: 4394 Loss: 0.028606900945305824\n",
      "Epoch: 4395 Loss: 0.02859797701239586\n",
      "Epoch: 4396 Loss: 0.028579341247677803\n",
      "Epoch: 4397 Loss: 0.02856859192252159\n",
      "Epoch: 4398 Loss: 0.028576329350471497\n",
      "Epoch: 4399 Loss: 0.028542058542370796\n",
      "Epoch: 4400 Loss: 0.028530964627861977\n",
      "Epoch: 4401 Loss: 0.028529101982712746\n",
      "Epoch: 4402 Loss: 0.028511840850114822\n",
      "Epoch: 4403 Loss: 0.028509216383099556\n",
      "Epoch: 4404 Loss: 0.028499271720647812\n",
      "Epoch: 4405 Loss: 0.02849116362631321\n",
      "Epoch: 4406 Loss: 0.02846629172563553\n",
      "Epoch: 4407 Loss: 0.028460338711738586\n",
      "Epoch: 4408 Loss: 0.02843378856778145\n",
      "Epoch: 4409 Loss: 0.028438923880457878\n",
      "Epoch: 4410 Loss: 0.02841491810977459\n",
      "Epoch: 4411 Loss: 0.028426144272089005\n",
      "Epoch: 4412 Loss: 0.02840125933289528\n",
      "Epoch: 4413 Loss: 0.028387825936079025\n",
      "Epoch: 4414 Loss: 0.028376661241054535\n",
      "Epoch: 4415 Loss: 0.02836223505437374\n",
      "Epoch: 4416 Loss: 0.028351474553346634\n",
      "Epoch: 4417 Loss: 0.028341058641672134\n",
      "Epoch: 4418 Loss: 0.02832990325987339\n",
      "Epoch: 4419 Loss: 0.028310328722000122\n",
      "Epoch: 4420 Loss: 0.02832692489027977\n",
      "Epoch: 4421 Loss: 0.028296031057834625\n",
      "Epoch: 4422 Loss: 0.02828717790544033\n",
      "Epoch: 4423 Loss: 0.028278525918722153\n",
      "Epoch: 4424 Loss: 0.02825150452554226\n",
      "Epoch: 4425 Loss: 0.028266342356801033\n",
      "Epoch: 4426 Loss: 0.028243986889719963\n",
      "Epoch: 4427 Loss: 0.028230564668774605\n",
      "Epoch: 4428 Loss: 0.02823849767446518\n",
      "Epoch: 4429 Loss: 0.028202582150697708\n",
      "Epoch: 4430 Loss: 0.028197266161441803\n",
      "Epoch: 4431 Loss: 0.02817612513899803\n",
      "Epoch: 4432 Loss: 0.02816668152809143\n",
      "Epoch: 4433 Loss: 0.028161173686385155\n",
      "Epoch: 4434 Loss: 0.02815185859799385\n",
      "Epoch: 4435 Loss: 0.028161291033029556\n",
      "Epoch: 4436 Loss: 0.0281133521348238\n",
      "Epoch: 4437 Loss: 0.028122419491410255\n",
      "Epoch: 4438 Loss: 0.028106829151511192\n",
      "Epoch: 4439 Loss: 0.028092749416828156\n",
      "Epoch: 4440 Loss: 0.028074949979782104\n",
      "Epoch: 4441 Loss: 0.028069784864783287\n",
      "Epoch: 4442 Loss: 0.028051169589161873\n",
      "Epoch: 4443 Loss: 0.028040403500199318\n",
      "Epoch: 4444 Loss: 0.0280295480042696\n",
      "Epoch: 4445 Loss: 0.028019845485687256\n",
      "Epoch: 4446 Loss: 0.028006428852677345\n",
      "Epoch: 4447 Loss: 0.027999140322208405\n",
      "Epoch: 4448 Loss: 0.027986766770482063\n",
      "Epoch: 4449 Loss: 0.027975471690297127\n",
      "Epoch: 4450 Loss: 0.02796034701168537\n",
      "Epoch: 4451 Loss: 0.027956673875451088\n",
      "Epoch: 4452 Loss: 0.027938466519117355\n",
      "Epoch: 4453 Loss: 0.027928460389375687\n",
      "Epoch: 4454 Loss: 0.0279085710644722\n",
      "Epoch: 4455 Loss: 0.027904819697141647\n",
      "Epoch: 4456 Loss: 0.027912288904190063\n",
      "Epoch: 4457 Loss: 0.02789558283984661\n",
      "Epoch: 4458 Loss: 0.027865106239914894\n",
      "Epoch: 4459 Loss: 0.02785724401473999\n",
      "Epoch: 4460 Loss: 0.027847958728671074\n",
      "Epoch: 4461 Loss: 0.027839727699756622\n",
      "Epoch: 4462 Loss: 0.027850482612848282\n",
      "Epoch: 4463 Loss: 0.027837887406349182\n",
      "Epoch: 4464 Loss: 0.027813991531729698\n",
      "Epoch: 4465 Loss: 0.02779955230653286\n",
      "Epoch: 4466 Loss: 0.027788924053311348\n",
      "Epoch: 4467 Loss: 0.027761731296777725\n",
      "Epoch: 4468 Loss: 0.027760235592722893\n",
      "Epoch: 4469 Loss: 0.027751484885811806\n",
      "Epoch: 4470 Loss: 0.02774096466600895\n",
      "Epoch: 4471 Loss: 0.02772795595228672\n",
      "Epoch: 4472 Loss: 0.027709132060408592\n",
      "Epoch: 4473 Loss: 0.027701571583747864\n",
      "Epoch: 4474 Loss: 0.027700670063495636\n",
      "Epoch: 4475 Loss: 0.027678631246089935\n",
      "Epoch: 4476 Loss: 0.02767205610871315\n",
      "Epoch: 4477 Loss: 0.02768714912235737\n",
      "Epoch: 4478 Loss: 0.02766444906592369\n",
      "Epoch: 4479 Loss: 0.027638481929898262\n",
      "Epoch: 4480 Loss: 0.02762608975172043\n",
      "Epoch: 4481 Loss: 0.027612529695034027\n",
      "Epoch: 4482 Loss: 0.02760365605354309\n",
      "Epoch: 4483 Loss: 0.027597520500421524\n",
      "Epoch: 4484 Loss: 0.027570094913244247\n",
      "Epoch: 4485 Loss: 0.027566637843847275\n",
      "Epoch: 4486 Loss: 0.027558287605643272\n",
      "Epoch: 4487 Loss: 0.027555283159017563\n",
      "Epoch: 4488 Loss: 0.027531007304787636\n",
      "Epoch: 4489 Loss: 0.027521759271621704\n",
      "Epoch: 4490 Loss: 0.02751193381845951\n",
      "Epoch: 4491 Loss: 0.027511747553944588\n",
      "Epoch: 4492 Loss: 0.027513382956385612\n",
      "Epoch: 4493 Loss: 0.027494750916957855\n",
      "Epoch: 4494 Loss: 0.02747092954814434\n",
      "Epoch: 4495 Loss: 0.027463899925351143\n",
      "Epoch: 4496 Loss: 0.027452202513813972\n",
      "Epoch: 4497 Loss: 0.027430284768342972\n",
      "Epoch: 4498 Loss: 0.02742471545934677\n",
      "Epoch: 4499 Loss: 0.027411526069045067\n",
      "Epoch: 4500 Loss: 0.0274093896150589\n",
      "Epoch: 4501 Loss: 0.02739008702337742\n",
      "Epoch: 4502 Loss: 0.027386244386434555\n",
      "Epoch: 4503 Loss: 0.027375338599085808\n",
      "Epoch: 4504 Loss: 0.0273628868162632\n",
      "Epoch: 4505 Loss: 0.027356762439012527\n",
      "Epoch: 4506 Loss: 0.02734067104756832\n",
      "Epoch: 4507 Loss: 0.02732965722680092\n",
      "Epoch: 4508 Loss: 0.02731616236269474\n",
      "Epoch: 4509 Loss: 0.0273041483014822\n",
      "Epoch: 4510 Loss: 0.027297094464302063\n",
      "Epoch: 4511 Loss: 0.02731744945049286\n",
      "Epoch: 4512 Loss: 0.02727331593632698\n",
      "Epoch: 4513 Loss: 0.027266299352049828\n",
      "Epoch: 4514 Loss: 0.027257025241851807\n",
      "Epoch: 4515 Loss: 0.02723841555416584\n",
      "Epoch: 4516 Loss: 0.027229398488998413\n",
      "Epoch: 4517 Loss: 0.02721548080444336\n",
      "Epoch: 4518 Loss: 0.027229420840740204\n",
      "Epoch: 4519 Loss: 0.027222078293561935\n",
      "Epoch: 4520 Loss: 0.027184924110770226\n",
      "Epoch: 4521 Loss: 0.027187442407011986\n",
      "Epoch: 4522 Loss: 0.027178458869457245\n",
      "Epoch: 4523 Loss: 0.027159109711647034\n",
      "Epoch: 4524 Loss: 0.027146069332957268\n",
      "Epoch: 4525 Loss: 0.027136024087667465\n",
      "Epoch: 4526 Loss: 0.027118908241391182\n",
      "Epoch: 4527 Loss: 0.027112413197755814\n",
      "Epoch: 4528 Loss: 0.02709769643843174\n",
      "Epoch: 4529 Loss: 0.027092119678854942\n",
      "Epoch: 4530 Loss: 0.027081916108727455\n",
      "Epoch: 4531 Loss: 0.02706618793308735\n",
      "Epoch: 4532 Loss: 0.027058236300945282\n",
      "Epoch: 4533 Loss: 0.027072248980402946\n",
      "Epoch: 4534 Loss: 0.027044327929615974\n",
      "Epoch: 4535 Loss: 0.027033403515815735\n",
      "Epoch: 4536 Loss: 0.02701682597398758\n",
      "Epoch: 4537 Loss: 0.027010779827833176\n",
      "Epoch: 4538 Loss: 0.027004113420844078\n",
      "Epoch: 4539 Loss: 0.0269793551415205\n",
      "Epoch: 4540 Loss: 0.026972701773047447\n",
      "Epoch: 4541 Loss: 0.026957310736179352\n",
      "Epoch: 4542 Loss: 0.026955051347613335\n",
      "Epoch: 4543 Loss: 0.026943938806653023\n",
      "Epoch: 4544 Loss: 0.026931896805763245\n",
      "Epoch: 4545 Loss: 0.026916353031992912\n",
      "Epoch: 4546 Loss: 0.026922186836600304\n",
      "Epoch: 4547 Loss: 0.026912745088338852\n",
      "Epoch: 4548 Loss: 0.02689737267792225\n",
      "Epoch: 4549 Loss: 0.02688695676624775\n",
      "Epoch: 4550 Loss: 0.026861336082220078\n",
      "Epoch: 4551 Loss: 0.02686244249343872\n",
      "Epoch: 4552 Loss: 0.026840364560484886\n",
      "Epoch: 4553 Loss: 0.026837941259145737\n",
      "Epoch: 4554 Loss: 0.026818566024303436\n",
      "Epoch: 4555 Loss: 0.026815088465809822\n",
      "Epoch: 4556 Loss: 0.02679821290075779\n",
      "Epoch: 4557 Loss: 0.026791980490088463\n",
      "Epoch: 4558 Loss: 0.026789112016558647\n",
      "Epoch: 4559 Loss: 0.026772504672408104\n",
      "Epoch: 4560 Loss: 0.02675662189722061\n",
      "Epoch: 4561 Loss: 0.02674897387623787\n",
      "Epoch: 4562 Loss: 0.02674834243953228\n",
      "Epoch: 4563 Loss: 0.02673083357512951\n",
      "Epoch: 4564 Loss: 0.026709992438554764\n",
      "Epoch: 4565 Loss: 0.026704350486397743\n",
      "Epoch: 4566 Loss: 0.02669915370643139\n",
      "Epoch: 4567 Loss: 0.026688918471336365\n",
      "Epoch: 4568 Loss: 0.026680268347263336\n",
      "Epoch: 4569 Loss: 0.026663778349757195\n",
      "Epoch: 4570 Loss: 0.02666230872273445\n",
      "Epoch: 4571 Loss: 0.026668250560760498\n",
      "Epoch: 4572 Loss: 0.02665715664625168\n",
      "Epoch: 4573 Loss: 0.02663482166826725\n",
      "Epoch: 4574 Loss: 0.02662617526948452\n",
      "Epoch: 4575 Loss: 0.026601508259773254\n",
      "Epoch: 4576 Loss: 0.026602180674672127\n",
      "Epoch: 4577 Loss: 0.02659171260893345\n",
      "Epoch: 4578 Loss: 0.026597140356898308\n",
      "Epoch: 4579 Loss: 0.026569882407784462\n",
      "Epoch: 4580 Loss: 0.02655673772096634\n",
      "Epoch: 4581 Loss: 0.026533782482147217\n",
      "Epoch: 4582 Loss: 0.026541586965322495\n",
      "Epoch: 4583 Loss: 0.026513921096920967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4584 Loss: 0.02650831826031208\n",
      "Epoch: 4585 Loss: 0.026502549648284912\n",
      "Epoch: 4586 Loss: 0.02648783102631569\n",
      "Epoch: 4587 Loss: 0.026474803686141968\n",
      "Epoch: 4588 Loss: 0.026474975049495697\n",
      "Epoch: 4589 Loss: 0.026460379362106323\n",
      "Epoch: 4590 Loss: 0.02644963562488556\n",
      "Epoch: 4591 Loss: 0.026437778025865555\n",
      "Epoch: 4592 Loss: 0.0264251958578825\n",
      "Epoch: 4593 Loss: 0.026422036811709404\n",
      "Epoch: 4594 Loss: 0.026402892544865608\n",
      "Epoch: 4595 Loss: 0.026397066190838814\n",
      "Epoch: 4596 Loss: 0.026393307372927666\n",
      "Epoch: 4597 Loss: 0.02637767605483532\n",
      "Epoch: 4598 Loss: 0.026388607919216156\n",
      "Epoch: 4599 Loss: 0.026369476690888405\n",
      "Epoch: 4600 Loss: 0.026348022744059563\n",
      "Epoch: 4601 Loss: 0.026339272037148476\n",
      "Epoch: 4602 Loss: 0.026331881061196327\n",
      "Epoch: 4603 Loss: 0.026311229914426804\n",
      "Epoch: 4604 Loss: 0.02630537562072277\n",
      "Epoch: 4605 Loss: 0.02629939094185829\n",
      "Epoch: 4606 Loss: 0.02627985179424286\n",
      "Epoch: 4607 Loss: 0.026276525110006332\n",
      "Epoch: 4608 Loss: 0.026269955560564995\n",
      "Epoch: 4609 Loss: 0.026245011016726494\n",
      "Epoch: 4610 Loss: 0.02624651975929737\n",
      "Epoch: 4611 Loss: 0.02623819187283516\n",
      "Epoch: 4612 Loss: 0.026223739609122276\n",
      "Epoch: 4613 Loss: 0.02622796781361103\n",
      "Epoch: 4614 Loss: 0.026219993829727173\n",
      "Epoch: 4615 Loss: 0.026186548173427582\n",
      "Epoch: 4616 Loss: 0.026204904541373253\n",
      "Epoch: 4617 Loss: 0.026176590472459793\n",
      "Epoch: 4618 Loss: 0.0261809341609478\n",
      "Epoch: 4619 Loss: 0.02614961564540863\n",
      "Epoch: 4620 Loss: 0.026154015213251114\n",
      "Epoch: 4621 Loss: 0.026125356554985046\n",
      "Epoch: 4622 Loss: 0.02614137902855873\n",
      "Epoch: 4623 Loss: 0.026115084066987038\n",
      "Epoch: 4624 Loss: 0.026110373437404633\n",
      "Epoch: 4625 Loss: 0.02609187923371792\n",
      "Epoch: 4626 Loss: 0.02608446218073368\n",
      "Epoch: 4627 Loss: 0.02607715129852295\n",
      "Epoch: 4628 Loss: 0.02606050670146942\n",
      "Epoch: 4629 Loss: 0.02605089545249939\n",
      "Epoch: 4630 Loss: 0.02604391984641552\n",
      "Epoch: 4631 Loss: 0.026036443188786507\n",
      "Epoch: 4632 Loss: 0.02601911686360836\n",
      "Epoch: 4633 Loss: 0.02601686306297779\n",
      "Epoch: 4634 Loss: 0.02600078098475933\n",
      "Epoch: 4635 Loss: 0.025991985574364662\n",
      "Epoch: 4636 Loss: 0.02598293498158455\n",
      "Epoch: 4637 Loss: 0.025968143716454506\n",
      "Epoch: 4638 Loss: 0.02596740424633026\n",
      "Epoch: 4639 Loss: 0.0259516853839159\n",
      "Epoch: 4640 Loss: 0.025951268151402473\n",
      "Epoch: 4641 Loss: 0.025931883603334427\n",
      "Epoch: 4642 Loss: 0.025922782719135284\n",
      "Epoch: 4643 Loss: 0.025904741138219833\n",
      "Epoch: 4644 Loss: 0.025904502719640732\n",
      "Epoch: 4645 Loss: 0.025890758261084557\n",
      "Epoch: 4646 Loss: 0.025889748707413673\n",
      "Epoch: 4647 Loss: 0.025867395102977753\n",
      "Epoch: 4648 Loss: 0.025864142924547195\n",
      "Epoch: 4649 Loss: 0.025871574878692627\n",
      "Epoch: 4650 Loss: 0.025861922651529312\n",
      "Epoch: 4651 Loss: 0.02583409659564495\n",
      "Epoch: 4652 Loss: 0.02583680860698223\n",
      "Epoch: 4653 Loss: 0.025830188766121864\n",
      "Epoch: 4654 Loss: 0.02580353245139122\n",
      "Epoch: 4655 Loss: 0.025816617533564568\n",
      "Epoch: 4656 Loss: 0.025785241276025772\n",
      "Epoch: 4657 Loss: 0.025782836601138115\n",
      "Epoch: 4658 Loss: 0.025764642283320427\n",
      "Epoch: 4659 Loss: 0.02576119266450405\n",
      "Epoch: 4660 Loss: 0.025753187015652657\n",
      "Epoch: 4661 Loss: 0.02573615126311779\n",
      "Epoch: 4662 Loss: 0.025730380788445473\n",
      "Epoch: 4663 Loss: 0.025715140625834465\n",
      "Epoch: 4664 Loss: 0.025706490501761436\n",
      "Epoch: 4665 Loss: 0.025695158168673515\n",
      "Epoch: 4666 Loss: 0.02568693831562996\n",
      "Epoch: 4667 Loss: 0.025668229907751083\n",
      "Epoch: 4668 Loss: 0.02566528134047985\n",
      "Epoch: 4669 Loss: 0.025651568546891212\n",
      "Epoch: 4670 Loss: 0.025651026517152786\n",
      "Epoch: 4671 Loss: 0.02564365416765213\n",
      "Epoch: 4672 Loss: 0.025630081072449684\n",
      "Epoch: 4673 Loss: 0.025614144280552864\n",
      "Epoch: 4674 Loss: 0.025602271780371666\n",
      "Epoch: 4675 Loss: 0.025600053369998932\n",
      "Epoch: 4676 Loss: 0.025587284937500954\n",
      "Epoch: 4677 Loss: 0.02558177337050438\n",
      "Epoch: 4678 Loss: 0.025573289021849632\n",
      "Epoch: 4679 Loss: 0.025559624657034874\n",
      "Epoch: 4680 Loss: 0.02555198222398758\n",
      "Epoch: 4681 Loss: 0.025554079562425613\n",
      "Epoch: 4682 Loss: 0.025544391945004463\n",
      "Epoch: 4683 Loss: 0.025518452748656273\n",
      "Epoch: 4684 Loss: 0.02553471177816391\n",
      "Epoch: 4685 Loss: 0.02550642192363739\n",
      "Epoch: 4686 Loss: 0.02549707144498825\n",
      "Epoch: 4687 Loss: 0.02548457682132721\n",
      "Epoch: 4688 Loss: 0.025488177314400673\n",
      "Epoch: 4689 Loss: 0.025470053777098656\n",
      "Epoch: 4690 Loss: 0.02544877491891384\n",
      "Epoch: 4691 Loss: 0.025455094873905182\n",
      "Epoch: 4692 Loss: 0.025429407134652138\n",
      "Epoch: 4693 Loss: 0.025421423837542534\n",
      "Epoch: 4694 Loss: 0.025422263890504837\n",
      "Epoch: 4695 Loss: 0.025407077744603157\n",
      "Epoch: 4696 Loss: 0.0253992211073637\n",
      "Epoch: 4697 Loss: 0.02538679540157318\n",
      "Epoch: 4698 Loss: 0.025377986952662468\n",
      "Epoch: 4699 Loss: 0.025361819192767143\n",
      "Epoch: 4700 Loss: 0.025355936959385872\n",
      "Epoch: 4701 Loss: 0.025344813242554665\n",
      "Epoch: 4702 Loss: 0.025340376421809196\n",
      "Epoch: 4703 Loss: 0.025335995480418205\n",
      "Epoch: 4704 Loss: 0.02531205676496029\n",
      "Epoch: 4705 Loss: 0.025312259793281555\n",
      "Epoch: 4706 Loss: 0.025296654552221298\n",
      "Epoch: 4707 Loss: 0.025292007252573967\n",
      "Epoch: 4708 Loss: 0.025275349617004395\n",
      "Epoch: 4709 Loss: 0.025265533477067947\n",
      "Epoch: 4710 Loss: 0.02528831548988819\n",
      "Epoch: 4711 Loss: 0.025265678763389587\n",
      "Epoch: 4712 Loss: 0.025242658331990242\n",
      "Epoch: 4713 Loss: 0.025245893746614456\n",
      "Epoch: 4714 Loss: 0.0252247117459774\n",
      "Epoch: 4715 Loss: 0.025214435532689095\n",
      "Epoch: 4716 Loss: 0.025202760472893715\n",
      "Epoch: 4717 Loss: 0.025194769725203514\n",
      "Epoch: 4718 Loss: 0.025189027190208435\n",
      "Epoch: 4719 Loss: 0.025181742385029793\n",
      "Epoch: 4720 Loss: 0.02516135200858116\n",
      "Epoch: 4721 Loss: 0.025163020938634872\n",
      "Epoch: 4722 Loss: 0.02515147440135479\n",
      "Epoch: 4723 Loss: 0.025136537849903107\n",
      "Epoch: 4724 Loss: 0.025140345096588135\n",
      "Epoch: 4725 Loss: 0.02511724829673767\n",
      "Epoch: 4726 Loss: 0.025130141526460648\n",
      "Epoch: 4727 Loss: 0.02509715035557747\n",
      "Epoch: 4728 Loss: 0.025095537304878235\n",
      "Epoch: 4729 Loss: 0.02508433721959591\n",
      "Epoch: 4730 Loss: 0.025069473311305046\n",
      "Epoch: 4731 Loss: 0.02507447823882103\n",
      "Epoch: 4732 Loss: 0.025045055896043777\n",
      "Epoch: 4733 Loss: 0.025044862180948257\n",
      "Epoch: 4734 Loss: 0.025032205507159233\n",
      "Epoch: 4735 Loss: 0.025030124932527542\n",
      "Epoch: 4736 Loss: 0.025027215480804443\n",
      "Epoch: 4737 Loss: 0.025013331323862076\n",
      "Epoch: 4738 Loss: 0.024995174258947372\n",
      "Epoch: 4739 Loss: 0.02499331906437874\n",
      "Epoch: 4740 Loss: 0.024993661791086197\n",
      "Epoch: 4741 Loss: 0.024973783642053604\n",
      "Epoch: 4742 Loss: 0.024967776611447334\n",
      "Epoch: 4743 Loss: 0.024947622790932655\n",
      "Epoch: 4744 Loss: 0.024952126666903496\n",
      "Epoch: 4745 Loss: 0.024930866435170174\n",
      "Epoch: 4746 Loss: 0.02494574710726738\n",
      "Epoch: 4747 Loss: 0.024927135556936264\n",
      "Epoch: 4748 Loss: 0.02490762621164322\n",
      "Epoch: 4749 Loss: 0.024893159046769142\n",
      "Epoch: 4750 Loss: 0.024882419034838676\n",
      "Epoch: 4751 Loss: 0.02487853728234768\n",
      "Epoch: 4752 Loss: 0.02488844096660614\n",
      "Epoch: 4753 Loss: 0.02485961839556694\n",
      "Epoch: 4754 Loss: 0.024848084896802902\n",
      "Epoch: 4755 Loss: 0.024837953969836235\n",
      "Epoch: 4756 Loss: 0.024831436574459076\n",
      "Epoch: 4757 Loss: 0.024815062060952187\n",
      "Epoch: 4758 Loss: 0.024818209931254387\n",
      "Epoch: 4759 Loss: 0.024802114814519882\n",
      "Epoch: 4760 Loss: 0.024803202599287033\n",
      "Epoch: 4761 Loss: 0.02477511763572693\n",
      "Epoch: 4762 Loss: 0.024773191660642624\n",
      "Epoch: 4763 Loss: 0.024767840281128883\n",
      "Epoch: 4764 Loss: 0.0247600469738245\n",
      "Epoch: 4765 Loss: 0.024742919951677322\n",
      "Epoch: 4766 Loss: 0.02473895438015461\n",
      "Epoch: 4767 Loss: 0.024724755436182022\n",
      "Epoch: 4768 Loss: 0.024718601256608963\n",
      "Epoch: 4769 Loss: 0.02471425011754036\n",
      "Epoch: 4770 Loss: 0.024700455367565155\n",
      "Epoch: 4771 Loss: 0.024685852229595184\n",
      "Epoch: 4772 Loss: 0.024679262191057205\n",
      "Epoch: 4773 Loss: 0.02466888353228569\n",
      "Epoch: 4774 Loss: 0.024664979428052902\n",
      "Epoch: 4775 Loss: 0.024662060663104057\n",
      "Epoch: 4776 Loss: 0.02465006150305271\n",
      "Epoch: 4777 Loss: 0.024634994566440582\n",
      "Epoch: 4778 Loss: 0.024625377729535103\n",
      "Epoch: 4779 Loss: 0.024622710421681404\n",
      "Epoch: 4780 Loss: 0.02460961975157261\n",
      "Epoch: 4781 Loss: 0.024617446586489677\n",
      "Epoch: 4782 Loss: 0.02460060454905033\n",
      "Epoch: 4783 Loss: 0.024584747850894928\n",
      "Epoch: 4784 Loss: 0.024575259536504745\n",
      "Epoch: 4785 Loss: 0.024583725258708\n",
      "Epoch: 4786 Loss: 0.02456565387547016\n",
      "Epoch: 4787 Loss: 0.024547526612877846\n",
      "Epoch: 4788 Loss: 0.02455269545316696\n",
      "Epoch: 4789 Loss: 0.024530775845050812\n",
      "Epoch: 4790 Loss: 0.024528609588742256\n",
      "Epoch: 4791 Loss: 0.02451472356915474\n",
      "Epoch: 4792 Loss: 0.02450660802423954\n",
      "Epoch: 4793 Loss: 0.024493534117937088\n",
      "Epoch: 4794 Loss: 0.02448919601738453\n",
      "Epoch: 4795 Loss: 0.024479631334543228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4796 Loss: 0.024475684389472008\n",
      "Epoch: 4797 Loss: 0.0244619008153677\n",
      "Epoch: 4798 Loss: 0.024462934583425522\n",
      "Epoch: 4799 Loss: 0.02443576604127884\n",
      "Epoch: 4800 Loss: 0.024438951164484024\n",
      "Epoch: 4801 Loss: 0.024418462067842484\n",
      "Epoch: 4802 Loss: 0.02440616860985756\n",
      "Epoch: 4803 Loss: 0.02440042607486248\n",
      "Epoch: 4804 Loss: 0.02439405955374241\n",
      "Epoch: 4805 Loss: 0.024389345198869705\n",
      "Epoch: 4806 Loss: 0.02437085658311844\n",
      "Epoch: 4807 Loss: 0.02437242679297924\n",
      "Epoch: 4808 Loss: 0.0243550892919302\n",
      "Epoch: 4809 Loss: 0.02434581331908703\n",
      "Epoch: 4810 Loss: 0.024335499852895737\n",
      "Epoch: 4811 Loss: 0.024330895394086838\n",
      "Epoch: 4812 Loss: 0.024321621283888817\n",
      "Epoch: 4813 Loss: 0.024315886199474335\n",
      "Epoch: 4814 Loss: 0.02430216409265995\n",
      "Epoch: 4815 Loss: 0.02429346740245819\n",
      "Epoch: 4816 Loss: 0.02428961731493473\n",
      "Epoch: 4817 Loss: 0.024273250252008438\n",
      "Epoch: 4818 Loss: 0.024264460429549217\n",
      "Epoch: 4819 Loss: 0.02426619827747345\n",
      "Epoch: 4820 Loss: 0.02424491196870804\n",
      "Epoch: 4821 Loss: 0.02424008399248123\n",
      "Epoch: 4822 Loss: 0.024236848577857018\n",
      "Epoch: 4823 Loss: 0.02422189898788929\n",
      "Epoch: 4824 Loss: 0.024216823279857635\n",
      "Epoch: 4825 Loss: 0.02420639619231224\n",
      "Epoch: 4826 Loss: 0.024200167506933212\n",
      "Epoch: 4827 Loss: 0.02418445236980915\n",
      "Epoch: 4828 Loss: 0.024176156148314476\n",
      "Epoch: 4829 Loss: 0.02419157512485981\n",
      "Epoch: 4830 Loss: 0.024166282266378403\n",
      "Epoch: 4831 Loss: 0.0241545420140028\n",
      "Epoch: 4832 Loss: 0.024151360616087914\n",
      "Epoch: 4833 Loss: 0.024136757478117943\n",
      "Epoch: 4834 Loss: 0.024125531315803528\n",
      "Epoch: 4835 Loss: 0.024115635082125664\n",
      "Epoch: 4836 Loss: 0.024109378457069397\n",
      "Epoch: 4837 Loss: 0.02409859374165535\n",
      "Epoch: 4838 Loss: 0.024111544713377953\n",
      "Epoch: 4839 Loss: 0.024087194353342056\n",
      "Epoch: 4840 Loss: 0.0240979865193367\n",
      "Epoch: 4841 Loss: 0.02406478300690651\n",
      "Epoch: 4842 Loss: 0.024074319750070572\n",
      "Epoch: 4843 Loss: 0.02404950186610222\n",
      "Epoch: 4844 Loss: 0.024043235927820206\n",
      "Epoch: 4845 Loss: 0.02403504215180874\n",
      "Epoch: 4846 Loss: 0.024035930633544922\n",
      "Epoch: 4847 Loss: 0.024014465510845184\n",
      "Epoch: 4848 Loss: 0.024018529802560806\n",
      "Epoch: 4849 Loss: 0.024001576006412506\n",
      "Epoch: 4850 Loss: 0.023983817547559738\n",
      "Epoch: 4851 Loss: 0.023985590785741806\n",
      "Epoch: 4852 Loss: 0.023968074470758438\n",
      "Epoch: 4853 Loss: 0.023968350142240524\n",
      "Epoch: 4854 Loss: 0.023954754695296288\n",
      "Epoch: 4855 Loss: 0.023936830461025238\n",
      "Epoch: 4856 Loss: 0.023933110758662224\n",
      "Epoch: 4857 Loss: 0.02393179200589657\n",
      "Epoch: 4858 Loss: 0.02392050437629223\n",
      "Epoch: 4859 Loss: 0.023909643292427063\n",
      "Epoch: 4860 Loss: 0.023898836225271225\n",
      "Epoch: 4861 Loss: 0.023880111053586006\n",
      "Epoch: 4862 Loss: 0.023881351575255394\n",
      "Epoch: 4863 Loss: 0.02387663908302784\n",
      "Epoch: 4864 Loss: 0.02386035956442356\n",
      "Epoch: 4865 Loss: 0.023859797045588493\n",
      "Epoch: 4866 Loss: 0.023848261684179306\n",
      "Epoch: 4867 Loss: 0.02384449541568756\n",
      "Epoch: 4868 Loss: 0.023829244077205658\n",
      "Epoch: 4869 Loss: 0.023826660588383675\n",
      "Epoch: 4870 Loss: 0.023830335587263107\n",
      "Epoch: 4871 Loss: 0.023805832490324974\n",
      "Epoch: 4872 Loss: 0.02380645088851452\n",
      "Epoch: 4873 Loss: 0.023787884041666985\n",
      "Epoch: 4874 Loss: 0.023772140964865685\n",
      "Epoch: 4875 Loss: 0.023773489519953728\n",
      "Epoch: 4876 Loss: 0.023759514093399048\n",
      "Epoch: 4877 Loss: 0.02375718206167221\n",
      "Epoch: 4878 Loss: 0.023742826655507088\n",
      "Epoch: 4879 Loss: 0.023734766989946365\n",
      "Epoch: 4880 Loss: 0.02373350039124489\n",
      "Epoch: 4881 Loss: 0.023733332753181458\n",
      "Epoch: 4882 Loss: 0.0237142201513052\n",
      "Epoch: 4883 Loss: 0.02371223457157612\n",
      "Epoch: 4884 Loss: 0.023695992305874825\n",
      "Epoch: 4885 Loss: 0.023692673072218895\n",
      "Epoch: 4886 Loss: 0.023682860657572746\n",
      "Epoch: 4887 Loss: 0.023674920201301575\n",
      "Epoch: 4888 Loss: 0.02366045117378235\n",
      "Epoch: 4889 Loss: 0.02366115152835846\n",
      "Epoch: 4890 Loss: 0.023641522973775864\n",
      "Epoch: 4891 Loss: 0.02364729531109333\n",
      "Epoch: 4892 Loss: 0.023623496294021606\n",
      "Epoch: 4893 Loss: 0.023626169189810753\n",
      "Epoch: 4894 Loss: 0.023608259856700897\n",
      "Epoch: 4895 Loss: 0.023609135299921036\n",
      "Epoch: 4896 Loss: 0.023595528677105904\n",
      "Epoch: 4897 Loss: 0.023587854579091072\n",
      "Epoch: 4898 Loss: 0.023575162515044212\n",
      "Epoch: 4899 Loss: 0.02356737107038498\n",
      "Epoch: 4900 Loss: 0.023555684834718704\n",
      "Epoch: 4901 Loss: 0.02354128658771515\n",
      "Epoch: 4902 Loss: 0.023539576679468155\n",
      "Epoch: 4903 Loss: 0.023536736145615578\n",
      "Epoch: 4904 Loss: 0.023520452901721\n",
      "Epoch: 4905 Loss: 0.023512378334999084\n",
      "Epoch: 4906 Loss: 0.023510821163654327\n",
      "Epoch: 4907 Loss: 0.023496098816394806\n",
      "Epoch: 4908 Loss: 0.023487767204642296\n",
      "Epoch: 4909 Loss: 0.02348146215081215\n",
      "Epoch: 4910 Loss: 0.023474641144275665\n",
      "Epoch: 4911 Loss: 0.02346445620059967\n",
      "Epoch: 4912 Loss: 0.023452015593647957\n",
      "Epoch: 4913 Loss: 0.02344529703259468\n",
      "Epoch: 4914 Loss: 0.02343224175274372\n",
      "Epoch: 4915 Loss: 0.023426515981554985\n",
      "Epoch: 4916 Loss: 0.023428793996572495\n",
      "Epoch: 4917 Loss: 0.02341247908771038\n",
      "Epoch: 4918 Loss: 0.023424163460731506\n",
      "Epoch: 4919 Loss: 0.023389849811792374\n",
      "Epoch: 4920 Loss: 0.023399705067276955\n",
      "Epoch: 4921 Loss: 0.0233884546905756\n",
      "Epoch: 4922 Loss: 0.02337651699781418\n",
      "Epoch: 4923 Loss: 0.0233590267598629\n",
      "Epoch: 4924 Loss: 0.023366665467619896\n",
      "Epoch: 4925 Loss: 0.023339206352829933\n",
      "Epoch: 4926 Loss: 0.02334699220955372\n",
      "Epoch: 4927 Loss: 0.023333542048931122\n",
      "Epoch: 4928 Loss: 0.023316990584135056\n",
      "Epoch: 4929 Loss: 0.023312203586101532\n",
      "Epoch: 4930 Loss: 0.023298950865864754\n",
      "Epoch: 4931 Loss: 0.02329132705926895\n",
      "Epoch: 4932 Loss: 0.023291008546948433\n",
      "Epoch: 4933 Loss: 0.023275544866919518\n",
      "Epoch: 4934 Loss: 0.023270366713404655\n",
      "Epoch: 4935 Loss: 0.023260360583662987\n",
      "Epoch: 4936 Loss: 0.023255134001374245\n",
      "Epoch: 4937 Loss: 0.023246552795171738\n",
      "Epoch: 4938 Loss: 0.023236816748976707\n",
      "Epoch: 4939 Loss: 0.023228546604514122\n",
      "Epoch: 4940 Loss: 0.02322298474609852\n",
      "Epoch: 4941 Loss: 0.023211689665913582\n",
      "Epoch: 4942 Loss: 0.02320086397230625\n",
      "Epoch: 4943 Loss: 0.023189790546894073\n",
      "Epoch: 4944 Loss: 0.023185929283499718\n",
      "Epoch: 4945 Loss: 0.02317357249557972\n",
      "Epoch: 4946 Loss: 0.023179491981863976\n",
      "Epoch: 4947 Loss: 0.023160021752119064\n",
      "Epoch: 4948 Loss: 0.023159828037023544\n",
      "Epoch: 4949 Loss: 0.02314165234565735\n",
      "Epoch: 4950 Loss: 0.023137085139751434\n",
      "Epoch: 4951 Loss: 0.023128535598516464\n",
      "Epoch: 4952 Loss: 0.023115739226341248\n",
      "Epoch: 4953 Loss: 0.02312072366476059\n",
      "Epoch: 4954 Loss: 0.023106113076210022\n",
      "Epoch: 4955 Loss: 0.023107999935746193\n",
      "Epoch: 4956 Loss: 0.023100480437278748\n",
      "Epoch: 4957 Loss: 0.02307760715484619\n",
      "Epoch: 4958 Loss: 0.023072343319654465\n",
      "Epoch: 4959 Loss: 0.02307070419192314\n",
      "Epoch: 4960 Loss: 0.023052209988236427\n",
      "Epoch: 4961 Loss: 0.02304811216890812\n",
      "Epoch: 4962 Loss: 0.023039905354380608\n",
      "Epoch: 4963 Loss: 0.02302977256476879\n",
      "Epoch: 4964 Loss: 0.023015744984149933\n",
      "Epoch: 4965 Loss: 0.023008322343230247\n",
      "Epoch: 4966 Loss: 0.0230086836963892\n",
      "Epoch: 4967 Loss: 0.02299918420612812\n",
      "Epoch: 4968 Loss: 0.022981807589530945\n",
      "Epoch: 4969 Loss: 0.02298005111515522\n",
      "Epoch: 4970 Loss: 0.022987164556980133\n",
      "Epoch: 4971 Loss: 0.02296707034111023\n",
      "Epoch: 4972 Loss: 0.02295113354921341\n",
      "Epoch: 4973 Loss: 0.022952556610107422\n",
      "Epoch: 4974 Loss: 0.022939393296837807\n",
      "Epoch: 4975 Loss: 0.022930951789021492\n",
      "Epoch: 4976 Loss: 0.0229168850928545\n",
      "Epoch: 4977 Loss: 0.02292407490313053\n",
      "Epoch: 4978 Loss: 0.022906649857759476\n",
      "Epoch: 4979 Loss: 0.022901929914951324\n",
      "Epoch: 4980 Loss: 0.022890618070960045\n",
      "Epoch: 4981 Loss: 0.022879334166646004\n",
      "Epoch: 4982 Loss: 0.02288421429693699\n",
      "Epoch: 4983 Loss: 0.022885162383317947\n",
      "Epoch: 4984 Loss: 0.022855622693896294\n",
      "Epoch: 4985 Loss: 0.02286124974489212\n",
      "Epoch: 4986 Loss: 0.022841040045022964\n",
      "Epoch: 4987 Loss: 0.02285229042172432\n",
      "Epoch: 4988 Loss: 0.02282467484474182\n",
      "Epoch: 4989 Loss: 0.022832585498690605\n",
      "Epoch: 4990 Loss: 0.0228123739361763\n",
      "Epoch: 4991 Loss: 0.022813336923718452\n",
      "Epoch: 4992 Loss: 0.022789934650063515\n",
      "Epoch: 4993 Loss: 0.022799136117100716\n",
      "Epoch: 4994 Loss: 0.02277526818215847\n",
      "Epoch: 4995 Loss: 0.022771425545215607\n",
      "Epoch: 4996 Loss: 0.022763654589653015\n",
      "Epoch: 4997 Loss: 0.02275818958878517\n",
      "Epoch: 4998 Loss: 0.02274731919169426\n",
      "Epoch: 4999 Loss: 0.02273622341454029\n",
      "Epoch: 5000 Loss: 0.02272949181497097\n",
      "Epoch: 5001 Loss: 0.022720973938703537\n",
      "Epoch: 5002 Loss: 0.022717632353305817\n",
      "Epoch: 5003 Loss: 0.022707026451826096\n",
      "Epoch: 5004 Loss: 0.02269708923995495\n",
      "Epoch: 5005 Loss: 0.022690510377287865\n",
      "Epoch: 5006 Loss: 0.022681305184960365\n",
      "Epoch: 5007 Loss: 0.02267284132540226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5008 Loss: 0.022664718329906464\n",
      "Epoch: 5009 Loss: 0.022655921056866646\n",
      "Epoch: 5010 Loss: 0.022654902189970016\n",
      "Epoch: 5011 Loss: 0.02263820916414261\n",
      "Epoch: 5012 Loss: 0.022644851356744766\n",
      "Epoch: 5013 Loss: 0.022620242089033127\n",
      "Epoch: 5014 Loss: 0.022610072046518326\n",
      "Epoch: 5015 Loss: 0.022608313709497452\n",
      "Epoch: 5016 Loss: 0.022599443793296814\n",
      "Epoch: 5017 Loss: 0.02258887328207493\n",
      "Epoch: 5018 Loss: 0.02259071171283722\n",
      "Epoch: 5019 Loss: 0.022572103887796402\n",
      "Epoch: 5020 Loss: 0.022577723488211632\n",
      "Epoch: 5021 Loss: 0.02255808562040329\n",
      "Epoch: 5022 Loss: 0.02255302295088768\n",
      "Epoch: 5023 Loss: 0.022560536861419678\n",
      "Epoch: 5024 Loss: 0.022538594901561737\n",
      "Epoch: 5025 Loss: 0.022539332509040833\n",
      "Epoch: 5026 Loss: 0.022525422275066376\n",
      "Epoch: 5027 Loss: 0.022525090724229813\n",
      "Epoch: 5028 Loss: 0.022509397938847542\n",
      "Epoch: 5029 Loss: 0.02250605635344982\n",
      "Epoch: 5030 Loss: 0.022485975176095963\n",
      "Epoch: 5031 Loss: 0.02248804271221161\n",
      "Epoch: 5032 Loss: 0.022474220022559166\n",
      "Epoch: 5033 Loss: 0.022475993260741234\n",
      "Epoch: 5034 Loss: 0.02245553769171238\n",
      "Epoch: 5035 Loss: 0.022455284371972084\n",
      "Epoch: 5036 Loss: 0.022441405802965164\n",
      "Epoch: 5037 Loss: 0.022447314113378525\n",
      "Epoch: 5038 Loss: 0.022430388256907463\n",
      "Epoch: 5039 Loss: 0.02242458052933216\n",
      "Epoch: 5040 Loss: 0.022411171346902847\n",
      "Epoch: 5041 Loss: 0.022401515394449234\n",
      "Epoch: 5042 Loss: 0.02239185944199562\n",
      "Epoch: 5043 Loss: 0.022385133430361748\n",
      "Epoch: 5044 Loss: 0.022380903363227844\n",
      "Epoch: 5045 Loss: 0.022375836968421936\n",
      "Epoch: 5046 Loss: 0.022357895970344543\n",
      "Epoch: 5047 Loss: 0.022358490154147148\n",
      "Epoch: 5048 Loss: 0.022345973178744316\n",
      "Epoch: 5049 Loss: 0.022340811789035797\n",
      "Epoch: 5050 Loss: 0.022335434332489967\n",
      "Epoch: 5051 Loss: 0.022327285259962082\n",
      "Epoch: 5052 Loss: 0.022316377609968185\n",
      "Epoch: 5053 Loss: 0.02230682410299778\n",
      "Epoch: 5054 Loss: 0.022302407771348953\n",
      "Epoch: 5055 Loss: 0.02229337766766548\n",
      "Epoch: 5056 Loss: 0.022283164784312248\n",
      "Epoch: 5057 Loss: 0.022275006398558617\n",
      "Epoch: 5058 Loss: 0.022279364988207817\n",
      "Epoch: 5059 Loss: 0.022262342274188995\n",
      "Epoch: 5060 Loss: 0.022253450006246567\n",
      "Epoch: 5061 Loss: 0.02224964089691639\n",
      "Epoch: 5062 Loss: 0.022239286452531815\n",
      "Epoch: 5063 Loss: 0.02224939689040184\n",
      "Epoch: 5064 Loss: 0.022223807871341705\n",
      "Epoch: 5065 Loss: 0.022224560379981995\n",
      "Epoch: 5066 Loss: 0.02220599539577961\n",
      "Epoch: 5067 Loss: 0.022212810814380646\n",
      "Epoch: 5068 Loss: 0.022187136113643646\n",
      "Epoch: 5069 Loss: 0.02219761721789837\n",
      "Epoch: 5070 Loss: 0.022172488272190094\n",
      "Epoch: 5071 Loss: 0.022171087563037872\n",
      "Epoch: 5072 Loss: 0.022163914516568184\n",
      "Epoch: 5073 Loss: 0.02216101624071598\n",
      "Epoch: 5074 Loss: 0.022146981209516525\n",
      "Epoch: 5075 Loss: 0.022134555503726006\n",
      "Epoch: 5076 Loss: 0.022133786231279373\n",
      "Epoch: 5077 Loss: 0.02212509699165821\n",
      "Epoch: 5078 Loss: 0.022114193066954613\n",
      "Epoch: 5079 Loss: 0.022110212594270706\n",
      "Epoch: 5080 Loss: 0.022099308669567108\n",
      "Epoch: 5081 Loss: 0.02208659239113331\n",
      "Epoch: 5082 Loss: 0.022082949057221413\n",
      "Epoch: 5083 Loss: 0.022075921297073364\n",
      "Epoch: 5084 Loss: 0.02207718975841999\n",
      "Epoch: 5085 Loss: 0.022058412432670593\n",
      "Epoch: 5086 Loss: 0.022051529958844185\n",
      "Epoch: 5087 Loss: 0.02204480953514576\n",
      "Epoch: 5088 Loss: 0.022038156166672707\n",
      "Epoch: 5089 Loss: 0.02203267067670822\n",
      "Epoch: 5090 Loss: 0.02201789990067482\n",
      "Epoch: 5091 Loss: 0.022016355767846107\n",
      "Epoch: 5092 Loss: 0.022000649943947792\n",
      "Epoch: 5093 Loss: 0.021997002884745598\n",
      "Epoch: 5094 Loss: 0.021991891786456108\n",
      "Epoch: 5095 Loss: 0.021984202787280083\n",
      "Epoch: 5096 Loss: 0.021976588293910027\n",
      "Epoch: 5097 Loss: 0.02197287231683731\n",
      "Epoch: 5098 Loss: 0.021965472027659416\n",
      "Epoch: 5099 Loss: 0.021958259865641594\n",
      "Epoch: 5100 Loss: 0.02194901555776596\n",
      "Epoch: 5101 Loss: 0.02195354737341404\n",
      "Epoch: 5102 Loss: 0.021931683644652367\n",
      "Epoch: 5103 Loss: 0.021922780200839043\n",
      "Epoch: 5104 Loss: 0.02191864885389805\n",
      "Epoch: 5105 Loss: 0.021910689771175385\n",
      "Epoch: 5106 Loss: 0.021898755803704262\n",
      "Epoch: 5107 Loss: 0.021905291825532913\n",
      "Epoch: 5108 Loss: 0.021886015310883522\n",
      "Epoch: 5109 Loss: 0.02187359146773815\n",
      "Epoch: 5110 Loss: 0.02186712808907032\n",
      "Epoch: 5111 Loss: 0.021879062056541443\n",
      "Epoch: 5112 Loss: 0.021869488060474396\n",
      "Epoch: 5113 Loss: 0.021854707971215248\n",
      "Epoch: 5114 Loss: 0.021851779893040657\n",
      "Epoch: 5115 Loss: 0.021833764389157295\n",
      "Epoch: 5116 Loss: 0.021843278780579567\n",
      "Epoch: 5117 Loss: 0.021821534261107445\n",
      "Epoch: 5118 Loss: 0.021816758438944817\n",
      "Epoch: 5119 Loss: 0.021801011636853218\n",
      "Epoch: 5120 Loss: 0.021802332252264023\n",
      "Epoch: 5121 Loss: 0.021788831800222397\n",
      "Epoch: 5122 Loss: 0.021788060665130615\n",
      "Epoch: 5123 Loss: 0.02177433669567108\n",
      "Epoch: 5124 Loss: 0.02177215740084648\n",
      "Epoch: 5125 Loss: 0.02175840362906456\n",
      "Epoch: 5126 Loss: 0.021748842671513557\n",
      "Epoch: 5127 Loss: 0.021741144359111786\n",
      "Epoch: 5128 Loss: 0.02173827402293682\n",
      "Epoch: 5129 Loss: 0.02172900177538395\n",
      "Epoch: 5130 Loss: 0.021731045097112656\n",
      "Epoch: 5131 Loss: 0.021710967645049095\n",
      "Epoch: 5132 Loss: 0.021714860573410988\n",
      "Epoch: 5133 Loss: 0.021704422309994698\n",
      "Epoch: 5134 Loss: 0.02169184759259224\n",
      "Epoch: 5135 Loss: 0.021685540676116943\n",
      "Epoch: 5136 Loss: 0.021673699840903282\n",
      "Epoch: 5137 Loss: 0.02166621759533882\n",
      "Epoch: 5138 Loss: 0.021662142127752304\n",
      "Epoch: 5139 Loss: 0.021656250581145287\n",
      "Epoch: 5140 Loss: 0.021647976711392403\n",
      "Epoch: 5141 Loss: 0.021644243970513344\n",
      "Epoch: 5142 Loss: 0.02164287678897381\n",
      "Epoch: 5143 Loss: 0.02161998860538006\n",
      "Epoch: 5144 Loss: 0.021623240783810616\n",
      "Epoch: 5145 Loss: 0.021618220955133438\n",
      "Epoch: 5146 Loss: 0.02160448394715786\n",
      "Epoch: 5147 Loss: 0.021593116223812103\n",
      "Epoch: 5148 Loss: 0.02158399671316147\n",
      "Epoch: 5149 Loss: 0.021587595343589783\n",
      "Epoch: 5150 Loss: 0.021569952368736267\n",
      "Epoch: 5151 Loss: 0.02156827598810196\n",
      "Epoch: 5152 Loss: 0.021559325978159904\n",
      "Epoch: 5153 Loss: 0.021549127995967865\n",
      "Epoch: 5154 Loss: 0.02154458314180374\n",
      "Epoch: 5155 Loss: 0.021532220765948296\n",
      "Epoch: 5156 Loss: 0.021529152989387512\n",
      "Epoch: 5157 Loss: 0.021522898226976395\n",
      "Epoch: 5158 Loss: 0.0215134397149086\n",
      "Epoch: 5159 Loss: 0.021504970267415047\n",
      "Epoch: 5160 Loss: 0.021500421687960625\n",
      "Epoch: 5161 Loss: 0.021488847211003304\n",
      "Epoch: 5162 Loss: 0.021482087671756744\n",
      "Epoch: 5163 Loss: 0.02146899700164795\n",
      "Epoch: 5164 Loss: 0.021484049037098885\n",
      "Epoch: 5165 Loss: 0.0214629415422678\n",
      "Epoch: 5166 Loss: 0.021467983722686768\n",
      "Epoch: 5167 Loss: 0.02144451253116131\n",
      "Epoch: 5168 Loss: 0.021451346576213837\n",
      "Epoch: 5169 Loss: 0.02143239974975586\n",
      "Epoch: 5170 Loss: 0.021421337500214577\n",
      "Epoch: 5171 Loss: 0.021421577781438828\n",
      "Epoch: 5172 Loss: 0.021404806524515152\n",
      "Epoch: 5173 Loss: 0.021404385566711426\n",
      "Epoch: 5174 Loss: 0.021397029981017113\n",
      "Epoch: 5175 Loss: 0.021385028958320618\n",
      "Epoch: 5176 Loss: 0.021382205188274384\n",
      "Epoch: 5177 Loss: 0.021369926631450653\n",
      "Epoch: 5178 Loss: 0.021363118663430214\n",
      "Epoch: 5179 Loss: 0.021358773112297058\n",
      "Epoch: 5180 Loss: 0.021352369338274002\n",
      "Epoch: 5181 Loss: 0.021349601447582245\n",
      "Epoch: 5182 Loss: 0.02132914960384369\n",
      "Epoch: 5183 Loss: 0.021326856687664986\n",
      "Epoch: 5184 Loss: 0.021320847794413567\n",
      "Epoch: 5185 Loss: 0.02132752165198326\n",
      "Epoch: 5186 Loss: 0.021303841844201088\n",
      "Epoch: 5187 Loss: 0.021304136142134666\n",
      "Epoch: 5188 Loss: 0.02129543013870716\n",
      "Epoch: 5189 Loss: 0.021291228011250496\n",
      "Epoch: 5190 Loss: 0.02127714268863201\n",
      "Epoch: 5191 Loss: 0.02127808704972267\n",
      "Epoch: 5192 Loss: 0.02126266621053219\n",
      "Epoch: 5193 Loss: 0.021261820569634438\n",
      "Epoch: 5194 Loss: 0.021247535943984985\n",
      "Epoch: 5195 Loss: 0.02125414088368416\n",
      "Epoch: 5196 Loss: 0.02123226411640644\n",
      "Epoch: 5197 Loss: 0.021225055679678917\n",
      "Epoch: 5198 Loss: 0.021221578121185303\n",
      "Epoch: 5199 Loss: 0.021213648840785027\n",
      "Epoch: 5200 Loss: 0.02119949832558632\n",
      "Epoch: 5201 Loss: 0.02119492180645466\n",
      "Epoch: 5202 Loss: 0.021195264533162117\n",
      "Epoch: 5203 Loss: 0.021175788715481758\n",
      "Epoch: 5204 Loss: 0.021192405372858047\n",
      "Epoch: 5205 Loss: 0.021164312958717346\n",
      "Epoch: 5206 Loss: 0.02116863802075386\n",
      "Epoch: 5207 Loss: 0.02115153893828392\n",
      "Epoch: 5208 Loss: 0.021153464913368225\n",
      "Epoch: 5209 Loss: 0.021136373281478882\n",
      "Epoch: 5210 Loss: 0.021129440516233444\n",
      "Epoch: 5211 Loss: 0.021132273599505424\n",
      "Epoch: 5212 Loss: 0.021116673946380615\n",
      "Epoch: 5213 Loss: 0.02110997959971428\n",
      "Epoch: 5214 Loss: 0.02110670879483223\n",
      "Epoch: 5215 Loss: 0.02109491266310215\n",
      "Epoch: 5216 Loss: 0.021084440872073174\n",
      "Epoch: 5217 Loss: 0.021079452708363533\n",
      "Epoch: 5218 Loss: 0.021074458956718445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5219 Loss: 0.02106330916285515\n",
      "Epoch: 5220 Loss: 0.021058961749076843\n",
      "Epoch: 5221 Loss: 0.021054577082395554\n",
      "Epoch: 5222 Loss: 0.02103879675269127\n",
      "Epoch: 5223 Loss: 0.0210349690169096\n",
      "Epoch: 5224 Loss: 0.021032122895121574\n",
      "Epoch: 5225 Loss: 0.02102215588092804\n",
      "Epoch: 5226 Loss: 0.02101711370050907\n",
      "Epoch: 5227 Loss: 0.021000072360038757\n",
      "Epoch: 5228 Loss: 0.020994046702980995\n",
      "Epoch: 5229 Loss: 0.02099994197487831\n",
      "Epoch: 5230 Loss: 0.020983409136533737\n",
      "Epoch: 5231 Loss: 0.020993608981370926\n",
      "Epoch: 5232 Loss: 0.020975880324840546\n",
      "Epoch: 5233 Loss: 0.020960833877325058\n",
      "Epoch: 5234 Loss: 0.0209753829985857\n",
      "Epoch: 5235 Loss: 0.020948203280568123\n",
      "Epoch: 5236 Loss: 0.020940646529197693\n",
      "Epoch: 5237 Loss: 0.020949769765138626\n",
      "Epoch: 5238 Loss: 0.020928846672177315\n",
      "Epoch: 5239 Loss: 0.020926978439092636\n",
      "Epoch: 5240 Loss: 0.020917434245347977\n",
      "Epoch: 5241 Loss: 0.020907577127218246\n",
      "Epoch: 5242 Loss: 0.02090400457382202\n",
      "Epoch: 5243 Loss: 0.020892206579446793\n",
      "Epoch: 5244 Loss: 0.02088383212685585\n",
      "Epoch: 5245 Loss: 0.02087664231657982\n",
      "Epoch: 5246 Loss: 0.020875899121165276\n",
      "Epoch: 5247 Loss: 0.020862463861703873\n",
      "Epoch: 5248 Loss: 0.02086544781923294\n",
      "Epoch: 5249 Loss: 0.020847098901867867\n",
      "Epoch: 5250 Loss: 0.020845239982008934\n",
      "Epoch: 5251 Loss: 0.020840011537075043\n",
      "Epoch: 5252 Loss: 0.02082596719264984\n",
      "Epoch: 5253 Loss: 0.02082439325749874\n",
      "Epoch: 5254 Loss: 0.020817484706640244\n",
      "Epoch: 5255 Loss: 0.020813576877117157\n",
      "Epoch: 5256 Loss: 0.02079857885837555\n",
      "Epoch: 5257 Loss: 0.02079150266945362\n",
      "Epoch: 5258 Loss: 0.020785706117749214\n",
      "Epoch: 5259 Loss: 0.02078181505203247\n",
      "Epoch: 5260 Loss: 0.020787732675671577\n",
      "Epoch: 5261 Loss: 0.02077046036720276\n",
      "Epoch: 5262 Loss: 0.020767411217093468\n",
      "Epoch: 5263 Loss: 0.02075028046965599\n",
      "Epoch: 5264 Loss: 0.02075158804655075\n",
      "Epoch: 5265 Loss: 0.020739955827593803\n",
      "Epoch: 5266 Loss: 0.020742326974868774\n",
      "Epoch: 5267 Loss: 0.02072405256330967\n",
      "Epoch: 5268 Loss: 0.02072610706090927\n",
      "Epoch: 5269 Loss: 0.02071286365389824\n",
      "Epoch: 5270 Loss: 0.02070915699005127\n",
      "Epoch: 5271 Loss: 0.02069620043039322\n",
      "Epoch: 5272 Loss: 0.020693253725767136\n",
      "Epoch: 5273 Loss: 0.02068343386054039\n",
      "Epoch: 5274 Loss: 0.020675616338849068\n",
      "Epoch: 5275 Loss: 0.02067580819129944\n",
      "Epoch: 5276 Loss: 0.02065974473953247\n",
      "Epoch: 5277 Loss: 0.020663348957896233\n",
      "Epoch: 5278 Loss: 0.020647961646318436\n",
      "Epoch: 5279 Loss: 0.020639339461922646\n",
      "Epoch: 5280 Loss: 0.020632686093449593\n",
      "Epoch: 5281 Loss: 0.020625466480851173\n",
      "Epoch: 5282 Loss: 0.02062341943383217\n",
      "Epoch: 5283 Loss: 0.020611505955457687\n",
      "Epoch: 5284 Loss: 0.020617887377738953\n",
      "Epoch: 5285 Loss: 0.02059793286025524\n",
      "Epoch: 5286 Loss: 0.020595790818333626\n",
      "Epoch: 5287 Loss: 0.020582005381584167\n",
      "Epoch: 5288 Loss: 0.020582061260938644\n",
      "Epoch: 5289 Loss: 0.020572125911712646\n",
      "Epoch: 5290 Loss: 0.020556822419166565\n",
      "Epoch: 5291 Loss: 0.020555417984724045\n",
      "Epoch: 5292 Loss: 0.02055048570036888\n",
      "Epoch: 5293 Loss: 0.020551037043333054\n",
      "Epoch: 5294 Loss: 0.02053876966238022\n",
      "Epoch: 5295 Loss: 0.020532151684165\n",
      "Epoch: 5296 Loss: 0.020517637953162193\n",
      "Epoch: 5297 Loss: 0.02051924355328083\n",
      "Epoch: 5298 Loss: 0.02050555683672428\n",
      "Epoch: 5299 Loss: 0.02050444483757019\n",
      "Epoch: 5300 Loss: 0.0204937644302845\n",
      "Epoch: 5301 Loss: 0.020492708310484886\n",
      "Epoch: 5302 Loss: 0.02048361860215664\n",
      "Epoch: 5303 Loss: 0.02047218382358551\n",
      "Epoch: 5304 Loss: 0.020465925335884094\n",
      "Epoch: 5305 Loss: 0.020463885739445686\n",
      "Epoch: 5306 Loss: 0.020457221195101738\n",
      "Epoch: 5307 Loss: 0.020462553948163986\n",
      "Epoch: 5308 Loss: 0.02045251801609993\n",
      "Epoch: 5309 Loss: 0.020431386306881905\n",
      "Epoch: 5310 Loss: 0.02043847180902958\n",
      "Epoch: 5311 Loss: 0.02041730284690857\n",
      "Epoch: 5312 Loss: 0.02041928842663765\n",
      "Epoch: 5313 Loss: 0.02040797472000122\n",
      "Epoch: 5314 Loss: 0.020399177446961403\n",
      "Epoch: 5315 Loss: 0.02038908563554287\n",
      "Epoch: 5316 Loss: 0.02038993127644062\n",
      "Epoch: 5317 Loss: 0.020375870168209076\n",
      "Epoch: 5318 Loss: 0.0203720573335886\n",
      "Epoch: 5319 Loss: 0.02036944031715393\n",
      "Epoch: 5320 Loss: 0.020355787128210068\n",
      "Epoch: 5321 Loss: 0.0203519556671381\n",
      "Epoch: 5322 Loss: 0.02034955844283104\n",
      "Epoch: 5323 Loss: 0.020341426134109497\n",
      "Epoch: 5324 Loss: 0.020332783460617065\n",
      "Epoch: 5325 Loss: 0.02032746560871601\n",
      "Epoch: 5326 Loss: 0.02032242715358734\n",
      "Epoch: 5327 Loss: 0.020316336303949356\n",
      "Epoch: 5328 Loss: 0.02030372805893421\n",
      "Epoch: 5329 Loss: 0.02030167169868946\n",
      "Epoch: 5330 Loss: 0.020288920029997826\n",
      "Epoch: 5331 Loss: 0.020298641175031662\n",
      "Epoch: 5332 Loss: 0.0202771108597517\n",
      "Epoch: 5333 Loss: 0.020276764407753944\n",
      "Epoch: 5334 Loss: 0.020277250558137894\n",
      "Epoch: 5335 Loss: 0.020268362015485764\n",
      "Epoch: 5336 Loss: 0.02024809457361698\n",
      "Epoch: 5337 Loss: 0.020256290212273598\n",
      "Epoch: 5338 Loss: 0.020237641409039497\n",
      "Epoch: 5339 Loss: 0.020232826471328735\n",
      "Epoch: 5340 Loss: 0.020224958658218384\n",
      "Epoch: 5341 Loss: 0.020215623080730438\n",
      "Epoch: 5342 Loss: 0.020217563956975937\n",
      "Epoch: 5343 Loss: 0.02021017111837864\n",
      "Epoch: 5344 Loss: 0.020197639241814613\n",
      "Epoch: 5345 Loss: 0.020191291347146034\n",
      "Epoch: 5346 Loss: 0.02017912082374096\n",
      "Epoch: 5347 Loss: 0.020180657505989075\n",
      "Epoch: 5348 Loss: 0.02016843669116497\n",
      "Epoch: 5349 Loss: 0.020173748955130577\n",
      "Epoch: 5350 Loss: 0.02015668898820877\n",
      "Epoch: 5351 Loss: 0.02016071043908596\n",
      "Epoch: 5352 Loss: 0.020141325891017914\n",
      "Epoch: 5353 Loss: 0.020135527476668358\n",
      "Epoch: 5354 Loss: 0.020133553072810173\n",
      "Epoch: 5355 Loss: 0.02013118378818035\n",
      "Epoch: 5356 Loss: 0.020116126164793968\n",
      "Epoch: 5357 Loss: 0.020111963152885437\n",
      "Epoch: 5358 Loss: 0.02010493539273739\n",
      "Epoch: 5359 Loss: 0.02009986899793148\n",
      "Epoch: 5360 Loss: 0.02009132318198681\n",
      "Epoch: 5361 Loss: 0.0200881976634264\n",
      "Epoch: 5362 Loss: 0.020086620002985\n",
      "Epoch: 5363 Loss: 0.02007577195763588\n",
      "Epoch: 5364 Loss: 0.020067289471626282\n",
      "Epoch: 5365 Loss: 0.02006290666759014\n",
      "Epoch: 5366 Loss: 0.02005871944129467\n",
      "Epoch: 5367 Loss: 0.020051203668117523\n",
      "Epoch: 5368 Loss: 0.020049436017870903\n",
      "Epoch: 5369 Loss: 0.020034104585647583\n",
      "Epoch: 5370 Loss: 0.020035041496157646\n",
      "Epoch: 5371 Loss: 0.020017962902784348\n",
      "Epoch: 5372 Loss: 0.0200197771191597\n",
      "Epoch: 5373 Loss: 0.020010698586702347\n",
      "Epoch: 5374 Loss: 0.020013315603137016\n",
      "Epoch: 5375 Loss: 0.019995536655187607\n",
      "Epoch: 5376 Loss: 0.019989587366580963\n",
      "Epoch: 5377 Loss: 0.019978933036327362\n",
      "Epoch: 5378 Loss: 0.019975269213318825\n",
      "Epoch: 5379 Loss: 0.01997297815978527\n",
      "Epoch: 5380 Loss: 0.0199586171656847\n",
      "Epoch: 5381 Loss: 0.01995721086859703\n",
      "Epoch: 5382 Loss: 0.01995031163096428\n",
      "Epoch: 5383 Loss: 0.019942015409469604\n",
      "Epoch: 5384 Loss: 0.01994040422141552\n",
      "Epoch: 5385 Loss: 0.019928395748138428\n",
      "Epoch: 5386 Loss: 0.01992354542016983\n",
      "Epoch: 5387 Loss: 0.01991308107972145\n",
      "Epoch: 5388 Loss: 0.019908595830202103\n",
      "Epoch: 5389 Loss: 0.01990065909922123\n",
      "Epoch: 5390 Loss: 0.019896117970347404\n",
      "Epoch: 5391 Loss: 0.019894476979970932\n",
      "Epoch: 5392 Loss: 0.019886186346411705\n",
      "Epoch: 5393 Loss: 0.019873321056365967\n",
      "Epoch: 5394 Loss: 0.019884051755070686\n",
      "Epoch: 5395 Loss: 0.01986367255449295\n",
      "Epoch: 5396 Loss: 0.019862942397594452\n",
      "Epoch: 5397 Loss: 0.019852781668305397\n",
      "Epoch: 5398 Loss: 0.01984253153204918\n",
      "Epoch: 5399 Loss: 0.01984114944934845\n",
      "Epoch: 5400 Loss: 0.019831180572509766\n",
      "Epoch: 5401 Loss: 0.01982603780925274\n",
      "Epoch: 5402 Loss: 0.019819289445877075\n",
      "Epoch: 5403 Loss: 0.0198111180216074\n",
      "Epoch: 5404 Loss: 0.019811006262898445\n",
      "Epoch: 5405 Loss: 0.019797205924987793\n",
      "Epoch: 5406 Loss: 0.019796647131443024\n",
      "Epoch: 5407 Loss: 0.019790876656770706\n",
      "Epoch: 5408 Loss: 0.01978299766778946\n",
      "Epoch: 5409 Loss: 0.019772900268435478\n",
      "Epoch: 5410 Loss: 0.01976531185209751\n",
      "Epoch: 5411 Loss: 0.019766708835959435\n",
      "Epoch: 5412 Loss: 0.019753601402044296\n",
      "Epoch: 5413 Loss: 0.019748561084270477\n",
      "Epoch: 5414 Loss: 0.01974530704319477\n",
      "Epoch: 5415 Loss: 0.01973988115787506\n",
      "Epoch: 5416 Loss: 0.019727088510990143\n",
      "Epoch: 5417 Loss: 0.01972581259906292\n",
      "Epoch: 5418 Loss: 0.019720593467354774\n",
      "Epoch: 5419 Loss: 0.019711844623088837\n",
      "Epoch: 5420 Loss: 0.01971474662423134\n",
      "Epoch: 5421 Loss: 0.01969587802886963\n",
      "Epoch: 5422 Loss: 0.019702082499861717\n",
      "Epoch: 5423 Loss: 0.019684063270688057\n",
      "Epoch: 5424 Loss: 0.019687671214342117\n",
      "Epoch: 5425 Loss: 0.019670316949486732\n",
      "Epoch: 5426 Loss: 0.019672436639666557\n",
      "Epoch: 5427 Loss: 0.01965964585542679\n",
      "Epoch: 5428 Loss: 0.01966780796647072\n",
      "Epoch: 5429 Loss: 0.019645819440484047\n",
      "Epoch: 5430 Loss: 0.01963946409523487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5431 Loss: 0.019630402326583862\n",
      "Epoch: 5432 Loss: 0.01963251456618309\n",
      "Epoch: 5433 Loss: 0.019622886553406715\n",
      "Epoch: 5434 Loss: 0.019616374745965004\n",
      "Epoch: 5435 Loss: 0.019615592435002327\n",
      "Epoch: 5436 Loss: 0.019603539258241653\n",
      "Epoch: 5437 Loss: 0.01960066705942154\n",
      "Epoch: 5438 Loss: 0.019586961716413498\n",
      "Epoch: 5439 Loss: 0.019593341276049614\n",
      "Epoch: 5440 Loss: 0.019579291343688965\n",
      "Epoch: 5441 Loss: 0.019574251025915146\n",
      "Epoch: 5442 Loss: 0.019566316157579422\n",
      "Epoch: 5443 Loss: 0.019557740539312363\n",
      "Epoch: 5444 Loss: 0.01955810748040676\n",
      "Epoch: 5445 Loss: 0.019545666873455048\n",
      "Epoch: 5446 Loss: 0.019538583233952522\n",
      "Epoch: 5447 Loss: 0.019535765051841736\n",
      "Epoch: 5448 Loss: 0.019532736390829086\n",
      "Epoch: 5449 Loss: 0.019522326067090034\n",
      "Epoch: 5450 Loss: 0.0195145383477211\n",
      "Epoch: 5451 Loss: 0.019507339224219322\n",
      "Epoch: 5452 Loss: 0.01949773170053959\n",
      "Epoch: 5453 Loss: 0.01949547789990902\n",
      "Epoch: 5454 Loss: 0.019488176330924034\n",
      "Epoch: 5455 Loss: 0.01948007382452488\n",
      "Epoch: 5456 Loss: 0.019482523202896118\n",
      "Epoch: 5457 Loss: 0.01946953497827053\n",
      "Epoch: 5458 Loss: 0.019465727731585503\n",
      "Epoch: 5459 Loss: 0.019459068775177002\n",
      "Epoch: 5460 Loss: 0.01944892108440399\n",
      "Epoch: 5461 Loss: 0.019448358565568924\n",
      "Epoch: 5462 Loss: 0.019444594159722328\n",
      "Epoch: 5463 Loss: 0.0194354560226202\n",
      "Epoch: 5464 Loss: 0.019431814551353455\n",
      "Epoch: 5465 Loss: 0.01943390816450119\n",
      "Epoch: 5466 Loss: 0.01942572183907032\n",
      "Epoch: 5467 Loss: 0.01940889097750187\n",
      "Epoch: 5468 Loss: 0.019406083971261978\n",
      "Epoch: 5469 Loss: 0.01940516196191311\n",
      "Epoch: 5470 Loss: 0.01939736306667328\n",
      "Epoch: 5471 Loss: 0.019386380910873413\n",
      "Epoch: 5472 Loss: 0.01938040554523468\n",
      "Epoch: 5473 Loss: 0.019368544220924377\n",
      "Epoch: 5474 Loss: 0.01938031241297722\n",
      "Epoch: 5475 Loss: 0.01935696415603161\n",
      "Epoch: 5476 Loss: 0.019350487738847733\n",
      "Epoch: 5477 Loss: 0.019346803426742554\n",
      "Epoch: 5478 Loss: 0.01933927647769451\n",
      "Epoch: 5479 Loss: 0.019338764250278473\n",
      "Epoch: 5480 Loss: 0.019332129508256912\n",
      "Epoch: 5481 Loss: 0.019323091953992844\n",
      "Epoch: 5482 Loss: 0.019311776384711266\n",
      "Epoch: 5483 Loss: 0.01930871792137623\n",
      "Epoch: 5484 Loss: 0.019304506480693817\n",
      "Epoch: 5485 Loss: 0.019305897876620293\n",
      "Epoch: 5486 Loss: 0.019290167838335037\n",
      "Epoch: 5487 Loss: 0.019297098740935326\n",
      "Epoch: 5488 Loss: 0.0192826259881258\n",
      "Epoch: 5489 Loss: 0.019270844757556915\n",
      "Epoch: 5490 Loss: 0.019271215423941612\n",
      "Epoch: 5491 Loss: 0.01926298812031746\n",
      "Epoch: 5492 Loss: 0.01925143599510193\n",
      "Epoch: 5493 Loss: 0.019251909106969833\n",
      "Epoch: 5494 Loss: 0.01924343965947628\n",
      "Epoch: 5495 Loss: 0.019234852865338326\n",
      "Epoch: 5496 Loss: 0.019236426800489426\n",
      "Epoch: 5497 Loss: 0.019223196431994438\n",
      "Epoch: 5498 Loss: 0.019218120723962784\n",
      "Epoch: 5499 Loss: 0.01921689510345459\n",
      "Epoch: 5500 Loss: 0.01919924095273018\n",
      "Epoch: 5501 Loss: 0.01919967494904995\n",
      "Epoch: 5502 Loss: 0.019191257655620575\n",
      "Epoch: 5503 Loss: 0.01919160783290863\n",
      "Epoch: 5504 Loss: 0.01917903684079647\n",
      "Epoch: 5505 Loss: 0.019171586260199547\n",
      "Epoch: 5506 Loss: 0.019171301275491714\n",
      "Epoch: 5507 Loss: 0.019164159893989563\n",
      "Epoch: 5508 Loss: 0.019161690026521683\n",
      "Epoch: 5509 Loss: 0.019152481108903885\n",
      "Epoch: 5510 Loss: 0.019138483330607414\n",
      "Epoch: 5511 Loss: 0.01913692243397236\n",
      "Epoch: 5512 Loss: 0.01913604885339737\n",
      "Epoch: 5513 Loss: 0.019125921651721\n",
      "Epoch: 5514 Loss: 0.01911969482898712\n",
      "Epoch: 5515 Loss: 0.019113484770059586\n",
      "Epoch: 5516 Loss: 0.019103074446320534\n",
      "Epoch: 5517 Loss: 0.019102660939097404\n",
      "Epoch: 5518 Loss: 0.01909765414893627\n",
      "Epoch: 5519 Loss: 0.019089408218860626\n",
      "Epoch: 5520 Loss: 0.01908816210925579\n",
      "Epoch: 5521 Loss: 0.019087759777903557\n",
      "Epoch: 5522 Loss: 0.019076300784945488\n",
      "Epoch: 5523 Loss: 0.01906789094209671\n",
      "Epoch: 5524 Loss: 0.019056836143136024\n",
      "Epoch: 5525 Loss: 0.019055822864174843\n",
      "Epoch: 5526 Loss: 0.019044220447540283\n",
      "Epoch: 5527 Loss: 0.019042683765292168\n",
      "Epoch: 5528 Loss: 0.019032977521419525\n",
      "Epoch: 5529 Loss: 0.019032545387744904\n",
      "Epoch: 5530 Loss: 0.019025111570954323\n",
      "Epoch: 5531 Loss: 0.01901525817811489\n",
      "Epoch: 5532 Loss: 0.01901634968817234\n",
      "Epoch: 5533 Loss: 0.019003238528966904\n",
      "Epoch: 5534 Loss: 0.019000539556145668\n",
      "Epoch: 5535 Loss: 0.018993059173226357\n",
      "Epoch: 5536 Loss: 0.01898743025958538\n",
      "Epoch: 5537 Loss: 0.018990566954016685\n",
      "Epoch: 5538 Loss: 0.018974585458636284\n",
      "Epoch: 5539 Loss: 0.018969174474477768\n",
      "Epoch: 5540 Loss: 0.018974272534251213\n",
      "Epoch: 5541 Loss: 0.018953008577227592\n",
      "Epoch: 5542 Loss: 0.018957821652293205\n",
      "Epoch: 5543 Loss: 0.018945995718240738\n",
      "Epoch: 5544 Loss: 0.018945256248116493\n",
      "Epoch: 5545 Loss: 0.018929867073893547\n",
      "Epoch: 5546 Loss: 0.01893363706767559\n",
      "Epoch: 5547 Loss: 0.018923496827483177\n",
      "Epoch: 5548 Loss: 0.018923403695225716\n",
      "Epoch: 5549 Loss: 0.01890893653035164\n",
      "Epoch: 5550 Loss: 0.01890564151108265\n",
      "Epoch: 5551 Loss: 0.018899327144026756\n",
      "Epoch: 5552 Loss: 0.01889145001769066\n",
      "Epoch: 5553 Loss: 0.01888476498425007\n",
      "Epoch: 5554 Loss: 0.018877478316426277\n",
      "Epoch: 5555 Loss: 0.01887357607483864\n",
      "Epoch: 5556 Loss: 0.01887270249426365\n",
      "Epoch: 5557 Loss: 0.018861940130591393\n",
      "Epoch: 5558 Loss: 0.018859149888157845\n",
      "Epoch: 5559 Loss: 0.018853560090065002\n",
      "Epoch: 5560 Loss: 0.018842345103621483\n",
      "Epoch: 5561 Loss: 0.018842432647943497\n",
      "Epoch: 5562 Loss: 0.01883341185748577\n",
      "Epoch: 5563 Loss: 0.018825316801667213\n",
      "Epoch: 5564 Loss: 0.01881543919444084\n",
      "Epoch: 5565 Loss: 0.018811268731951714\n",
      "Epoch: 5566 Loss: 0.01880725473165512\n",
      "Epoch: 5567 Loss: 0.01880681701004505\n",
      "Epoch: 5568 Loss: 0.018799981102347374\n",
      "Epoch: 5569 Loss: 0.018788402900099754\n",
      "Epoch: 5570 Loss: 0.01878412999212742\n",
      "Epoch: 5571 Loss: 0.018779387697577477\n",
      "Epoch: 5572 Loss: 0.018774624913930893\n",
      "Epoch: 5573 Loss: 0.018766894936561584\n",
      "Epoch: 5574 Loss: 0.018769429996609688\n",
      "Epoch: 5575 Loss: 0.018757307901978493\n",
      "Epoch: 5576 Loss: 0.01875925436615944\n",
      "Epoch: 5577 Loss: 0.01874179020524025\n",
      "Epoch: 5578 Loss: 0.018745075911283493\n",
      "Epoch: 5579 Loss: 0.018734145909547806\n",
      "Epoch: 5580 Loss: 0.01873612590134144\n",
      "Epoch: 5581 Loss: 0.018719399347901344\n",
      "Epoch: 5582 Loss: 0.018718931823968887\n",
      "Epoch: 5583 Loss: 0.018711606040596962\n",
      "Epoch: 5584 Loss: 0.018699858337640762\n",
      "Epoch: 5585 Loss: 0.018699361011385918\n",
      "Epoch: 5586 Loss: 0.018689926713705063\n",
      "Epoch: 5587 Loss: 0.01868845336139202\n",
      "Epoch: 5588 Loss: 0.01867692545056343\n",
      "Epoch: 5589 Loss: 0.01867588981986046\n",
      "Epoch: 5590 Loss: 0.0186674315482378\n",
      "Epoch: 5591 Loss: 0.018660075962543488\n",
      "Epoch: 5592 Loss: 0.01865781471133232\n",
      "Epoch: 5593 Loss: 0.018649207428097725\n",
      "Epoch: 5594 Loss: 0.01865079626441002\n",
      "Epoch: 5595 Loss: 0.018635034561157227\n",
      "Epoch: 5596 Loss: 0.01863306388258934\n",
      "Epoch: 5597 Loss: 0.018629245460033417\n",
      "Epoch: 5598 Loss: 0.01862788386642933\n",
      "Epoch: 5599 Loss: 0.018616745248436928\n",
      "Epoch: 5600 Loss: 0.0186056699603796\n",
      "Epoch: 5601 Loss: 0.01860288716852665\n",
      "Epoch: 5602 Loss: 0.018599074333906174\n",
      "Epoch: 5603 Loss: 0.01859135553240776\n",
      "Epoch: 5604 Loss: 0.018585380166769028\n",
      "Epoch: 5605 Loss: 0.01858171634376049\n",
      "Epoch: 5606 Loss: 0.018574494868516922\n",
      "Epoch: 5607 Loss: 0.018567383289337158\n",
      "Epoch: 5608 Loss: 0.01856229454278946\n",
      "Epoch: 5609 Loss: 0.018560737371444702\n",
      "Epoch: 5610 Loss: 0.01855604350566864\n",
      "Epoch: 5611 Loss: 0.018546996638178825\n",
      "Epoch: 5612 Loss: 0.01854403130710125\n",
      "Epoch: 5613 Loss: 0.018537437543272972\n",
      "Epoch: 5614 Loss: 0.018529191613197327\n",
      "Epoch: 5615 Loss: 0.018523328006267548\n",
      "Epoch: 5616 Loss: 0.018519148230552673\n",
      "Epoch: 5617 Loss: 0.01851610653102398\n",
      "Epoch: 5618 Loss: 0.018506834283471107\n",
      "Epoch: 5619 Loss: 0.018501846119761467\n",
      "Epoch: 5620 Loss: 0.018503885716199875\n",
      "Epoch: 5621 Loss: 0.01848718151450157\n",
      "Epoch: 5622 Loss: 0.01849464513361454\n",
      "Epoch: 5623 Loss: 0.018477842211723328\n",
      "Epoch: 5624 Loss: 0.01847147010266781\n",
      "Epoch: 5625 Loss: 0.018478333950042725\n",
      "Epoch: 5626 Loss: 0.018458446487784386\n",
      "Epoch: 5627 Loss: 0.018463442102074623\n",
      "Epoch: 5628 Loss: 0.018446702510118484\n",
      "Epoch: 5629 Loss: 0.01845262013375759\n",
      "Epoch: 5630 Loss: 0.01844356209039688\n",
      "Epoch: 5631 Loss: 0.018432948738336563\n",
      "Epoch: 5632 Loss: 0.018425101414322853\n",
      "Epoch: 5633 Loss: 0.018421746790409088\n",
      "Epoch: 5634 Loss: 0.018417250365018845\n",
      "Epoch: 5635 Loss: 0.0184083953499794\n",
      "Epoch: 5636 Loss: 0.01840508170425892\n",
      "Epoch: 5637 Loss: 0.018397903069853783\n",
      "Epoch: 5638 Loss: 0.018396807834506035\n",
      "Epoch: 5639 Loss: 0.01838913932442665\n",
      "Epoch: 5640 Loss: 0.01838357374072075\n",
      "Epoch: 5641 Loss: 0.018377073109149933\n",
      "Epoch: 5642 Loss: 0.018367629498243332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5643 Loss: 0.018366504460573196\n",
      "Epoch: 5644 Loss: 0.01836196519434452\n",
      "Epoch: 5645 Loss: 0.01836235821247101\n",
      "Epoch: 5646 Loss: 0.018352510407567024\n",
      "Epoch: 5647 Loss: 0.018343111500144005\n",
      "Epoch: 5648 Loss: 0.018339697271585464\n",
      "Epoch: 5649 Loss: 0.01833920180797577\n",
      "Epoch: 5650 Loss: 0.01832304708659649\n",
      "Epoch: 5651 Loss: 0.018324173986911774\n",
      "Epoch: 5652 Loss: 0.018320312723517418\n",
      "Epoch: 5653 Loss: 0.018309645354747772\n",
      "Epoch: 5654 Loss: 0.01830052211880684\n",
      "Epoch: 5655 Loss: 0.018294520676136017\n",
      "Epoch: 5656 Loss: 0.01829470694065094\n",
      "Epoch: 5657 Loss: 0.018296385183930397\n",
      "Epoch: 5658 Loss: 0.01827872544527054\n",
      "Epoch: 5659 Loss: 0.018281789496541023\n",
      "Epoch: 5660 Loss: 0.018271364271640778\n",
      "Epoch: 5661 Loss: 0.01827244833111763\n",
      "Epoch: 5662 Loss: 0.018257858231663704\n",
      "Epoch: 5663 Loss: 0.018254686146974564\n",
      "Epoch: 5664 Loss: 0.01824389211833477\n",
      "Epoch: 5665 Loss: 0.018249809741973877\n",
      "Epoch: 5666 Loss: 0.018236706033349037\n",
      "Epoch: 5667 Loss: 0.018231716006994247\n",
      "Epoch: 5668 Loss: 0.018226929008960724\n",
      "Epoch: 5669 Loss: 0.018230358138680458\n",
      "Epoch: 5670 Loss: 0.018217969685792923\n",
      "Epoch: 5671 Loss: 0.018217509612441063\n",
      "Epoch: 5672 Loss: 0.018200451508164406\n",
      "Epoch: 5673 Loss: 0.01819661632180214\n",
      "Epoch: 5674 Loss: 0.018199807032942772\n",
      "Epoch: 5675 Loss: 0.018191732466220856\n",
      "Epoch: 5676 Loss: 0.018179314211010933\n",
      "Epoch: 5677 Loss: 0.01817597821354866\n",
      "Epoch: 5678 Loss: 0.01816677860915661\n",
      "Epoch: 5679 Loss: 0.01817132905125618\n",
      "Epoch: 5680 Loss: 0.018170088529586792\n",
      "Epoch: 5681 Loss: 0.018152860924601555\n",
      "Epoch: 5682 Loss: 0.018145134672522545\n",
      "Epoch: 5683 Loss: 0.01814066804945469\n",
      "Epoch: 5684 Loss: 0.01814519800245762\n",
      "Epoch: 5685 Loss: 0.018132787197828293\n",
      "Epoch: 5686 Loss: 0.01812484860420227\n",
      "Epoch: 5687 Loss: 0.01812141202390194\n",
      "Epoch: 5688 Loss: 0.01812438666820526\n",
      "Epoch: 5689 Loss: 0.018111446872353554\n",
      "Epoch: 5690 Loss: 0.0181037075817585\n",
      "Epoch: 5691 Loss: 0.018098894506692886\n",
      "Epoch: 5692 Loss: 0.018093392252922058\n",
      "Epoch: 5693 Loss: 0.01809825748205185\n",
      "Epoch: 5694 Loss: 0.018082862719893456\n",
      "Epoch: 5695 Loss: 0.01807585172355175\n",
      "Epoch: 5696 Loss: 0.018076617270708084\n",
      "Epoch: 5697 Loss: 0.018062649294734\n",
      "Epoch: 5698 Loss: 0.018072614446282387\n",
      "Epoch: 5699 Loss: 0.018055053427815437\n",
      "Epoch: 5700 Loss: 0.018052970990538597\n",
      "Epoch: 5701 Loss: 0.01804145611822605\n",
      "Epoch: 5702 Loss: 0.01803997904062271\n",
      "Epoch: 5703 Loss: 0.01803506910800934\n",
      "Epoch: 5704 Loss: 0.018033383414149284\n",
      "Epoch: 5705 Loss: 0.018022889271378517\n",
      "Epoch: 5706 Loss: 0.018019268289208412\n",
      "Epoch: 5707 Loss: 0.01801634207367897\n",
      "Epoch: 5708 Loss: 0.018003107979893684\n",
      "Epoch: 5709 Loss: 0.01801103912293911\n",
      "Epoch: 5710 Loss: 0.017994919791817665\n",
      "Epoch: 5711 Loss: 0.01799335889518261\n",
      "Epoch: 5712 Loss: 0.017988041043281555\n",
      "Epoch: 5713 Loss: 0.01798161119222641\n",
      "Epoch: 5714 Loss: 0.017974119633436203\n",
      "Epoch: 5715 Loss: 0.017965367063879967\n",
      "Epoch: 5716 Loss: 0.01796247623860836\n",
      "Epoch: 5717 Loss: 0.017964163795113564\n",
      "Epoch: 5718 Loss: 0.01795331947505474\n",
      "Epoch: 5719 Loss: 0.01795116998255253\n",
      "Epoch: 5720 Loss: 0.01794160157442093\n",
      "Epoch: 5721 Loss: 0.017937494441866875\n",
      "Epoch: 5722 Loss: 0.01792936399579048\n",
      "Epoch: 5723 Loss: 0.01792844571173191\n",
      "Epoch: 5724 Loss: 0.017924446612596512\n",
      "Epoch: 5725 Loss: 0.017912177368998528\n",
      "Epoch: 5726 Loss: 0.01791262999176979\n",
      "Epoch: 5727 Loss: 0.017906958237290382\n",
      "Epoch: 5728 Loss: 0.017900675535202026\n",
      "Epoch: 5729 Loss: 0.017892420291900635\n",
      "Epoch: 5730 Loss: 0.017884675413370132\n",
      "Epoch: 5731 Loss: 0.017885610461235046\n",
      "Epoch: 5732 Loss: 0.01787719875574112\n",
      "Epoch: 5733 Loss: 0.017875922843813896\n",
      "Epoch: 5734 Loss: 0.01786583848297596\n",
      "Epoch: 5735 Loss: 0.017867350950837135\n",
      "Epoch: 5736 Loss: 0.017852086573839188\n",
      "Epoch: 5737 Loss: 0.017849735915660858\n",
      "Epoch: 5738 Loss: 0.01784529723227024\n",
      "Epoch: 5739 Loss: 0.017840076237916946\n",
      "Epoch: 5740 Loss: 0.01783440075814724\n",
      "Epoch: 5741 Loss: 0.01782931387424469\n",
      "Epoch: 5742 Loss: 0.017824852839112282\n",
      "Epoch: 5743 Loss: 0.017816144973039627\n",
      "Epoch: 5744 Loss: 0.017813274636864662\n",
      "Epoch: 5745 Loss: 0.01781068556010723\n",
      "Epoch: 5746 Loss: 0.01780160516500473\n",
      "Epoch: 5747 Loss: 0.017798345535993576\n",
      "Epoch: 5748 Loss: 0.017790503799915314\n",
      "Epoch: 5749 Loss: 0.017779666930437088\n",
      "Epoch: 5750 Loss: 0.0177890807390213\n",
      "Epoch: 5751 Loss: 0.01777469739317894\n",
      "Epoch: 5752 Loss: 0.01776329055428505\n",
      "Epoch: 5753 Loss: 0.017764700576663017\n",
      "Epoch: 5754 Loss: 0.017760315909981728\n",
      "Epoch: 5755 Loss: 0.01775352843105793\n",
      "Epoch: 5756 Loss: 0.01775386556982994\n",
      "Epoch: 5757 Loss: 0.017739759758114815\n",
      "Epoch: 5758 Loss: 0.01773928664624691\n",
      "Epoch: 5759 Loss: 0.017735008150339127\n",
      "Epoch: 5760 Loss: 0.017727158963680267\n",
      "Epoch: 5761 Loss: 0.017721276730298996\n",
      "Epoch: 5762 Loss: 0.017715901136398315\n",
      "Epoch: 5763 Loss: 0.017708970233798027\n",
      "Epoch: 5764 Loss: 0.017707090824842453\n",
      "Epoch: 5765 Loss: 0.017699187621474266\n",
      "Epoch: 5766 Loss: 0.017700377851724625\n",
      "Epoch: 5767 Loss: 0.01768677495419979\n",
      "Epoch: 5768 Loss: 0.017684873193502426\n",
      "Epoch: 5769 Loss: 0.017685336992144585\n",
      "Epoch: 5770 Loss: 0.017672503367066383\n",
      "Epoch: 5771 Loss: 0.017667030915617943\n",
      "Epoch: 5772 Loss: 0.017663482576608658\n",
      "Epoch: 5773 Loss: 0.01765659637749195\n",
      "Epoch: 5774 Loss: 0.017653778195381165\n",
      "Epoch: 5775 Loss: 0.017645319923758507\n",
      "Epoch: 5776 Loss: 0.017650704830884933\n",
      "Epoch: 5777 Loss: 0.017641428858041763\n",
      "Epoch: 5778 Loss: 0.017633317038416862\n",
      "Epoch: 5779 Loss: 0.01762457564473152\n",
      "Epoch: 5780 Loss: 0.017618617042899132\n",
      "Epoch: 5781 Loss: 0.017623277381062508\n",
      "Epoch: 5782 Loss: 0.017609650269150734\n",
      "Epoch: 5783 Loss: 0.017603054642677307\n",
      "Epoch: 5784 Loss: 0.017599280923604965\n",
      "Epoch: 5785 Loss: 0.0175912007689476\n",
      "Epoch: 5786 Loss: 0.017598461359739304\n",
      "Epoch: 5787 Loss: 0.01758228801190853\n",
      "Epoch: 5788 Loss: 0.017578376457095146\n",
      "Epoch: 5789 Loss: 0.017574632540345192\n",
      "Epoch: 5790 Loss: 0.0175712201744318\n",
      "Epoch: 5791 Loss: 0.017563827335834503\n",
      "Epoch: 5792 Loss: 0.01755765825510025\n",
      "Epoch: 5793 Loss: 0.017551157623529434\n",
      "Epoch: 5794 Loss: 0.01755228452384472\n",
      "Epoch: 5795 Loss: 0.017536338418722153\n",
      "Epoch: 5796 Loss: 0.017541086301207542\n",
      "Epoch: 5797 Loss: 0.01753506064414978\n",
      "Epoch: 5798 Loss: 0.017519664019346237\n",
      "Epoch: 5799 Loss: 0.017522908747196198\n",
      "Epoch: 5800 Loss: 0.017514178529381752\n",
      "Epoch: 5801 Loss: 0.01751319132745266\n",
      "Epoch: 5802 Loss: 0.017504677176475525\n",
      "Epoch: 5803 Loss: 0.017500439658761024\n",
      "Epoch: 5804 Loss: 0.017497891560196877\n",
      "Epoch: 5805 Loss: 0.017492948099970818\n",
      "Epoch: 5806 Loss: 0.017485937103629112\n",
      "Epoch: 5807 Loss: 0.017477890476584435\n",
      "Epoch: 5808 Loss: 0.01747441291809082\n",
      "Epoch: 5809 Loss: 0.017470763996243477\n",
      "Epoch: 5810 Loss: 0.017467128112912178\n",
      "Epoch: 5811 Loss: 0.017456410452723503\n",
      "Epoch: 5812 Loss: 0.017453214153647423\n",
      "Epoch: 5813 Loss: 0.017447812482714653\n",
      "Epoch: 5814 Loss: 0.017442727461457253\n",
      "Epoch: 5815 Loss: 0.01744045503437519\n",
      "Epoch: 5816 Loss: 0.017429374158382416\n",
      "Epoch: 5817 Loss: 0.017430925741791725\n",
      "Epoch: 5818 Loss: 0.017425665631890297\n",
      "Epoch: 5819 Loss: 0.017413508147001266\n",
      "Epoch: 5820 Loss: 0.017413750290870667\n",
      "Epoch: 5821 Loss: 0.017411787062883377\n",
      "Epoch: 5822 Loss: 0.017400985583662987\n",
      "Epoch: 5823 Loss: 0.017401045188307762\n",
      "Epoch: 5824 Loss: 0.017391357570886612\n",
      "Epoch: 5825 Loss: 0.017387308180332184\n",
      "Epoch: 5826 Loss: 0.017381157726049423\n",
      "Epoch: 5827 Loss: 0.01737741194665432\n",
      "Epoch: 5828 Loss: 0.017371492460370064\n",
      "Epoch: 5829 Loss: 0.017363689839839935\n",
      "Epoch: 5830 Loss: 0.017357101663947105\n",
      "Epoch: 5831 Loss: 0.017355317249894142\n",
      "Epoch: 5832 Loss: 0.017349081113934517\n",
      "Epoch: 5833 Loss: 0.01734774373471737\n",
      "Epoch: 5834 Loss: 0.017339622601866722\n",
      "Epoch: 5835 Loss: 0.017342202365398407\n",
      "Epoch: 5836 Loss: 0.01732608862221241\n",
      "Epoch: 5837 Loss: 0.017328741028904915\n",
      "Epoch: 5838 Loss: 0.017320578917860985\n",
      "Epoch: 5839 Loss: 0.017311714589595795\n",
      "Epoch: 5840 Loss: 0.0173138789832592\n",
      "Epoch: 5841 Loss: 0.017301196232438087\n",
      "Epoch: 5842 Loss: 0.017298387363553047\n",
      "Epoch: 5843 Loss: 0.017296504229307175\n",
      "Epoch: 5844 Loss: 0.017294829711318016\n",
      "Epoch: 5845 Loss: 0.017277995124459267\n",
      "Epoch: 5846 Loss: 0.017278142273426056\n",
      "Epoch: 5847 Loss: 0.017270240932703018\n",
      "Epoch: 5848 Loss: 0.01726412959396839\n",
      "Epoch: 5849 Loss: 0.017261827364563942\n",
      "Epoch: 5850 Loss: 0.017255935817956924\n",
      "Epoch: 5851 Loss: 0.017252372577786446\n",
      "Epoch: 5852 Loss: 0.017249200493097305\n",
      "Epoch: 5853 Loss: 0.017245419323444366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5854 Loss: 0.017235027626156807\n",
      "Epoch: 5855 Loss: 0.017233042046427727\n",
      "Epoch: 5856 Loss: 0.01722843572497368\n",
      "Epoch: 5857 Loss: 0.017220064997673035\n",
      "Epoch: 5858 Loss: 0.01721598580479622\n",
      "Epoch: 5859 Loss: 0.017212482169270515\n",
      "Epoch: 5860 Loss: 0.01720256917178631\n",
      "Epoch: 5861 Loss: 0.017202502116560936\n",
      "Epoch: 5862 Loss: 0.017199188470840454\n",
      "Epoch: 5863 Loss: 0.017195727676153183\n",
      "Epoch: 5864 Loss: 0.017191380262374878\n",
      "Epoch: 5865 Loss: 0.017182299867272377\n",
      "Epoch: 5866 Loss: 0.01717516779899597\n",
      "Epoch: 5867 Loss: 0.017173875123262405\n",
      "Epoch: 5868 Loss: 0.017168357968330383\n",
      "Epoch: 5869 Loss: 0.017160281538963318\n",
      "Epoch: 5870 Loss: 0.01715925894677639\n",
      "Epoch: 5871 Loss: 0.01715238392353058\n",
      "Epoch: 5872 Loss: 0.01714947074651718\n",
      "Epoch: 5873 Loss: 0.017138788476586342\n",
      "Epoch: 5874 Loss: 0.01713680848479271\n",
      "Epoch: 5875 Loss: 0.017122777178883553\n",
      "Epoch: 5876 Loss: 0.017125548794865608\n",
      "Epoch: 5877 Loss: 0.017120348289608955\n",
      "Epoch: 5878 Loss: 0.017120102420449257\n",
      "Epoch: 5879 Loss: 0.01710888184607029\n",
      "Epoch: 5880 Loss: 0.017104292288422585\n",
      "Epoch: 5881 Loss: 0.01709897071123123\n",
      "Epoch: 5882 Loss: 0.017106682062149048\n",
      "Epoch: 5883 Loss: 0.017086651176214218\n",
      "Epoch: 5884 Loss: 0.017090272158384323\n",
      "Epoch: 5885 Loss: 0.017075514420866966\n",
      "Epoch: 5886 Loss: 0.017070531845092773\n",
      "Epoch: 5887 Loss: 0.01707177795469761\n",
      "Epoch: 5888 Loss: 0.017061516642570496\n",
      "Epoch: 5889 Loss: 0.017058730125427246\n",
      "Epoch: 5890 Loss: 0.01705179736018181\n",
      "Epoch: 5891 Loss: 0.017047114670276642\n",
      "Epoch: 5892 Loss: 0.017049148678779602\n",
      "Epoch: 5893 Loss: 0.017042124643921852\n",
      "Epoch: 5894 Loss: 0.017036952078342438\n",
      "Epoch: 5895 Loss: 0.01702764444053173\n",
      "Epoch: 5896 Loss: 0.01702742837369442\n",
      "Epoch: 5897 Loss: 0.01702244207262993\n",
      "Epoch: 5898 Loss: 0.017011189833283424\n",
      "Epoch: 5899 Loss: 0.017016587778925896\n",
      "Epoch: 5900 Loss: 0.017002437263727188\n",
      "Epoch: 5901 Loss: 0.017001602798700333\n",
      "Epoch: 5902 Loss: 0.016994277015328407\n",
      "Epoch: 5903 Loss: 0.01698858104646206\n",
      "Epoch: 5904 Loss: 0.016983874142169952\n",
      "Epoch: 5905 Loss: 0.01697644405066967\n",
      "Epoch: 5906 Loss: 0.01697220653295517\n",
      "Epoch: 5907 Loss: 0.016969159245491028\n",
      "Epoch: 5908 Loss: 0.0169669259339571\n",
      "Epoch: 5909 Loss: 0.016954518854618073\n",
      "Epoch: 5910 Loss: 0.016955655068159103\n",
      "Epoch: 5911 Loss: 0.01694926805794239\n",
      "Epoch: 5912 Loss: 0.01694735512137413\n",
      "Epoch: 5913 Loss: 0.01693684794008732\n",
      "Epoch: 5914 Loss: 0.016932379454374313\n",
      "Epoch: 5915 Loss: 0.016929518431425095\n",
      "Epoch: 5916 Loss: 0.016927368938922882\n",
      "Epoch: 5917 Loss: 0.016918664798140526\n",
      "Epoch: 5918 Loss: 0.016914354637265205\n",
      "Epoch: 5919 Loss: 0.01690847985446453\n",
      "Epoch: 5920 Loss: 0.016907375305891037\n",
      "Epoch: 5921 Loss: 0.01690060831606388\n",
      "Epoch: 5922 Loss: 0.016899757087230682\n",
      "Epoch: 5923 Loss: 0.016887370496988297\n",
      "Epoch: 5924 Loss: 0.0168905146420002\n",
      "Epoch: 5925 Loss: 0.01687750592827797\n",
      "Epoch: 5926 Loss: 0.016880793496966362\n",
      "Epoch: 5927 Loss: 0.01687207818031311\n",
      "Epoch: 5928 Loss: 0.016866829246282578\n",
      "Epoch: 5929 Loss: 0.016859842464327812\n",
      "Epoch: 5930 Loss: 0.016852285712957382\n",
      "Epoch: 5931 Loss: 0.016858911141753197\n",
      "Epoch: 5932 Loss: 0.01684398576617241\n",
      "Epoch: 5933 Loss: 0.016843684017658234\n",
      "Epoch: 5934 Loss: 0.016835516318678856\n",
      "Epoch: 5935 Loss: 0.016838759183883667\n",
      "Epoch: 5936 Loss: 0.01682351902127266\n",
      "Epoch: 5937 Loss: 0.016821710392832756\n",
      "Epoch: 5938 Loss: 0.01682162471115589\n",
      "Epoch: 5939 Loss: 0.016813205555081367\n",
      "Epoch: 5940 Loss: 0.01680723950266838\n",
      "Epoch: 5941 Loss: 0.016801314428448677\n",
      "Epoch: 5942 Loss: 0.016798989847302437\n",
      "Epoch: 5943 Loss: 0.016796665266156197\n",
      "Epoch: 5944 Loss: 0.01678728312253952\n",
      "Epoch: 5945 Loss: 0.016783233731985092\n",
      "Epoch: 5946 Loss: 0.016780469566583633\n",
      "Epoch: 5947 Loss: 0.016774067655205727\n",
      "Epoch: 5948 Loss: 0.016764434054493904\n",
      "Epoch: 5949 Loss: 0.01676010526716709\n",
      "Epoch: 5950 Loss: 0.01676117442548275\n",
      "Epoch: 5951 Loss: 0.01675056666135788\n",
      "Epoch: 5952 Loss: 0.016753533855080605\n",
      "Epoch: 5953 Loss: 0.016743265092372894\n",
      "Epoch: 5954 Loss: 0.01673939637839794\n",
      "Epoch: 5955 Loss: 0.016733359545469284\n",
      "Epoch: 5956 Loss: 0.016736749559640884\n",
      "Epoch: 5957 Loss: 0.01672522723674774\n",
      "Epoch: 5958 Loss: 0.01672506332397461\n",
      "Epoch: 5959 Loss: 0.01671832799911499\n",
      "Epoch: 5960 Loss: 0.016707761213183403\n",
      "Epoch: 5961 Loss: 0.016706179827451706\n",
      "Epoch: 5962 Loss: 0.01670004241168499\n",
      "Epoch: 5963 Loss: 0.016698740422725677\n",
      "Epoch: 5964 Loss: 0.01668923906981945\n",
      "Epoch: 5965 Loss: 0.01668294332921505\n",
      "Epoch: 5966 Loss: 0.01667894795536995\n",
      "Epoch: 5967 Loss: 0.016682127490639687\n",
      "Epoch: 5968 Loss: 0.016667792573571205\n",
      "Epoch: 5969 Loss: 0.016674529761075974\n",
      "Epoch: 5970 Loss: 0.016659962013363838\n",
      "Epoch: 5971 Loss: 0.016657544299960136\n",
      "Epoch: 5972 Loss: 0.01665542460978031\n",
      "Epoch: 5973 Loss: 0.016650943085551262\n",
      "Epoch: 5974 Loss: 0.016639847308397293\n",
      "Epoch: 5975 Loss: 0.016637591645121574\n",
      "Epoch: 5976 Loss: 0.016631020233035088\n",
      "Epoch: 5977 Loss: 0.01663423702120781\n",
      "Epoch: 5978 Loss: 0.01662255823612213\n",
      "Epoch: 5979 Loss: 0.016623003408312798\n",
      "Epoch: 5980 Loss: 0.016613362357020378\n",
      "Epoch: 5981 Loss: 0.016610583290457726\n",
      "Epoch: 5982 Loss: 0.01660333015024662\n",
      "Epoch: 5983 Loss: 0.016598358750343323\n",
      "Epoch: 5984 Loss: 0.016594480723142624\n",
      "Epoch: 5985 Loss: 0.01658961921930313\n",
      "Epoch: 5986 Loss: 0.016584599390625954\n",
      "Epoch: 5987 Loss: 0.016582883894443512\n",
      "Epoch: 5988 Loss: 0.01657789573073387\n",
      "Epoch: 5989 Loss: 0.016567034646868706\n",
      "Epoch: 5990 Loss: 0.01656973920762539\n",
      "Epoch: 5991 Loss: 0.01656324975192547\n",
      "Epoch: 5992 Loss: 0.016558650881052017\n",
      "Epoch: 5993 Loss: 0.01655677519738674\n",
      "Epoch: 5994 Loss: 0.016546055674552917\n",
      "Epoch: 5995 Loss: 0.016542969271540642\n",
      "Epoch: 5996 Loss: 0.01653733290731907\n",
      "Epoch: 5997 Loss: 0.01653374172747135\n",
      "Epoch: 5998 Loss: 0.016530722379684448\n",
      "Epoch: 5999 Loss: 0.01652035303413868\n",
      "Epoch: 6000 Loss: 0.01652287319302559\n",
      "Epoch: 6001 Loss: 0.016512371599674225\n",
      "Epoch: 6002 Loss: 0.016509706154465675\n",
      "Epoch: 6003 Loss: 0.016505170613527298\n",
      "Epoch: 6004 Loss: 0.016495736315846443\n",
      "Epoch: 6005 Loss: 0.016492942348122597\n",
      "Epoch: 6006 Loss: 0.01649082452058792\n",
      "Epoch: 6007 Loss: 0.016485456377267838\n",
      "Epoch: 6008 Loss: 0.016479330137372017\n",
      "Epoch: 6009 Loss: 0.016477422788739204\n",
      "Epoch: 6010 Loss: 0.016476349905133247\n",
      "Epoch: 6011 Loss: 0.01646754890680313\n",
      "Epoch: 6012 Loss: 0.01645856909453869\n",
      "Epoch: 6013 Loss: 0.01645689457654953\n",
      "Epoch: 6014 Loss: 0.016461718827486038\n",
      "Epoch: 6015 Loss: 0.01644769310951233\n",
      "Epoch: 6016 Loss: 0.01644815504550934\n",
      "Epoch: 6017 Loss: 0.016436100006103516\n",
      "Epoch: 6018 Loss: 0.01643562689423561\n",
      "Epoch: 6019 Loss: 0.01643756963312626\n",
      "Epoch: 6020 Loss: 0.016424598172307014\n",
      "Epoch: 6021 Loss: 0.016422046348452568\n",
      "Epoch: 6022 Loss: 0.01641206070780754\n",
      "Epoch: 6023 Loss: 0.01640743389725685\n",
      "Epoch: 6024 Loss: 0.0164048932492733\n",
      "Epoch: 6025 Loss: 0.016403138637542725\n",
      "Epoch: 6026 Loss: 0.016393162310123444\n",
      "Epoch: 6027 Loss: 0.01639285497367382\n",
      "Epoch: 6028 Loss: 0.01638788916170597\n",
      "Epoch: 6029 Loss: 0.0163834560662508\n",
      "Epoch: 6030 Loss: 0.0163742508739233\n",
      "Epoch: 6031 Loss: 0.016378717496991158\n",
      "Epoch: 6032 Loss: 0.01636643521487713\n",
      "Epoch: 6033 Loss: 0.01636865735054016\n",
      "Epoch: 6034 Loss: 0.016360551118850708\n",
      "Epoch: 6035 Loss: 0.016351724043488503\n",
      "Epoch: 6036 Loss: 0.016351602971553802\n",
      "Epoch: 6037 Loss: 0.01634826511144638\n",
      "Epoch: 6038 Loss: 0.016338558867573738\n",
      "Epoch: 6039 Loss: 0.01633922941982746\n",
      "Epoch: 6040 Loss: 0.01633678562939167\n",
      "Epoch: 6041 Loss: 0.01632615737617016\n",
      "Epoch: 6042 Loss: 0.016326792538166046\n",
      "Epoch: 6043 Loss: 0.016316736117005348\n",
      "Epoch: 6044 Loss: 0.016309542581439018\n",
      "Epoch: 6045 Loss: 0.01631435938179493\n",
      "Epoch: 6046 Loss: 0.016299864277243614\n",
      "Epoch: 6047 Loss: 0.016301710158586502\n",
      "Epoch: 6048 Loss: 0.01629173569381237\n",
      "Epoch: 6049 Loss: 0.016294287517666817\n",
      "Epoch: 6050 Loss: 0.016285745427012444\n",
      "Epoch: 6051 Loss: 0.01628098078072071\n",
      "Epoch: 6052 Loss: 0.016276346519589424\n",
      "Epoch: 6053 Loss: 0.016269609332084656\n",
      "Epoch: 6054 Loss: 0.016264552250504494\n",
      "Epoch: 6055 Loss: 0.016264935955405235\n",
      "Epoch: 6056 Loss: 0.016257859766483307\n",
      "Epoch: 6057 Loss: 0.01625107228755951\n",
      "Epoch: 6058 Loss: 0.016250045970082283\n",
      "Epoch: 6059 Loss: 0.016239983960986137\n",
      "Epoch: 6060 Loss: 0.016242437064647675\n",
      "Epoch: 6061 Loss: 0.016232680529356003\n",
      "Epoch: 6062 Loss: 0.01623539812862873\n",
      "Epoch: 6063 Loss: 0.016222622245550156\n",
      "Epoch: 6064 Loss: 0.016220808029174805\n",
      "Epoch: 6065 Loss: 0.01622370071709156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6066 Loss: 0.016208970919251442\n",
      "Epoch: 6067 Loss: 0.016211193054914474\n",
      "Epoch: 6068 Loss: 0.01620197854936123\n",
      "Epoch: 6069 Loss: 0.01620187610387802\n",
      "Epoch: 6070 Loss: 0.016191786155104637\n",
      "Epoch: 6071 Loss: 0.016184154897928238\n",
      "Epoch: 6072 Loss: 0.016181642189621925\n",
      "Epoch: 6073 Loss: 0.01618550345301628\n",
      "Epoch: 6074 Loss: 0.016172295436263084\n",
      "Epoch: 6075 Loss: 0.01617502048611641\n",
      "Epoch: 6076 Loss: 0.0161634162068367\n",
      "Epoch: 6077 Loss: 0.016164781525731087\n",
      "Epoch: 6078 Loss: 0.01615702547132969\n",
      "Epoch: 6079 Loss: 0.01615230180323124\n",
      "Epoch: 6080 Loss: 0.016150273382663727\n",
      "Epoch: 6081 Loss: 0.01614685356616974\n",
      "Epoch: 6082 Loss: 0.016139307990670204\n",
      "Epoch: 6083 Loss: 0.016134057193994522\n",
      "Epoch: 6084 Loss: 0.016128214076161385\n",
      "Epoch: 6085 Loss: 0.016126956790685654\n",
      "Epoch: 6086 Loss: 0.016122017055749893\n",
      "Epoch: 6087 Loss: 0.01611149124801159\n",
      "Epoch: 6088 Loss: 0.016112226992845535\n",
      "Epoch: 6089 Loss: 0.016112612560391426\n",
      "Epoch: 6090 Loss: 0.016100358217954636\n",
      "Epoch: 6091 Loss: 0.01610265113413334\n",
      "Epoch: 6092 Loss: 0.016091808676719666\n",
      "Epoch: 6093 Loss: 0.01608959026634693\n",
      "Epoch: 6094 Loss: 0.01608263887465\n",
      "Epoch: 6095 Loss: 0.016078168526291847\n",
      "Epoch: 6096 Loss: 0.016080008819699287\n",
      "Epoch: 6097 Loss: 0.016070012003183365\n",
      "Epoch: 6098 Loss: 0.016070546582341194\n",
      "Epoch: 6099 Loss: 0.016064487397670746\n",
      "Epoch: 6100 Loss: 0.016057631000876427\n",
      "Epoch: 6101 Loss: 0.016058335080742836\n",
      "Epoch: 6102 Loss: 0.016047507524490356\n",
      "Epoch: 6103 Loss: 0.01604587398469448\n",
      "Epoch: 6104 Loss: 0.016041938215494156\n",
      "Epoch: 6105 Loss: 0.016032788902521133\n",
      "Epoch: 6106 Loss: 0.016031494364142418\n",
      "Epoch: 6107 Loss: 0.016025986522436142\n",
      "Epoch: 6108 Loss: 0.016019515693187714\n",
      "Epoch: 6109 Loss: 0.016014857217669487\n",
      "Epoch: 6110 Loss: 0.016011005267500877\n",
      "Epoch: 6111 Loss: 0.016012586653232574\n",
      "Epoch: 6112 Loss: 0.016000743955373764\n",
      "Epoch: 6113 Loss: 0.01599675603210926\n",
      "Epoch: 6114 Loss: 0.016002031043171883\n",
      "Epoch: 6115 Loss: 0.015987692400813103\n",
      "Epoch: 6116 Loss: 0.01598893664777279\n",
      "Epoch: 6117 Loss: 0.015986014157533646\n",
      "Epoch: 6118 Loss: 0.015975838527083397\n",
      "Epoch: 6119 Loss: 0.01597036048769951\n",
      "Epoch: 6120 Loss: 0.015965528786182404\n",
      "Epoch: 6121 Loss: 0.0159682035446167\n",
      "Epoch: 6122 Loss: 0.015956789255142212\n",
      "Epoch: 6123 Loss: 0.01595200225710869\n",
      "Epoch: 6124 Loss: 0.015956372022628784\n",
      "Epoch: 6125 Loss: 0.015941880643367767\n",
      "Epoch: 6126 Loss: 0.015935655683279037\n",
      "Epoch: 6127 Loss: 0.015931840986013412\n",
      "Epoch: 6128 Loss: 0.01593252271413803\n",
      "Epoch: 6129 Loss: 0.015928396955132484\n",
      "Epoch: 6130 Loss: 0.01592366211116314\n",
      "Epoch: 6131 Loss: 0.015915922820568085\n",
      "Epoch: 6132 Loss: 0.015910854563117027\n",
      "Epoch: 6133 Loss: 0.015912262722849846\n",
      "Epoch: 6134 Loss: 0.015906887128949165\n",
      "Epoch: 6135 Loss: 0.015902217477560043\n",
      "Epoch: 6136 Loss: 0.01590247079730034\n",
      "Epoch: 6137 Loss: 0.015892967581748962\n",
      "Epoch: 6138 Loss: 0.01588560827076435\n",
      "Epoch: 6139 Loss: 0.015882432460784912\n",
      "Epoch: 6140 Loss: 0.015880223363637924\n",
      "Epoch: 6141 Loss: 0.01587153784930706\n",
      "Epoch: 6142 Loss: 0.015875067561864853\n",
      "Epoch: 6143 Loss: 0.015861036255955696\n",
      "Epoch: 6144 Loss: 0.015862155705690384\n",
      "Epoch: 6145 Loss: 0.015856435522437096\n",
      "Epoch: 6146 Loss: 0.015855569392442703\n",
      "Epoch: 6147 Loss: 0.01584482751786709\n",
      "Epoch: 6148 Loss: 0.01583987846970558\n",
      "Epoch: 6149 Loss: 0.01583457551896572\n",
      "Epoch: 6150 Loss: 0.01583326794207096\n",
      "Epoch: 6151 Loss: 0.01583288609981537\n",
      "Epoch: 6152 Loss: 0.015825847163796425\n",
      "Epoch: 6153 Loss: 0.015820253640413284\n",
      "Epoch: 6154 Loss: 0.015821294859051704\n",
      "Epoch: 6155 Loss: 0.015809625387191772\n",
      "Epoch: 6156 Loss: 0.015806550160050392\n",
      "Epoch: 6157 Loss: 0.015800179913640022\n",
      "Epoch: 6158 Loss: 0.015801256522536278\n",
      "Epoch: 6159 Loss: 0.015794038772583008\n",
      "Epoch: 6160 Loss: 0.015787214040756226\n",
      "Epoch: 6161 Loss: 0.015782753005623817\n",
      "Epoch: 6162 Loss: 0.015778273344039917\n",
      "Epoch: 6163 Loss: 0.015776457265019417\n",
      "Epoch: 6164 Loss: 0.01577826403081417\n",
      "Epoch: 6165 Loss: 0.015765246003866196\n",
      "Epoch: 6166 Loss: 0.015770873054862022\n",
      "Epoch: 6167 Loss: 0.015761855989694595\n",
      "Epoch: 6168 Loss: 0.01575210690498352\n",
      "Epoch: 6169 Loss: 0.015751440078020096\n",
      "Epoch: 6170 Loss: 0.015744062140583992\n",
      "Epoch: 6171 Loss: 0.015740137547254562\n",
      "Epoch: 6172 Loss: 0.015737056732177734\n",
      "Epoch: 6173 Loss: 0.015735436230897903\n",
      "Epoch: 6174 Loss: 0.015729740262031555\n",
      "Epoch: 6175 Loss: 0.015724506229162216\n",
      "Epoch: 6176 Loss: 0.01571933552622795\n",
      "Epoch: 6177 Loss: 0.015720082446932793\n",
      "Epoch: 6178 Loss: 0.015706509351730347\n",
      "Epoch: 6179 Loss: 0.01570574752986431\n",
      "Epoch: 6180 Loss: 0.015701983124017715\n",
      "Epoch: 6181 Loss: 0.015703190118074417\n",
      "Epoch: 6182 Loss: 0.015695536509156227\n",
      "Epoch: 6183 Loss: 0.015687160193920135\n",
      "Epoch: 6184 Loss: 0.01568603515625\n",
      "Epoch: 6185 Loss: 0.015686124563217163\n",
      "Epoch: 6186 Loss: 0.015676019713282585\n",
      "Epoch: 6187 Loss: 0.015675311908125877\n",
      "Epoch: 6188 Loss: 0.015666957944631577\n",
      "Epoch: 6189 Loss: 0.01566157117486\n",
      "Epoch: 6190 Loss: 0.015657790005207062\n",
      "Epoch: 6191 Loss: 0.01565263606607914\n",
      "Epoch: 6192 Loss: 0.015651317313313484\n",
      "Epoch: 6193 Loss: 0.015645604580640793\n",
      "Epoch: 6194 Loss: 0.015649404376745224\n",
      "Epoch: 6195 Loss: 0.015635503455996513\n",
      "Epoch: 6196 Loss: 0.01563256047666073\n",
      "Epoch: 6197 Loss: 0.015631569549441338\n",
      "Epoch: 6198 Loss: 0.015624193474650383\n",
      "Epoch: 6199 Loss: 0.015624449588358402\n",
      "Epoch: 6200 Loss: 0.015615317970514297\n",
      "Epoch: 6201 Loss: 0.015609688125550747\n",
      "Epoch: 6202 Loss: 0.015605407766997814\n",
      "Epoch: 6203 Loss: 0.015607798472046852\n",
      "Epoch: 6204 Loss: 0.015595703385770321\n",
      "Epoch: 6205 Loss: 0.01559310033917427\n",
      "Epoch: 6206 Loss: 0.01558777131140232\n",
      "Epoch: 6207 Loss: 0.015581601299345493\n",
      "Epoch: 6208 Loss: 0.015579202212393284\n",
      "Epoch: 6209 Loss: 0.015579826198518276\n",
      "Epoch: 6210 Loss: 0.015572045929729939\n",
      "Epoch: 6211 Loss: 0.015572582371532917\n",
      "Epoch: 6212 Loss: 0.015560519881546497\n",
      "Epoch: 6213 Loss: 0.015559520572423935\n",
      "Epoch: 6214 Loss: 0.015559190884232521\n",
      "Epoch: 6215 Loss: 0.015547528862953186\n",
      "Epoch: 6216 Loss: 0.015545115806162357\n",
      "Epoch: 6217 Loss: 0.015541819855570793\n",
      "Epoch: 6218 Loss: 0.015535116195678711\n",
      "Epoch: 6219 Loss: 0.015541215427219868\n",
      "Epoch: 6220 Loss: 0.01552540436387062\n",
      "Epoch: 6221 Loss: 0.01552257314324379\n",
      "Epoch: 6222 Loss: 0.015527949668467045\n",
      "Epoch: 6223 Loss: 0.015516369603574276\n",
      "Epoch: 6224 Loss: 0.015513388440012932\n",
      "Epoch: 6225 Loss: 0.015506462194025517\n",
      "Epoch: 6226 Loss: 0.015506211668252945\n",
      "Epoch: 6227 Loss: 0.015494541265070438\n",
      "Epoch: 6228 Loss: 0.015496977604925632\n",
      "Epoch: 6229 Loss: 0.015492829494178295\n",
      "Epoch: 6230 Loss: 0.015485366806387901\n",
      "Epoch: 6231 Loss: 0.015483255498111248\n",
      "Epoch: 6232 Loss: 0.015475491061806679\n",
      "Epoch: 6233 Loss: 0.01547482330352068\n",
      "Epoch: 6234 Loss: 0.015471816062927246\n",
      "Epoch: 6235 Loss: 0.015466303564608097\n",
      "Epoch: 6236 Loss: 0.015460317954421043\n",
      "Epoch: 6237 Loss: 0.015456326305866241\n",
      "Epoch: 6238 Loss: 0.015447225421667099\n",
      "Epoch: 6239 Loss: 0.015452774241566658\n",
      "Epoch: 6240 Loss: 0.01544190663844347\n",
      "Epoch: 6241 Loss: 0.015438321977853775\n",
      "Epoch: 6242 Loss: 0.01543337944895029\n",
      "Epoch: 6243 Loss: 0.015435470268130302\n",
      "Epoch: 6244 Loss: 0.015426304191350937\n",
      "Epoch: 6245 Loss: 0.015426907688379288\n",
      "Epoch: 6246 Loss: 0.015422988682985306\n",
      "Epoch: 6247 Loss: 0.015413731336593628\n",
      "Epoch: 6248 Loss: 0.015411282889544964\n",
      "Epoch: 6249 Loss: 0.015409771353006363\n",
      "Epoch: 6250 Loss: 0.01539829932153225\n",
      "Epoch: 6251 Loss: 0.015398561023175716\n",
      "Epoch: 6252 Loss: 0.015390358865261078\n",
      "Epoch: 6253 Loss: 0.015391957946121693\n",
      "Epoch: 6254 Loss: 0.015386294573545456\n",
      "Epoch: 6255 Loss: 0.015380539000034332\n",
      "Epoch: 6256 Loss: 0.015374995768070221\n",
      "Epoch: 6257 Loss: 0.015374108217656612\n",
      "Epoch: 6258 Loss: 0.015368668362498283\n",
      "Epoch: 6259 Loss: 0.015363899990916252\n",
      "Epoch: 6260 Loss: 0.015364243648946285\n",
      "Epoch: 6261 Loss: 0.015354152768850327\n",
      "Epoch: 6262 Loss: 0.015351355075836182\n",
      "Epoch: 6263 Loss: 0.015352885238826275\n",
      "Epoch: 6264 Loss: 0.015340869314968586\n",
      "Epoch: 6265 Loss: 0.015334810130298138\n",
      "Epoch: 6266 Loss: 0.015333559364080429\n",
      "Epoch: 6267 Loss: 0.015333404764533043\n",
      "Epoch: 6268 Loss: 0.015326648019254208\n",
      "Epoch: 6269 Loss: 0.015318438410758972\n",
      "Epoch: 6270 Loss: 0.015317780897021294\n",
      "Epoch: 6271 Loss: 0.01531164813786745\n",
      "Epoch: 6272 Loss: 0.015307568944990635\n",
      "Epoch: 6273 Loss: 0.01530483178794384\n",
      "Epoch: 6274 Loss: 0.015307183377444744\n",
      "Epoch: 6275 Loss: 0.01529608853161335\n",
      "Epoch: 6276 Loss: 0.015291658230125904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6277 Loss: 0.015293457545340061\n",
      "Epoch: 6278 Loss: 0.015281787142157555\n",
      "Epoch: 6279 Loss: 0.015279457904398441\n",
      "Epoch: 6280 Loss: 0.015277737751603127\n",
      "Epoch: 6281 Loss: 0.01527487114071846\n",
      "Epoch: 6282 Loss: 0.015264777466654778\n",
      "Epoch: 6283 Loss: 0.015266494825482368\n",
      "Epoch: 6284 Loss: 0.015255718491971493\n",
      "Epoch: 6285 Loss: 0.01525099016726017\n",
      "Epoch: 6286 Loss: 0.015252144075930119\n",
      "Epoch: 6287 Loss: 0.015254057012498379\n",
      "Epoch: 6288 Loss: 0.01524109672755003\n",
      "Epoch: 6289 Loss: 0.01523952092975378\n",
      "Epoch: 6290 Loss: 0.015235040336847305\n",
      "Epoch: 6291 Loss: 0.01522713154554367\n",
      "Epoch: 6292 Loss: 0.015223617665469646\n",
      "Epoch: 6293 Loss: 0.01522841677069664\n",
      "Epoch: 6294 Loss: 0.015213387086987495\n",
      "Epoch: 6295 Loss: 0.015218283049762249\n",
      "Epoch: 6296 Loss: 0.015207178890705109\n",
      "Epoch: 6297 Loss: 0.015199312940239906\n",
      "Epoch: 6298 Loss: 0.015199176967144012\n",
      "Epoch: 6299 Loss: 0.015200613997876644\n",
      "Epoch: 6300 Loss: 0.015187595039606094\n",
      "Epoch: 6301 Loss: 0.015187143348157406\n",
      "Epoch: 6302 Loss: 0.015186750330030918\n",
      "Epoch: 6303 Loss: 0.01517817098647356\n",
      "Epoch: 6304 Loss: 0.015176353976130486\n",
      "Epoch: 6305 Loss: 0.015169896185398102\n",
      "Epoch: 6306 Loss: 0.015171040780842304\n",
      "Epoch: 6307 Loss: 0.015164315700531006\n",
      "Epoch: 6308 Loss: 0.015157089568674564\n",
      "Epoch: 6309 Loss: 0.015154886059463024\n",
      "Epoch: 6310 Loss: 0.015156576409935951\n",
      "Epoch: 6311 Loss: 0.015146848745644093\n",
      "Epoch: 6312 Loss: 0.015140828676521778\n",
      "Epoch: 6313 Loss: 0.01513835322111845\n",
      "Epoch: 6314 Loss: 0.015134766697883606\n",
      "Epoch: 6315 Loss: 0.015134381130337715\n",
      "Epoch: 6316 Loss: 0.015126887708902359\n",
      "Epoch: 6317 Loss: 0.015120502561330795\n",
      "Epoch: 6318 Loss: 0.015117675065994263\n",
      "Epoch: 6319 Loss: 0.015111911110579967\n",
      "Epoch: 6320 Loss: 0.015111539512872696\n",
      "Epoch: 6321 Loss: 0.015106119215488434\n",
      "Epoch: 6322 Loss: 0.015103017911314964\n",
      "Epoch: 6323 Loss: 0.015097140334546566\n",
      "Epoch: 6324 Loss: 0.01509485300630331\n",
      "Epoch: 6325 Loss: 0.015086137689650059\n",
      "Epoch: 6326 Loss: 0.015090055763721466\n",
      "Epoch: 6327 Loss: 0.015083245933055878\n",
      "Epoch: 6328 Loss: 0.015082175843417645\n",
      "Epoch: 6329 Loss: 0.015074008144438267\n",
      "Epoch: 6330 Loss: 0.015069405548274517\n",
      "Epoch: 6331 Loss: 0.015062235295772552\n",
      "Epoch: 6332 Loss: 0.0150647247210145\n",
      "Epoch: 6333 Loss: 0.01505373790860176\n",
      "Epoch: 6334 Loss: 0.015058544464409351\n",
      "Epoch: 6335 Loss: 0.01505171786993742\n",
      "Epoch: 6336 Loss: 0.015042461454868317\n",
      "Epoch: 6337 Loss: 0.01504107378423214\n",
      "Epoch: 6338 Loss: 0.015036315657198429\n",
      "Epoch: 6339 Loss: 0.01503058522939682\n",
      "Epoch: 6340 Loss: 0.01503006648272276\n",
      "Epoch: 6341 Loss: 0.015026980079710484\n",
      "Epoch: 6342 Loss: 0.015022211708128452\n",
      "Epoch: 6343 Loss: 0.01501485239714384\n",
      "Epoch: 6344 Loss: 0.015016216784715652\n",
      "Epoch: 6345 Loss: 0.015009364113211632\n",
      "Epoch: 6346 Loss: 0.015004994347691536\n",
      "Epoch: 6347 Loss: 0.014998672530055046\n",
      "Epoch: 6348 Loss: 0.015003066509962082\n",
      "Epoch: 6349 Loss: 0.014988862909376621\n",
      "Epoch: 6350 Loss: 0.014991015195846558\n",
      "Epoch: 6351 Loss: 0.014985130168497562\n",
      "Epoch: 6352 Loss: 0.01498057134449482\n",
      "Epoch: 6353 Loss: 0.014977654442191124\n",
      "Epoch: 6354 Loss: 0.014968985691666603\n",
      "Epoch: 6355 Loss: 0.01496858149766922\n",
      "Epoch: 6356 Loss: 0.014965402893722057\n",
      "Epoch: 6357 Loss: 0.014959210529923439\n",
      "Epoch: 6358 Loss: 0.014958391897380352\n",
      "Epoch: 6359 Loss: 0.014951611869037151\n",
      "Epoch: 6360 Loss: 0.014947907999157906\n",
      "Epoch: 6361 Loss: 0.014944275841116905\n",
      "Epoch: 6362 Loss: 0.014938989654183388\n",
      "Epoch: 6363 Loss: 0.014938185922801495\n",
      "Epoch: 6364 Loss: 0.014929704368114471\n",
      "Epoch: 6365 Loss: 0.014930609613656998\n",
      "Epoch: 6366 Loss: 0.014923772774636745\n",
      "Epoch: 6367 Loss: 0.01491946168243885\n",
      "Epoch: 6368 Loss: 0.014912365935742855\n",
      "Epoch: 6369 Loss: 0.014913334511220455\n",
      "Epoch: 6370 Loss: 0.014906277880072594\n",
      "Epoch: 6371 Loss: 0.014910496771335602\n",
      "Epoch: 6372 Loss: 0.014901199378073215\n",
      "Epoch: 6373 Loss: 0.014896538108587265\n",
      "Epoch: 6374 Loss: 0.01489355880767107\n",
      "Epoch: 6375 Loss: 0.014886862598359585\n",
      "Epoch: 6376 Loss: 0.014883594587445259\n",
      "Epoch: 6377 Loss: 0.014881731942296028\n",
      "Epoch: 6378 Loss: 0.014876917004585266\n",
      "Epoch: 6379 Loss: 0.014868958853185177\n",
      "Epoch: 6380 Loss: 0.014868301339447498\n",
      "Epoch: 6381 Loss: 0.014863597229123116\n",
      "Epoch: 6382 Loss: 0.014859264716506004\n",
      "Epoch: 6383 Loss: 0.014857453294098377\n",
      "Epoch: 6384 Loss: 0.01485887449234724\n",
      "Epoch: 6385 Loss: 0.014848563820123672\n",
      "Epoch: 6386 Loss: 0.014845174737274647\n",
      "Epoch: 6387 Loss: 0.014844328165054321\n",
      "Epoch: 6388 Loss: 0.014833714812994003\n",
      "Epoch: 6389 Loss: 0.014836708083748817\n",
      "Epoch: 6390 Loss: 0.014829264022409916\n",
      "Epoch: 6391 Loss: 0.014822366647422314\n",
      "Epoch: 6392 Loss: 0.014822820201516151\n",
      "Epoch: 6393 Loss: 0.014815954491496086\n",
      "Epoch: 6394 Loss: 0.014815090224146843\n",
      "Epoch: 6395 Loss: 0.014810696244239807\n",
      "Epoch: 6396 Loss: 0.014807689934968948\n",
      "Epoch: 6397 Loss: 0.014798908494412899\n",
      "Epoch: 6398 Loss: 0.01479604933410883\n",
      "Epoch: 6399 Loss: 0.014791430905461311\n",
      "Epoch: 6400 Loss: 0.014790697023272514\n",
      "Epoch: 6401 Loss: 0.014782256446778774\n",
      "Epoch: 6402 Loss: 0.014788515865802765\n",
      "Epoch: 6403 Loss: 0.014775273390114307\n",
      "Epoch: 6404 Loss: 0.014775276184082031\n",
      "Epoch: 6405 Loss: 0.014767038635909557\n",
      "Epoch: 6406 Loss: 0.014765025116503239\n",
      "Epoch: 6407 Loss: 0.014758364297449589\n",
      "Epoch: 6408 Loss: 0.014760697260499\n",
      "Epoch: 6409 Loss: 0.014751330018043518\n",
      "Epoch: 6410 Loss: 0.01474761962890625\n",
      "Epoch: 6411 Loss: 0.014744778163731098\n",
      "Epoch: 6412 Loss: 0.014747101813554764\n",
      "Epoch: 6413 Loss: 0.014733904041349888\n",
      "Epoch: 6414 Loss: 0.014736882410943508\n",
      "Epoch: 6415 Loss: 0.01472848653793335\n",
      "Epoch: 6416 Loss: 0.014725925400853157\n",
      "Epoch: 6417 Loss: 0.014718330465257168\n",
      "Epoch: 6418 Loss: 0.014716236852109432\n",
      "Epoch: 6419 Loss: 0.014711011201143265\n",
      "Epoch: 6420 Loss: 0.014712648466229439\n",
      "Epoch: 6421 Loss: 0.014705942943692207\n",
      "Epoch: 6422 Loss: 0.014699794352054596\n",
      "Epoch: 6423 Loss: 0.014696295373141766\n",
      "Epoch: 6424 Loss: 0.01469406858086586\n",
      "Epoch: 6425 Loss: 0.014687884598970413\n",
      "Epoch: 6426 Loss: 0.014681952074170113\n",
      "Epoch: 6427 Loss: 0.014686040580272675\n",
      "Epoch: 6428 Loss: 0.014680217020213604\n",
      "Epoch: 6429 Loss: 0.01467128749936819\n",
      "Epoch: 6430 Loss: 0.014672777615487576\n",
      "Epoch: 6431 Loss: 0.014662927947938442\n",
      "Epoch: 6432 Loss: 0.01466389186680317\n",
      "Epoch: 6433 Loss: 0.014656644314527512\n",
      "Epoch: 6434 Loss: 0.014649009332060814\n",
      "Epoch: 6435 Loss: 0.014654339291155338\n",
      "Epoch: 6436 Loss: 0.014641396701335907\n",
      "Epoch: 6437 Loss: 0.014642404392361641\n",
      "Epoch: 6438 Loss: 0.014637683518230915\n",
      "Epoch: 6439 Loss: 0.014636391773819923\n",
      "Epoch: 6440 Loss: 0.014631403610110283\n",
      "Epoch: 6441 Loss: 0.014621861279010773\n",
      "Epoch: 6442 Loss: 0.014623566530644894\n",
      "Epoch: 6443 Loss: 0.014621615409851074\n",
      "Epoch: 6444 Loss: 0.01461176760494709\n",
      "Epoch: 6445 Loss: 0.01460713054984808\n",
      "Epoch: 6446 Loss: 0.014604207128286362\n",
      "Epoch: 6447 Loss: 0.014603386633098125\n",
      "Epoch: 6448 Loss: 0.014597336761653423\n",
      "Epoch: 6449 Loss: 0.014595446176826954\n",
      "Epoch: 6450 Loss: 0.014595604501664639\n",
      "Epoch: 6451 Loss: 0.014582788571715355\n",
      "Epoch: 6452 Loss: 0.01458748709410429\n",
      "Epoch: 6453 Loss: 0.014579548500478268\n",
      "Epoch: 6454 Loss: 0.014572997577488422\n",
      "Epoch: 6455 Loss: 0.014569512568414211\n",
      "Epoch: 6456 Loss: 0.01456377748399973\n",
      "Epoch: 6457 Loss: 0.014565777033567429\n",
      "Epoch: 6458 Loss: 0.01455619465559721\n",
      "Epoch: 6459 Loss: 0.014554069377481937\n",
      "Epoch: 6460 Loss: 0.014555389061570168\n",
      "Epoch: 6461 Loss: 0.01454712264239788\n",
      "Epoch: 6462 Loss: 0.014544688165187836\n",
      "Epoch: 6463 Loss: 0.014538358896970749\n",
      "Epoch: 6464 Loss: 0.014539715833961964\n",
      "Epoch: 6465 Loss: 0.014528724364936352\n",
      "Epoch: 6466 Loss: 0.014532865956425667\n",
      "Epoch: 6467 Loss: 0.014524279162287712\n",
      "Epoch: 6468 Loss: 0.014524308033287525\n",
      "Epoch: 6469 Loss: 0.014513871632516384\n",
      "Epoch: 6470 Loss: 0.014511913061141968\n",
      "Epoch: 6471 Loss: 0.014506739564239979\n",
      "Epoch: 6472 Loss: 0.014505887404084206\n",
      "Epoch: 6473 Loss: 0.014500957913696766\n",
      "Epoch: 6474 Loss: 0.014498879201710224\n",
      "Epoch: 6475 Loss: 0.014495243318378925\n",
      "Epoch: 6476 Loss: 0.014489291235804558\n",
      "Epoch: 6477 Loss: 0.014487170614302158\n",
      "Epoch: 6478 Loss: 0.014483990147709846\n",
      "Epoch: 6479 Loss: 0.01447510439902544\n",
      "Epoch: 6480 Loss: 0.014472783543169498\n",
      "Epoch: 6481 Loss: 0.014471780508756638\n",
      "Epoch: 6482 Loss: 0.01446593925356865\n",
      "Epoch: 6483 Loss: 0.014464715495705605\n",
      "Epoch: 6484 Loss: 0.014463409781455994\n",
      "Epoch: 6485 Loss: 0.01445302739739418\n",
      "Epoch: 6486 Loss: 0.014453767798841\n",
      "Epoch: 6487 Loss: 0.014444331638514996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6488 Loss: 0.014441343024373055\n",
      "Epoch: 6489 Loss: 0.014437396079301834\n",
      "Epoch: 6490 Loss: 0.014440896920859814\n",
      "Epoch: 6491 Loss: 0.014431515708565712\n",
      "Epoch: 6492 Loss: 0.014426948502659798\n",
      "Epoch: 6493 Loss: 0.014420179650187492\n",
      "Epoch: 6494 Loss: 0.014427611604332924\n",
      "Epoch: 6495 Loss: 0.014415138401091099\n",
      "Epoch: 6496 Loss: 0.014410548843443394\n",
      "Epoch: 6497 Loss: 0.014409594237804413\n",
      "Epoch: 6498 Loss: 0.014405421912670135\n",
      "Epoch: 6499 Loss: 0.014402884058654308\n",
      "Epoch: 6500 Loss: 0.014394918456673622\n",
      "Epoch: 6501 Loss: 0.014392444863915443\n",
      "Epoch: 6502 Loss: 0.014389054849743843\n",
      "Epoch: 6503 Loss: 0.01439059991389513\n",
      "Epoch: 6504 Loss: 0.014384816400706768\n",
      "Epoch: 6505 Loss: 0.014378857798874378\n",
      "Epoch: 6506 Loss: 0.014374110847711563\n",
      "Epoch: 6507 Loss: 0.014369262382388115\n",
      "Epoch: 6508 Loss: 0.01436582487076521\n",
      "Epoch: 6509 Loss: 0.014364433474838734\n",
      "Epoch: 6510 Loss: 0.014360551722347736\n",
      "Epoch: 6511 Loss: 0.014356265775859356\n",
      "Epoch: 6512 Loss: 0.01435016468167305\n",
      "Epoch: 6513 Loss: 0.014345786534249783\n",
      "Epoch: 6514 Loss: 0.0143425352871418\n",
      "Epoch: 6515 Loss: 0.014343904331326485\n",
      "Epoch: 6516 Loss: 0.014333529397845268\n",
      "Epoch: 6517 Loss: 0.014333953149616718\n",
      "Epoch: 6518 Loss: 0.014328192919492722\n",
      "Epoch: 6519 Loss: 0.014324803836643696\n",
      "Epoch: 6520 Loss: 0.014322754926979542\n",
      "Epoch: 6521 Loss: 0.014314763247966766\n",
      "Epoch: 6522 Loss: 0.014315422624349594\n",
      "Epoch: 6523 Loss: 0.014312256127595901\n",
      "Epoch: 6524 Loss: 0.014306838624179363\n",
      "Epoch: 6525 Loss: 0.014304636046290398\n",
      "Epoch: 6526 Loss: 0.014295632019639015\n",
      "Epoch: 6527 Loss: 0.014293705113232136\n",
      "Epoch: 6528 Loss: 0.014292515814304352\n",
      "Epoch: 6529 Loss: 0.014286132529377937\n",
      "Epoch: 6530 Loss: 0.014288501814007759\n",
      "Epoch: 6531 Loss: 0.014280581846833229\n",
      "Epoch: 6532 Loss: 0.014278138056397438\n",
      "Epoch: 6533 Loss: 0.014269114471971989\n",
      "Epoch: 6534 Loss: 0.014267515391111374\n",
      "Epoch: 6535 Loss: 0.014265775680541992\n",
      "Epoch: 6536 Loss: 0.014263680204749107\n",
      "Epoch: 6537 Loss: 0.014257175847887993\n",
      "Epoch: 6538 Loss: 0.014250049367547035\n",
      "Epoch: 6539 Loss: 0.01425760518759489\n",
      "Epoch: 6540 Loss: 0.014248300343751907\n",
      "Epoch: 6541 Loss: 0.014243550598621368\n",
      "Epoch: 6542 Loss: 0.014238306321203709\n",
      "Epoch: 6543 Loss: 0.014235762879252434\n",
      "Epoch: 6544 Loss: 0.014230792410671711\n",
      "Epoch: 6545 Loss: 0.01422943826764822\n",
      "Epoch: 6546 Loss: 0.014221210032701492\n",
      "Epoch: 6547 Loss: 0.014218145050108433\n",
      "Epoch: 6548 Loss: 0.014216829091310501\n",
      "Epoch: 6549 Loss: 0.014213268645107746\n",
      "Epoch: 6550 Loss: 0.014213296584784985\n",
      "Epoch: 6551 Loss: 0.014202361926436424\n",
      "Epoch: 6552 Loss: 0.014197863638401031\n",
      "Epoch: 6553 Loss: 0.014198452234268188\n",
      "Epoch: 6554 Loss: 0.0141966063529253\n",
      "Epoch: 6555 Loss: 0.014193611219525337\n",
      "Epoch: 6556 Loss: 0.014187435619533062\n",
      "Epoch: 6557 Loss: 0.014186390675604343\n",
      "Epoch: 6558 Loss: 0.014181826263666153\n",
      "Epoch: 6559 Loss: 0.014172345399856567\n",
      "Epoch: 6560 Loss: 0.014175028540194035\n",
      "Epoch: 6561 Loss: 0.014164889231324196\n",
      "Epoch: 6562 Loss: 0.01416429877281189\n",
      "Epoch: 6563 Loss: 0.014163860119879246\n",
      "Epoch: 6564 Loss: 0.014157329685986042\n",
      "Epoch: 6565 Loss: 0.014157782308757305\n",
      "Epoch: 6566 Loss: 0.014151448383927345\n",
      "Epoch: 6567 Loss: 0.014144273474812508\n",
      "Epoch: 6568 Loss: 0.014146043919026852\n",
      "Epoch: 6569 Loss: 0.01413988322019577\n",
      "Epoch: 6570 Loss: 0.014133431948721409\n",
      "Epoch: 6571 Loss: 0.014127617701888084\n",
      "Epoch: 6572 Loss: 0.014128362759947777\n",
      "Epoch: 6573 Loss: 0.014123472385108471\n",
      "Epoch: 6574 Loss: 0.014117622748017311\n",
      "Epoch: 6575 Loss: 0.014119226485490799\n",
      "Epoch: 6576 Loss: 0.01411473285406828\n",
      "Epoch: 6577 Loss: 0.01410936564207077\n",
      "Epoch: 6578 Loss: 0.014107066206634045\n",
      "Epoch: 6579 Loss: 0.014103656634688377\n",
      "Epoch: 6580 Loss: 0.014095165766775608\n",
      "Epoch: 6581 Loss: 0.0140997264534235\n",
      "Epoch: 6582 Loss: 0.01409327331930399\n",
      "Epoch: 6583 Loss: 0.014088449068367481\n",
      "Epoch: 6584 Loss: 0.014083804562687874\n",
      "Epoch: 6585 Loss: 0.014078516513109207\n",
      "Epoch: 6586 Loss: 0.014076970517635345\n",
      "Epoch: 6587 Loss: 0.014074946753680706\n",
      "Epoch: 6588 Loss: 0.01406675111502409\n",
      "Epoch: 6589 Loss: 0.014065158553421497\n",
      "Epoch: 6590 Loss: 0.014060579240322113\n",
      "Epoch: 6591 Loss: 0.014065757393836975\n",
      "Epoch: 6592 Loss: 0.014053172431886196\n",
      "Epoch: 6593 Loss: 0.014047475531697273\n",
      "Epoch: 6594 Loss: 0.014047904871404171\n",
      "Epoch: 6595 Loss: 0.014047300443053246\n",
      "Epoch: 6596 Loss: 0.014041418209671974\n",
      "Epoch: 6597 Loss: 0.014035632833838463\n",
      "Epoch: 6598 Loss: 0.014030572026968002\n",
      "Epoch: 6599 Loss: 0.014032339677214622\n",
      "Epoch: 6600 Loss: 0.01402556523680687\n",
      "Epoch: 6601 Loss: 0.014024283736944199\n",
      "Epoch: 6602 Loss: 0.01401980035007\n",
      "Epoch: 6603 Loss: 0.014012579806149006\n",
      "Epoch: 6604 Loss: 0.014010262675583363\n",
      "Epoch: 6605 Loss: 0.014007708989083767\n",
      "Epoch: 6606 Loss: 0.014001443050801754\n",
      "Epoch: 6607 Loss: 0.014001956209540367\n",
      "Epoch: 6608 Loss: 0.013996503315865993\n",
      "Epoch: 6609 Loss: 0.013992800377309322\n",
      "Epoch: 6610 Loss: 0.01399302575737238\n",
      "Epoch: 6611 Loss: 0.013987382873892784\n",
      "Epoch: 6612 Loss: 0.013981039635837078\n",
      "Epoch: 6613 Loss: 0.013983548618853092\n",
      "Epoch: 6614 Loss: 0.013975097797811031\n",
      "Epoch: 6615 Loss: 0.01397425401955843\n",
      "Epoch: 6616 Loss: 0.013968748971819878\n",
      "Epoch: 6617 Loss: 0.013964556157588959\n",
      "Epoch: 6618 Loss: 0.013962988741695881\n",
      "Epoch: 6619 Loss: 0.013956258073449135\n",
      "Epoch: 6620 Loss: 0.013953973539173603\n",
      "Epoch: 6621 Loss: 0.013948330655694008\n",
      "Epoch: 6622 Loss: 0.01394702959805727\n",
      "Epoch: 6623 Loss: 0.013947232626378536\n",
      "Epoch: 6624 Loss: 0.01393826398998499\n",
      "Epoch: 6625 Loss: 0.013940410688519478\n",
      "Epoch: 6626 Loss: 0.01393162738531828\n",
      "Epoch: 6627 Loss: 0.013926186598837376\n",
      "Epoch: 6628 Loss: 0.013923951424658298\n",
      "Epoch: 6629 Loss: 0.0139198312535882\n",
      "Epoch: 6630 Loss: 0.013920027762651443\n",
      "Epoch: 6631 Loss: 0.013913372531533241\n",
      "Epoch: 6632 Loss: 0.013912954367697239\n",
      "Epoch: 6633 Loss: 0.013904551975429058\n",
      "Epoch: 6634 Loss: 0.013906462118029594\n",
      "Epoch: 6635 Loss: 0.013903696089982986\n",
      "Epoch: 6636 Loss: 0.013899249956011772\n",
      "Epoch: 6637 Loss: 0.01389374677091837\n",
      "Epoch: 6638 Loss: 0.013890180736780167\n",
      "Epoch: 6639 Loss: 0.013882569968700409\n",
      "Epoch: 6640 Loss: 0.013884121552109718\n",
      "Epoch: 6641 Loss: 0.013875271193683147\n",
      "Epoch: 6642 Loss: 0.013873445801436901\n",
      "Epoch: 6643 Loss: 0.013872643001377583\n",
      "Epoch: 6644 Loss: 0.013866182416677475\n",
      "Epoch: 6645 Loss: 0.013864939101040363\n",
      "Epoch: 6646 Loss: 0.013859731145203114\n",
      "Epoch: 6647 Loss: 0.013858870603144169\n",
      "Epoch: 6648 Loss: 0.013849799521267414\n",
      "Epoch: 6649 Loss: 0.013847019523382187\n",
      "Epoch: 6650 Loss: 0.013851753436028957\n",
      "Epoch: 6651 Loss: 0.013842582702636719\n",
      "Epoch: 6652 Loss: 0.013837178237736225\n",
      "Epoch: 6653 Loss: 0.0138325747102499\n",
      "Epoch: 6654 Loss: 0.013833891600370407\n",
      "Epoch: 6655 Loss: 0.013825526461005211\n",
      "Epoch: 6656 Loss: 0.013826697133481503\n",
      "Epoch: 6657 Loss: 0.013822190463542938\n",
      "Epoch: 6658 Loss: 0.013819224201142788\n",
      "Epoch: 6659 Loss: 0.013815554790198803\n",
      "Epoch: 6660 Loss: 0.013812791556119919\n",
      "Epoch: 6661 Loss: 0.013810978271067142\n",
      "Epoch: 6662 Loss: 0.013804345391690731\n",
      "Epoch: 6663 Loss: 0.01379745826125145\n",
      "Epoch: 6664 Loss: 0.013797309249639511\n",
      "Epoch: 6665 Loss: 0.013793433085083961\n",
      "Epoch: 6666 Loss: 0.013793296180665493\n",
      "Epoch: 6667 Loss: 0.013783263973891735\n",
      "Epoch: 6668 Loss: 0.013787155039608479\n",
      "Epoch: 6669 Loss: 0.01378063578158617\n",
      "Epoch: 6670 Loss: 0.013771976344287395\n",
      "Epoch: 6671 Loss: 0.013773583807051182\n",
      "Epoch: 6672 Loss: 0.013767854310572147\n",
      "Epoch: 6673 Loss: 0.01376609317958355\n",
      "Epoch: 6674 Loss: 0.013758737593889236\n",
      "Epoch: 6675 Loss: 0.01376237440854311\n",
      "Epoch: 6676 Loss: 0.013757508248090744\n",
      "Epoch: 6677 Loss: 0.013752860948443413\n",
      "Epoch: 6678 Loss: 0.01374491024762392\n",
      "Epoch: 6679 Loss: 0.013749786652624607\n",
      "Epoch: 6680 Loss: 0.01374159287661314\n",
      "Epoch: 6681 Loss: 0.013736625202000141\n",
      "Epoch: 6682 Loss: 0.013732242397964\n",
      "Epoch: 6683 Loss: 0.013733994215726852\n",
      "Epoch: 6684 Loss: 0.013725475408136845\n",
      "Epoch: 6685 Loss: 0.013724924065172672\n",
      "Epoch: 6686 Loss: 0.013722958974540234\n",
      "Epoch: 6687 Loss: 0.01371739711612463\n",
      "Epoch: 6688 Loss: 0.013714620843529701\n",
      "Epoch: 6689 Loss: 0.013708001002669334\n",
      "Epoch: 6690 Loss: 0.013708787970244884\n",
      "Epoch: 6691 Loss: 0.013702903874218464\n",
      "Epoch: 6692 Loss: 0.013699465431272984\n",
      "Epoch: 6693 Loss: 0.013695417903363705\n",
      "Epoch: 6694 Loss: 0.013696469366550446\n",
      "Epoch: 6695 Loss: 0.01368597149848938\n",
      "Epoch: 6696 Loss: 0.013687411323189735\n",
      "Epoch: 6697 Loss: 0.01367978472262621\n",
      "Epoch: 6698 Loss: 0.013676191680133343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6699 Loss: 0.013677502050995827\n",
      "Epoch: 6700 Loss: 0.013670291751623154\n",
      "Epoch: 6701 Loss: 0.013669594191014767\n",
      "Epoch: 6702 Loss: 0.01366325281560421\n",
      "Epoch: 6703 Loss: 0.013665442354977131\n",
      "Epoch: 6704 Loss: 0.013658369891345501\n",
      "Epoch: 6705 Loss: 0.013654530048370361\n",
      "Epoch: 6706 Loss: 0.01365496776998043\n",
      "Epoch: 6707 Loss: 0.013643614947795868\n",
      "Epoch: 6708 Loss: 0.013641893863677979\n",
      "Epoch: 6709 Loss: 0.013645777478814125\n",
      "Epoch: 6710 Loss: 0.013638176023960114\n",
      "Epoch: 6711 Loss: 0.013634759932756424\n",
      "Epoch: 6712 Loss: 0.013629346154630184\n",
      "Epoch: 6713 Loss: 0.013628237880766392\n",
      "Epoch: 6714 Loss: 0.013624166138470173\n",
      "Epoch: 6715 Loss: 0.013616535812616348\n",
      "Epoch: 6716 Loss: 0.01361448410898447\n",
      "Epoch: 6717 Loss: 0.013613563030958176\n",
      "Epoch: 6718 Loss: 0.01361231692135334\n",
      "Epoch: 6719 Loss: 0.013604959473013878\n",
      "Epoch: 6720 Loss: 0.013606392778456211\n",
      "Epoch: 6721 Loss: 0.013602356426417828\n",
      "Epoch: 6722 Loss: 0.01359637826681137\n",
      "Epoch: 6723 Loss: 0.013591623865067959\n",
      "Epoch: 6724 Loss: 0.013589669018983841\n",
      "Epoch: 6725 Loss: 0.013584459200501442\n",
      "Epoch: 6726 Loss: 0.013580632396042347\n",
      "Epoch: 6727 Loss: 0.013579671271145344\n",
      "Epoch: 6728 Loss: 0.013577193953096867\n",
      "Epoch: 6729 Loss: 0.01356924045830965\n",
      "Epoch: 6730 Loss: 0.013570182956755161\n",
      "Epoch: 6731 Loss: 0.013566797599196434\n",
      "Epoch: 6732 Loss: 0.013559723272919655\n",
      "Epoch: 6733 Loss: 0.013562498614192009\n",
      "Epoch: 6734 Loss: 0.013555187731981277\n",
      "Epoch: 6735 Loss: 0.0135502303019166\n",
      "Epoch: 6736 Loss: 0.013545667752623558\n",
      "Epoch: 6737 Loss: 0.013541243970394135\n",
      "Epoch: 6738 Loss: 0.01354423351585865\n",
      "Epoch: 6739 Loss: 0.013537565246224403\n",
      "Epoch: 6740 Loss: 0.01353465300053358\n",
      "Epoch: 6741 Loss: 0.013535639271140099\n",
      "Epoch: 6742 Loss: 0.013527510687708855\n",
      "Epoch: 6743 Loss: 0.013526789844036102\n",
      "Epoch: 6744 Loss: 0.013519149273633957\n",
      "Epoch: 6745 Loss: 0.013515057042241096\n",
      "Epoch: 6746 Loss: 0.013515097089111805\n",
      "Epoch: 6747 Loss: 0.013512065634131432\n",
      "Epoch: 6748 Loss: 0.01350559201091528\n",
      "Epoch: 6749 Loss: 0.013506099581718445\n",
      "Epoch: 6750 Loss: 0.01350464764982462\n",
      "Epoch: 6751 Loss: 0.013496143743395805\n",
      "Epoch: 6752 Loss: 0.013497387059032917\n",
      "Epoch: 6753 Loss: 0.013491054065525532\n",
      "Epoch: 6754 Loss: 0.013486974872648716\n",
      "Epoch: 6755 Loss: 0.01348270382732153\n",
      "Epoch: 6756 Loss: 0.013479412533342838\n",
      "Epoch: 6757 Loss: 0.013479786925017834\n",
      "Epoch: 6758 Loss: 0.013473276048898697\n",
      "Epoch: 6759 Loss: 0.013472641818225384\n",
      "Epoch: 6760 Loss: 0.01346477959305048\n",
      "Epoch: 6761 Loss: 0.013462762348353863\n",
      "Epoch: 6762 Loss: 0.013461955823004246\n",
      "Epoch: 6763 Loss: 0.013457062654197216\n",
      "Epoch: 6764 Loss: 0.013450093567371368\n",
      "Epoch: 6765 Loss: 0.013451579958200455\n",
      "Epoch: 6766 Loss: 0.013448615558445454\n",
      "Epoch: 6767 Loss: 0.013443504460155964\n",
      "Epoch: 6768 Loss: 0.013439078815281391\n",
      "Epoch: 6769 Loss: 0.01343604177236557\n",
      "Epoch: 6770 Loss: 0.013436626642942429\n",
      "Epoch: 6771 Loss: 0.013431727886199951\n",
      "Epoch: 6772 Loss: 0.013427799567580223\n",
      "Epoch: 6773 Loss: 0.013422487303614616\n",
      "Epoch: 6774 Loss: 0.01341873686760664\n",
      "Epoch: 6775 Loss: 0.013417086564004421\n",
      "Epoch: 6776 Loss: 0.013414544984698296\n",
      "Epoch: 6777 Loss: 0.013410228304564953\n",
      "Epoch: 6778 Loss: 0.013407557271420956\n",
      "Epoch: 6779 Loss: 0.013404930010437965\n",
      "Epoch: 6780 Loss: 0.013399260118603706\n",
      "Epoch: 6781 Loss: 0.013394203037023544\n",
      "Epoch: 6782 Loss: 0.013391266576945782\n",
      "Epoch: 6783 Loss: 0.013391162268817425\n",
      "Epoch: 6784 Loss: 0.013386569917201996\n",
      "Epoch: 6785 Loss: 0.013386492617428303\n",
      "Epoch: 6786 Loss: 0.013378670439124107\n",
      "Epoch: 6787 Loss: 0.013379187323153019\n",
      "Epoch: 6788 Loss: 0.013373084366321564\n",
      "Epoch: 6789 Loss: 0.013368211686611176\n",
      "Epoch: 6790 Loss: 0.01336852740496397\n",
      "Epoch: 6791 Loss: 0.013359790667891502\n",
      "Epoch: 6792 Loss: 0.013359987176954746\n",
      "Epoch: 6793 Loss: 0.01335868053138256\n",
      "Epoch: 6794 Loss: 0.013350395485758781\n",
      "Epoch: 6795 Loss: 0.013353037647902966\n",
      "Epoch: 6796 Loss: 0.013344405218958855\n",
      "Epoch: 6797 Loss: 0.013345952145755291\n",
      "Epoch: 6798 Loss: 0.013338729739189148\n",
      "Epoch: 6799 Loss: 0.013334599323570728\n",
      "Epoch: 6800 Loss: 0.013331569731235504\n",
      "Epoch: 6801 Loss: 0.01333001721650362\n",
      "Epoch: 6802 Loss: 0.01332597155123949\n",
      "Epoch: 6803 Loss: 0.013324219733476639\n",
      "Epoch: 6804 Loss: 0.013318578712642193\n",
      "Epoch: 6805 Loss: 0.013317826204001904\n",
      "Epoch: 6806 Loss: 0.01331355795264244\n",
      "Epoch: 6807 Loss: 0.013311847113072872\n",
      "Epoch: 6808 Loss: 0.013304202817380428\n",
      "Epoch: 6809 Loss: 0.013305624946951866\n",
      "Epoch: 6810 Loss: 0.013299938291311264\n",
      "Epoch: 6811 Loss: 0.013297400437295437\n",
      "Epoch: 6812 Loss: 0.013291576877236366\n",
      "Epoch: 6813 Loss: 0.01328777614980936\n",
      "Epoch: 6814 Loss: 0.013293623924255371\n",
      "Epoch: 6815 Loss: 0.013283043168485165\n",
      "Epoch: 6816 Loss: 0.013281495310366154\n",
      "Epoch: 6817 Loss: 0.013276433572173119\n",
      "Epoch: 6818 Loss: 0.01327447034418583\n",
      "Epoch: 6819 Loss: 0.01327051967382431\n",
      "Epoch: 6820 Loss: 0.013265983201563358\n",
      "Epoch: 6821 Loss: 0.01326430682092905\n",
      "Epoch: 6822 Loss: 0.013260726816952229\n",
      "Epoch: 6823 Loss: 0.013260922394692898\n",
      "Epoch: 6824 Loss: 0.013255544006824493\n",
      "Epoch: 6825 Loss: 0.0132509246468544\n",
      "Epoch: 6826 Loss: 0.013247002847492695\n",
      "Epoch: 6827 Loss: 0.013241264969110489\n",
      "Epoch: 6828 Loss: 0.013243363238871098\n",
      "Epoch: 6829 Loss: 0.013236532919108868\n",
      "Epoch: 6830 Loss: 0.013237073086202145\n",
      "Epoch: 6831 Loss: 0.013230184093117714\n",
      "Epoch: 6832 Loss: 0.01322934404015541\n",
      "Epoch: 6833 Loss: 0.013224794529378414\n",
      "Epoch: 6834 Loss: 0.013223194517195225\n",
      "Epoch: 6835 Loss: 0.013216601684689522\n",
      "Epoch: 6836 Loss: 0.013217635452747345\n",
      "Epoch: 6837 Loss: 0.013209795579314232\n",
      "Epoch: 6838 Loss: 0.013208217918872833\n",
      "Epoch: 6839 Loss: 0.013207119889557362\n",
      "Epoch: 6840 Loss: 0.013199534267187119\n",
      "Epoch: 6841 Loss: 0.013200612738728523\n",
      "Epoch: 6842 Loss: 0.013196957297623158\n",
      "Epoch: 6843 Loss: 0.013192982412874699\n",
      "Epoch: 6844 Loss: 0.013189822435379028\n",
      "Epoch: 6845 Loss: 0.01318361796438694\n",
      "Epoch: 6846 Loss: 0.013181732967495918\n",
      "Epoch: 6847 Loss: 0.013179137371480465\n",
      "Epoch: 6848 Loss: 0.013178505003452301\n",
      "Epoch: 6849 Loss: 0.013171575032174587\n",
      "Epoch: 6850 Loss: 0.01317252591252327\n",
      "Epoch: 6851 Loss: 0.013164302334189415\n",
      "Epoch: 6852 Loss: 0.01316334679722786\n",
      "Epoch: 6853 Loss: 0.01316041685640812\n",
      "Epoch: 6854 Loss: 0.013158908113837242\n",
      "Epoch: 6855 Loss: 0.013153130188584328\n",
      "Epoch: 6856 Loss: 0.013149155303835869\n",
      "Epoch: 6857 Loss: 0.013148825615644455\n",
      "Epoch: 6858 Loss: 0.013143152929842472\n",
      "Epoch: 6859 Loss: 0.013137023895978928\n",
      "Epoch: 6860 Loss: 0.013140757568180561\n",
      "Epoch: 6861 Loss: 0.013135164976119995\n",
      "Epoch: 6862 Loss: 0.013132160529494286\n",
      "Epoch: 6863 Loss: 0.013126839883625507\n",
      "Epoch: 6864 Loss: 0.013120551593601704\n",
      "Epoch: 6865 Loss: 0.013123225420713425\n",
      "Epoch: 6866 Loss: 0.01311743725091219\n",
      "Epoch: 6867 Loss: 0.013113213703036308\n",
      "Epoch: 6868 Loss: 0.013115300796926022\n",
      "Epoch: 6869 Loss: 0.01311020739376545\n",
      "Epoch: 6870 Loss: 0.013101761229336262\n",
      "Epoch: 6871 Loss: 0.013102449476718903\n",
      "Epoch: 6872 Loss: 0.013099520467221737\n",
      "Epoch: 6873 Loss: 0.013094126246869564\n",
      "Epoch: 6874 Loss: 0.01309351995587349\n",
      "Epoch: 6875 Loss: 0.013089404441416264\n",
      "Epoch: 6876 Loss: 0.01308800745755434\n",
      "Epoch: 6877 Loss: 0.013083148747682571\n",
      "Epoch: 6878 Loss: 0.013078976422548294\n",
      "Epoch: 6879 Loss: 0.013077601790428162\n",
      "Epoch: 6880 Loss: 0.013070698827505112\n",
      "Epoch: 6881 Loss: 0.013067680411040783\n",
      "Epoch: 6882 Loss: 0.013071098364889622\n",
      "Epoch: 6883 Loss: 0.013063745573163033\n",
      "Epoch: 6884 Loss: 0.013060529716312885\n",
      "Epoch: 6885 Loss: 0.013058227486908436\n",
      "Epoch: 6886 Loss: 0.013055197894573212\n",
      "Epoch: 6887 Loss: 0.013053339906036854\n",
      "Epoch: 6888 Loss: 0.013047365471720695\n",
      "Epoch: 6889 Loss: 0.01304291095584631\n",
      "Epoch: 6890 Loss: 0.013039212673902512\n",
      "Epoch: 6891 Loss: 0.013039808720350266\n",
      "Epoch: 6892 Loss: 0.01303586084395647\n",
      "Epoch: 6893 Loss: 0.013032462447881699\n",
      "Epoch: 6894 Loss: 0.013028635643422604\n",
      "Epoch: 6895 Loss: 0.01302627194672823\n",
      "Epoch: 6896 Loss: 0.013022815808653831\n",
      "Epoch: 6897 Loss: 0.013016522862017155\n",
      "Epoch: 6898 Loss: 0.013021249324083328\n",
      "Epoch: 6899 Loss: 0.013008838519454002\n",
      "Epoch: 6900 Loss: 0.013013536110520363\n",
      "Epoch: 6901 Loss: 0.013005047105252743\n",
      "Epoch: 6902 Loss: 0.01300388015806675\n",
      "Epoch: 6903 Loss: 0.012999546714127064\n",
      "Epoch: 6904 Loss: 0.012996828183531761\n",
      "Epoch: 6905 Loss: 0.01299221720546484\n",
      "Epoch: 6906 Loss: 0.012992613017559052\n",
      "Epoch: 6907 Loss: 0.012987102381885052\n",
      "Epoch: 6908 Loss: 0.012984473258256912\n",
      "Epoch: 6909 Loss: 0.012983164750039577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6910 Loss: 0.012975716963410378\n",
      "Epoch: 6911 Loss: 0.01297629065811634\n",
      "Epoch: 6912 Loss: 0.012972857803106308\n",
      "Epoch: 6913 Loss: 0.012969987466931343\n",
      "Epoch: 6914 Loss: 0.012963468208909035\n",
      "Epoch: 6915 Loss: 0.012964988127350807\n",
      "Epoch: 6916 Loss: 0.012958734296262264\n",
      "Epoch: 6917 Loss: 0.012955163605511189\n",
      "Epoch: 6918 Loss: 0.012952114455401897\n",
      "Epoch: 6919 Loss: 0.01295043807476759\n",
      "Epoch: 6920 Loss: 0.012946098111569881\n",
      "Epoch: 6921 Loss: 0.012940588407218456\n",
      "Epoch: 6922 Loss: 0.012940720655024052\n",
      "Epoch: 6923 Loss: 0.012936641462147236\n",
      "Epoch: 6924 Loss: 0.01293251384049654\n",
      "Epoch: 6925 Loss: 0.01293143816292286\n",
      "Epoch: 6926 Loss: 0.012925473041832447\n",
      "Epoch: 6927 Loss: 0.012924447655677795\n",
      "Epoch: 6928 Loss: 0.012922566384077072\n",
      "Epoch: 6929 Loss: 0.012920045293867588\n",
      "Epoch: 6930 Loss: 0.012913551181554794\n",
      "Epoch: 6931 Loss: 0.012911789119243622\n",
      "Epoch: 6932 Loss: 0.01290962565690279\n",
      "Epoch: 6933 Loss: 0.012906743213534355\n",
      "Epoch: 6934 Loss: 0.012903264723718166\n",
      "Epoch: 6935 Loss: 0.012896386906504631\n",
      "Epoch: 6936 Loss: 0.012895011343061924\n",
      "Epoch: 6937 Loss: 0.012892186641693115\n",
      "Epoch: 6938 Loss: 0.01289589423686266\n",
      "Epoch: 6939 Loss: 0.0128859281539917\n",
      "Epoch: 6940 Loss: 0.012883069925010204\n",
      "Epoch: 6941 Loss: 0.012881753034889698\n",
      "Epoch: 6942 Loss: 0.012878495268523693\n",
      "Epoch: 6943 Loss: 0.012874581851065159\n",
      "Epoch: 6944 Loss: 0.01287217065691948\n",
      "Epoch: 6945 Loss: 0.012867029756307602\n",
      "Epoch: 6946 Loss: 0.012867511250078678\n",
      "Epoch: 6947 Loss: 0.012859837152063847\n",
      "Epoch: 6948 Loss: 0.012858136557042599\n",
      "Epoch: 6949 Loss: 0.012853661552071571\n",
      "Epoch: 6950 Loss: 0.01284970622509718\n",
      "Epoch: 6951 Loss: 0.012849558144807816\n",
      "Epoch: 6952 Loss: 0.012845704331994057\n",
      "Epoch: 6953 Loss: 0.01284408662468195\n",
      "Epoch: 6954 Loss: 0.01284171361476183\n",
      "Epoch: 6955 Loss: 0.012836874462664127\n",
      "Epoch: 6956 Loss: 0.012831028550863266\n",
      "Epoch: 6957 Loss: 0.012831348925828934\n",
      "Epoch: 6958 Loss: 0.01282456610351801\n",
      "Epoch: 6959 Loss: 0.012822968885302544\n",
      "Epoch: 6960 Loss: 0.012819808907806873\n",
      "Epoch: 6961 Loss: 0.012819535098969936\n",
      "Epoch: 6962 Loss: 0.012816610746085644\n",
      "Epoch: 6963 Loss: 0.012812540866434574\n",
      "Epoch: 6964 Loss: 0.01280756015330553\n",
      "Epoch: 6965 Loss: 0.012809226289391518\n",
      "Epoch: 6966 Loss: 0.012799961492419243\n",
      "Epoch: 6967 Loss: 0.012798478826880455\n",
      "Epoch: 6968 Loss: 0.012798224575817585\n",
      "Epoch: 6969 Loss: 0.012793286703526974\n",
      "Epoch: 6970 Loss: 0.012791454792022705\n",
      "Epoch: 6971 Loss: 0.012788034044206142\n",
      "Epoch: 6972 Loss: 0.01278324332088232\n",
      "Epoch: 6973 Loss: 0.012779914774000645\n",
      "Epoch: 6974 Loss: 0.012778155505657196\n",
      "Epoch: 6975 Loss: 0.012774480506777763\n",
      "Epoch: 6976 Loss: 0.012772233225405216\n",
      "Epoch: 6977 Loss: 0.01276554074138403\n",
      "Epoch: 6978 Loss: 0.012769501656293869\n",
      "Epoch: 6979 Loss: 0.01276182010769844\n",
      "Epoch: 6980 Loss: 0.012759000062942505\n",
      "Epoch: 6981 Loss: 0.012757738120853901\n",
      "Epoch: 6982 Loss: 0.012750749476253986\n",
      "Epoch: 6983 Loss: 0.012752893380820751\n",
      "Epoch: 6984 Loss: 0.012750946916639805\n",
      "Epoch: 6985 Loss: 0.012742087244987488\n",
      "Epoch: 6986 Loss: 0.01274073775857687\n",
      "Epoch: 6987 Loss: 0.01273917593061924\n",
      "Epoch: 6988 Loss: 0.01273351814597845\n",
      "Epoch: 6989 Loss: 0.01273014210164547\n",
      "Epoch: 6990 Loss: 0.012729191221296787\n",
      "Epoch: 6991 Loss: 0.012724969536066055\n",
      "Epoch: 6992 Loss: 0.012724830769002438\n",
      "Epoch: 6993 Loss: 0.012717126868665218\n",
      "Epoch: 6994 Loss: 0.012717189267277718\n",
      "Epoch: 6995 Loss: 0.012713664211332798\n",
      "Epoch: 6996 Loss: 0.012711486779153347\n",
      "Epoch: 6997 Loss: 0.012707107700407505\n",
      "Epoch: 6998 Loss: 0.012704484164714813\n",
      "Epoch: 6999 Loss: 0.01270237285643816\n",
      "Epoch: 7000 Loss: 0.01269685011357069\n",
      "Epoch: 7001 Loss: 0.012696896679699421\n",
      "Epoch: 7002 Loss: 0.012689350172877312\n",
      "Epoch: 7003 Loss: 0.012688864953815937\n",
      "Epoch: 7004 Loss: 0.012682209722697735\n",
      "Epoch: 7005 Loss: 0.01268168818205595\n",
      "Epoch: 7006 Loss: 0.012682066299021244\n",
      "Epoch: 7007 Loss: 0.012677325867116451\n",
      "Epoch: 7008 Loss: 0.012674441561102867\n",
      "Epoch: 7009 Loss: 0.012669818475842476\n",
      "Epoch: 7010 Loss: 0.012666498310863972\n",
      "Epoch: 7011 Loss: 0.012666299939155579\n",
      "Epoch: 7012 Loss: 0.012662474066019058\n",
      "Epoch: 7013 Loss: 0.012660511769354343\n",
      "Epoch: 7014 Loss: 0.012658100575208664\n",
      "Epoch: 7015 Loss: 0.012655236758291721\n",
      "Epoch: 7016 Loss: 0.01264739315956831\n",
      "Epoch: 7017 Loss: 0.012648604810237885\n",
      "Epoch: 7018 Loss: 0.012644139118492603\n",
      "Epoch: 7019 Loss: 0.012639256194233894\n",
      "Epoch: 7020 Loss: 0.012636099010705948\n",
      "Epoch: 7021 Loss: 0.012633679434657097\n",
      "Epoch: 7022 Loss: 0.012633787468075752\n",
      "Epoch: 7023 Loss: 0.012629183940589428\n",
      "Epoch: 7024 Loss: 0.012624634429812431\n",
      "Epoch: 7025 Loss: 0.012620411813259125\n",
      "Epoch: 7026 Loss: 0.012618624605238438\n",
      "Epoch: 7027 Loss: 0.01261490024626255\n",
      "Epoch: 7028 Loss: 0.012613408267498016\n",
      "Epoch: 7029 Loss: 0.01261039450764656\n",
      "Epoch: 7030 Loss: 0.012612457387149334\n",
      "Epoch: 7031 Loss: 0.012602852657437325\n",
      "Epoch: 7032 Loss: 0.012601000256836414\n",
      "Epoch: 7033 Loss: 0.012596909888088703\n",
      "Epoch: 7034 Loss: 0.012595610693097115\n",
      "Epoch: 7035 Loss: 0.012591821141541004\n",
      "Epoch: 7036 Loss: 0.012589963153004646\n",
      "Epoch: 7037 Loss: 0.012589160352945328\n",
      "Epoch: 7038 Loss: 0.012582204304635525\n",
      "Epoch: 7039 Loss: 0.01258110161870718\n",
      "Epoch: 7040 Loss: 0.01257764920592308\n",
      "Epoch: 7041 Loss: 0.012574129737913609\n",
      "Epoch: 7042 Loss: 0.012572565115988255\n",
      "Epoch: 7043 Loss: 0.012569944374263287\n",
      "Epoch: 7044 Loss: 0.012563386932015419\n",
      "Epoch: 7045 Loss: 0.012563924305140972\n",
      "Epoch: 7046 Loss: 0.012557880021631718\n",
      "Epoch: 7047 Loss: 0.012555638328194618\n",
      "Epoch: 7048 Loss: 0.012555223889648914\n",
      "Epoch: 7049 Loss: 0.012550627812743187\n",
      "Epoch: 7050 Loss: 0.012543672695755959\n",
      "Epoch: 7051 Loss: 0.01254644338041544\n",
      "Epoch: 7052 Loss: 0.012543527409434319\n",
      "Epoch: 7053 Loss: 0.012538726441562176\n",
      "Epoch: 7054 Loss: 0.01253267377614975\n",
      "Epoch: 7055 Loss: 0.012531571090221405\n",
      "Epoch: 7056 Loss: 0.012529691681265831\n",
      "Epoch: 7057 Loss: 0.012530092149972916\n",
      "Epoch: 7058 Loss: 0.012520497664809227\n",
      "Epoch: 7059 Loss: 0.012520641088485718\n",
      "Epoch: 7060 Loss: 0.012520601972937584\n",
      "Epoch: 7061 Loss: 0.012511631473898888\n",
      "Epoch: 7062 Loss: 0.012509990483522415\n",
      "Epoch: 7063 Loss: 0.012509465217590332\n",
      "Epoch: 7064 Loss: 0.012506336905062199\n",
      "Epoch: 7065 Loss: 0.012504377402365208\n",
      "Epoch: 7066 Loss: 0.012500761076807976\n",
      "Epoch: 7067 Loss: 0.012499283067882061\n",
      "Epoch: 7068 Loss: 0.012493686750531197\n",
      "Epoch: 7069 Loss: 0.01248912699520588\n",
      "Epoch: 7070 Loss: 0.012486027553677559\n",
      "Epoch: 7071 Loss: 0.012484749779105186\n",
      "Epoch: 7072 Loss: 0.012478439137339592\n",
      "Epoch: 7073 Loss: 0.012480081990361214\n",
      "Epoch: 7074 Loss: 0.012474562041461468\n",
      "Epoch: 7075 Loss: 0.012473450042307377\n",
      "Epoch: 7076 Loss: 0.012474274262785912\n",
      "Epoch: 7077 Loss: 0.01246683020144701\n",
      "Epoch: 7078 Loss: 0.01246569398790598\n",
      "Epoch: 7079 Loss: 0.012462213635444641\n",
      "Epoch: 7080 Loss: 0.01245805248618126\n",
      "Epoch: 7081 Loss: 0.012453866191208363\n",
      "Epoch: 7082 Loss: 0.012456098571419716\n",
      "Epoch: 7083 Loss: 0.0124509921297431\n",
      "Epoch: 7084 Loss: 0.012449546717107296\n",
      "Epoch: 7085 Loss: 0.012443500570952892\n",
      "Epoch: 7086 Loss: 0.012443846091628075\n",
      "Epoch: 7087 Loss: 0.012437814846634865\n",
      "Epoch: 7088 Loss: 0.012436212040483952\n",
      "Epoch: 7089 Loss: 0.012430218979716301\n",
      "Epoch: 7090 Loss: 0.01242857426404953\n",
      "Epoch: 7091 Loss: 0.0124266492202878\n",
      "Epoch: 7092 Loss: 0.012420166283845901\n",
      "Epoch: 7093 Loss: 0.012418331578373909\n",
      "Epoch: 7094 Loss: 0.012416641227900982\n",
      "Epoch: 7095 Loss: 0.012417546473443508\n",
      "Epoch: 7096 Loss: 0.012408528476953506\n",
      "Epoch: 7097 Loss: 0.01241215318441391\n",
      "Epoch: 7098 Loss: 0.012404627166688442\n",
      "Epoch: 7099 Loss: 0.012400230392813683\n",
      "Epoch: 7100 Loss: 0.012403690256178379\n",
      "Epoch: 7101 Loss: 0.012395958416163921\n",
      "Epoch: 7102 Loss: 0.012397898361086845\n",
      "Epoch: 7103 Loss: 0.01239089947193861\n",
      "Epoch: 7104 Loss: 0.012390751391649246\n",
      "Epoch: 7105 Loss: 0.012384406290948391\n",
      "Epoch: 7106 Loss: 0.012381462380290031\n",
      "Epoch: 7107 Loss: 0.012380060739815235\n",
      "Epoch: 7108 Loss: 0.012374456971883774\n",
      "Epoch: 7109 Loss: 0.01237184926867485\n",
      "Epoch: 7110 Loss: 0.01236975658684969\n",
      "Epoch: 7111 Loss: 0.012368912808597088\n",
      "Epoch: 7112 Loss: 0.01236306969076395\n",
      "Epoch: 7113 Loss: 0.012362280860543251\n",
      "Epoch: 7114 Loss: 0.012356575578451157\n",
      "Epoch: 7115 Loss: 0.012353629805147648\n",
      "Epoch: 7116 Loss: 0.01235289964824915\n",
      "Epoch: 7117 Loss: 0.012352300807833672\n",
      "Epoch: 7118 Loss: 0.012347966432571411\n",
      "Epoch: 7119 Loss: 0.01234493963420391\n",
      "Epoch: 7120 Loss: 0.012343215756118298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7121 Loss: 0.012338750064373016\n",
      "Epoch: 7122 Loss: 0.012336580082774162\n",
      "Epoch: 7123 Loss: 0.012332262471318245\n",
      "Epoch: 7124 Loss: 0.012327105738222599\n",
      "Epoch: 7125 Loss: 0.012328977696597576\n",
      "Epoch: 7126 Loss: 0.012323540635406971\n",
      "Epoch: 7127 Loss: 0.012324693612754345\n",
      "Epoch: 7128 Loss: 0.012317649088799953\n",
      "Epoch: 7129 Loss: 0.012318364344537258\n",
      "Epoch: 7130 Loss: 0.012310488149523735\n",
      "Epoch: 7131 Loss: 0.012313244864344597\n",
      "Epoch: 7132 Loss: 0.012305942364037037\n",
      "Epoch: 7133 Loss: 0.012304417788982391\n",
      "Epoch: 7134 Loss: 0.012300257571041584\n",
      "Epoch: 7135 Loss: 0.012297755107283592\n",
      "Epoch: 7136 Loss: 0.012294451706111431\n",
      "Epoch: 7137 Loss: 0.012295006774365902\n",
      "Epoch: 7138 Loss: 0.01229019183665514\n",
      "Epoch: 7139 Loss: 0.012287821620702744\n",
      "Epoch: 7140 Loss: 0.012283770367503166\n",
      "Epoch: 7141 Loss: 0.012279285117983818\n",
      "Epoch: 7142 Loss: 0.012281577102839947\n",
      "Epoch: 7143 Loss: 0.012273618020117283\n",
      "Epoch: 7144 Loss: 0.012273786589503288\n",
      "Epoch: 7145 Loss: 0.012269181199371815\n",
      "Epoch: 7146 Loss: 0.012266241945326328\n",
      "Epoch: 7147 Loss: 0.012261096388101578\n",
      "Epoch: 7148 Loss: 0.012260365299880505\n",
      "Epoch: 7149 Loss: 0.012259832583367825\n",
      "Epoch: 7150 Loss: 0.012254598550498486\n",
      "Epoch: 7151 Loss: 0.012253030203282833\n",
      "Epoch: 7152 Loss: 0.01224668137729168\n",
      "Epoch: 7153 Loss: 0.01224371138960123\n",
      "Epoch: 7154 Loss: 0.012242329306900501\n",
      "Epoch: 7155 Loss: 0.012244202196598053\n",
      "Epoch: 7156 Loss: 0.012238141149282455\n",
      "Epoch: 7157 Loss: 0.012233016081154346\n",
      "Epoch: 7158 Loss: 0.012230959720909595\n",
      "Epoch: 7159 Loss: 0.01223081536591053\n",
      "Epoch: 7160 Loss: 0.012226409278810024\n",
      "Epoch: 7161 Loss: 0.01222408190369606\n",
      "Epoch: 7162 Loss: 0.012219646014273167\n",
      "Epoch: 7163 Loss: 0.01222248189151287\n",
      "Epoch: 7164 Loss: 0.012213554233312607\n",
      "Epoch: 7165 Loss: 0.012212206609547138\n",
      "Epoch: 7166 Loss: 0.01220810879021883\n",
      "Epoch: 7167 Loss: 0.012208356522023678\n",
      "Epoch: 7168 Loss: 0.012202495709061623\n",
      "Epoch: 7169 Loss: 0.012201705947518349\n",
      "Epoch: 7170 Loss: 0.012198884040117264\n",
      "Epoch: 7171 Loss: 0.012195144779980183\n",
      "Epoch: 7172 Loss: 0.012191171757876873\n",
      "Epoch: 7173 Loss: 0.012189077213406563\n",
      "Epoch: 7174 Loss: 0.012186018750071526\n",
      "Epoch: 7175 Loss: 0.012185022234916687\n",
      "Epoch: 7176 Loss: 0.012179971672594547\n",
      "Epoch: 7177 Loss: 0.012179356068372726\n",
      "Epoch: 7178 Loss: 0.01217516977339983\n",
      "Epoch: 7179 Loss: 0.012173875235021114\n",
      "Epoch: 7180 Loss: 0.012172500602900982\n",
      "Epoch: 7181 Loss: 0.012166748754680157\n",
      "Epoch: 7182 Loss: 0.012164022773504257\n",
      "Epoch: 7183 Loss: 0.012163161300122738\n",
      "Epoch: 7184 Loss: 0.012157401069998741\n",
      "Epoch: 7185 Loss: 0.012154710479080677\n",
      "Epoch: 7186 Loss: 0.01215277798473835\n",
      "Epoch: 7187 Loss: 0.012148224748671055\n",
      "Epoch: 7188 Loss: 0.012148095294833183\n",
      "Epoch: 7189 Loss: 0.012145423330366611\n",
      "Epoch: 7190 Loss: 0.01214018277823925\n",
      "Epoch: 7191 Loss: 0.01214007381349802\n",
      "Epoch: 7192 Loss: 0.012136721983551979\n",
      "Epoch: 7193 Loss: 0.012135175056755543\n",
      "Epoch: 7194 Loss: 0.012128477916121483\n",
      "Epoch: 7195 Loss: 0.012127404101192951\n",
      "Epoch: 7196 Loss: 0.012122080661356449\n",
      "Epoch: 7197 Loss: 0.0121195949614048\n",
      "Epoch: 7198 Loss: 0.012119264341890812\n",
      "Epoch: 7199 Loss: 0.012116581201553345\n",
      "Epoch: 7200 Loss: 0.012112540192902088\n",
      "Epoch: 7201 Loss: 0.012113760225474834\n",
      "Epoch: 7202 Loss: 0.012107220478355885\n",
      "Epoch: 7203 Loss: 0.01210390031337738\n",
      "Epoch: 7204 Loss: 0.012100588530302048\n",
      "Epoch: 7205 Loss: 0.01210085954517126\n",
      "Epoch: 7206 Loss: 0.012098443694412708\n",
      "Epoch: 7207 Loss: 0.012094903737306595\n",
      "Epoch: 7208 Loss: 0.012092499062418938\n",
      "Epoch: 7209 Loss: 0.012086096219718456\n",
      "Epoch: 7210 Loss: 0.012084382586181164\n",
      "Epoch: 7211 Loss: 0.012082413770258427\n",
      "Epoch: 7212 Loss: 0.012082671746611595\n",
      "Epoch: 7213 Loss: 0.012074971571564674\n",
      "Epoch: 7214 Loss: 0.01207187119871378\n",
      "Epoch: 7215 Loss: 0.012077138759195805\n",
      "Epoch: 7216 Loss: 0.012067535892128944\n",
      "Epoch: 7217 Loss: 0.012064619921147823\n",
      "Epoch: 7218 Loss: 0.01206295657902956\n",
      "Epoch: 7219 Loss: 0.012058306485414505\n",
      "Epoch: 7220 Loss: 0.012062465772032738\n",
      "Epoch: 7221 Loss: 0.012056710198521614\n",
      "Epoch: 7222 Loss: 0.012051007710397243\n",
      "Epoch: 7223 Loss: 0.01204770989716053\n",
      "Epoch: 7224 Loss: 0.012045742943882942\n",
      "Epoch: 7225 Loss: 0.012046445161104202\n",
      "Epoch: 7226 Loss: 0.01204068772494793\n",
      "Epoch: 7227 Loss: 0.012038560584187508\n",
      "Epoch: 7228 Loss: 0.01203463040292263\n",
      "Epoch: 7229 Loss: 0.012034472078084946\n",
      "Epoch: 7230 Loss: 0.012030273675918579\n",
      "Epoch: 7231 Loss: 0.012028190307319164\n",
      "Epoch: 7232 Loss: 0.0120204146951437\n",
      "Epoch: 7233 Loss: 0.012023240327835083\n",
      "Epoch: 7234 Loss: 0.012019981630146503\n",
      "Epoch: 7235 Loss: 0.012017863802611828\n",
      "Epoch: 7236 Loss: 0.012012194842100143\n",
      "Epoch: 7237 Loss: 0.01201257947832346\n",
      "Epoch: 7238 Loss: 0.012008856981992722\n",
      "Epoch: 7239 Loss: 0.012006006203591824\n",
      "Epoch: 7240 Loss: 0.012001672759652138\n",
      "Epoch: 7241 Loss: 0.011999678798019886\n",
      "Epoch: 7242 Loss: 0.011994651518762112\n",
      "Epoch: 7243 Loss: 0.01199009083211422\n",
      "Epoch: 7244 Loss: 0.011993645690381527\n",
      "Epoch: 7245 Loss: 0.011990764178335667\n",
      "Epoch: 7246 Loss: 0.011983138509094715\n",
      "Epoch: 7247 Loss: 0.011984296143054962\n",
      "Epoch: 7248 Loss: 0.011979754082858562\n",
      "Epoch: 7249 Loss: 0.011977934278547764\n",
      "Epoch: 7250 Loss: 0.011974248103797436\n",
      "Epoch: 7251 Loss: 0.011972804553806782\n",
      "Epoch: 7252 Loss: 0.011969713494181633\n",
      "Epoch: 7253 Loss: 0.01196772139519453\n",
      "Epoch: 7254 Loss: 0.011961329728364944\n",
      "Epoch: 7255 Loss: 0.011957879178225994\n",
      "Epoch: 7256 Loss: 0.011960548348724842\n",
      "Epoch: 7257 Loss: 0.011954930610954762\n",
      "Epoch: 7258 Loss: 0.011953437700867653\n",
      "Epoch: 7259 Loss: 0.011949319392442703\n",
      "Epoch: 7260 Loss: 0.011946328915655613\n",
      "Epoch: 7261 Loss: 0.011946133337914944\n",
      "Epoch: 7262 Loss: 0.011940437369048595\n",
      "Epoch: 7263 Loss: 0.011942001059651375\n",
      "Epoch: 7264 Loss: 0.0119364894926548\n",
      "Epoch: 7265 Loss: 0.011933128349483013\n",
      "Epoch: 7266 Loss: 0.01193071249872446\n",
      "Epoch: 7267 Loss: 0.011925899423658848\n",
      "Epoch: 7268 Loss: 0.011924280785024166\n",
      "Epoch: 7269 Loss: 0.011926150880753994\n",
      "Epoch: 7270 Loss: 0.011918885633349419\n",
      "Epoch: 7271 Loss: 0.01191720925271511\n",
      "Epoch: 7272 Loss: 0.011915015056729317\n",
      "Epoch: 7273 Loss: 0.011910151690244675\n",
      "Epoch: 7274 Loss: 0.011907395906746387\n",
      "Epoch: 7275 Loss: 0.011909718625247478\n",
      "Epoch: 7276 Loss: 0.011901503428816795\n",
      "Epoch: 7277 Loss: 0.01190373208373785\n",
      "Epoch: 7278 Loss: 0.011894691735506058\n",
      "Epoch: 7279 Loss: 0.01189453899860382\n",
      "Epoch: 7280 Loss: 0.011891748756170273\n",
      "Epoch: 7281 Loss: 0.011892452836036682\n",
      "Epoch: 7282 Loss: 0.01188602950423956\n",
      "Epoch: 7283 Loss: 0.011883201077580452\n",
      "Epoch: 7284 Loss: 0.011882152408361435\n",
      "Epoch: 7285 Loss: 0.011880848556756973\n",
      "Epoch: 7286 Loss: 0.011874985881149769\n",
      "Epoch: 7287 Loss: 0.011871458031237125\n",
      "Epoch: 7288 Loss: 0.011874215677380562\n",
      "Epoch: 7289 Loss: 0.011867554858326912\n",
      "Epoch: 7290 Loss: 0.01186391618102789\n",
      "Epoch: 7291 Loss: 0.011864086613059044\n",
      "Epoch: 7292 Loss: 0.01185885164886713\n",
      "Epoch: 7293 Loss: 0.011858867481350899\n",
      "Epoch: 7294 Loss: 0.011853052303195\n",
      "Epoch: 7295 Loss: 0.01185064110904932\n",
      "Epoch: 7296 Loss: 0.011846954934298992\n",
      "Epoch: 7297 Loss: 0.011849774047732353\n",
      "Epoch: 7298 Loss: 0.011845231987535954\n",
      "Epoch: 7299 Loss: 0.011841321364045143\n",
      "Epoch: 7300 Loss: 0.011836346238851547\n",
      "Epoch: 7301 Loss: 0.011834516189992428\n",
      "Epoch: 7302 Loss: 0.011835183948278427\n",
      "Epoch: 7303 Loss: 0.011830208823084831\n",
      "Epoch: 7304 Loss: 0.011824201792478561\n",
      "Epoch: 7305 Loss: 0.011825553141534328\n",
      "Epoch: 7306 Loss: 0.011824753135442734\n",
      "Epoch: 7307 Loss: 0.011818419210612774\n",
      "Epoch: 7308 Loss: 0.011817465536296368\n",
      "Epoch: 7309 Loss: 0.011812957935035229\n",
      "Epoch: 7310 Loss: 0.011811114847660065\n",
      "Epoch: 7311 Loss: 0.011806375347077847\n",
      "Epoch: 7312 Loss: 0.01180645264685154\n",
      "Epoch: 7313 Loss: 0.011803219094872475\n",
      "Epoch: 7314 Loss: 0.01180021557956934\n",
      "Epoch: 7315 Loss: 0.011796780861914158\n",
      "Epoch: 7316 Loss: 0.011796507984399796\n",
      "Epoch: 7317 Loss: 0.01179167628288269\n",
      "Epoch: 7318 Loss: 0.011790304444730282\n",
      "Epoch: 7319 Loss: 0.011783234775066376\n",
      "Epoch: 7320 Loss: 0.011783763766288757\n",
      "Epoch: 7321 Loss: 0.01178397610783577\n",
      "Epoch: 7322 Loss: 0.011776631698012352\n",
      "Epoch: 7323 Loss: 0.011774442158639431\n",
      "Epoch: 7324 Loss: 0.01177698839455843\n",
      "Epoch: 7325 Loss: 0.011772789992392063\n",
      "Epoch: 7326 Loss: 0.011767360381782055\n",
      "Epoch: 7327 Loss: 0.011766187846660614\n",
      "Epoch: 7328 Loss: 0.01176034938544035\n",
      "Epoch: 7329 Loss: 0.011759893968701363\n",
      "Epoch: 7330 Loss: 0.011755643412470818\n",
      "Epoch: 7331 Loss: 0.011751861311495304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7332 Loss: 0.011751516722142696\n",
      "Epoch: 7333 Loss: 0.011749742552638054\n",
      "Epoch: 7334 Loss: 0.01174484845250845\n",
      "Epoch: 7335 Loss: 0.011746757663786411\n",
      "Epoch: 7336 Loss: 0.011740592308342457\n",
      "Epoch: 7337 Loss: 0.011739619076251984\n",
      "Epoch: 7338 Loss: 0.011737870052456856\n",
      "Epoch: 7339 Loss: 0.011731612496078014\n",
      "Epoch: 7340 Loss: 0.011730342172086239\n",
      "Epoch: 7341 Loss: 0.011728283949196339\n",
      "Epoch: 7342 Loss: 0.011724792420864105\n",
      "Epoch: 7343 Loss: 0.01172205526381731\n",
      "Epoch: 7344 Loss: 0.01172073557972908\n",
      "Epoch: 7345 Loss: 0.01171799749135971\n",
      "Epoch: 7346 Loss: 0.01171465776860714\n",
      "Epoch: 7347 Loss: 0.011712812818586826\n",
      "Epoch: 7348 Loss: 0.011710315942764282\n",
      "Epoch: 7349 Loss: 0.011705719865858555\n",
      "Epoch: 7350 Loss: 0.011704226024448872\n",
      "Epoch: 7351 Loss: 0.011701486073434353\n",
      "Epoch: 7352 Loss: 0.011697920970618725\n",
      "Epoch: 7353 Loss: 0.011694717220962048\n",
      "Epoch: 7354 Loss: 0.011693190783262253\n",
      "Epoch: 7355 Loss: 0.011689376085996628\n",
      "Epoch: 7356 Loss: 0.011692219413816929\n",
      "Epoch: 7357 Loss: 0.011685004457831383\n",
      "Epoch: 7358 Loss: 0.01168470922857523\n",
      "Epoch: 7359 Loss: 0.011678255163133144\n",
      "Epoch: 7360 Loss: 0.01167667843401432\n",
      "Epoch: 7361 Loss: 0.011674950830638409\n",
      "Epoch: 7362 Loss: 0.011673427186906338\n",
      "Epoch: 7363 Loss: 0.011667079292237759\n",
      "Epoch: 7364 Loss: 0.011666412465274334\n",
      "Epoch: 7365 Loss: 0.011665580794215202\n",
      "Epoch: 7366 Loss: 0.011657800525426865\n",
      "Epoch: 7367 Loss: 0.011658703908324242\n",
      "Epoch: 7368 Loss: 0.011659955605864525\n",
      "Epoch: 7369 Loss: 0.011652753688395023\n",
      "Epoch: 7370 Loss: 0.011650499887764454\n",
      "Epoch: 7371 Loss: 0.011647828854620457\n",
      "Epoch: 7372 Loss: 0.011644992046058178\n",
      "Epoch: 7373 Loss: 0.011646447703242302\n",
      "Epoch: 7374 Loss: 0.011639782227575779\n",
      "Epoch: 7375 Loss: 0.01163798663765192\n",
      "Epoch: 7376 Loss: 0.011637479066848755\n",
      "Epoch: 7377 Loss: 0.011629153043031693\n",
      "Epoch: 7378 Loss: 0.011630424298346043\n",
      "Epoch: 7379 Loss: 0.011626657098531723\n",
      "Epoch: 7380 Loss: 0.01162468921393156\n",
      "Epoch: 7381 Loss: 0.011622746475040913\n",
      "Epoch: 7382 Loss: 0.0116190854460001\n",
      "Epoch: 7383 Loss: 0.01161630917340517\n",
      "Epoch: 7384 Loss: 0.011612527072429657\n",
      "Epoch: 7385 Loss: 0.011608844622969627\n",
      "Epoch: 7386 Loss: 0.011608892120420933\n",
      "Epoch: 7387 Loss: 0.01160504762083292\n",
      "Epoch: 7388 Loss: 0.011603830382227898\n",
      "Epoch: 7389 Loss: 0.011603111401200294\n",
      "Epoch: 7390 Loss: 0.011598814278841019\n",
      "Epoch: 7391 Loss: 0.011595971882343292\n",
      "Epoch: 7392 Loss: 0.0115911103785038\n",
      "Epoch: 7393 Loss: 0.011588744819164276\n",
      "Epoch: 7394 Loss: 0.011591662652790546\n",
      "Epoch: 7395 Loss: 0.011584530584514141\n",
      "Epoch: 7396 Loss: 0.011582276783883572\n",
      "Epoch: 7397 Loss: 0.011579775251448154\n",
      "Epoch: 7398 Loss: 0.011578559875488281\n",
      "Epoch: 7399 Loss: 0.011574522592127323\n",
      "Epoch: 7400 Loss: 0.011571267619729042\n",
      "Epoch: 7401 Loss: 0.011569609865546227\n",
      "Epoch: 7402 Loss: 0.011567764915525913\n",
      "Epoch: 7403 Loss: 0.011565349996089935\n",
      "Epoch: 7404 Loss: 0.0115595618262887\n",
      "Epoch: 7405 Loss: 0.011558293364942074\n",
      "Epoch: 7406 Loss: 0.011557498015463352\n",
      "Epoch: 7407 Loss: 0.011553955264389515\n",
      "Epoch: 7408 Loss: 0.011550710536539555\n",
      "Epoch: 7409 Loss: 0.011546971276402473\n",
      "Epoch: 7410 Loss: 0.01154353003948927\n",
      "Epoch: 7411 Loss: 0.011545905843377113\n",
      "Epoch: 7412 Loss: 0.011542090214788914\n",
      "Epoch: 7413 Loss: 0.011539604514837265\n",
      "Epoch: 7414 Loss: 0.011538241058588028\n",
      "Epoch: 7415 Loss: 0.01153364684432745\n",
      "Epoch: 7416 Loss: 0.011529035866260529\n",
      "Epoch: 7417 Loss: 0.011527277529239655\n",
      "Epoch: 7418 Loss: 0.011523363180458546\n",
      "Epoch: 7419 Loss: 0.011526281014084816\n",
      "Epoch: 7420 Loss: 0.011520029045641422\n",
      "Epoch: 7421 Loss: 0.011516467668116093\n",
      "Epoch: 7422 Loss: 0.011514880694448948\n",
      "Epoch: 7423 Loss: 0.011511591263115406\n",
      "Epoch: 7424 Loss: 0.011511175893247128\n",
      "Epoch: 7425 Loss: 0.011507513001561165\n",
      "Epoch: 7426 Loss: 0.011503927409648895\n",
      "Epoch: 7427 Loss: 0.011502820067107677\n",
      "Epoch: 7428 Loss: 0.011499067768454552\n",
      "Epoch: 7429 Loss: 0.011498738080263138\n",
      "Epoch: 7430 Loss: 0.011494639329612255\n",
      "Epoch: 7431 Loss: 0.011491402052342892\n",
      "Epoch: 7432 Loss: 0.011492348276078701\n",
      "Epoch: 7433 Loss: 0.011486991308629513\n",
      "Epoch: 7434 Loss: 0.011481952853500843\n",
      "Epoch: 7435 Loss: 0.011480037122964859\n",
      "Epoch: 7436 Loss: 0.011476268991827965\n",
      "Epoch: 7437 Loss: 0.011479527689516544\n",
      "Epoch: 7438 Loss: 0.011473236605525017\n",
      "Epoch: 7439 Loss: 0.01147427037358284\n",
      "Epoch: 7440 Loss: 0.011469634249806404\n",
      "Epoch: 7441 Loss: 0.01146659441292286\n",
      "Epoch: 7442 Loss: 0.011463356204330921\n",
      "Epoch: 7443 Loss: 0.011461272835731506\n",
      "Epoch: 7444 Loss: 0.011460375972092152\n",
      "Epoch: 7445 Loss: 0.011455127969384193\n",
      "Epoch: 7446 Loss: 0.01145394891500473\n",
      "Epoch: 7447 Loss: 0.011451405473053455\n",
      "Epoch: 7448 Loss: 0.011448243632912636\n",
      "Epoch: 7449 Loss: 0.011448320932686329\n",
      "Epoch: 7450 Loss: 0.01144348457455635\n",
      "Epoch: 7451 Loss: 0.01143997348845005\n",
      "Epoch: 7452 Loss: 0.011439689435064793\n",
      "Epoch: 7453 Loss: 0.011436586268246174\n",
      "Epoch: 7454 Loss: 0.0114326486364007\n",
      "Epoch: 7455 Loss: 0.011432995088398457\n",
      "Epoch: 7456 Loss: 0.011428053490817547\n",
      "Epoch: 7457 Loss: 0.011426473036408424\n",
      "Epoch: 7458 Loss: 0.011421618051826954\n",
      "Epoch: 7459 Loss: 0.011420589871704578\n",
      "Epoch: 7460 Loss: 0.011418505571782589\n",
      "Epoch: 7461 Loss: 0.011414332315325737\n",
      "Epoch: 7462 Loss: 0.011412475258111954\n",
      "Epoch: 7463 Loss: 0.011412621475756168\n",
      "Epoch: 7464 Loss: 0.011409238912165165\n",
      "Epoch: 7465 Loss: 0.011406074278056622\n",
      "Epoch: 7466 Loss: 0.011404392309486866\n",
      "Epoch: 7467 Loss: 0.011399228125810623\n",
      "Epoch: 7468 Loss: 0.011397629044950008\n",
      "Epoch: 7469 Loss: 0.011395024135708809\n",
      "Epoch: 7470 Loss: 0.011390648782253265\n",
      "Epoch: 7471 Loss: 0.011392057873308659\n",
      "Epoch: 7472 Loss: 0.011387745849788189\n",
      "Epoch: 7473 Loss: 0.011386128142476082\n",
      "Epoch: 7474 Loss: 0.01138282474130392\n",
      "Epoch: 7475 Loss: 0.01137964241206646\n",
      "Epoch: 7476 Loss: 0.011375815607607365\n",
      "Epoch: 7477 Loss: 0.01137660164386034\n",
      "Epoch: 7478 Loss: 0.011374331079423428\n",
      "Epoch: 7479 Loss: 0.011370825581252575\n",
      "Epoch: 7480 Loss: 0.01136819552630186\n",
      "Epoch: 7481 Loss: 0.011364102363586426\n",
      "Epoch: 7482 Loss: 0.011362230405211449\n",
      "Epoch: 7483 Loss: 0.011360231786966324\n",
      "Epoch: 7484 Loss: 0.011355504393577576\n",
      "Epoch: 7485 Loss: 0.011353659443557262\n",
      "Epoch: 7486 Loss: 0.011352472007274628\n",
      "Epoch: 7487 Loss: 0.011349476873874664\n",
      "Epoch: 7488 Loss: 0.011346710845828056\n",
      "Epoch: 7489 Loss: 0.011345867067575455\n",
      "Epoch: 7490 Loss: 0.011342806741595268\n",
      "Epoch: 7491 Loss: 0.011340197175741196\n",
      "Epoch: 7492 Loss: 0.011335073970258236\n",
      "Epoch: 7493 Loss: 0.011334337294101715\n",
      "Epoch: 7494 Loss: 0.011332417838275433\n",
      "Epoch: 7495 Loss: 0.011329411529004574\n",
      "Epoch: 7496 Loss: 0.0113268056884408\n",
      "Epoch: 7497 Loss: 0.011321560479700565\n",
      "Epoch: 7498 Loss: 0.011322221718728542\n",
      "Epoch: 7499 Loss: 0.011321098543703556\n",
      "Epoch: 7500 Loss: 0.011316309683024883\n",
      "Epoch: 7501 Loss: 0.011317150667309761\n",
      "Epoch: 7502 Loss: 0.011313799768686295\n",
      "Epoch: 7503 Loss: 0.011309206485748291\n",
      "Epoch: 7504 Loss: 0.011308690533041954\n",
      "Epoch: 7505 Loss: 0.011305765248835087\n",
      "Epoch: 7506 Loss: 0.011300782673060894\n",
      "Epoch: 7507 Loss: 0.011299427598714828\n",
      "Epoch: 7508 Loss: 0.01129868347197771\n",
      "Epoch: 7509 Loss: 0.011294763535261154\n",
      "Epoch: 7510 Loss: 0.011290780268609524\n",
      "Epoch: 7511 Loss: 0.011290003545582294\n",
      "Epoch: 7512 Loss: 0.011287081986665726\n",
      "Epoch: 7513 Loss: 0.011284706182777882\n",
      "Epoch: 7514 Loss: 0.011282544583082199\n",
      "Epoch: 7515 Loss: 0.01128164492547512\n",
      "Epoch: 7516 Loss: 0.011276258155703545\n",
      "Epoch: 7517 Loss: 0.011275038123130798\n",
      "Epoch: 7518 Loss: 0.011271845549345016\n",
      "Epoch: 7519 Loss: 0.011269938200712204\n",
      "Epoch: 7520 Loss: 0.011268040165305138\n",
      "Epoch: 7521 Loss: 0.011262993328273296\n",
      "Epoch: 7522 Loss: 0.011262882500886917\n",
      "Epoch: 7523 Loss: 0.011259173043072224\n",
      "Epoch: 7524 Loss: 0.011258476413786411\n",
      "Epoch: 7525 Loss: 0.011256287805736065\n",
      "Epoch: 7526 Loss: 0.011254295706748962\n",
      "Epoch: 7527 Loss: 0.011249530129134655\n",
      "Epoch: 7528 Loss: 0.011246532201766968\n",
      "Epoch: 7529 Loss: 0.011243566870689392\n",
      "Epoch: 7530 Loss: 0.011241462081670761\n",
      "Epoch: 7531 Loss: 0.011242185719311237\n",
      "Epoch: 7532 Loss: 0.011240021325647831\n",
      "Epoch: 7533 Loss: 0.011235613375902176\n",
      "Epoch: 7534 Loss: 0.011233005672693253\n",
      "Epoch: 7535 Loss: 0.011231270618736744\n",
      "Epoch: 7536 Loss: 0.011225772090256214\n",
      "Epoch: 7537 Loss: 0.011227180249989033\n",
      "Epoch: 7538 Loss: 0.01122117880731821\n",
      "Epoch: 7539 Loss: 0.011219460517168045\n",
      "Epoch: 7540 Loss: 0.011220669373869896\n",
      "Epoch: 7541 Loss: 0.011215560138225555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7542 Loss: 0.011211843229830265\n",
      "Epoch: 7543 Loss: 0.011212269775569439\n",
      "Epoch: 7544 Loss: 0.01120558101683855\n",
      "Epoch: 7545 Loss: 0.011205676943063736\n",
      "Epoch: 7546 Loss: 0.011202927678823471\n",
      "Epoch: 7547 Loss: 0.011200660839676857\n",
      "Epoch: 7548 Loss: 0.011197700165212154\n",
      "Epoch: 7549 Loss: 0.011198450811207294\n",
      "Epoch: 7550 Loss: 0.011193188838660717\n",
      "Epoch: 7551 Loss: 0.011190082877874374\n",
      "Epoch: 7552 Loss: 0.011188091710209846\n",
      "Epoch: 7553 Loss: 0.011184507049620152\n",
      "Epoch: 7554 Loss: 0.01118476502597332\n",
      "Epoch: 7555 Loss: 0.011182622984051704\n",
      "Epoch: 7556 Loss: 0.011176747269928455\n",
      "Epoch: 7557 Loss: 0.011175629682838917\n",
      "Epoch: 7558 Loss: 0.011172179132699966\n",
      "Epoch: 7559 Loss: 0.011173378676176071\n",
      "Epoch: 7560 Loss: 0.011167734861373901\n",
      "Epoch: 7561 Loss: 0.011166310869157314\n",
      "Epoch: 7562 Loss: 0.011162039823830128\n",
      "Epoch: 7563 Loss: 0.011161628179252148\n",
      "Epoch: 7564 Loss: 0.011159946210682392\n",
      "Epoch: 7565 Loss: 0.011155006475746632\n",
      "Epoch: 7566 Loss: 0.0111548388376832\n",
      "Epoch: 7567 Loss: 0.011152147315442562\n",
      "Epoch: 7568 Loss: 0.011148436926305294\n",
      "Epoch: 7569 Loss: 0.011147775687277317\n",
      "Epoch: 7570 Loss: 0.011144602671265602\n",
      "Epoch: 7571 Loss: 0.011141793802380562\n",
      "Epoch: 7572 Loss: 0.011138605885207653\n",
      "Epoch: 7573 Loss: 0.011137695983052254\n",
      "Epoch: 7574 Loss: 0.011133314110338688\n",
      "Epoch: 7575 Loss: 0.01113064493983984\n",
      "Epoch: 7576 Loss: 0.011131799779832363\n",
      "Epoch: 7577 Loss: 0.01112736389040947\n",
      "Epoch: 7578 Loss: 0.011124570854008198\n",
      "Epoch: 7579 Loss: 0.011121761053800583\n",
      "Epoch: 7580 Loss: 0.011120333336293697\n",
      "Epoch: 7581 Loss: 0.011120682582259178\n",
      "Epoch: 7582 Loss: 0.011114259250462055\n",
      "Epoch: 7583 Loss: 0.011116063222289085\n",
      "Epoch: 7584 Loss: 0.011109654791653156\n",
      "Epoch: 7585 Loss: 0.011108973994851112\n",
      "Epoch: 7586 Loss: 0.01110590435564518\n",
      "Epoch: 7587 Loss: 0.01110411249101162\n",
      "Epoch: 7588 Loss: 0.011098576709628105\n",
      "Epoch: 7589 Loss: 0.011098140850663185\n",
      "Epoch: 7590 Loss: 0.011098073795437813\n",
      "Epoch: 7591 Loss: 0.01109461858868599\n",
      "Epoch: 7592 Loss: 0.011091344989836216\n",
      "Epoch: 7593 Loss: 0.011088395491242409\n",
      "Epoch: 7594 Loss: 0.011085476726293564\n",
      "Epoch: 7595 Loss: 0.011084857396781445\n",
      "Epoch: 7596 Loss: 0.011081610806286335\n",
      "Epoch: 7597 Loss: 0.011079752817749977\n",
      "Epoch: 7598 Loss: 0.01107794139534235\n",
      "Epoch: 7599 Loss: 0.011072803288698196\n",
      "Epoch: 7600 Loss: 0.011071416549384594\n",
      "Epoch: 7601 Loss: 0.011069731786847115\n",
      "Epoch: 7602 Loss: 0.011068268679082394\n",
      "Epoch: 7603 Loss: 0.011064027436077595\n",
      "Epoch: 7604 Loss: 0.011061281897127628\n",
      "Epoch: 7605 Loss: 0.011060950346291065\n",
      "Epoch: 7606 Loss: 0.011057407595217228\n",
      "Epoch: 7607 Loss: 0.011054866015911102\n",
      "Epoch: 7608 Loss: 0.011053026653826237\n",
      "Epoch: 7609 Loss: 0.01104940939694643\n",
      "Epoch: 7610 Loss: 0.011049098335206509\n",
      "Epoch: 7611 Loss: 0.011046675965189934\n",
      "Epoch: 7612 Loss: 0.01104412879794836\n",
      "Epoch: 7613 Loss: 0.011042478494346142\n",
      "Epoch: 7614 Loss: 0.01103909406810999\n",
      "Epoch: 7615 Loss: 0.011033757589757442\n",
      "Epoch: 7616 Loss: 0.011032248847186565\n",
      "Epoch: 7617 Loss: 0.011034112423658371\n",
      "Epoch: 7618 Loss: 0.011027047410607338\n",
      "Epoch: 7619 Loss: 0.011028261855244637\n",
      "Epoch: 7620 Loss: 0.011024309322237968\n",
      "Epoch: 7621 Loss: 0.01102366391569376\n",
      "Epoch: 7622 Loss: 0.011019183322787285\n",
      "Epoch: 7623 Loss: 0.011016542091965675\n",
      "Epoch: 7624 Loss: 0.01101505197584629\n",
      "Epoch: 7625 Loss: 0.011015630327165127\n",
      "Epoch: 7626 Loss: 0.011009609326720238\n",
      "Epoch: 7627 Loss: 0.011007281020283699\n",
      "Epoch: 7628 Loss: 0.011005152016878128\n",
      "Epoch: 7629 Loss: 0.011002260260283947\n",
      "Epoch: 7630 Loss: 0.011000511236488819\n",
      "Epoch: 7631 Loss: 0.010997290723025799\n",
      "Epoch: 7632 Loss: 0.010995080694556236\n",
      "Epoch: 7633 Loss: 0.010992378927767277\n",
      "Epoch: 7634 Loss: 0.010990217328071594\n",
      "Epoch: 7635 Loss: 0.010989128611981869\n",
      "Epoch: 7636 Loss: 0.010988556779921055\n",
      "Epoch: 7637 Loss: 0.010981976054608822\n",
      "Epoch: 7638 Loss: 0.010982919484376907\n",
      "Epoch: 7639 Loss: 0.01097816787660122\n",
      "Epoch: 7640 Loss: 0.010974655859172344\n",
      "Epoch: 7641 Loss: 0.010974951088428497\n",
      "Epoch: 7642 Loss: 0.010972561314702034\n",
      "Epoch: 7643 Loss: 0.010967460460960865\n",
      "Epoch: 7644 Loss: 0.0109659219160676\n",
      "Epoch: 7645 Loss: 0.01096551027148962\n",
      "Epoch: 7646 Loss: 0.010961604304611683\n",
      "Epoch: 7647 Loss: 0.010960251092910767\n",
      "Epoch: 7648 Loss: 0.010955129750072956\n",
      "Epoch: 7649 Loss: 0.010952724143862724\n",
      "Epoch: 7650 Loss: 0.010954080149531364\n",
      "Epoch: 7651 Loss: 0.010952687822282314\n",
      "Epoch: 7652 Loss: 0.010948287323117256\n",
      "Epoch: 7653 Loss: 0.010945622809231281\n",
      "Epoch: 7654 Loss: 0.010940196923911572\n",
      "Epoch: 7655 Loss: 0.010940708220005035\n",
      "Epoch: 7656 Loss: 0.010938425548374653\n",
      "Epoch: 7657 Loss: 0.010934322141110897\n",
      "Epoch: 7658 Loss: 0.010931949131190777\n",
      "Epoch: 7659 Loss: 0.010929797776043415\n",
      "Epoch: 7660 Loss: 0.010928679257631302\n",
      "Epoch: 7661 Loss: 0.010925930924713612\n",
      "Epoch: 7662 Loss: 0.010921758599579334\n",
      "Epoch: 7663 Loss: 0.01092066615819931\n",
      "Epoch: 7664 Loss: 0.010918821208178997\n",
      "Epoch: 7665 Loss: 0.01091743540018797\n",
      "Epoch: 7666 Loss: 0.010913706384599209\n",
      "Epoch: 7667 Loss: 0.010911723598837852\n",
      "Epoch: 7668 Loss: 0.010910051874816418\n",
      "Epoch: 7669 Loss: 0.010905677452683449\n",
      "Epoch: 7670 Loss: 0.010903979651629925\n",
      "Epoch: 7671 Loss: 0.010902035050094128\n",
      "Epoch: 7672 Loss: 0.010900872759521008\n",
      "Epoch: 7673 Loss: 0.01089496724307537\n",
      "Epoch: 7674 Loss: 0.010893489234149456\n",
      "Epoch: 7675 Loss: 0.0108918696641922\n",
      "Epoch: 7676 Loss: 0.010889292694628239\n",
      "Epoch: 7677 Loss: 0.010885920375585556\n",
      "Epoch: 7678 Loss: 0.010887127369642258\n",
      "Epoch: 7679 Loss: 0.010882855392992496\n",
      "Epoch: 7680 Loss: 0.010882880538702011\n",
      "Epoch: 7681 Loss: 0.0108764274045825\n",
      "Epoch: 7682 Loss: 0.01087704487144947\n",
      "Epoch: 7683 Loss: 0.010872756130993366\n",
      "Epoch: 7684 Loss: 0.010871081613004208\n",
      "Epoch: 7685 Loss: 0.010870366357266903\n",
      "Epoch: 7686 Loss: 0.010865421034395695\n",
      "Epoch: 7687 Loss: 0.010866005904972553\n",
      "Epoch: 7688 Loss: 0.010860179550945759\n",
      "Epoch: 7689 Loss: 0.010859766975045204\n",
      "Epoch: 7690 Loss: 0.010856780223548412\n",
      "Epoch: 7691 Loss: 0.010854387655854225\n",
      "Epoch: 7692 Loss: 0.010849414393305779\n",
      "Epoch: 7693 Loss: 0.010848790407180786\n",
      "Epoch: 7694 Loss: 0.01084625069051981\n",
      "Epoch: 7695 Loss: 0.010846156626939774\n",
      "Epoch: 7696 Loss: 0.010842001996934414\n",
      "Epoch: 7697 Loss: 0.01083889789879322\n",
      "Epoch: 7698 Loss: 0.010837385430932045\n",
      "Epoch: 7699 Loss: 0.010836894623935223\n",
      "Epoch: 7700 Loss: 0.010831463150680065\n",
      "Epoch: 7701 Loss: 0.010829012840986252\n",
      "Epoch: 7702 Loss: 0.010830545797944069\n",
      "Epoch: 7703 Loss: 0.010824344120919704\n",
      "Epoch: 7704 Loss: 0.010824284516274929\n",
      "Epoch: 7705 Loss: 0.010821647942066193\n",
      "Epoch: 7706 Loss: 0.010819130577147007\n",
      "Epoch: 7707 Loss: 0.01081487163901329\n",
      "Epoch: 7708 Loss: 0.010812437161803246\n",
      "Epoch: 7709 Loss: 0.010813313536345959\n",
      "Epoch: 7710 Loss: 0.010809692554175854\n",
      "Epoch: 7711 Loss: 0.010805915109813213\n",
      "Epoch: 7712 Loss: 0.010805116966366768\n",
      "Epoch: 7713 Loss: 0.010801571421325207\n",
      "Epoch: 7714 Loss: 0.010798734612762928\n",
      "Epoch: 7715 Loss: 0.010798148810863495\n",
      "Epoch: 7716 Loss: 0.010798951610922813\n",
      "Epoch: 7717 Loss: 0.010793483816087246\n",
      "Epoch: 7718 Loss: 0.010788834653794765\n",
      "Epoch: 7719 Loss: 0.010789942927658558\n",
      "Epoch: 7720 Loss: 0.01078565139323473\n",
      "Epoch: 7721 Loss: 0.010783940553665161\n",
      "Epoch: 7722 Loss: 0.010778884403407574\n",
      "Epoch: 7723 Loss: 0.010781336575746536\n",
      "Epoch: 7724 Loss: 0.010777654126286507\n",
      "Epoch: 7725 Loss: 0.010774546302855015\n",
      "Epoch: 7726 Loss: 0.010771647095680237\n",
      "Epoch: 7727 Loss: 0.010769760236144066\n",
      "Epoch: 7728 Loss: 0.010769037529826164\n",
      "Epoch: 7729 Loss: 0.010763907805085182\n",
      "Epoch: 7730 Loss: 0.010760893113911152\n",
      "Epoch: 7731 Loss: 0.010759048163890839\n",
      "Epoch: 7732 Loss: 0.01075785979628563\n",
      "Epoch: 7733 Loss: 0.010756445117294788\n",
      "Epoch: 7734 Loss: 0.01075312215834856\n",
      "Epoch: 7735 Loss: 0.010753241367638111\n",
      "Epoch: 7736 Loss: 0.010747787542641163\n",
      "Epoch: 7737 Loss: 0.010746118612587452\n",
      "Epoch: 7738 Loss: 0.010742687620222569\n",
      "Epoch: 7739 Loss: 0.010742533020675182\n",
      "Epoch: 7740 Loss: 0.010739648714661598\n",
      "Epoch: 7741 Loss: 0.010736874304711819\n",
      "Epoch: 7742 Loss: 0.01073478627949953\n",
      "Epoch: 7743 Loss: 0.010732890106737614\n",
      "Epoch: 7744 Loss: 0.010729101486504078\n",
      "Epoch: 7745 Loss: 0.010728716850280762\n",
      "Epoch: 7746 Loss: 0.010727683082222939\n",
      "Epoch: 7747 Loss: 0.010722622275352478\n",
      "Epoch: 7748 Loss: 0.010720746591687202\n",
      "Epoch: 7749 Loss: 0.010720664635300636\n",
      "Epoch: 7750 Loss: 0.010715972632169724\n",
      "Epoch: 7751 Loss: 0.010712280869483948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7752 Loss: 0.01071358472108841\n",
      "Epoch: 7753 Loss: 0.010709492489695549\n",
      "Epoch: 7754 Loss: 0.010707016102969646\n",
      "Epoch: 7755 Loss: 0.0107034957036376\n",
      "Epoch: 7756 Loss: 0.010702506639063358\n",
      "Epoch: 7757 Loss: 0.01070021279156208\n",
      "Epoch: 7758 Loss: 0.010701454244554043\n",
      "Epoch: 7759 Loss: 0.0106947747990489\n",
      "Epoch: 7760 Loss: 0.010692443698644638\n",
      "Epoch: 7761 Loss: 0.010692368261516094\n",
      "Epoch: 7762 Loss: 0.010689185000956059\n",
      "Epoch: 7763 Loss: 0.010687173344194889\n",
      "Epoch: 7764 Loss: 0.010682260617613792\n",
      "Epoch: 7765 Loss: 0.010682106018066406\n",
      "Epoch: 7766 Loss: 0.010679584927856922\n",
      "Epoch: 7767 Loss: 0.01067686453461647\n",
      "Epoch: 7768 Loss: 0.010676591657102108\n",
      "Epoch: 7769 Loss: 0.01067190058529377\n",
      "Epoch: 7770 Loss: 0.010670258663594723\n",
      "Epoch: 7771 Loss: 0.01067042350769043\n",
      "Epoch: 7772 Loss: 0.010665043257176876\n",
      "Epoch: 7773 Loss: 0.010662705637514591\n",
      "Epoch: 7774 Loss: 0.010659780353307724\n",
      "Epoch: 7775 Loss: 0.010659157298505306\n",
      "Epoch: 7776 Loss: 0.010658832266926765\n",
      "Epoch: 7777 Loss: 0.010653558187186718\n",
      "Epoch: 7778 Loss: 0.010654183104634285\n",
      "Epoch: 7779 Loss: 0.010648874565958977\n",
      "Epoch: 7780 Loss: 0.010648252442479134\n",
      "Epoch: 7781 Loss: 0.010645736008882523\n",
      "Epoch: 7782 Loss: 0.010642609558999538\n",
      "Epoch: 7783 Loss: 0.010639026761054993\n",
      "Epoch: 7784 Loss: 0.010635984130203724\n",
      "Epoch: 7785 Loss: 0.010636072605848312\n",
      "Epoch: 7786 Loss: 0.010632629506289959\n",
      "Epoch: 7787 Loss: 0.010632402263581753\n",
      "Epoch: 7788 Loss: 0.010627888143062592\n",
      "Epoch: 7789 Loss: 0.010627370327711105\n",
      "Epoch: 7790 Loss: 0.010624488815665245\n",
      "Epoch: 7791 Loss: 0.010622077621519566\n",
      "Epoch: 7792 Loss: 0.010620065964758396\n",
      "Epoch: 7793 Loss: 0.010617310181260109\n",
      "Epoch: 7794 Loss: 0.010615489445626736\n",
      "Epoch: 7795 Loss: 0.010612236335873604\n",
      "Epoch: 7796 Loss: 0.010612410493195057\n",
      "Epoch: 7797 Loss: 0.010607068426907063\n",
      "Epoch: 7798 Loss: 0.010606556199491024\n",
      "Epoch: 7799 Loss: 0.010604854673147202\n",
      "Epoch: 7800 Loss: 0.010600855574011803\n",
      "Epoch: 7801 Loss: 0.010602590627968311\n",
      "Epoch: 7802 Loss: 0.010597648099064827\n",
      "Epoch: 7803 Loss: 0.01059548370540142\n",
      "Epoch: 7804 Loss: 0.01059652492403984\n",
      "Epoch: 7805 Loss: 0.010590847581624985\n",
      "Epoch: 7806 Loss: 0.01058775931596756\n",
      "Epoch: 7807 Loss: 0.010587042197585106\n",
      "Epoch: 7808 Loss: 0.010584976524114609\n",
      "Epoch: 7809 Loss: 0.010581335052847862\n",
      "Epoch: 7810 Loss: 0.01058039627969265\n",
      "Epoch: 7811 Loss: 0.010576016269624233\n",
      "Epoch: 7812 Loss: 0.010577152483165264\n",
      "Epoch: 7813 Loss: 0.010572247207164764\n",
      "Epoch: 7814 Loss: 0.0105697400867939\n",
      "Epoch: 7815 Loss: 0.010567530058324337\n",
      "Epoch: 7816 Loss: 0.010565510019659996\n",
      "Epoch: 7817 Loss: 0.01056446973234415\n",
      "Epoch: 7818 Loss: 0.010562039911746979\n",
      "Epoch: 7819 Loss: 0.010559079237282276\n",
      "Epoch: 7820 Loss: 0.010557886213064194\n",
      "Epoch: 7821 Loss: 0.010554964654147625\n",
      "Epoch: 7822 Loss: 0.010553867556154728\n",
      "Epoch: 7823 Loss: 0.010550965555012226\n",
      "Epoch: 7824 Loss: 0.010547351092100143\n",
      "Epoch: 7825 Loss: 0.01054676715284586\n",
      "Epoch: 7826 Loss: 0.010542104952037334\n",
      "Epoch: 7827 Loss: 0.010541785508394241\n",
      "Epoch: 7828 Loss: 0.010539622977375984\n",
      "Epoch: 7829 Loss: 0.010537030175328255\n",
      "Epoch: 7830 Loss: 0.01053375843912363\n",
      "Epoch: 7831 Loss: 0.010532522574067116\n",
      "Epoch: 7832 Loss: 0.010531168431043625\n",
      "Epoch: 7833 Loss: 0.010528281331062317\n",
      "Epoch: 7834 Loss: 0.010525691322982311\n",
      "Epoch: 7835 Loss: 0.010523042641580105\n",
      "Epoch: 7836 Loss: 0.010522977448999882\n",
      "Epoch: 7837 Loss: 0.010519123636186123\n",
      "Epoch: 7838 Loss: 0.010514970868825912\n",
      "Epoch: 7839 Loss: 0.010515292175114155\n",
      "Epoch: 7840 Loss: 0.010514545254409313\n",
      "Epoch: 7841 Loss: 0.010509154759347439\n",
      "Epoch: 7842 Loss: 0.01051015593111515\n",
      "Epoch: 7843 Loss: 0.010504298843443394\n",
      "Epoch: 7844 Loss: 0.010502530261874199\n",
      "Epoch: 7845 Loss: 0.010501918382942677\n",
      "Epoch: 7846 Loss: 0.010500306263566017\n",
      "Epoch: 7847 Loss: 0.01049569621682167\n",
      "Epoch: 7848 Loss: 0.010496670380234718\n",
      "Epoch: 7849 Loss: 0.010491618886590004\n",
      "Epoch: 7850 Loss: 0.010488549247384071\n",
      "Epoch: 7851 Loss: 0.010488595813512802\n",
      "Epoch: 7852 Loss: 0.010485886596143246\n",
      "Epoch: 7853 Loss: 0.010484734550118446\n",
      "Epoch: 7854 Loss: 0.010479571297764778\n",
      "Epoch: 7855 Loss: 0.010479864664375782\n",
      "Epoch: 7856 Loss: 0.010476994328200817\n",
      "Epoch: 7857 Loss: 0.010475625284016132\n",
      "Epoch: 7858 Loss: 0.010472879745066166\n",
      "Epoch: 7859 Loss: 0.010470387525856495\n",
      "Epoch: 7860 Loss: 0.010467602871358395\n",
      "Epoch: 7861 Loss: 0.01046585850417614\n",
      "Epoch: 7862 Loss: 0.010464847087860107\n",
      "Epoch: 7863 Loss: 0.010459944605827332\n",
      "Epoch: 7864 Loss: 0.010459785349667072\n",
      "Epoch: 7865 Loss: 0.010457235388457775\n",
      "Epoch: 7866 Loss: 0.010454383678734303\n",
      "Epoch: 7867 Loss: 0.01045367494225502\n",
      "Epoch: 7868 Loss: 0.010448501445353031\n",
      "Epoch: 7869 Loss: 0.010450059548020363\n",
      "Epoch: 7870 Loss: 0.0104452446103096\n",
      "Epoch: 7871 Loss: 0.010445451363921165\n",
      "Epoch: 7872 Loss: 0.010441765189170837\n",
      "Epoch: 7873 Loss: 0.010441821999847889\n",
      "Epoch: 7874 Loss: 0.01043648924678564\n",
      "Epoch: 7875 Loss: 0.010434746742248535\n",
      "Epoch: 7876 Loss: 0.01043264102190733\n",
      "Epoch: 7877 Loss: 0.01043002214282751\n",
      "Epoch: 7878 Loss: 0.010430574417114258\n",
      "Epoch: 7879 Loss: 0.010425945743918419\n",
      "Epoch: 7880 Loss: 0.010424015112221241\n",
      "Epoch: 7881 Loss: 0.010424657724797726\n",
      "Epoch: 7882 Loss: 0.010419711470603943\n",
      "Epoch: 7883 Loss: 0.010418063960969448\n",
      "Epoch: 7884 Loss: 0.010414743795990944\n",
      "Epoch: 7885 Loss: 0.010413741692900658\n",
      "Epoch: 7886 Loss: 0.010413062758743763\n",
      "Epoch: 7887 Loss: 0.01040692813694477\n",
      "Epoch: 7888 Loss: 0.010407124646008015\n",
      "Epoch: 7889 Loss: 0.01040542870759964\n",
      "Epoch: 7890 Loss: 0.010400506667792797\n",
      "Epoch: 7891 Loss: 0.01039956696331501\n",
      "Epoch: 7892 Loss: 0.010397352278232574\n",
      "Epoch: 7893 Loss: 0.010396520607173443\n",
      "Epoch: 7894 Loss: 0.010395609773695469\n",
      "Epoch: 7895 Loss: 0.010393286123871803\n",
      "Epoch: 7896 Loss: 0.010389026254415512\n",
      "Epoch: 7897 Loss: 0.010389596223831177\n",
      "Epoch: 7898 Loss: 0.010385215282440186\n",
      "Epoch: 7899 Loss: 0.010383620858192444\n",
      "Epoch: 7900 Loss: 0.010381188243627548\n",
      "Epoch: 7901 Loss: 0.010377191938459873\n",
      "Epoch: 7902 Loss: 0.010376869700849056\n",
      "Epoch: 7903 Loss: 0.010374198667705059\n",
      "Epoch: 7904 Loss: 0.010372416116297245\n",
      "Epoch: 7905 Loss: 0.010369584895670414\n",
      "Epoch: 7906 Loss: 0.01036795973777771\n",
      "Epoch: 7907 Loss: 0.010367144830524921\n",
      "Epoch: 7908 Loss: 0.010363643988966942\n",
      "Epoch: 7909 Loss: 0.01035955362021923\n",
      "Epoch: 7910 Loss: 0.010358878411352634\n",
      "Epoch: 7911 Loss: 0.01035916619002819\n",
      "Epoch: 7912 Loss: 0.0103557538241148\n",
      "Epoch: 7913 Loss: 0.010352796874940395\n",
      "Epoch: 7914 Loss: 0.010349998250603676\n",
      "Epoch: 7915 Loss: 0.010347864590585232\n",
      "Epoch: 7916 Loss: 0.010345791466534138\n",
      "Epoch: 7917 Loss: 0.01034357026219368\n",
      "Epoch: 7918 Loss: 0.010340730659663677\n",
      "Epoch: 7919 Loss: 0.010339178144931793\n",
      "Epoch: 7920 Loss: 0.01033786591142416\n",
      "Epoch: 7921 Loss: 0.010334771126508713\n",
      "Epoch: 7922 Loss: 0.01033371314406395\n",
      "Epoch: 7923 Loss: 0.010330471210181713\n",
      "Epoch: 7924 Loss: 0.010327832773327827\n",
      "Epoch: 7925 Loss: 0.010326150804758072\n",
      "Epoch: 7926 Loss: 0.010326831601560116\n",
      "Epoch: 7927 Loss: 0.01032285112887621\n",
      "Epoch: 7928 Loss: 0.01032191887497902\n",
      "Epoch: 7929 Loss: 0.010318728163838387\n",
      "Epoch: 7930 Loss: 0.010316374711692333\n",
      "Epoch: 7931 Loss: 0.01031441893428564\n",
      "Epoch: 7932 Loss: 0.010311106219887733\n",
      "Epoch: 7933 Loss: 0.01030875276774168\n",
      "Epoch: 7934 Loss: 0.010308897122740746\n",
      "Epoch: 7935 Loss: 0.01030438207089901\n",
      "Epoch: 7936 Loss: 0.010305026546120644\n",
      "Epoch: 7937 Loss: 0.010299473069608212\n",
      "Epoch: 7938 Loss: 0.010298489592969418\n",
      "Epoch: 7939 Loss: 0.010297173634171486\n",
      "Epoch: 7940 Loss: 0.010293912142515182\n",
      "Epoch: 7941 Loss: 0.010292316786944866\n",
      "Epoch: 7942 Loss: 0.010291235521435738\n",
      "Epoch: 7943 Loss: 0.01028717402368784\n",
      "Epoch: 7944 Loss: 0.010288137011229992\n",
      "Epoch: 7945 Loss: 0.010282664559781551\n",
      "Epoch: 7946 Loss: 0.01028167549520731\n",
      "Epoch: 7947 Loss: 0.010279936715960503\n",
      "Epoch: 7948 Loss: 0.01027686893939972\n",
      "Epoch: 7949 Loss: 0.01027609035372734\n",
      "Epoch: 7950 Loss: 0.010273613035678864\n",
      "Epoch: 7951 Loss: 0.010272311978042126\n",
      "Epoch: 7952 Loss: 0.010269839316606522\n",
      "Epoch: 7953 Loss: 0.010267267003655434\n",
      "Epoch: 7954 Loss: 0.010263701900839806\n",
      "Epoch: 7955 Loss: 0.010262525640428066\n",
      "Epoch: 7956 Loss: 0.010259220376610756\n",
      "Epoch: 7957 Loss: 0.010257599875330925\n",
      "Epoch: 7958 Loss: 0.010259203612804413\n",
      "Epoch: 7959 Loss: 0.010253596119582653\n",
      "Epoch: 7960 Loss: 0.010253503918647766\n",
      "Epoch: 7961 Loss: 0.010249187238514423\n",
      "Epoch: 7962 Loss: 0.010248529724776745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7963 Loss: 0.010245437733829021\n",
      "Epoch: 7964 Loss: 0.01024144422262907\n",
      "Epoch: 7965 Loss: 0.01024196483194828\n",
      "Epoch: 7966 Loss: 0.010238809511065483\n",
      "Epoch: 7967 Loss: 0.010238075628876686\n",
      "Epoch: 7968 Loss: 0.010234435088932514\n",
      "Epoch: 7969 Loss: 0.010233636945486069\n",
      "Epoch: 7970 Loss: 0.010229585692286491\n",
      "Epoch: 7971 Loss: 0.010227646678686142\n",
      "Epoch: 7972 Loss: 0.010225696489214897\n",
      "Epoch: 7973 Loss: 0.010227516293525696\n",
      "Epoch: 7974 Loss: 0.010223123244941235\n",
      "Epoch: 7975 Loss: 0.010221190750598907\n",
      "Epoch: 7976 Loss: 0.01021785568445921\n",
      "Epoch: 7977 Loss: 0.010216020978987217\n",
      "Epoch: 7978 Loss: 0.010214261710643768\n",
      "Epoch: 7979 Loss: 0.01021112222224474\n",
      "Epoch: 7980 Loss: 0.010209384374320507\n",
      "Epoch: 7981 Loss: 0.010208181105554104\n",
      "Epoch: 7982 Loss: 0.010206608101725578\n",
      "Epoch: 7983 Loss: 0.01020297035574913\n",
      "Epoch: 7984 Loss: 0.010200988501310349\n",
      "Epoch: 7985 Loss: 0.010199165903031826\n",
      "Epoch: 7986 Loss: 0.010198703035712242\n",
      "Epoch: 7987 Loss: 0.010194633156061172\n",
      "Epoch: 7988 Loss: 0.010192238725721836\n",
      "Epoch: 7989 Loss: 0.010190815664827824\n",
      "Epoch: 7990 Loss: 0.010188882239162922\n",
      "Epoch: 7991 Loss: 0.01018721517175436\n",
      "Epoch: 7992 Loss: 0.010183248668909073\n",
      "Epoch: 7993 Loss: 0.01018261443823576\n",
      "Epoch: 7994 Loss: 0.010181844234466553\n",
      "Epoch: 7995 Loss: 0.010177602991461754\n",
      "Epoch: 7996 Loss: 0.010176263749599457\n",
      "Epoch: 7997 Loss: 0.010171948000788689\n",
      "Epoch: 7998 Loss: 0.010171186178922653\n",
      "Epoch: 7999 Loss: 0.01017060037702322\n",
      "Epoch: 8000 Loss: 0.010165944695472717\n",
      "Epoch: 8001 Loss: 0.010166246443986893\n",
      "Epoch: 8002 Loss: 0.01016581803560257\n",
      "Epoch: 8003 Loss: 0.01016147155314684\n",
      "Epoch: 8004 Loss: 0.010159007273614407\n",
      "Epoch: 8005 Loss: 0.010157356970012188\n",
      "Epoch: 8006 Loss: 0.010155578143894672\n",
      "Epoch: 8007 Loss: 0.010152552276849747\n",
      "Epoch: 8008 Loss: 0.010152468457818031\n",
      "Epoch: 8009 Loss: 0.010149476118385792\n",
      "Epoch: 8010 Loss: 0.010146946646273136\n",
      "Epoch: 8011 Loss: 0.010143959894776344\n",
      "Epoch: 8012 Loss: 0.01014300249516964\n",
      "Epoch: 8013 Loss: 0.010140816681087017\n",
      "Epoch: 8014 Loss: 0.010137300007045269\n",
      "Epoch: 8015 Loss: 0.010135677643120289\n",
      "Epoch: 8016 Loss: 0.010135090909898281\n",
      "Epoch: 8017 Loss: 0.01013155560940504\n",
      "Epoch: 8018 Loss: 0.010131675750017166\n",
      "Epoch: 8019 Loss: 0.010126729495823383\n",
      "Epoch: 8020 Loss: 0.01012762077152729\n",
      "Epoch: 8021 Loss: 0.010124260559678078\n",
      "Epoch: 8022 Loss: 0.01012198906391859\n",
      "Epoch: 8023 Loss: 0.010119149461388588\n",
      "Epoch: 8024 Loss: 0.010118081234395504\n",
      "Epoch: 8025 Loss: 0.01011653896421194\n",
      "Epoch: 8026 Loss: 0.010113283060491085\n",
      "Epoch: 8027 Loss: 0.0101095512509346\n",
      "Epoch: 8028 Loss: 0.010109450668096542\n",
      "Epoch: 8029 Loss: 0.010108333081007004\n",
      "Epoch: 8030 Loss: 0.010105851106345654\n",
      "Epoch: 8031 Loss: 0.010104082524776459\n",
      "Epoch: 8032 Loss: 0.010102378204464912\n",
      "Epoch: 8033 Loss: 0.010098258033394814\n",
      "Epoch: 8034 Loss: 0.010098172351717949\n",
      "Epoch: 8035 Loss: 0.010093984194099903\n",
      "Epoch: 8036 Loss: 0.010092290118336678\n",
      "Epoch: 8037 Loss: 0.010092450305819511\n",
      "Epoch: 8038 Loss: 0.010087204165756702\n",
      "Epoch: 8039 Loss: 0.010089660994708538\n",
      "Epoch: 8040 Loss: 0.010084562003612518\n",
      "Epoch: 8041 Loss: 0.010081334970891476\n",
      "Epoch: 8042 Loss: 0.010081146843731403\n",
      "Epoch: 8043 Loss: 0.010078574530780315\n",
      "Epoch: 8044 Loss: 0.010074375197291374\n",
      "Epoch: 8045 Loss: 0.010074867866933346\n",
      "Epoch: 8046 Loss: 0.010074108839035034\n",
      "Epoch: 8047 Loss: 0.01006930973380804\n",
      "Epoch: 8048 Loss: 0.01006972324103117\n",
      "Epoch: 8049 Loss: 0.010064576752483845\n",
      "Epoch: 8050 Loss: 0.010063566267490387\n",
      "Epoch: 8051 Loss: 0.010061489418148994\n",
      "Epoch: 8052 Loss: 0.010058925487101078\n",
      "Epoch: 8053 Loss: 0.010059457272291183\n",
      "Epoch: 8054 Loss: 0.01005629077553749\n",
      "Epoch: 8055 Loss: 0.010053029283881187\n",
      "Epoch: 8056 Loss: 0.010051961988210678\n",
      "Epoch: 8057 Loss: 0.010048962198197842\n",
      "Epoch: 8058 Loss: 0.01004605833441019\n",
      "Epoch: 8059 Loss: 0.010046004317700863\n",
      "Epoch: 8060 Loss: 0.010043829679489136\n",
      "Epoch: 8061 Loss: 0.010040679015219212\n",
      "Epoch: 8062 Loss: 0.010040652938187122\n",
      "Epoch: 8063 Loss: 0.010036650113761425\n",
      "Epoch: 8064 Loss: 0.010035061277449131\n",
      "Epoch: 8065 Loss: 0.010032969526946545\n",
      "Epoch: 8066 Loss: 0.010032642632722855\n",
      "Epoch: 8067 Loss: 0.010029350407421589\n",
      "Epoch: 8068 Loss: 0.010027174837887287\n",
      "Epoch: 8069 Loss: 0.010024386458098888\n",
      "Epoch: 8070 Loss: 0.010021974332630634\n",
      "Epoch: 8071 Loss: 0.010019540786743164\n",
      "Epoch: 8072 Loss: 0.010019836947321892\n",
      "Epoch: 8073 Loss: 0.010016024112701416\n",
      "Epoch: 8074 Loss: 0.010015401989221573\n",
      "Epoch: 8075 Loss: 0.010012444108724594\n",
      "Epoch: 8076 Loss: 0.010011090897023678\n",
      "Epoch: 8077 Loss: 0.010008900426328182\n",
      "Epoch: 8078 Loss: 0.010007243603467941\n",
      "Epoch: 8079 Loss: 0.010005838237702847\n",
      "Epoch: 8080 Loss: 0.010002047754824162\n",
      "Epoch: 8081 Loss: 0.010000680573284626\n",
      "Epoch: 8082 Loss: 0.009998202323913574\n",
      "Epoch: 8083 Loss: 0.009994488209486008\n",
      "Epoch: 8084 Loss: 0.00999291893094778\n",
      "Epoch: 8085 Loss: 0.00999491848051548\n",
      "Epoch: 8086 Loss: 0.009990331716835499\n",
      "Epoch: 8087 Loss: 0.009990359656512737\n",
      "Epoch: 8088 Loss: 0.00998567882925272\n",
      "Epoch: 8089 Loss: 0.00998672004789114\n",
      "Epoch: 8090 Loss: 0.009982570074498653\n",
      "Epoch: 8091 Loss: 0.00997946411371231\n",
      "Epoch: 8092 Loss: 0.009977620095014572\n",
      "Epoch: 8093 Loss: 0.009975992143154144\n",
      "Epoch: 8094 Loss: 0.009974180720746517\n",
      "Epoch: 8095 Loss: 0.009973081760108471\n",
      "Epoch: 8096 Loss: 0.009969052858650684\n",
      "Epoch: 8097 Loss: 0.009967426769435406\n",
      "Epoch: 8098 Loss: 0.009967871941626072\n",
      "Epoch: 8099 Loss: 0.0099639892578125\n",
      "Epoch: 8100 Loss: 0.009961993433535099\n",
      "Epoch: 8101 Loss: 0.009959083050489426\n",
      "Epoch: 8102 Loss: 0.009956014342606068\n",
      "Epoch: 8103 Loss: 0.009957182221114635\n",
      "Epoch: 8104 Loss: 0.009956334717571735\n",
      "Epoch: 8105 Loss: 0.009951744228601456\n",
      "Epoch: 8106 Loss: 0.009950360283255577\n",
      "Epoch: 8107 Loss: 0.009945460595190525\n",
      "Epoch: 8108 Loss: 0.009945397265255451\n",
      "Epoch: 8109 Loss: 0.00994329247623682\n",
      "Epoch: 8110 Loss: 0.009943092241883278\n",
      "Epoch: 8111 Loss: 0.009940343908965588\n",
      "Epoch: 8112 Loss: 0.009936586953699589\n",
      "Epoch: 8113 Loss: 0.009935149922966957\n",
      "Epoch: 8114 Loss: 0.009935503825545311\n",
      "Epoch: 8115 Loss: 0.009930490516126156\n",
      "Epoch: 8116 Loss: 0.009931843727827072\n",
      "Epoch: 8117 Loss: 0.009928882122039795\n",
      "Epoch: 8118 Loss: 0.009925415739417076\n",
      "Epoch: 8119 Loss: 0.009924225509166718\n",
      "Epoch: 8120 Loss: 0.009920683689415455\n",
      "Epoch: 8121 Loss: 0.00991880614310503\n",
      "Epoch: 8122 Loss: 0.009917288087308407\n",
      "Epoch: 8123 Loss: 0.009918187744915485\n",
      "Epoch: 8124 Loss: 0.009915531612932682\n",
      "Epoch: 8125 Loss: 0.009912215173244476\n",
      "Epoch: 8126 Loss: 0.009908405132591724\n",
      "Epoch: 8127 Loss: 0.009906258434057236\n",
      "Epoch: 8128 Loss: 0.009904976934194565\n",
      "Epoch: 8129 Loss: 0.009902884252369404\n",
      "Epoch: 8130 Loss: 0.009903852827847004\n",
      "Epoch: 8131 Loss: 0.009898535907268524\n",
      "Epoch: 8132 Loss: 0.009897969663143158\n",
      "Epoch: 8133 Loss: 0.009894933551549911\n",
      "Epoch: 8134 Loss: 0.00989499781280756\n",
      "Epoch: 8135 Loss: 0.009890595450997353\n",
      "Epoch: 8136 Loss: 0.009891266003251076\n",
      "Epoch: 8137 Loss: 0.009887040592730045\n",
      "Epoch: 8138 Loss: 0.009884935803711414\n",
      "Epoch: 8139 Loss: 0.009883901104331017\n",
      "Epoch: 8140 Loss: 0.00988081842660904\n",
      "Epoch: 8141 Loss: 0.009882363490760326\n",
      "Epoch: 8142 Loss: 0.009876314550638199\n",
      "Epoch: 8143 Loss: 0.00987635925412178\n",
      "Epoch: 8144 Loss: 0.009873393923044205\n",
      "Epoch: 8145 Loss: 0.009869889356195927\n",
      "Epoch: 8146 Loss: 0.009870108217000961\n",
      "Epoch: 8147 Loss: 0.009867883287370205\n",
      "Epoch: 8148 Loss: 0.009865791536867619\n",
      "Epoch: 8149 Loss: 0.00986450258642435\n",
      "Epoch: 8150 Loss: 0.009861870668828487\n",
      "Epoch: 8151 Loss: 0.009859119541943073\n",
      "Epoch: 8152 Loss: 0.009859781712293625\n",
      "Epoch: 8153 Loss: 0.009854933246970177\n",
      "Epoch: 8154 Loss: 0.009852396324276924\n",
      "Epoch: 8155 Loss: 0.00985137838870287\n",
      "Epoch: 8156 Loss: 0.009851599112153053\n",
      "Epoch: 8157 Loss: 0.009846811182796955\n",
      "Epoch: 8158 Loss: 0.009846052154898643\n",
      "Epoch: 8159 Loss: 0.009843016974627972\n",
      "Epoch: 8160 Loss: 0.009843427687883377\n",
      "Epoch: 8161 Loss: 0.009840586222708225\n",
      "Epoch: 8162 Loss: 0.009839258156716824\n",
      "Epoch: 8163 Loss: 0.009836649522185326\n",
      "Epoch: 8164 Loss: 0.00983322411775589\n",
      "Epoch: 8165 Loss: 0.00983154121786356\n",
      "Epoch: 8166 Loss: 0.009832407347857952\n",
      "Epoch: 8167 Loss: 0.009827116504311562\n",
      "Epoch: 8168 Loss: 0.009826618246734142\n",
      "Epoch: 8169 Loss: 0.009825185872614384\n",
      "Epoch: 8170 Loss: 0.009820276871323586\n",
      "Epoch: 8171 Loss: 0.00981893390417099\n",
      "Epoch: 8172 Loss: 0.009819656610488892\n",
      "Epoch: 8173 Loss: 0.009815945290029049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8174 Loss: 0.009814353659749031\n",
      "Epoch: 8175 Loss: 0.009812308475375175\n",
      "Epoch: 8176 Loss: 0.009809087961912155\n",
      "Epoch: 8177 Loss: 0.00980925653129816\n",
      "Epoch: 8178 Loss: 0.009805773384869099\n",
      "Epoch: 8179 Loss: 0.009803352877497673\n",
      "Epoch: 8180 Loss: 0.009803073480725288\n",
      "Epoch: 8181 Loss: 0.009801332838833332\n",
      "Epoch: 8182 Loss: 0.009798821993172169\n",
      "Epoch: 8183 Loss: 0.009796719066798687\n",
      "Epoch: 8184 Loss: 0.009794076904654503\n",
      "Epoch: 8185 Loss: 0.00979231670498848\n",
      "Epoch: 8186 Loss: 0.009790013544261456\n",
      "Epoch: 8187 Loss: 0.009789232164621353\n",
      "Epoch: 8188 Loss: 0.009785255417227745\n",
      "Epoch: 8189 Loss: 0.009786093607544899\n",
      "Epoch: 8190 Loss: 0.009782669134438038\n",
      "Epoch: 8191 Loss: 0.0097826411947608\n",
      "Epoch: 8192 Loss: 0.009777930565178394\n",
      "Epoch: 8193 Loss: 0.009777247905731201\n",
      "Epoch: 8194 Loss: 0.009776277467608452\n",
      "Epoch: 8195 Loss: 0.009772338904440403\n",
      "Epoch: 8196 Loss: 0.009769017808139324\n",
      "Epoch: 8197 Loss: 0.009767847135663033\n",
      "Epoch: 8198 Loss: 0.00976862758398056\n",
      "Epoch: 8199 Loss: 0.009764629416167736\n",
      "Epoch: 8200 Loss: 0.009764914400875568\n",
      "Epoch: 8201 Loss: 0.009759965352714062\n",
      "Epoch: 8202 Loss: 0.009758414700627327\n",
      "Epoch: 8203 Loss: 0.009755974635481834\n",
      "Epoch: 8204 Loss: 0.009755812585353851\n",
      "Epoch: 8205 Loss: 0.009754098951816559\n",
      "Epoch: 8206 Loss: 0.009751024655997753\n",
      "Epoch: 8207 Loss: 0.009748530574142933\n",
      "Epoch: 8208 Loss: 0.009747713804244995\n",
      "Epoch: 8209 Loss: 0.009744614362716675\n",
      "Epoch: 8210 Loss: 0.009745411574840546\n",
      "Epoch: 8211 Loss: 0.009740887209773064\n",
      "Epoch: 8212 Loss: 0.00974047277122736\n",
      "Epoch: 8213 Loss: 0.00973670557141304\n",
      "Epoch: 8214 Loss: 0.009737567976117134\n",
      "Epoch: 8215 Loss: 0.009731830097734928\n",
      "Epoch: 8216 Loss: 0.0097315963357687\n",
      "Epoch: 8217 Loss: 0.009729965589940548\n",
      "Epoch: 8218 Loss: 0.009728658013045788\n",
      "Epoch: 8219 Loss: 0.009725741110742092\n",
      "Epoch: 8220 Loss: 0.00972399115562439\n",
      "Epoch: 8221 Loss: 0.009721623733639717\n",
      "Epoch: 8222 Loss: 0.009721480309963226\n",
      "Epoch: 8223 Loss: 0.009717230685055256\n",
      "Epoch: 8224 Loss: 0.009716046042740345\n",
      "Epoch: 8225 Loss: 0.009714505635201931\n",
      "Epoch: 8226 Loss: 0.009711331687867641\n",
      "Epoch: 8227 Loss: 0.009708397090435028\n",
      "Epoch: 8228 Loss: 0.00970715843141079\n",
      "Epoch: 8229 Loss: 0.009707157500088215\n",
      "Epoch: 8230 Loss: 0.009705964475870132\n",
      "Epoch: 8231 Loss: 0.009700944647192955\n",
      "Epoch: 8232 Loss: 0.009700225666165352\n",
      "Epoch: 8233 Loss: 0.009697829373180866\n",
      "Epoch: 8234 Loss: 0.009698927402496338\n",
      "Epoch: 8235 Loss: 0.009694389067590237\n",
      "Epoch: 8236 Loss: 0.009693421423435211\n",
      "Epoch: 8237 Loss: 0.0096893310546875\n",
      "Epoch: 8238 Loss: 0.00968930497765541\n",
      "Epoch: 8239 Loss: 0.00968637503683567\n",
      "Epoch: 8240 Loss: 0.009685023687779903\n",
      "Epoch: 8241 Loss: 0.009683233685791492\n",
      "Epoch: 8242 Loss: 0.009680675342679024\n",
      "Epoch: 8243 Loss: 0.009680399671196938\n",
      "Epoch: 8244 Loss: 0.009676751680672169\n",
      "Epoch: 8245 Loss: 0.009675589390099049\n",
      "Epoch: 8246 Loss: 0.009672985412180424\n",
      "Epoch: 8247 Loss: 0.009670513682067394\n",
      "Epoch: 8248 Loss: 0.00966921541839838\n",
      "Epoch: 8249 Loss: 0.009666492231190205\n",
      "Epoch: 8250 Loss: 0.009667105972766876\n",
      "Epoch: 8251 Loss: 0.009662534110248089\n",
      "Epoch: 8252 Loss: 0.009664349257946014\n",
      "Epoch: 8253 Loss: 0.00965893268585205\n",
      "Epoch: 8254 Loss: 0.00966025423258543\n",
      "Epoch: 8255 Loss: 0.00965550821274519\n",
      "Epoch: 8256 Loss: 0.009653812274336815\n",
      "Epoch: 8257 Loss: 0.009651586413383484\n",
      "Epoch: 8258 Loss: 0.009649031795561314\n",
      "Epoch: 8259 Loss: 0.009649575687944889\n",
      "Epoch: 8260 Loss: 0.009646615013480186\n",
      "Epoch: 8261 Loss: 0.00964534655213356\n",
      "Epoch: 8262 Loss: 0.009642857126891613\n",
      "Epoch: 8263 Loss: 0.009639997035264969\n",
      "Epoch: 8264 Loss: 0.009637430310249329\n",
      "Epoch: 8265 Loss: 0.009635834023356438\n",
      "Epoch: 8266 Loss: 0.009635485708713531\n",
      "Epoch: 8267 Loss: 0.009634437039494514\n",
      "Epoch: 8268 Loss: 0.00963081419467926\n",
      "Epoch: 8269 Loss: 0.009628783911466599\n",
      "Epoch: 8270 Loss: 0.009626450948417187\n",
      "Epoch: 8271 Loss: 0.009624320082366467\n",
      "Epoch: 8272 Loss: 0.009623845107853413\n",
      "Epoch: 8273 Loss: 0.0096231484785676\n",
      "Epoch: 8274 Loss: 0.00961997825652361\n",
      "Epoch: 8275 Loss: 0.00961843878030777\n",
      "Epoch: 8276 Loss: 0.009615839459002018\n",
      "Epoch: 8277 Loss: 0.009612556546926498\n",
      "Epoch: 8278 Loss: 0.009611349552869797\n",
      "Epoch: 8279 Loss: 0.00960932020097971\n",
      "Epoch: 8280 Loss: 0.009608963504433632\n",
      "Epoch: 8281 Loss: 0.009605882689356804\n",
      "Epoch: 8282 Loss: 0.009605543687939644\n",
      "Epoch: 8283 Loss: 0.009602796286344528\n",
      "Epoch: 8284 Loss: 0.00959967914968729\n",
      "Epoch: 8285 Loss: 0.009599808603525162\n",
      "Epoch: 8286 Loss: 0.00959604699164629\n",
      "Epoch: 8287 Loss: 0.009596643969416618\n",
      "Epoch: 8288 Loss: 0.009593840688467026\n",
      "Epoch: 8289 Loss: 0.009592153131961823\n",
      "Epoch: 8290 Loss: 0.00958862155675888\n",
      "Epoch: 8291 Loss: 0.00958702526986599\n",
      "Epoch: 8292 Loss: 0.009584400802850723\n",
      "Epoch: 8293 Loss: 0.009583722800016403\n",
      "Epoch: 8294 Loss: 0.009583349339663982\n",
      "Epoch: 8295 Loss: 0.009579534642398357\n",
      "Epoch: 8296 Loss: 0.009576624259352684\n",
      "Epoch: 8297 Loss: 0.009574086405336857\n",
      "Epoch: 8298 Loss: 0.009572961367666721\n",
      "Epoch: 8299 Loss: 0.009572849608957767\n",
      "Epoch: 8300 Loss: 0.009570971131324768\n",
      "Epoch: 8301 Loss: 0.00956923421472311\n",
      "Epoch: 8302 Loss: 0.00956712570041418\n",
      "Epoch: 8303 Loss: 0.009566032327711582\n",
      "Epoch: 8304 Loss: 0.009562656283378601\n",
      "Epoch: 8305 Loss: 0.009560317732393742\n",
      "Epoch: 8306 Loss: 0.009558247402310371\n",
      "Epoch: 8307 Loss: 0.009559699334204197\n",
      "Epoch: 8308 Loss: 0.009553680196404457\n",
      "Epoch: 8309 Loss: 0.009555063210427761\n",
      "Epoch: 8310 Loss: 0.009551056660711765\n",
      "Epoch: 8311 Loss: 0.00954967550933361\n",
      "Epoch: 8312 Loss: 0.009547159075737\n",
      "Epoch: 8313 Loss: 0.009546397253870964\n",
      "Epoch: 8314 Loss: 0.009542383253574371\n",
      "Epoch: 8315 Loss: 0.00954231433570385\n",
      "Epoch: 8316 Loss: 0.009538962505757809\n",
      "Epoch: 8317 Loss: 0.009540620259940624\n",
      "Epoch: 8318 Loss: 0.0095376530662179\n",
      "Epoch: 8319 Loss: 0.009533504024147987\n",
      "Epoch: 8320 Loss: 0.009532012045383453\n",
      "Epoch: 8321 Loss: 0.009531138464808464\n",
      "Epoch: 8322 Loss: 0.009527181275188923\n",
      "Epoch: 8323 Loss: 0.009527206420898438\n",
      "Epoch: 8324 Loss: 0.009524732828140259\n",
      "Epoch: 8325 Loss: 0.009524347260594368\n",
      "Epoch: 8326 Loss: 0.009521501138806343\n",
      "Epoch: 8327 Loss: 0.009520973078906536\n",
      "Epoch: 8328 Loss: 0.00951658096164465\n",
      "Epoch: 8329 Loss: 0.009516152553260326\n",
      "Epoch: 8330 Loss: 0.009511874988675117\n",
      "Epoch: 8331 Loss: 0.009513866156339645\n",
      "Epoch: 8332 Loss: 0.009510191157460213\n",
      "Epoch: 8333 Loss: 0.009508641436696053\n",
      "Epoch: 8334 Loss: 0.009506669826805592\n",
      "Epoch: 8335 Loss: 0.00950284581631422\n",
      "Epoch: 8336 Loss: 0.009502138942480087\n",
      "Epoch: 8337 Loss: 0.00950014777481556\n",
      "Epoch: 8338 Loss: 0.009497824124991894\n",
      "Epoch: 8339 Loss: 0.009497086517512798\n",
      "Epoch: 8340 Loss: 0.009495814330875874\n",
      "Epoch: 8341 Loss: 0.009493269957602024\n",
      "Epoch: 8342 Loss: 0.009491628035902977\n",
      "Epoch: 8343 Loss: 0.009490085765719414\n",
      "Epoch: 8344 Loss: 0.009486021474003792\n",
      "Epoch: 8345 Loss: 0.009484929032623768\n",
      "Epoch: 8346 Loss: 0.009484733454883099\n",
      "Epoch: 8347 Loss: 0.009481461718678474\n",
      "Epoch: 8348 Loss: 0.009480862878262997\n",
      "Epoch: 8349 Loss: 0.009479348547756672\n",
      "Epoch: 8350 Loss: 0.009476757608354092\n",
      "Epoch: 8351 Loss: 0.00947408564388752\n",
      "Epoch: 8352 Loss: 0.009471459314227104\n",
      "Epoch: 8353 Loss: 0.009472916834056377\n",
      "Epoch: 8354 Loss: 0.009468321688473225\n",
      "Epoch: 8355 Loss: 0.009466330520808697\n",
      "Epoch: 8356 Loss: 0.009464208967983723\n",
      "Epoch: 8357 Loss: 0.009463993832468987\n",
      "Epoch: 8358 Loss: 0.00945974700152874\n",
      "Epoch: 8359 Loss: 0.009460242465138435\n",
      "Epoch: 8360 Loss: 0.009457124397158623\n",
      "Epoch: 8361 Loss: 0.00945581216365099\n",
      "Epoch: 8362 Loss: 0.009453228674829006\n",
      "Epoch: 8363 Loss: 0.009452302940189838\n",
      "Epoch: 8364 Loss: 0.009449073113501072\n",
      "Epoch: 8365 Loss: 0.009450572542846203\n",
      "Epoch: 8366 Loss: 0.009446142241358757\n",
      "Epoch: 8367 Loss: 0.009445221163332462\n",
      "Epoch: 8368 Loss: 0.009442293085157871\n",
      "Epoch: 8369 Loss: 0.009440128691494465\n",
      "Epoch: 8370 Loss: 0.009438215754926205\n",
      "Epoch: 8371 Loss: 0.009438294917345047\n",
      "Epoch: 8372 Loss: 0.009434277191758156\n",
      "Epoch: 8373 Loss: 0.009432976134121418\n",
      "Epoch: 8374 Loss: 0.009431039914488792\n",
      "Epoch: 8375 Loss: 0.009428814053535461\n",
      "Epoch: 8376 Loss: 0.009427037090063095\n",
      "Epoch: 8377 Loss: 0.009424218907952309\n",
      "Epoch: 8378 Loss: 0.009423737414181232\n",
      "Epoch: 8379 Loss: 0.009425400756299496\n",
      "Epoch: 8380 Loss: 0.009420939721167088\n",
      "Epoch: 8381 Loss: 0.009418024681508541\n",
      "Epoch: 8382 Loss: 0.00941859558224678\n",
      "Epoch: 8383 Loss: 0.0094135208055377\n",
      "Epoch: 8384 Loss: 0.009415690787136555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8385 Loss: 0.009410257451236248\n",
      "Epoch: 8386 Loss: 0.009408164769411087\n",
      "Epoch: 8387 Loss: 0.009407280012965202\n",
      "Epoch: 8388 Loss: 0.00940706767141819\n",
      "Epoch: 8389 Loss: 0.009403713978827\n",
      "Epoch: 8390 Loss: 0.009402341209352016\n",
      "Epoch: 8391 Loss: 0.009399773553013802\n",
      "Epoch: 8392 Loss: 0.00939889531582594\n",
      "Epoch: 8393 Loss: 0.009396613575518131\n",
      "Epoch: 8394 Loss: 0.009392747655510902\n",
      "Epoch: 8395 Loss: 0.009393873624503613\n",
      "Epoch: 8396 Loss: 0.009391027502715588\n",
      "Epoch: 8397 Loss: 0.009388111531734467\n",
      "Epoch: 8398 Loss: 0.009387001395225525\n",
      "Epoch: 8399 Loss: 0.00938517414033413\n",
      "Epoch: 8400 Loss: 0.009384898468852043\n",
      "Epoch: 8401 Loss: 0.009381471201777458\n",
      "Epoch: 8402 Loss: 0.009378673508763313\n",
      "Epoch: 8403 Loss: 0.009377563372254372\n",
      "Epoch: 8404 Loss: 0.009375834837555885\n",
      "Epoch: 8405 Loss: 0.009374462068080902\n",
      "Epoch: 8406 Loss: 0.009373062290251255\n",
      "Epoch: 8407 Loss: 0.009369083680212498\n",
      "Epoch: 8408 Loss: 0.009367423132061958\n",
      "Epoch: 8409 Loss: 0.00936795398592949\n",
      "Epoch: 8410 Loss: 0.009366708807647228\n",
      "Epoch: 8411 Loss: 0.009364090859889984\n",
      "Epoch: 8412 Loss: 0.009363108314573765\n",
      "Epoch: 8413 Loss: 0.009360020980238914\n",
      "Epoch: 8414 Loss: 0.009359381161630154\n",
      "Epoch: 8415 Loss: 0.009356090798974037\n",
      "Epoch: 8416 Loss: 0.00935312919318676\n",
      "Epoch: 8417 Loss: 0.009351572953164577\n",
      "Epoch: 8418 Loss: 0.009351243264973164\n",
      "Epoch: 8419 Loss: 0.009350094012916088\n",
      "Epoch: 8420 Loss: 0.009348271414637566\n",
      "Epoch: 8421 Loss: 0.00934553612023592\n",
      "Epoch: 8422 Loss: 0.009343373589217663\n",
      "Epoch: 8423 Loss: 0.00934132281690836\n",
      "Epoch: 8424 Loss: 0.009340611286461353\n",
      "Epoch: 8425 Loss: 0.00933680310845375\n",
      "Epoch: 8426 Loss: 0.00933731347322464\n",
      "Epoch: 8427 Loss: 0.009333495050668716\n",
      "Epoch: 8428 Loss: 0.009333289228379726\n",
      "Epoch: 8429 Loss: 0.009331087581813335\n",
      "Epoch: 8430 Loss: 0.009329745545983315\n",
      "Epoch: 8431 Loss: 0.009325689636170864\n",
      "Epoch: 8432 Loss: 0.009325931780040264\n",
      "Epoch: 8433 Loss: 0.009322993457317352\n",
      "Epoch: 8434 Loss: 0.009322025813162327\n",
      "Epoch: 8435 Loss: 0.009318921715021133\n",
      "Epoch: 8436 Loss: 0.009316456504166126\n",
      "Epoch: 8437 Loss: 0.009318159893155098\n",
      "Epoch: 8438 Loss: 0.009312789887189865\n",
      "Epoch: 8439 Loss: 0.009313677437603474\n",
      "Epoch: 8440 Loss: 0.009309493005275726\n",
      "Epoch: 8441 Loss: 0.009309130720794201\n",
      "Epoch: 8442 Loss: 0.009307445958256721\n",
      "Epoch: 8443 Loss: 0.009304869920015335\n",
      "Epoch: 8444 Loss: 0.009304976090788841\n",
      "Epoch: 8445 Loss: 0.009302658960223198\n",
      "Epoch: 8446 Loss: 0.009298721328377724\n",
      "Epoch: 8447 Loss: 0.009297922253608704\n",
      "Epoch: 8448 Loss: 0.009296336211264133\n",
      "Epoch: 8449 Loss: 0.009297190234065056\n",
      "Epoch: 8450 Loss: 0.00929331872612238\n",
      "Epoch: 8451 Loss: 0.009292088449001312\n",
      "Epoch: 8452 Loss: 0.009288945235311985\n",
      "Epoch: 8453 Loss: 0.00928713008761406\n",
      "Epoch: 8454 Loss: 0.009285149164497852\n",
      "Epoch: 8455 Loss: 0.009283369407057762\n",
      "Epoch: 8456 Loss: 0.009281537495553493\n",
      "Epoch: 8457 Loss: 0.009278859943151474\n",
      "Epoch: 8458 Loss: 0.009278522804379463\n",
      "Epoch: 8459 Loss: 0.00927911326289177\n",
      "Epoch: 8460 Loss: 0.009274180978536606\n",
      "Epoch: 8461 Loss: 0.009273814968764782\n",
      "Epoch: 8462 Loss: 0.009270962327718735\n",
      "Epoch: 8463 Loss: 0.009270263835787773\n",
      "Epoch: 8464 Loss: 0.009266759268939495\n",
      "Epoch: 8465 Loss: 0.0092659592628479\n",
      "Epoch: 8466 Loss: 0.009263833984732628\n",
      "Epoch: 8467 Loss: 0.009264588356018066\n",
      "Epoch: 8468 Loss: 0.009259846061468124\n",
      "Epoch: 8469 Loss: 0.009258389472961426\n",
      "Epoch: 8470 Loss: 0.009258093312382698\n",
      "Epoch: 8471 Loss: 0.00925382412970066\n",
      "Epoch: 8472 Loss: 0.009254010394215584\n",
      "Epoch: 8473 Loss: 0.009250587783753872\n",
      "Epoch: 8474 Loss: 0.009249750524759293\n",
      "Epoch: 8475 Loss: 0.009249665774405003\n",
      "Epoch: 8476 Loss: 0.009246421046555042\n",
      "Epoch: 8477 Loss: 0.00924630369991064\n",
      "Epoch: 8478 Loss: 0.00924228597432375\n",
      "Epoch: 8479 Loss: 0.009240100160241127\n",
      "Epoch: 8480 Loss: 0.009239599108695984\n",
      "Epoch: 8481 Loss: 0.009237658232450485\n",
      "Epoch: 8482 Loss: 0.009235182777047157\n",
      "Epoch: 8483 Loss: 0.00923602469265461\n",
      "Epoch: 8484 Loss: 0.009233295917510986\n",
      "Epoch: 8485 Loss: 0.009229601360857487\n",
      "Epoch: 8486 Loss: 0.00922870822250843\n",
      "Epoch: 8487 Loss: 0.009226811118423939\n",
      "Epoch: 8488 Loss: 0.009226375259459019\n",
      "Epoch: 8489 Loss: 0.009223097935318947\n",
      "Epoch: 8490 Loss: 0.009222328662872314\n",
      "Epoch: 8491 Loss: 0.009219436906278133\n",
      "Epoch: 8492 Loss: 0.009217722341418266\n",
      "Epoch: 8493 Loss: 0.009216670878231525\n",
      "Epoch: 8494 Loss: 0.009214293211698532\n",
      "Epoch: 8495 Loss: 0.00921416562050581\n",
      "Epoch: 8496 Loss: 0.009210544638335705\n",
      "Epoch: 8497 Loss: 0.00920774694532156\n",
      "Epoch: 8498 Loss: 0.009206651709973812\n",
      "Epoch: 8499 Loss: 0.009207086637616158\n",
      "Epoch: 8500 Loss: 0.00920372549444437\n",
      "Epoch: 8501 Loss: 0.009202544577419758\n",
      "Epoch: 8502 Loss: 0.009199847467243671\n",
      "Epoch: 8503 Loss: 0.009198772720992565\n",
      "Epoch: 8504 Loss: 0.009196221828460693\n",
      "Epoch: 8505 Loss: 0.009195682592689991\n",
      "Epoch: 8506 Loss: 0.009193625301122665\n",
      "Epoch: 8507 Loss: 0.009193121455609798\n",
      "Epoch: 8508 Loss: 0.009190400131046772\n",
      "Epoch: 8509 Loss: 0.009187444113194942\n",
      "Epoch: 8510 Loss: 0.009186580777168274\n",
      "Epoch: 8511 Loss: 0.009184792637825012\n",
      "Epoch: 8512 Loss: 0.00918520800769329\n",
      "Epoch: 8513 Loss: 0.009180364198982716\n",
      "Epoch: 8514 Loss: 0.009179133921861649\n",
      "Epoch: 8515 Loss: 0.009177301079034805\n",
      "Epoch: 8516 Loss: 0.009176169522106647\n",
      "Epoch: 8517 Loss: 0.009173263795673847\n",
      "Epoch: 8518 Loss: 0.009174315258860588\n",
      "Epoch: 8519 Loss: 0.009170569479465485\n",
      "Epoch: 8520 Loss: 0.009169102646410465\n",
      "Epoch: 8521 Loss: 0.009166046977043152\n",
      "Epoch: 8522 Loss: 0.009165112860500813\n",
      "Epoch: 8523 Loss: 0.009165222756564617\n",
      "Epoch: 8524 Loss: 0.009160644374787807\n",
      "Epoch: 8525 Loss: 0.009160807356238365\n",
      "Epoch: 8526 Loss: 0.009157877415418625\n",
      "Epoch: 8527 Loss: 0.009157419204711914\n",
      "Epoch: 8528 Loss: 0.009154289960861206\n",
      "Epoch: 8529 Loss: 0.009153531864285469\n",
      "Epoch: 8530 Loss: 0.009151700884103775\n",
      "Epoch: 8531 Loss: 0.009149664081633091\n",
      "Epoch: 8532 Loss: 0.00914628617465496\n",
      "Epoch: 8533 Loss: 0.00914702471345663\n",
      "Epoch: 8534 Loss: 0.009144620969891548\n",
      "Epoch: 8535 Loss: 0.009143575094640255\n",
      "Epoch: 8536 Loss: 0.009140203706920147\n",
      "Epoch: 8537 Loss: 0.009138516150414944\n",
      "Epoch: 8538 Loss: 0.009137563407421112\n",
      "Epoch: 8539 Loss: 0.009136559441685677\n",
      "Epoch: 8540 Loss: 0.009135305881500244\n",
      "Epoch: 8541 Loss: 0.009132321923971176\n",
      "Epoch: 8542 Loss: 0.009130221791565418\n",
      "Epoch: 8543 Loss: 0.0091286301612854\n",
      "Epoch: 8544 Loss: 0.009127812460064888\n",
      "Epoch: 8545 Loss: 0.009126164019107819\n",
      "Epoch: 8546 Loss: 0.009122638031840324\n",
      "Epoch: 8547 Loss: 0.009121728129684925\n",
      "Epoch: 8548 Loss: 0.00912007037550211\n",
      "Epoch: 8549 Loss: 0.009117957204580307\n",
      "Epoch: 8550 Loss: 0.009116316214203835\n",
      "Epoch: 8551 Loss: 0.009116007015109062\n",
      "Epoch: 8552 Loss: 0.009112845174968243\n",
      "Epoch: 8553 Loss: 0.009110771119594574\n",
      "Epoch: 8554 Loss: 0.009112208150327206\n",
      "Epoch: 8555 Loss: 0.00910718273371458\n",
      "Epoch: 8556 Loss: 0.009106594137847424\n",
      "Epoch: 8557 Loss: 0.009105128236114979\n",
      "Epoch: 8558 Loss: 0.009101802483201027\n",
      "Epoch: 8559 Loss: 0.009101402945816517\n",
      "Epoch: 8560 Loss: 0.009100278839468956\n",
      "Epoch: 8561 Loss: 0.009097559377551079\n",
      "Epoch: 8562 Loss: 0.009095662273466587\n",
      "Epoch: 8563 Loss: 0.009094465523958206\n",
      "Epoch: 8564 Loss: 0.0090912114828825\n",
      "Epoch: 8565 Loss: 0.009090124629437923\n",
      "Epoch: 8566 Loss: 0.009087967686355114\n",
      "Epoch: 8567 Loss: 0.009090821258723736\n",
      "Epoch: 8568 Loss: 0.009084581397473812\n",
      "Epoch: 8569 Loss: 0.009085304103791714\n",
      "Epoch: 8570 Loss: 0.009081601165235043\n",
      "Epoch: 8571 Loss: 0.009079545736312866\n",
      "Epoch: 8572 Loss: 0.009078255854547024\n",
      "Epoch: 8573 Loss: 0.009078689850866795\n",
      "Epoch: 8574 Loss: 0.00907631404697895\n",
      "Epoch: 8575 Loss: 0.009073580615222454\n",
      "Epoch: 8576 Loss: 0.00907291192561388\n",
      "Epoch: 8577 Loss: 0.009068953804671764\n",
      "Epoch: 8578 Loss: 0.009067894890904427\n",
      "Epoch: 8579 Loss: 0.009066407568752766\n",
      "Epoch: 8580 Loss: 0.00906695332378149\n",
      "Epoch: 8581 Loss: 0.0090642673894763\n",
      "Epoch: 8582 Loss: 0.009061898104846478\n",
      "Epoch: 8583 Loss: 0.009059633128345013\n",
      "Epoch: 8584 Loss: 0.009057082235813141\n",
      "Epoch: 8585 Loss: 0.009056948125362396\n",
      "Epoch: 8586 Loss: 0.00905404333025217\n",
      "Epoch: 8587 Loss: 0.009054495953023434\n",
      "Epoch: 8588 Loss: 0.009051026776432991\n",
      "Epoch: 8589 Loss: 0.009049762040376663\n",
      "Epoch: 8590 Loss: 0.009047524072229862\n",
      "Epoch: 8591 Loss: 0.009046071209013462\n",
      "Epoch: 8592 Loss: 0.009044764563441277\n",
      "Epoch: 8593 Loss: 0.00904130283743143\n",
      "Epoch: 8594 Loss: 0.009042879566550255\n",
      "Epoch: 8595 Loss: 0.009040885604918003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8596 Loss: 0.009039564989507198\n",
      "Epoch: 8597 Loss: 0.009037237614393234\n",
      "Epoch: 8598 Loss: 0.009034101851284504\n",
      "Epoch: 8599 Loss: 0.00903293676674366\n",
      "Epoch: 8600 Loss: 0.0090297507122159\n",
      "Epoch: 8601 Loss: 0.009030956774950027\n",
      "Epoch: 8602 Loss: 0.009028551168739796\n",
      "Epoch: 8603 Loss: 0.009027065709233284\n",
      "Epoch: 8604 Loss: 0.009025794453918934\n",
      "Epoch: 8605 Loss: 0.009021949954330921\n",
      "Epoch: 8606 Loss: 0.009020415134727955\n",
      "Epoch: 8607 Loss: 0.00901717133820057\n",
      "Epoch: 8608 Loss: 0.009017235599458218\n",
      "Epoch: 8609 Loss: 0.009016643278300762\n",
      "Epoch: 8610 Loss: 0.00901438295841217\n",
      "Epoch: 8611 Loss: 0.009013702161610126\n",
      "Epoch: 8612 Loss: 0.009010478854179382\n",
      "Epoch: 8613 Loss: 0.009007961489260197\n",
      "Epoch: 8614 Loss: 0.00900834146887064\n",
      "Epoch: 8615 Loss: 0.009006131440401077\n",
      "Epoch: 8616 Loss: 0.009004208259284496\n",
      "Epoch: 8617 Loss: 0.009003369137644768\n",
      "Epoch: 8618 Loss: 0.009001177735626698\n",
      "Epoch: 8619 Loss: 0.008998207747936249\n",
      "Epoch: 8620 Loss: 0.008996511809527874\n",
      "Epoch: 8621 Loss: 0.008994662202894688\n",
      "Epoch: 8622 Loss: 0.008995105512440205\n",
      "Epoch: 8623 Loss: 0.008992688730359077\n",
      "Epoch: 8624 Loss: 0.008990232832729816\n",
      "Epoch: 8625 Loss: 0.008988507091999054\n",
      "Epoch: 8626 Loss: 0.00898653268814087\n",
      "Epoch: 8627 Loss: 0.008986658416688442\n",
      "Epoch: 8628 Loss: 0.008983374573290348\n",
      "Epoch: 8629 Loss: 0.008980156853795052\n",
      "Epoch: 8630 Loss: 0.00898059830069542\n",
      "Epoch: 8631 Loss: 0.008978532627224922\n",
      "Epoch: 8632 Loss: 0.008975856937468052\n",
      "Epoch: 8633 Loss: 0.008976866491138935\n",
      "Epoch: 8634 Loss: 0.008973888121545315\n",
      "Epoch: 8635 Loss: 0.008971348404884338\n",
      "Epoch: 8636 Loss: 0.008969483897089958\n",
      "Epoch: 8637 Loss: 0.008970465511083603\n",
      "Epoch: 8638 Loss: 0.008967320434749126\n",
      "Epoch: 8639 Loss: 0.008966056630015373\n",
      "Epoch: 8640 Loss: 0.0089633259922266\n",
      "Epoch: 8641 Loss: 0.008963377214968204\n",
      "Epoch: 8642 Loss: 0.00895979069173336\n",
      "Epoch: 8643 Loss: 0.008960895240306854\n",
      "Epoch: 8644 Loss: 0.00895758904516697\n",
      "Epoch: 8645 Loss: 0.008955119177699089\n",
      "Epoch: 8646 Loss: 0.008953365497291088\n",
      "Epoch: 8647 Loss: 0.008951405994594097\n",
      "Epoch: 8648 Loss: 0.008952083066105843\n",
      "Epoch: 8649 Loss: 0.008947186172008514\n",
      "Epoch: 8650 Loss: 0.00894711073487997\n",
      "Epoch: 8651 Loss: 0.008946813642978668\n",
      "Epoch: 8652 Loss: 0.008942083455622196\n",
      "Epoch: 8653 Loss: 0.00894191861152649\n",
      "Epoch: 8654 Loss: 0.00893909391015768\n",
      "Epoch: 8655 Loss: 0.008938027545809746\n",
      "Epoch: 8656 Loss: 0.00893644243478775\n",
      "Epoch: 8657 Loss: 0.00893468502908945\n",
      "Epoch: 8658 Loss: 0.008935072459280491\n",
      "Epoch: 8659 Loss: 0.008932173252105713\n",
      "Epoch: 8660 Loss: 0.008930185809731483\n",
      "Epoch: 8661 Loss: 0.008928720839321613\n",
      "Epoch: 8662 Loss: 0.008929051458835602\n",
      "Epoch: 8663 Loss: 0.008924216032028198\n",
      "Epoch: 8664 Loss: 0.008924275636672974\n",
      "Epoch: 8665 Loss: 0.008921797387301922\n",
      "Epoch: 8666 Loss: 0.008919605985283852\n",
      "Epoch: 8667 Loss: 0.008918575011193752\n",
      "Epoch: 8668 Loss: 0.008918194100260735\n",
      "Epoch: 8669 Loss: 0.008916785009205341\n",
      "Epoch: 8670 Loss: 0.008913422003388405\n",
      "Epoch: 8671 Loss: 0.00891224853694439\n",
      "Epoch: 8672 Loss: 0.008910401724278927\n",
      "Epoch: 8673 Loss: 0.00890857633203268\n",
      "Epoch: 8674 Loss: 0.008907439187169075\n",
      "Epoch: 8675 Loss: 0.00890500470995903\n",
      "Epoch: 8676 Loss: 0.008902336470782757\n",
      "Epoch: 8677 Loss: 0.008902153000235558\n",
      "Epoch: 8678 Loss: 0.008900187909603119\n",
      "Epoch: 8679 Loss: 0.008900181390345097\n",
      "Epoch: 8680 Loss: 0.00889615062624216\n",
      "Epoch: 8681 Loss: 0.00889587216079235\n",
      "Epoch: 8682 Loss: 0.008894418366253376\n",
      "Epoch: 8683 Loss: 0.008891741745173931\n",
      "Epoch: 8684 Loss: 0.00888808723539114\n",
      "Epoch: 8685 Loss: 0.00888876710087061\n",
      "Epoch: 8686 Loss: 0.008889072574675083\n",
      "Epoch: 8687 Loss: 0.008885872550308704\n",
      "Epoch: 8688 Loss: 0.008885052986443043\n",
      "Epoch: 8689 Loss: 0.008881991729140282\n",
      "Epoch: 8690 Loss: 0.00888036098331213\n",
      "Epoch: 8691 Loss: 0.008878182619810104\n",
      "Epoch: 8692 Loss: 0.008876608684659004\n",
      "Epoch: 8693 Loss: 0.008876373991370201\n",
      "Epoch: 8694 Loss: 0.008874266408383846\n",
      "Epoch: 8695 Loss: 0.008874181658029556\n",
      "Epoch: 8696 Loss: 0.008871231228113174\n",
      "Epoch: 8697 Loss: 0.00886889360845089\n",
      "Epoch: 8698 Loss: 0.008867661468684673\n",
      "Epoch: 8699 Loss: 0.008865897543728352\n",
      "Epoch: 8700 Loss: 0.008865855634212494\n",
      "Epoch: 8701 Loss: 0.00886103231459856\n",
      "Epoch: 8702 Loss: 0.008861107751727104\n",
      "Epoch: 8703 Loss: 0.008859128691256046\n",
      "Epoch: 8704 Loss: 0.008859379217028618\n",
      "Epoch: 8705 Loss: 0.008855486288666725\n",
      "Epoch: 8706 Loss: 0.008855289779603481\n",
      "Epoch: 8707 Loss: 0.008851874619722366\n",
      "Epoch: 8708 Loss: 0.00885078590363264\n",
      "Epoch: 8709 Loss: 0.008848730474710464\n",
      "Epoch: 8710 Loss: 0.00884890928864479\n",
      "Epoch: 8711 Loss: 0.008846500888466835\n",
      "Epoch: 8712 Loss: 0.008844267576932907\n",
      "Epoch: 8713 Loss: 0.008841942995786667\n",
      "Epoch: 8714 Loss: 0.008841772563755512\n",
      "Epoch: 8715 Loss: 0.008839690126478672\n",
      "Epoch: 8716 Loss: 0.008837012574076653\n",
      "Epoch: 8717 Loss: 0.008835616521537304\n",
      "Epoch: 8718 Loss: 0.008836374618113041\n",
      "Epoch: 8719 Loss: 0.00883248820900917\n",
      "Epoch: 8720 Loss: 0.008832630701363087\n",
      "Epoch: 8721 Loss: 0.008830121718347073\n",
      "Epoch: 8722 Loss: 0.008828516118228436\n",
      "Epoch: 8723 Loss: 0.008825913071632385\n",
      "Epoch: 8724 Loss: 0.008823798038065434\n",
      "Epoch: 8725 Loss: 0.008824885822832584\n",
      "Epoch: 8726 Loss: 0.008821672759950161\n",
      "Epoch: 8727 Loss: 0.008820556104183197\n",
      "Epoch: 8728 Loss: 0.008817937225103378\n",
      "Epoch: 8729 Loss: 0.008817438036203384\n",
      "Epoch: 8730 Loss: 0.008815271779894829\n",
      "Epoch: 8731 Loss: 0.008813750930130482\n",
      "Epoch: 8732 Loss: 0.008811852894723415\n",
      "Epoch: 8733 Loss: 0.008811267092823982\n",
      "Epoch: 8734 Loss: 0.008808472193777561\n",
      "Epoch: 8735 Loss: 0.008806982077658176\n",
      "Epoch: 8736 Loss: 0.008806551806628704\n",
      "Epoch: 8737 Loss: 0.008803688921034336\n",
      "Epoch: 8738 Loss: 0.008802092634141445\n",
      "Epoch: 8739 Loss: 0.008800620213150978\n",
      "Epoch: 8740 Loss: 0.008799012750387192\n",
      "Epoch: 8741 Loss: 0.008797883987426758\n",
      "Epoch: 8742 Loss: 0.008796499110758305\n",
      "Epoch: 8743 Loss: 0.008793237619102001\n",
      "Epoch: 8744 Loss: 0.008792374283075333\n",
      "Epoch: 8745 Loss: 0.008790874853730202\n",
      "Epoch: 8746 Loss: 0.008789430372416973\n",
      "Epoch: 8747 Loss: 0.00878792256116867\n",
      "Epoch: 8748 Loss: 0.008785202167928219\n",
      "Epoch: 8749 Loss: 0.008784234523773193\n",
      "Epoch: 8750 Loss: 0.008783059194684029\n",
      "Epoch: 8751 Loss: 0.008780214935541153\n",
      "Epoch: 8752 Loss: 0.008781162090599537\n",
      "Epoch: 8753 Loss: 0.008777862414717674\n",
      "Epoch: 8754 Loss: 0.00877787359058857\n",
      "Epoch: 8755 Loss: 0.008774359710514545\n",
      "Epoch: 8756 Loss: 0.008772555738687515\n",
      "Epoch: 8757 Loss: 0.00877137016505003\n",
      "Epoch: 8758 Loss: 0.008770412765443325\n",
      "Epoch: 8759 Loss: 0.008768185041844845\n",
      "Epoch: 8760 Loss: 0.008766449987888336\n",
      "Epoch: 8761 Loss: 0.00876691285520792\n",
      "Epoch: 8762 Loss: 0.00876435823738575\n",
      "Epoch: 8763 Loss: 0.008761919103562832\n",
      "Epoch: 8764 Loss: 0.008759718388319016\n",
      "Epoch: 8765 Loss: 0.008757884614169598\n",
      "Epoch: 8766 Loss: 0.008756536990404129\n",
      "Epoch: 8767 Loss: 0.008755918592214584\n",
      "Epoch: 8768 Loss: 0.008753765374422073\n",
      "Epoch: 8769 Loss: 0.008752568624913692\n",
      "Epoch: 8770 Loss: 0.008749507367610931\n",
      "Epoch: 8771 Loss: 0.008749288506805897\n",
      "Epoch: 8772 Loss: 0.008748064748942852\n",
      "Epoch: 8773 Loss: 0.00874465610831976\n",
      "Epoch: 8774 Loss: 0.00874483771622181\n",
      "Epoch: 8775 Loss: 0.008744591847062111\n",
      "Epoch: 8776 Loss: 0.008740491233766079\n",
      "Epoch: 8777 Loss: 0.00873956922441721\n",
      "Epoch: 8778 Loss: 0.0087388064712286\n",
      "Epoch: 8779 Loss: 0.008736727759242058\n",
      "Epoch: 8780 Loss: 0.00873454101383686\n",
      "Epoch: 8781 Loss: 0.008731798268854618\n",
      "Epoch: 8782 Loss: 0.008733394555747509\n",
      "Epoch: 8783 Loss: 0.008729878813028336\n",
      "Epoch: 8784 Loss: 0.008729987777769566\n",
      "Epoch: 8785 Loss: 0.008725995197892189\n",
      "Epoch: 8786 Loss: 0.008725013583898544\n",
      "Epoch: 8787 Loss: 0.008722013793885708\n",
      "Epoch: 8788 Loss: 0.00872137863188982\n",
      "Epoch: 8789 Loss: 0.00872013345360756\n",
      "Epoch: 8790 Loss: 0.008717385120689869\n",
      "Epoch: 8791 Loss: 0.00871836394071579\n",
      "Epoch: 8792 Loss: 0.008715043775737286\n",
      "Epoch: 8793 Loss: 0.008713518269360065\n",
      "Epoch: 8794 Loss: 0.008712765760719776\n",
      "Epoch: 8795 Loss: 0.008710606023669243\n",
      "Epoch: 8796 Loss: 0.008710379712283611\n",
      "Epoch: 8797 Loss: 0.008708583191037178\n",
      "Epoch: 8798 Loss: 0.008704856038093567\n",
      "Epoch: 8799 Loss: 0.00870331097394228\n",
      "Epoch: 8800 Loss: 0.008703190833330154\n",
      "Epoch: 8801 Loss: 0.008700045756995678\n",
      "Epoch: 8802 Loss: 0.008700060658156872\n",
      "Epoch: 8803 Loss: 0.00869988277554512\n",
      "Epoch: 8804 Loss: 0.008696405217051506\n",
      "Epoch: 8805 Loss: 0.008695741184055805\n",
      "Epoch: 8806 Loss: 0.008692474104464054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8807 Loss: 0.008691161870956421\n",
      "Epoch: 8808 Loss: 0.008690773509442806\n",
      "Epoch: 8809 Loss: 0.0086869727820158\n",
      "Epoch: 8810 Loss: 0.008687221445143223\n",
      "Epoch: 8811 Loss: 0.008685048669576645\n",
      "Epoch: 8812 Loss: 0.008684951812028885\n",
      "Epoch: 8813 Loss: 0.008681927807629108\n",
      "Epoch: 8814 Loss: 0.008682546205818653\n",
      "Epoch: 8815 Loss: 0.008678250014781952\n",
      "Epoch: 8816 Loss: 0.008676857687532902\n",
      "Epoch: 8817 Loss: 0.008675388991832733\n",
      "Epoch: 8818 Loss: 0.008674715645611286\n",
      "Epoch: 8819 Loss: 0.008673912845551968\n",
      "Epoch: 8820 Loss: 0.008671076968312263\n",
      "Epoch: 8821 Loss: 0.008669481612741947\n",
      "Epoch: 8822 Loss: 0.00866849347949028\n",
      "Epoch: 8823 Loss: 0.008665661327540874\n",
      "Epoch: 8824 Loss: 0.008664622902870178\n",
      "Epoch: 8825 Loss: 0.008663220331072807\n",
      "Epoch: 8826 Loss: 0.008661550469696522\n",
      "Epoch: 8827 Loss: 0.008659928105771542\n",
      "Epoch: 8828 Loss: 0.008658980950713158\n",
      "Epoch: 8829 Loss: 0.008656993508338928\n",
      "Epoch: 8830 Loss: 0.008657140657305717\n",
      "Epoch: 8831 Loss: 0.008653772063553333\n",
      "Epoch: 8832 Loss: 0.008651084266602993\n",
      "Epoch: 8833 Loss: 0.008651752024888992\n",
      "Epoch: 8834 Loss: 0.008647013455629349\n",
      "Epoch: 8835 Loss: 0.00864715687930584\n",
      "Epoch: 8836 Loss: 0.008647673763334751\n",
      "Epoch: 8837 Loss: 0.008644026704132557\n",
      "Epoch: 8838 Loss: 0.008643642999231815\n",
      "Epoch: 8839 Loss: 0.008640781044960022\n",
      "Epoch: 8840 Loss: 0.008638707920908928\n",
      "Epoch: 8841 Loss: 0.008638720028102398\n",
      "Epoch: 8842 Loss: 0.008638916537165642\n",
      "Epoch: 8843 Loss: 0.00863451324403286\n",
      "Epoch: 8844 Loss: 0.008633478544652462\n",
      "Epoch: 8845 Loss: 0.008631308563053608\n",
      "Epoch: 8846 Loss: 0.008631284348666668\n",
      "Epoch: 8847 Loss: 0.008628766983747482\n",
      "Epoch: 8848 Loss: 0.008625723421573639\n",
      "Epoch: 8849 Loss: 0.008625878021121025\n",
      "Epoch: 8850 Loss: 0.008624608628451824\n",
      "Epoch: 8851 Loss: 0.008620766922831535\n",
      "Epoch: 8852 Loss: 0.008621858432888985\n",
      "Epoch: 8853 Loss: 0.008617940358817577\n",
      "Epoch: 8854 Loss: 0.008617470972239971\n",
      "Epoch: 8855 Loss: 0.008616406470537186\n",
      "Epoch: 8856 Loss: 0.008615455590188503\n",
      "Epoch: 8857 Loss: 0.008613087236881256\n",
      "Epoch: 8858 Loss: 0.00861185323446989\n",
      "Epoch: 8859 Loss: 0.008610224351286888\n",
      "Epoch: 8860 Loss: 0.008608349598944187\n",
      "Epoch: 8861 Loss: 0.008607435040175915\n",
      "Epoch: 8862 Loss: 0.00860497448593378\n",
      "Epoch: 8863 Loss: 0.008603743277490139\n",
      "Epoch: 8864 Loss: 0.008602382615208626\n",
      "Epoch: 8865 Loss: 0.00860028900206089\n",
      "Epoch: 8866 Loss: 0.00859920959919691\n",
      "Epoch: 8867 Loss: 0.008597610518336296\n",
      "Epoch: 8868 Loss: 0.008596490137279034\n",
      "Epoch: 8869 Loss: 0.008594396524131298\n",
      "Epoch: 8870 Loss: 0.008591179735958576\n",
      "Epoch: 8871 Loss: 0.008591018617153168\n",
      "Epoch: 8872 Loss: 0.00859051663428545\n",
      "Epoch: 8873 Loss: 0.008587600663304329\n",
      "Epoch: 8874 Loss: 0.008587665855884552\n",
      "Epoch: 8875 Loss: 0.008584786206483841\n",
      "Epoch: 8876 Loss: 0.008583136834204197\n",
      "Epoch: 8877 Loss: 0.008581207133829594\n",
      "Epoch: 8878 Loss: 0.008579747751355171\n",
      "Epoch: 8879 Loss: 0.008578411303460598\n",
      "Epoch: 8880 Loss: 0.008577309548854828\n",
      "Epoch: 8881 Loss: 0.008574443869292736\n",
      "Epoch: 8882 Loss: 0.00857304222881794\n",
      "Epoch: 8883 Loss: 0.008574455045163631\n",
      "Epoch: 8884 Loss: 0.00856985617429018\n",
      "Epoch: 8885 Loss: 0.008570512756705284\n",
      "Epoch: 8886 Loss: 0.008567051030695438\n",
      "Epoch: 8887 Loss: 0.008565989322960377\n",
      "Epoch: 8888 Loss: 0.008564377203583717\n",
      "Epoch: 8889 Loss: 0.008563936688005924\n",
      "Epoch: 8890 Loss: 0.008561833761632442\n",
      "Epoch: 8891 Loss: 0.008559622801840305\n",
      "Epoch: 8892 Loss: 0.008557775989174843\n",
      "Epoch: 8893 Loss: 0.008556096814572811\n",
      "Epoch: 8894 Loss: 0.008556611835956573\n",
      "Epoch: 8895 Loss: 0.008555319160223007\n",
      "Epoch: 8896 Loss: 0.008552880957722664\n",
      "Epoch: 8897 Loss: 0.00855175033211708\n",
      "Epoch: 8898 Loss: 0.008549181744456291\n",
      "Epoch: 8899 Loss: 0.008547574281692505\n",
      "Epoch: 8900 Loss: 0.00854573491960764\n",
      "Epoch: 8901 Loss: 0.008543062023818493\n",
      "Epoch: 8902 Loss: 0.008543932810425758\n",
      "Epoch: 8903 Loss: 0.008541404269635677\n",
      "Epoch: 8904 Loss: 0.008538899011909962\n",
      "Epoch: 8905 Loss: 0.008538919501006603\n",
      "Epoch: 8906 Loss: 0.008536036126315594\n",
      "Epoch: 8907 Loss: 0.008536025881767273\n",
      "Epoch: 8908 Loss: 0.008533110842108727\n",
      "Epoch: 8909 Loss: 0.008531803265213966\n",
      "Epoch: 8910 Loss: 0.008530260063707829\n",
      "Epoch: 8911 Loss: 0.008530829101800919\n",
      "Epoch: 8912 Loss: 0.008527705445885658\n",
      "Epoch: 8913 Loss: 0.008527734316885471\n",
      "Epoch: 8914 Loss: 0.008524925448000431\n",
      "Epoch: 8915 Loss: 0.008522739633917809\n",
      "Epoch: 8916 Loss: 0.00852037314325571\n",
      "Epoch: 8917 Loss: 0.008519190363585949\n",
      "Epoch: 8918 Loss: 0.008518357761204243\n",
      "Epoch: 8919 Loss: 0.008515660651028156\n",
      "Epoch: 8920 Loss: 0.008516398258507252\n",
      "Epoch: 8921 Loss: 0.008513378910720348\n",
      "Epoch: 8922 Loss: 0.008513553068041801\n",
      "Epoch: 8923 Loss: 0.008509908802807331\n",
      "Epoch: 8924 Loss: 0.008510186336934566\n",
      "Epoch: 8925 Loss: 0.008506766520440578\n",
      "Epoch: 8926 Loss: 0.008505419827997684\n",
      "Epoch: 8927 Loss: 0.008504390716552734\n",
      "Epoch: 8928 Loss: 0.008504760451614857\n",
      "Epoch: 8929 Loss: 0.008501176722347736\n",
      "Epoch: 8930 Loss: 0.008499911054968834\n",
      "Epoch: 8931 Loss: 0.008498284965753555\n",
      "Epoch: 8932 Loss: 0.008497452363371849\n",
      "Epoch: 8933 Loss: 0.008495992980897427\n",
      "Epoch: 8934 Loss: 0.00849517434835434\n",
      "Epoch: 8935 Loss: 0.0084927286952734\n",
      "Epoch: 8936 Loss: 0.00849022064357996\n",
      "Epoch: 8937 Loss: 0.008489714935421944\n",
      "Epoch: 8938 Loss: 0.008486948907375336\n",
      "Epoch: 8939 Loss: 0.008487768471240997\n",
      "Epoch: 8940 Loss: 0.008483920246362686\n",
      "Epoch: 8941 Loss: 0.0084847966209054\n",
      "Epoch: 8942 Loss: 0.00848026666790247\n",
      "Epoch: 8943 Loss: 0.008480171672999859\n",
      "Epoch: 8944 Loss: 0.008477414958178997\n",
      "Epoch: 8945 Loss: 0.008479369804263115\n",
      "Epoch: 8946 Loss: 0.008474505506455898\n",
      "Epoch: 8947 Loss: 0.008475078269839287\n",
      "Epoch: 8948 Loss: 0.008472705259919167\n",
      "Epoch: 8949 Loss: 0.008470600470900536\n",
      "Epoch: 8950 Loss: 0.008469858206808567\n",
      "Epoch: 8951 Loss: 0.0084690498188138\n",
      "Epoch: 8952 Loss: 0.008466736413538456\n",
      "Epoch: 8953 Loss: 0.008465172722935677\n",
      "Epoch: 8954 Loss: 0.008463036268949509\n",
      "Epoch: 8955 Loss: 0.00846216082572937\n",
      "Epoch: 8956 Loss: 0.00846121832728386\n",
      "Epoch: 8957 Loss: 0.008458182215690613\n",
      "Epoch: 8958 Loss: 0.008458270691335201\n",
      "Epoch: 8959 Loss: 0.0084557319059968\n",
      "Epoch: 8960 Loss: 0.008455181494355202\n",
      "Epoch: 8961 Loss: 0.008452128618955612\n",
      "Epoch: 8962 Loss: 0.008452740497887135\n",
      "Epoch: 8963 Loss: 0.008448648266494274\n",
      "Epoch: 8964 Loss: 0.008449256420135498\n",
      "Epoch: 8965 Loss: 0.008447068743407726\n",
      "Epoch: 8966 Loss: 0.008444688282907009\n",
      "Epoch: 8967 Loss: 0.008444706909358501\n",
      "Epoch: 8968 Loss: 0.008441987447440624\n",
      "Epoch: 8969 Loss: 0.008441106416285038\n",
      "Epoch: 8970 Loss: 0.008438203483819962\n",
      "Epoch: 8971 Loss: 0.008437734097242355\n",
      "Epoch: 8972 Loss: 0.00843556597828865\n",
      "Epoch: 8973 Loss: 0.008433409035205841\n",
      "Epoch: 8974 Loss: 0.00843346118927002\n",
      "Epoch: 8975 Loss: 0.008431532420217991\n",
      "Epoch: 8976 Loss: 0.008429727517068386\n",
      "Epoch: 8977 Loss: 0.00842845905572176\n",
      "Epoch: 8978 Loss: 0.008428345434367657\n",
      "Epoch: 8979 Loss: 0.008426059037446976\n",
      "Epoch: 8980 Loss: 0.008422710932791233\n",
      "Epoch: 8981 Loss: 0.008421043865382671\n",
      "Epoch: 8982 Loss: 0.008420834317803383\n",
      "Epoch: 8983 Loss: 0.00841994397342205\n",
      "Epoch: 8984 Loss: 0.00841835793107748\n",
      "Epoch: 8985 Loss: 0.008415973745286465\n",
      "Epoch: 8986 Loss: 0.008414763025939465\n",
      "Epoch: 8987 Loss: 0.008414127863943577\n",
      "Epoch: 8988 Loss: 0.008410454727709293\n",
      "Epoch: 8989 Loss: 0.008409855887293816\n",
      "Epoch: 8990 Loss: 0.008408469147980213\n",
      "Epoch: 8991 Loss: 0.008407541550695896\n",
      "Epoch: 8992 Loss: 0.008405481465160847\n",
      "Epoch: 8993 Loss: 0.008405263535678387\n",
      "Epoch: 8994 Loss: 0.008403606712818146\n",
      "Epoch: 8995 Loss: 0.008401540108025074\n",
      "Epoch: 8996 Loss: 0.00839888583868742\n",
      "Epoch: 8997 Loss: 0.008398276753723621\n",
      "Epoch: 8998 Loss: 0.00839633122086525\n",
      "Epoch: 8999 Loss: 0.008394838310778141\n",
      "Epoch: 9000 Loss: 0.008394792675971985\n",
      "Epoch: 9001 Loss: 0.008391490206122398\n",
      "Epoch: 9002 Loss: 0.008390950970351696\n",
      "Epoch: 9003 Loss: 0.008388670161366463\n",
      "Epoch: 9004 Loss: 0.008387686684727669\n",
      "Epoch: 9005 Loss: 0.00838606245815754\n",
      "Epoch: 9006 Loss: 0.008385906927287579\n",
      "Epoch: 9007 Loss: 0.00838282611221075\n",
      "Epoch: 9008 Loss: 0.008382960222661495\n",
      "Epoch: 9009 Loss: 0.008378923870623112\n",
      "Epoch: 9010 Loss: 0.008379871025681496\n",
      "Epoch: 9011 Loss: 0.008376548066735268\n",
      "Epoch: 9012 Loss: 0.008376779034733772\n",
      "Epoch: 9013 Loss: 0.008373488672077656\n",
      "Epoch: 9014 Loss: 0.008374171331524849\n",
      "Epoch: 9015 Loss: 0.008369983173906803\n",
      "Epoch: 9016 Loss: 0.008370507508516312\n",
      "Epoch: 9017 Loss: 0.008368810638785362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9018 Loss: 0.008366095833480358\n",
      "Epoch: 9019 Loss: 0.008365835063159466\n",
      "Epoch: 9020 Loss: 0.008362245745956898\n",
      "Epoch: 9021 Loss: 0.008363158442080021\n",
      "Epoch: 9022 Loss: 0.008361408486962318\n",
      "Epoch: 9023 Loss: 0.008359527215361595\n",
      "Epoch: 9024 Loss: 0.008358237333595753\n",
      "Epoch: 9025 Loss: 0.008355372585356236\n",
      "Epoch: 9026 Loss: 0.00835416465997696\n",
      "Epoch: 9027 Loss: 0.008353564888238907\n",
      "Epoch: 9028 Loss: 0.008353703655302525\n",
      "Epoch: 9029 Loss: 0.008350304327905178\n",
      "Epoch: 9030 Loss: 0.008349190466105938\n",
      "Epoch: 9031 Loss: 0.008347251452505589\n",
      "Epoch: 9032 Loss: 0.008344486355781555\n",
      "Epoch: 9033 Loss: 0.008344761095941067\n",
      "Epoch: 9034 Loss: 0.008342038840055466\n",
      "Epoch: 9035 Loss: 0.0083413515239954\n",
      "Epoch: 9036 Loss: 0.008341345004737377\n",
      "Epoch: 9037 Loss: 0.008338822983205318\n",
      "Epoch: 9038 Loss: 0.008337332867085934\n",
      "Epoch: 9039 Loss: 0.008334635756909847\n",
      "Epoch: 9040 Loss: 0.008334430865943432\n",
      "Epoch: 9041 Loss: 0.008331706747412682\n",
      "Epoch: 9042 Loss: 0.008330631069839\n",
      "Epoch: 9043 Loss: 0.008328547701239586\n",
      "Epoch: 9044 Loss: 0.008329133503139019\n",
      "Epoch: 9045 Loss: 0.008328369818627834\n",
      "Epoch: 9046 Loss: 0.008324041031301022\n",
      "Epoch: 9047 Loss: 0.008323010057210922\n",
      "Epoch: 9048 Loss: 0.008322044275701046\n",
      "Epoch: 9049 Loss: 0.008321767672896385\n",
      "Epoch: 9050 Loss: 0.008319951593875885\n",
      "Epoch: 9051 Loss: 0.008317172527313232\n",
      "Epoch: 9052 Loss: 0.00831700675189495\n",
      "Epoch: 9053 Loss: 0.008314263075590134\n",
      "Epoch: 9054 Loss: 0.00831421185284853\n",
      "Epoch: 9055 Loss: 0.008312036283314228\n",
      "Epoch: 9056 Loss: 0.008310232311487198\n",
      "Epoch: 9057 Loss: 0.008309539407491684\n",
      "Epoch: 9058 Loss: 0.008308343589305878\n",
      "Epoch: 9059 Loss: 0.008305500261485577\n",
      "Epoch: 9060 Loss: 0.008304482325911522\n",
      "Epoch: 9061 Loss: 0.0083039915189147\n",
      "Epoch: 9062 Loss: 0.00830045435577631\n",
      "Epoch: 9063 Loss: 0.008300763554871082\n",
      "Epoch: 9064 Loss: 0.008297881111502647\n",
      "Epoch: 9065 Loss: 0.008295493200421333\n",
      "Epoch: 9066 Loss: 0.0082967234775424\n",
      "Epoch: 9067 Loss: 0.00829518772661686\n",
      "Epoch: 9068 Loss: 0.008292987942695618\n",
      "Epoch: 9069 Loss: 0.008292454294860363\n",
      "Epoch: 9070 Loss: 0.008288735523819923\n",
      "Epoch: 9071 Loss: 0.008287710137665272\n",
      "Epoch: 9072 Loss: 0.008286228403449059\n",
      "Epoch: 9073 Loss: 0.008284755051136017\n",
      "Epoch: 9074 Loss: 0.008285694755613804\n",
      "Epoch: 9075 Loss: 0.008282437920570374\n",
      "Epoch: 9076 Loss: 0.00828263908624649\n",
      "Epoch: 9077 Loss: 0.008279295638203621\n",
      "Epoch: 9078 Loss: 0.00827813521027565\n",
      "Epoch: 9079 Loss: 0.008276069536805153\n",
      "Epoch: 9080 Loss: 0.00827641598880291\n",
      "Epoch: 9081 Loss: 0.008273144252598286\n",
      "Epoch: 9082 Loss: 0.008274165913462639\n",
      "Epoch: 9083 Loss: 0.008270367048680782\n",
      "Epoch: 9084 Loss: 0.00826926901936531\n",
      "Epoch: 9085 Loss: 0.008267929777503014\n",
      "Epoch: 9086 Loss: 0.00826758611947298\n",
      "Epoch: 9087 Loss: 0.008264651522040367\n",
      "Epoch: 9088 Loss: 0.008264179341495037\n",
      "Epoch: 9089 Loss: 0.008262116461992264\n",
      "Epoch: 9090 Loss: 0.00826028548181057\n",
      "Epoch: 9091 Loss: 0.008258667774498463\n",
      "Epoch: 9092 Loss: 0.008257213048636913\n",
      "Epoch: 9093 Loss: 0.008255848661065102\n",
      "Epoch: 9094 Loss: 0.00825437530875206\n",
      "Epoch: 9095 Loss: 0.008252767845988274\n",
      "Epoch: 9096 Loss: 0.008253880776464939\n",
      "Epoch: 9097 Loss: 0.008249464444816113\n",
      "Epoch: 9098 Loss: 0.008249596692621708\n",
      "Epoch: 9099 Loss: 0.008248482830822468\n",
      "Epoch: 9100 Loss: 0.008245804347097874\n",
      "Epoch: 9101 Loss: 0.00824417732656002\n",
      "Epoch: 9102 Loss: 0.008243481628596783\n",
      "Epoch: 9103 Loss: 0.0082404725253582\n",
      "Epoch: 9104 Loss: 0.008242019452154636\n",
      "Epoch: 9105 Loss: 0.008238585665822029\n",
      "Epoch: 9106 Loss: 0.008237463422119617\n",
      "Epoch: 9107 Loss: 0.008235341869294643\n",
      "Epoch: 9108 Loss: 0.008235125802457333\n",
      "Epoch: 9109 Loss: 0.008232615888118744\n",
      "Epoch: 9110 Loss: 0.008231647312641144\n",
      "Epoch: 9111 Loss: 0.008230889216065407\n",
      "Epoch: 9112 Loss: 0.008228408172726631\n",
      "Epoch: 9113 Loss: 0.008228645659983158\n",
      "Epoch: 9114 Loss: 0.008224732242524624\n",
      "Epoch: 9115 Loss: 0.008224207907915115\n",
      "Epoch: 9116 Loss: 0.008222597651183605\n",
      "Epoch: 9117 Loss: 0.008221501484513283\n",
      "Epoch: 9118 Loss: 0.008219619281589985\n",
      "Epoch: 9119 Loss: 0.008219926618039608\n",
      "Epoch: 9120 Loss: 0.008216106332838535\n",
      "Epoch: 9121 Loss: 0.008214357309043407\n",
      "Epoch: 9122 Loss: 0.008213799446821213\n",
      "Epoch: 9123 Loss: 0.008212859742343426\n",
      "Epoch: 9124 Loss: 0.008211738429963589\n",
      "Epoch: 9125 Loss: 0.00821067113429308\n",
      "Epoch: 9126 Loss: 0.008209344930946827\n",
      "Epoch: 9127 Loss: 0.008207679726183414\n",
      "Epoch: 9128 Loss: 0.00820589903742075\n",
      "Epoch: 9129 Loss: 0.008202909491956234\n",
      "Epoch: 9130 Loss: 0.008202340453863144\n",
      "Epoch: 9131 Loss: 0.00820169411599636\n",
      "Epoch: 9132 Loss: 0.008202067576348782\n",
      "Epoch: 9133 Loss: 0.008198766969144344\n",
      "Epoch: 9134 Loss: 0.008198143914341927\n",
      "Epoch: 9135 Loss: 0.008195070549845695\n",
      "Epoch: 9136 Loss: 0.008194800466299057\n",
      "Epoch: 9137 Loss: 0.008191813714802265\n",
      "Epoch: 9138 Loss: 0.008191771805286407\n",
      "Epoch: 9139 Loss: 0.00819141510874033\n",
      "Epoch: 9140 Loss: 0.008187913335859776\n",
      "Epoch: 9141 Loss: 0.00818726047873497\n",
      "Epoch: 9142 Loss: 0.008185715414583683\n",
      "Epoch: 9143 Loss: 0.00818348303437233\n",
      "Epoch: 9144 Loss: 0.008182629942893982\n",
      "Epoch: 9145 Loss: 0.008181318640708923\n",
      "Epoch: 9146 Loss: 0.008178764022886753\n",
      "Epoch: 9147 Loss: 0.008179713040590286\n",
      "Epoch: 9148 Loss: 0.008178242482244968\n",
      "Epoch: 9149 Loss: 0.008175058290362358\n",
      "Epoch: 9150 Loss: 0.008174454793334007\n",
      "Epoch: 9151 Loss: 0.008173688314855099\n",
      "Epoch: 9152 Loss: 0.008170961402356625\n",
      "Epoch: 9153 Loss: 0.008170521818101406\n",
      "Epoch: 9154 Loss: 0.008168581873178482\n",
      "Epoch: 9155 Loss: 0.008167494088411331\n",
      "Epoch: 9156 Loss: 0.00816589966416359\n",
      "Epoch: 9157 Loss: 0.00816443283110857\n",
      "Epoch: 9158 Loss: 0.008163491263985634\n",
      "Epoch: 9159 Loss: 0.008161854930222034\n",
      "Epoch: 9160 Loss: 0.008159412071108818\n",
      "Epoch: 9161 Loss: 0.00815972127020359\n",
      "Epoch: 9162 Loss: 0.008157524280250072\n",
      "Epoch: 9163 Loss: 0.008156857453286648\n",
      "Epoch: 9164 Loss: 0.00815499946475029\n",
      "Epoch: 9165 Loss: 0.008152964524924755\n",
      "Epoch: 9166 Loss: 0.008151654154062271\n",
      "Epoch: 9167 Loss: 0.008148799650371075\n",
      "Epoch: 9168 Loss: 0.008149564266204834\n",
      "Epoch: 9169 Loss: 0.008147620595991611\n",
      "Epoch: 9170 Loss: 0.008145874366164207\n",
      "Epoch: 9171 Loss: 0.008144429884850979\n",
      "Epoch: 9172 Loss: 0.008142908103764057\n",
      "Epoch: 9173 Loss: 0.008139927871525288\n",
      "Epoch: 9174 Loss: 0.008141673170030117\n",
      "Epoch: 9175 Loss: 0.008138203993439674\n",
      "Epoch: 9176 Loss: 0.008139782585203648\n",
      "Epoch: 9177 Loss: 0.008136062882840633\n",
      "Epoch: 9178 Loss: 0.008133278228342533\n",
      "Epoch: 9179 Loss: 0.008133139461278915\n",
      "Epoch: 9180 Loss: 0.008131573908030987\n",
      "Epoch: 9181 Loss: 0.008130738511681557\n",
      "Epoch: 9182 Loss: 0.008130629546940327\n",
      "Epoch: 9183 Loss: 0.008127782493829727\n",
      "Epoch: 9184 Loss: 0.008127165026962757\n",
      "Epoch: 9185 Loss: 0.00812536384910345\n",
      "Epoch: 9186 Loss: 0.008122853003442287\n",
      "Epoch: 9187 Loss: 0.008122064173221588\n",
      "Epoch: 9188 Loss: 0.008121362887322903\n",
      "Epoch: 9189 Loss: 0.008118240162730217\n",
      "Epoch: 9190 Loss: 0.008117224089801311\n",
      "Epoch: 9191 Loss: 0.008116418495774269\n",
      "Epoch: 9192 Loss: 0.008116546086966991\n",
      "Epoch: 9193 Loss: 0.0081139812245965\n",
      "Epoch: 9194 Loss: 0.008112163282930851\n",
      "Epoch: 9195 Loss: 0.008111145347356796\n",
      "Epoch: 9196 Loss: 0.008110062219202518\n",
      "Epoch: 9197 Loss: 0.008107759058475494\n",
      "Epoch: 9198 Loss: 0.008107536472380161\n",
      "Epoch: 9199 Loss: 0.008107248693704605\n",
      "Epoch: 9200 Loss: 0.008103511296212673\n",
      "Epoch: 9201 Loss: 0.00810337159782648\n",
      "Epoch: 9202 Loss: 0.008101814426481724\n",
      "Epoch: 9203 Loss: 0.008099819533526897\n",
      "Epoch: 9204 Loss: 0.008097773417830467\n",
      "Epoch: 9205 Loss: 0.00809631310403347\n",
      "Epoch: 9206 Loss: 0.008096190169453621\n",
      "Epoch: 9207 Loss: 0.008094298653304577\n",
      "Epoch: 9208 Loss: 0.00809415802359581\n",
      "Epoch: 9209 Loss: 0.008091400377452374\n",
      "Epoch: 9210 Loss: 0.008090216666460037\n",
      "Epoch: 9211 Loss: 0.0080881267786026\n",
      "Epoch: 9212 Loss: 0.008087396621704102\n",
      "Epoch: 9213 Loss: 0.008086329326033592\n",
      "Epoch: 9214 Loss: 0.008084977976977825\n",
      "Epoch: 9215 Loss: 0.008085113950073719\n",
      "Epoch: 9216 Loss: 0.008081154897809029\n",
      "Epoch: 9217 Loss: 0.008080732077360153\n",
      "Epoch: 9218 Loss: 0.008078385144472122\n",
      "Epoch: 9219 Loss: 0.00807864684611559\n",
      "Epoch: 9220 Loss: 0.008076496422290802\n",
      "Epoch: 9221 Loss: 0.008076390251517296\n",
      "Epoch: 9222 Loss: 0.008073792792856693\n",
      "Epoch: 9223 Loss: 0.008072759956121445\n",
      "Epoch: 9224 Loss: 0.008070412091910839\n",
      "Epoch: 9225 Loss: 0.008069036528468132\n",
      "Epoch: 9226 Loss: 0.008068243972957134\n",
      "Epoch: 9227 Loss: 0.008066290989518166\n",
      "Epoch: 9228 Loss: 0.008065760135650635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9229 Loss: 0.008065410889685154\n",
      "Epoch: 9230 Loss: 0.008063126355409622\n",
      "Epoch: 9231 Loss: 0.008062590844929218\n",
      "Epoch: 9232 Loss: 0.008059917017817497\n",
      "Epoch: 9233 Loss: 0.008057991042733192\n",
      "Epoch: 9234 Loss: 0.008056676015257835\n",
      "Epoch: 9235 Loss: 0.008056667633354664\n",
      "Epoch: 9236 Loss: 0.008054149337112904\n",
      "Epoch: 9237 Loss: 0.008053140714764595\n",
      "Epoch: 9238 Loss: 0.008051207289099693\n",
      "Epoch: 9239 Loss: 0.008051753975450993\n",
      "Epoch: 9240 Loss: 0.008048572577536106\n",
      "Epoch: 9241 Loss: 0.008048422634601593\n",
      "Epoch: 9242 Loss: 0.008046719245612621\n",
      "Epoch: 9243 Loss: 0.008043814450502396\n",
      "Epoch: 9244 Loss: 0.008043681271374226\n",
      "Epoch: 9245 Loss: 0.008042174391448498\n",
      "Epoch: 9246 Loss: 0.008040567860007286\n",
      "Epoch: 9247 Loss: 0.008041037246584892\n",
      "Epoch: 9248 Loss: 0.008038198575377464\n",
      "Epoch: 9249 Loss: 0.008037485182285309\n",
      "Epoch: 9250 Loss: 0.008035843260586262\n",
      "Epoch: 9251 Loss: 0.00803342740982771\n",
      "Epoch: 9252 Loss: 0.008032134734094143\n",
      "Epoch: 9253 Loss: 0.008033109828829765\n",
      "Epoch: 9254 Loss: 0.008029844611883163\n",
      "Epoch: 9255 Loss: 0.008028674870729446\n",
      "Epoch: 9256 Loss: 0.008026153780519962\n",
      "Epoch: 9257 Loss: 0.00802687555551529\n",
      "Epoch: 9258 Loss: 0.008023261092603207\n",
      "Epoch: 9259 Loss: 0.008023427799344063\n",
      "Epoch: 9260 Loss: 0.008020983077585697\n",
      "Epoch: 9261 Loss: 0.008021148853003979\n",
      "Epoch: 9262 Loss: 0.008018642663955688\n",
      "Epoch: 9263 Loss: 0.008018638007342815\n",
      "Epoch: 9264 Loss: 0.008016156032681465\n",
      "Epoch: 9265 Loss: 0.008014831691980362\n",
      "Epoch: 9266 Loss: 0.008013027720153332\n",
      "Epoch: 9267 Loss: 0.008012359030544758\n",
      "Epoch: 9268 Loss: 0.0080106221139431\n",
      "Epoch: 9269 Loss: 0.008011418394744396\n",
      "Epoch: 9270 Loss: 0.008007325232028961\n",
      "Epoch: 9271 Loss: 0.008007168769836426\n",
      "Epoch: 9272 Loss: 0.008005351759493351\n",
      "Epoch: 9273 Loss: 0.00800312403589487\n",
      "Epoch: 9274 Loss: 0.00800186675041914\n",
      "Epoch: 9275 Loss: 0.008001413196325302\n",
      "Epoch: 9276 Loss: 0.008000829257071018\n",
      "Epoch: 9277 Loss: 0.00799883808940649\n",
      "Epoch: 9278 Loss: 0.00799714308232069\n",
      "Epoch: 9279 Loss: 0.007996284402906895\n",
      "Epoch: 9280 Loss: 0.00799581129103899\n",
      "Epoch: 9281 Loss: 0.00799253024160862\n",
      "Epoch: 9282 Loss: 0.007992550730705261\n",
      "Epoch: 9283 Loss: 0.007989848032593727\n",
      "Epoch: 9284 Loss: 0.0079894894734025\n",
      "Epoch: 9285 Loss: 0.007988441735506058\n",
      "Epoch: 9286 Loss: 0.007987529039382935\n",
      "Epoch: 9287 Loss: 0.00798443891108036\n",
      "Epoch: 9288 Loss: 0.007984653115272522\n",
      "Epoch: 9289 Loss: 0.00798130128532648\n",
      "Epoch: 9290 Loss: 0.007982547394931316\n",
      "Epoch: 9291 Loss: 0.007979498244822025\n",
      "Epoch: 9292 Loss: 0.007978042587637901\n",
      "Epoch: 9293 Loss: 0.00797786470502615\n",
      "Epoch: 9294 Loss: 0.007975134998559952\n",
      "Epoch: 9295 Loss: 0.007975038141012192\n",
      "Epoch: 9296 Loss: 0.00797331053763628\n",
      "Epoch: 9297 Loss: 0.007971067912876606\n",
      "Epoch: 9298 Loss: 0.00797017477452755\n",
      "Epoch: 9299 Loss: 0.007968287914991379\n",
      "Epoch: 9300 Loss: 0.007967742159962654\n",
      "Epoch: 9301 Loss: 0.007965358905494213\n",
      "Epoch: 9302 Loss: 0.0079652713611722\n",
      "Epoch: 9303 Loss: 0.007962449453771114\n",
      "Epoch: 9304 Loss: 0.007964457385241985\n",
      "Epoch: 9305 Loss: 0.007960655726492405\n",
      "Epoch: 9306 Loss: 0.007959846407175064\n",
      "Epoch: 9307 Loss: 0.007957926951348782\n",
      "Epoch: 9308 Loss: 0.007956166751682758\n",
      "Epoch: 9309 Loss: 0.007955607958137989\n",
      "Epoch: 9310 Loss: 0.007955034263432026\n",
      "Epoch: 9311 Loss: 0.00795185100287199\n",
      "Epoch: 9312 Loss: 0.00795238371938467\n",
      "Epoch: 9313 Loss: 0.00794988963752985\n",
      "Epoch: 9314 Loss: 0.00794814433902502\n",
      "Epoch: 9315 Loss: 0.007946920581161976\n",
      "Epoch: 9316 Loss: 0.007945090532302856\n",
      "Epoch: 9317 Loss: 0.007946007885038853\n",
      "Epoch: 9318 Loss: 0.007943302392959595\n",
      "Epoch: 9319 Loss: 0.007941268384456635\n",
      "Epoch: 9320 Loss: 0.00794226210564375\n",
      "Epoch: 9321 Loss: 0.00794061180204153\n",
      "Epoch: 9322 Loss: 0.007937694899737835\n",
      "Epoch: 9323 Loss: 0.007936418056488037\n",
      "Epoch: 9324 Loss: 0.007934560999274254\n",
      "Epoch: 9325 Loss: 0.007936053909361362\n",
      "Epoch: 9326 Loss: 0.007932963781058788\n",
      "Epoch: 9327 Loss: 0.007932737469673157\n",
      "Epoch: 9328 Loss: 0.007929598912596703\n",
      "Epoch: 9329 Loss: 0.007928334176540375\n",
      "Epoch: 9330 Loss: 0.007926937192678452\n",
      "Epoch: 9331 Loss: 0.007925758138298988\n",
      "Epoch: 9332 Loss: 0.007924383506178856\n",
      "Epoch: 9333 Loss: 0.007923426106572151\n",
      "Epoch: 9334 Loss: 0.007921862415969372\n",
      "Epoch: 9335 Loss: 0.00791994296014309\n",
      "Epoch: 9336 Loss: 0.007920623756945133\n",
      "Epoch: 9337 Loss: 0.007917637005448341\n",
      "Epoch: 9338 Loss: 0.007917197421193123\n",
      "Epoch: 9339 Loss: 0.007914457470178604\n",
      "Epoch: 9340 Loss: 0.007913798093795776\n",
      "Epoch: 9341 Loss: 0.007912438362836838\n",
      "Epoch: 9342 Loss: 0.007911366410553455\n",
      "Epoch: 9343 Loss: 0.007909473963081837\n",
      "Epoch: 9344 Loss: 0.00790821947157383\n",
      "Epoch: 9345 Loss: 0.007906896993517876\n",
      "Epoch: 9346 Loss: 0.007906266488134861\n",
      "Epoch: 9347 Loss: 0.007904820144176483\n",
      "Epoch: 9348 Loss: 0.0079020531848073\n",
      "Epoch: 9349 Loss: 0.007901052013039589\n",
      "Epoch: 9350 Loss: 0.007901066914200783\n",
      "Epoch: 9351 Loss: 0.007898921146988869\n",
      "Epoch: 9352 Loss: 0.00789736583828926\n",
      "Epoch: 9353 Loss: 0.007897517643868923\n",
      "Epoch: 9354 Loss: 0.00789513811469078\n",
      "Epoch: 9355 Loss: 0.00789522286504507\n",
      "Epoch: 9356 Loss: 0.00789231713861227\n",
      "Epoch: 9357 Loss: 0.007890830747783184\n",
      "Epoch: 9358 Loss: 0.007889695465564728\n",
      "Epoch: 9359 Loss: 0.007887227460741997\n",
      "Epoch: 9360 Loss: 0.007887134328484535\n",
      "Epoch: 9361 Loss: 0.007885836996138096\n",
      "Epoch: 9362 Loss: 0.007884213700890541\n",
      "Epoch: 9363 Loss: 0.007884171791374683\n",
      "Epoch: 9364 Loss: 0.007882030680775642\n",
      "Epoch: 9365 Loss: 0.007880344986915588\n",
      "Epoch: 9366 Loss: 0.007879136130213737\n",
      "Epoch: 9367 Loss: 0.007877388969063759\n",
      "Epoch: 9368 Loss: 0.007876419462263584\n",
      "Epoch: 9369 Loss: 0.007875331677496433\n",
      "Epoch: 9370 Loss: 0.007873158901929855\n",
      "Epoch: 9371 Loss: 0.00787318218499422\n",
      "Epoch: 9372 Loss: 0.007870983332395554\n",
      "Epoch: 9373 Loss: 0.00787032674998045\n",
      "Epoch: 9374 Loss: 0.007868004031479359\n",
      "Epoch: 9375 Loss: 0.007867089472711086\n",
      "Epoch: 9376 Loss: 0.00786508060991764\n",
      "Epoch: 9377 Loss: 0.007865658029913902\n",
      "Epoch: 9378 Loss: 0.007863296195864677\n",
      "Epoch: 9379 Loss: 0.007862432859838009\n",
      "Epoch: 9380 Loss: 0.007860318757593632\n",
      "Epoch: 9381 Loss: 0.007859496399760246\n",
      "Epoch: 9382 Loss: 0.007856909185647964\n",
      "Epoch: 9383 Loss: 0.00785622838884592\n",
      "Epoch: 9384 Loss: 0.007855706848204136\n",
      "Epoch: 9385 Loss: 0.007854806259274483\n",
      "Epoch: 9386 Loss: 0.007852358743548393\n",
      "Epoch: 9387 Loss: 0.007850682362914085\n",
      "Epoch: 9388 Loss: 0.007850668393075466\n",
      "Epoch: 9389 Loss: 0.007847482338547707\n",
      "Epoch: 9390 Loss: 0.007847776636481285\n",
      "Epoch: 9391 Loss: 0.00784611701965332\n",
      "Epoch: 9392 Loss: 0.007846005260944366\n",
      "Epoch: 9393 Loss: 0.007843281142413616\n",
      "Epoch: 9394 Loss: 0.00784212164580822\n",
      "Epoch: 9395 Loss: 0.00784015841782093\n",
      "Epoch: 9396 Loss: 0.007839211262762547\n",
      "Epoch: 9397 Loss: 0.007837653160095215\n",
      "Epoch: 9398 Loss: 0.007837015204131603\n",
      "Epoch: 9399 Loss: 0.007836129516363144\n",
      "Epoch: 9400 Loss: 0.007834449410438538\n",
      "Epoch: 9401 Loss: 0.007832026109099388\n",
      "Epoch: 9402 Loss: 0.007831471972167492\n",
      "Epoch: 9403 Loss: 0.007831410504877567\n",
      "Epoch: 9404 Loss: 0.0078284228220582\n",
      "Epoch: 9405 Loss: 0.00782906822860241\n",
      "Epoch: 9406 Loss: 0.00782647542655468\n",
      "Epoch: 9407 Loss: 0.007824732922017574\n",
      "Epoch: 9408 Loss: 0.007823697291314602\n",
      "Epoch: 9409 Loss: 0.007822184823453426\n",
      "Epoch: 9410 Loss: 0.007821197621524334\n",
      "Epoch: 9411 Loss: 0.007819521240890026\n",
      "Epoch: 9412 Loss: 0.007818461395800114\n",
      "Epoch: 9413 Loss: 0.007818802259862423\n",
      "Epoch: 9414 Loss: 0.007814968004822731\n",
      "Epoch: 9415 Loss: 0.007815147750079632\n",
      "Epoch: 9416 Loss: 0.007813111878931522\n",
      "Epoch: 9417 Loss: 0.007811881601810455\n",
      "Epoch: 9418 Loss: 0.007810824550688267\n",
      "Epoch: 9419 Loss: 0.007808991242200136\n",
      "Epoch: 9420 Loss: 0.007807527668774128\n",
      "Epoch: 9421 Loss: 0.0078063546679914\n",
      "Epoch: 9422 Loss: 0.007804383523762226\n",
      "Epoch: 9423 Loss: 0.007804613560438156\n",
      "Epoch: 9424 Loss: 0.00780424103140831\n",
      "Epoch: 9425 Loss: 0.00780131621286273\n",
      "Epoch: 9426 Loss: 0.00779979582875967\n",
      "Epoch: 9427 Loss: 0.007798795588314533\n",
      "Epoch: 9428 Loss: 0.00779719790443778\n",
      "Epoch: 9429 Loss: 0.007796437945216894\n",
      "Epoch: 9430 Loss: 0.0077952612191438675\n",
      "Epoch: 9431 Loss: 0.007794886827468872\n",
      "Epoch: 9432 Loss: 0.007792896591126919\n",
      "Epoch: 9433 Loss: 0.007790978066623211\n",
      "Epoch: 9434 Loss: 0.007789534516632557\n",
      "Epoch: 9435 Loss: 0.007788035552948713\n",
      "Epoch: 9436 Loss: 0.007786572445183992\n",
      "Epoch: 9437 Loss: 0.007786577567458153\n",
      "Epoch: 9438 Loss: 0.007784706074744463\n",
      "Epoch: 9439 Loss: 0.007783019449561834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9440 Loss: 0.0077818105928599834\n",
      "Epoch: 9441 Loss: 0.00778015935793519\n",
      "Epoch: 9442 Loss: 0.007779161911457777\n",
      "Epoch: 9443 Loss: 0.007778869941830635\n",
      "Epoch: 9444 Loss: 0.0077768657356500626\n",
      "Epoch: 9445 Loss: 0.00777604803442955\n",
      "Epoch: 9446 Loss: 0.00777348130941391\n",
      "Epoch: 9447 Loss: 0.007772673387080431\n",
      "Epoch: 9448 Loss: 0.007770674768835306\n",
      "Epoch: 9449 Loss: 0.007770088966935873\n",
      "Epoch: 9450 Loss: 0.007769712246954441\n",
      "Epoch: 9451 Loss: 0.007767428178340197\n",
      "Epoch: 9452 Loss: 0.007767190225422382\n",
      "Epoch: 9453 Loss: 0.007764569018036127\n",
      "Epoch: 9454 Loss: 0.007764304522424936\n",
      "Epoch: 9455 Loss: 0.00776159530505538\n",
      "Epoch: 9456 Loss: 0.00776186166331172\n",
      "Epoch: 9457 Loss: 0.007759660482406616\n",
      "Epoch: 9458 Loss: 0.007759453728795052\n",
      "Epoch: 9459 Loss: 0.0077573680318892\n",
      "Epoch: 9460 Loss: 0.007756866980344057\n",
      "Epoch: 9461 Loss: 0.0077538564801216125\n",
      "Epoch: 9462 Loss: 0.007754669990390539\n",
      "Epoch: 9463 Loss: 0.0077517107129096985\n",
      "Epoch: 9464 Loss: 0.007750430144369602\n",
      "Epoch: 9465 Loss: 0.007749214768409729\n",
      "Epoch: 9466 Loss: 0.007747812196612358\n",
      "Epoch: 9467 Loss: 0.007748066447675228\n",
      "Epoch: 9468 Loss: 0.007746601477265358\n",
      "Epoch: 9469 Loss: 0.007744651287794113\n",
      "Epoch: 9470 Loss: 0.007743839640170336\n",
      "Epoch: 9471 Loss: 0.007741882465779781\n",
      "Epoch: 9472 Loss: 0.007740602362900972\n",
      "Epoch: 9473 Loss: 0.007739303633570671\n",
      "Epoch: 9474 Loss: 0.007738128304481506\n",
      "Epoch: 9475 Loss: 0.007737237960100174\n",
      "Epoch: 9476 Loss: 0.007735538762062788\n",
      "Epoch: 9477 Loss: 0.007735376711934805\n",
      "Epoch: 9478 Loss: 0.007732369005680084\n",
      "Epoch: 9479 Loss: 0.007732156664133072\n",
      "Epoch: 9480 Loss: 0.007729488890618086\n",
      "Epoch: 9481 Loss: 0.007730518002063036\n",
      "Epoch: 9482 Loss: 0.00772840017452836\n",
      "Epoch: 9483 Loss: 0.007725895848125219\n",
      "Epoch: 9484 Loss: 0.007724958471953869\n",
      "Epoch: 9485 Loss: 0.007724852301180363\n",
      "Epoch: 9486 Loss: 0.007722740061581135\n",
      "Epoch: 9487 Loss: 0.007721255533397198\n",
      "Epoch: 9488 Loss: 0.007719343528151512\n",
      "Epoch: 9489 Loss: 0.00771786505356431\n",
      "Epoch: 9490 Loss: 0.007717412896454334\n",
      "Epoch: 9491 Loss: 0.0077157109044492245\n",
      "Epoch: 9492 Loss: 0.007715901359915733\n",
      "Epoch: 9493 Loss: 0.007713341154158115\n",
      "Epoch: 9494 Loss: 0.007713006343692541\n",
      "Epoch: 9495 Loss: 0.007710812613368034\n",
      "Epoch: 9496 Loss: 0.0077102589420974255\n",
      "Epoch: 9497 Loss: 0.0077091241255402565\n",
      "Epoch: 9498 Loss: 0.00770827941596508\n",
      "Epoch: 9499 Loss: 0.007706277538090944\n",
      "Epoch: 9500 Loss: 0.007703902665525675\n",
      "Epoch: 9501 Loss: 0.007703765761107206\n",
      "Epoch: 9502 Loss: 0.00770092336460948\n",
      "Epoch: 9503 Loss: 0.007700888440012932\n",
      "Epoch: 9504 Loss: 0.007698927074670792\n",
      "Epoch: 9505 Loss: 0.007698265835642815\n",
      "Epoch: 9506 Loss: 0.0076965996995568275\n",
      "Epoch: 9507 Loss: 0.007697489578276873\n",
      "Epoch: 9508 Loss: 0.007694116793572903\n",
      "Epoch: 9509 Loss: 0.007694227155297995\n",
      "Epoch: 9510 Loss: 0.007691048085689545\n",
      "Epoch: 9511 Loss: 0.007690634578466415\n",
      "Epoch: 9512 Loss: 0.007689652498811483\n",
      "Epoch: 9513 Loss: 0.007687471341341734\n",
      "Epoch: 9514 Loss: 0.007686493452638388\n",
      "Epoch: 9515 Loss: 0.0076873404905200005\n",
      "Epoch: 9516 Loss: 0.007683535106480122\n",
      "Epoch: 9517 Loss: 0.007684867363423109\n",
      "Epoch: 9518 Loss: 0.007681503891944885\n",
      "Epoch: 9519 Loss: 0.007680580019950867\n",
      "Epoch: 9520 Loss: 0.0076798973605036736\n",
      "Epoch: 9521 Loss: 0.007677977904677391\n",
      "Epoch: 9522 Loss: 0.007677420042455196\n",
      "Epoch: 9523 Loss: 0.007676349952816963\n",
      "Epoch: 9524 Loss: 0.007672958076000214\n",
      "Epoch: 9525 Loss: 0.007673537824302912\n",
      "Epoch: 9526 Loss: 0.00767203513532877\n",
      "Epoch: 9527 Loss: 0.007670652586966753\n",
      "Epoch: 9528 Loss: 0.007669466082006693\n",
      "Epoch: 9529 Loss: 0.00766757782548666\n",
      "Epoch: 9530 Loss: 0.0076680900529026985\n",
      "Epoch: 9531 Loss: 0.007665757555514574\n",
      "Epoch: 9532 Loss: 0.007664151024073362\n",
      "Epoch: 9533 Loss: 0.007663095835596323\n",
      "Epoch: 9534 Loss: 0.00766186136752367\n",
      "Epoch: 9535 Loss: 0.007660591043531895\n",
      "Epoch: 9536 Loss: 0.0076590231619775295\n",
      "Epoch: 9537 Loss: 0.007657576352357864\n",
      "Epoch: 9538 Loss: 0.007656174246221781\n",
      "Epoch: 9539 Loss: 0.007656843867152929\n",
      "Epoch: 9540 Loss: 0.007654438726603985\n",
      "Epoch: 9541 Loss: 0.007653425447642803\n",
      "Epoch: 9542 Loss: 0.007652942556887865\n",
      "Epoch: 9543 Loss: 0.007649999111890793\n",
      "Epoch: 9544 Loss: 0.007648939732462168\n",
      "Epoch: 9545 Loss: 0.007647467311471701\n",
      "Epoch: 9546 Loss: 0.007646417710930109\n",
      "Epoch: 9547 Loss: 0.00764482980594039\n",
      "Epoch: 9548 Loss: 0.0076455832459032536\n",
      "Epoch: 9549 Loss: 0.007642433978617191\n",
      "Epoch: 9550 Loss: 0.0076422132551670074\n",
      "Epoch: 9551 Loss: 0.007640201598405838\n",
      "Epoch: 9552 Loss: 0.007638347800821066\n",
      "Epoch: 9553 Loss: 0.007637334987521172\n",
      "Epoch: 9554 Loss: 0.007638219743967056\n",
      "Epoch: 9555 Loss: 0.007635662332177162\n",
      "Epoch: 9556 Loss: 0.007635193411260843\n",
      "Epoch: 9557 Loss: 0.00763187138363719\n",
      "Epoch: 9558 Loss: 0.007632649037986994\n",
      "Epoch: 9559 Loss: 0.0076292939484119415\n",
      "Epoch: 9560 Loss: 0.007628754246979952\n",
      "Epoch: 9561 Loss: 0.00762792956084013\n",
      "Epoch: 9562 Loss: 0.0076260678470134735\n",
      "Epoch: 9563 Loss: 0.007625439204275608\n",
      "Epoch: 9564 Loss: 0.0076244669035077095\n",
      "Epoch: 9565 Loss: 0.007623280864208937\n",
      "Epoch: 9566 Loss: 0.0076215933077037334\n",
      "Epoch: 9567 Loss: 0.007621860131621361\n",
      "Epoch: 9568 Loss: 0.007619818672537804\n",
      "Epoch: 9569 Loss: 0.007618541829288006\n",
      "Epoch: 9570 Loss: 0.007615908980369568\n",
      "Epoch: 9571 Loss: 0.007614279165863991\n",
      "Epoch: 9572 Loss: 0.0076133799739181995\n",
      "Epoch: 9573 Loss: 0.007614150643348694\n",
      "Epoch: 9574 Loss: 0.007610730826854706\n",
      "Epoch: 9575 Loss: 0.007612049579620361\n",
      "Epoch: 9576 Loss: 0.007608703337609768\n",
      "Epoch: 9577 Loss: 0.007608203217387199\n",
      "Epoch: 9578 Loss: 0.007605748251080513\n",
      "Epoch: 9579 Loss: 0.007604858372360468\n",
      "Epoch: 9580 Loss: 0.007605093996971846\n",
      "Epoch: 9581 Loss: 0.007601996883749962\n",
      "Epoch: 9582 Loss: 0.007602945435792208\n",
      "Epoch: 9583 Loss: 0.0076007056050002575\n",
      "Epoch: 9584 Loss: 0.0075994026847183704\n",
      "Epoch: 9585 Loss: 0.007597522810101509\n",
      "Epoch: 9586 Loss: 0.007597058080136776\n",
      "Epoch: 9587 Loss: 0.007595096714794636\n",
      "Epoch: 9588 Loss: 0.007595105562359095\n",
      "Epoch: 9589 Loss: 0.007592613808810711\n",
      "Epoch: 9590 Loss: 0.0075910394079983234\n",
      "Epoch: 9591 Loss: 0.007590604480355978\n",
      "Epoch: 9592 Loss: 0.007588416337966919\n",
      "Epoch: 9593 Loss: 0.007589159533381462\n",
      "Epoch: 9594 Loss: 0.007587042637169361\n",
      "Epoch: 9595 Loss: 0.00758536858484149\n",
      "Epoch: 9596 Loss: 0.007584112696349621\n",
      "Epoch: 9597 Loss: 0.007582912687212229\n",
      "Epoch: 9598 Loss: 0.007581747602671385\n",
      "Epoch: 9599 Loss: 0.00758024537935853\n",
      "Epoch: 9600 Loss: 0.00757921626791358\n",
      "Epoch: 9601 Loss: 0.007577701471745968\n",
      "Epoch: 9602 Loss: 0.007579410448670387\n",
      "Epoch: 9603 Loss: 0.007576069328933954\n",
      "Epoch: 9604 Loss: 0.007575239520519972\n",
      "Epoch: 9605 Loss: 0.007573367096483707\n",
      "Epoch: 9606 Loss: 0.0075712851248681545\n",
      "Epoch: 9607 Loss: 0.007570662535727024\n",
      "Epoch: 9608 Loss: 0.007569689303636551\n",
      "Epoch: 9609 Loss: 0.00756876403465867\n",
      "Epoch: 9610 Loss: 0.007567198947072029\n",
      "Epoch: 9611 Loss: 0.00756815355271101\n",
      "Epoch: 9612 Loss: 0.007563300896435976\n",
      "Epoch: 9613 Loss: 0.007564936764538288\n",
      "Epoch: 9614 Loss: 0.007561625447124243\n",
      "Epoch: 9615 Loss: 0.0075608170591294765\n",
      "Epoch: 9616 Loss: 0.007559593301266432\n",
      "Epoch: 9617 Loss: 0.007558127865195274\n",
      "Epoch: 9618 Loss: 0.0075570023618638515\n",
      "Epoch: 9619 Loss: 0.007555263116955757\n",
      "Epoch: 9620 Loss: 0.007554489187896252\n",
      "Epoch: 9621 Loss: 0.007552855648100376\n",
      "Epoch: 9622 Loss: 0.007552431896328926\n",
      "Epoch: 9623 Loss: 0.00755255576223135\n",
      "Epoch: 9624 Loss: 0.007550403010100126\n",
      "Epoch: 9625 Loss: 0.007548388559371233\n",
      "Epoch: 9626 Loss: 0.007546746637672186\n",
      "Epoch: 9627 Loss: 0.0075461906380951405\n",
      "Epoch: 9628 Loss: 0.007545835338532925\n",
      "Epoch: 9629 Loss: 0.007545317057520151\n",
      "Epoch: 9630 Loss: 0.007542433682829142\n",
      "Epoch: 9631 Loss: 0.007541645783931017\n",
      "Epoch: 9632 Loss: 0.00754051236435771\n",
      "Epoch: 9633 Loss: 0.007539091631770134\n",
      "Epoch: 9634 Loss: 0.007537001743912697\n",
      "Epoch: 9635 Loss: 0.007536397781223059\n",
      "Epoch: 9636 Loss: 0.0075354608707129955\n",
      "Epoch: 9637 Loss: 0.007532511837780476\n",
      "Epoch: 9638 Loss: 0.007533088326454163\n",
      "Epoch: 9639 Loss: 0.007531145121902227\n",
      "Epoch: 9640 Loss: 0.007532580755650997\n",
      "Epoch: 9641 Loss: 0.00752984406426549\n",
      "Epoch: 9642 Loss: 0.007528358139097691\n",
      "Epoch: 9643 Loss: 0.007525708992034197\n",
      "Epoch: 9644 Loss: 0.0075249928049743176\n",
      "Epoch: 9645 Loss: 0.007523677311837673\n",
      "Epoch: 9646 Loss: 0.007523721549659967\n",
      "Epoch: 9647 Loss: 0.007522747851908207\n",
      "Epoch: 9648 Loss: 0.0075198570266366005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9649 Loss: 0.007519821170717478\n",
      "Epoch: 9650 Loss: 0.0075194574892520905\n",
      "Epoch: 9651 Loss: 0.007516226731240749\n",
      "Epoch: 9652 Loss: 0.007516443729400635\n",
      "Epoch: 9653 Loss: 0.007514316122978926\n",
      "Epoch: 9654 Loss: 0.007512956392019987\n",
      "Epoch: 9655 Loss: 0.007511714473366737\n",
      "Epoch: 9656 Loss: 0.007510228548198938\n",
      "Epoch: 9657 Loss: 0.007510131224989891\n",
      "Epoch: 9658 Loss: 0.0075102560222148895\n",
      "Epoch: 9659 Loss: 0.007507494185119867\n",
      "Epoch: 9660 Loss: 0.007507339119911194\n",
      "Epoch: 9661 Loss: 0.007504912093281746\n",
      "Epoch: 9662 Loss: 0.007502904161810875\n",
      "Epoch: 9663 Loss: 0.007503639906644821\n",
      "Epoch: 9664 Loss: 0.0075004748068749905\n",
      "Epoch: 9665 Loss: 0.007500283420085907\n",
      "Epoch: 9666 Loss: 0.0074988496489822865\n",
      "Epoch: 9667 Loss: 0.0074975620955228806\n",
      "Epoch: 9668 Loss: 0.007495954167097807\n",
      "Epoch: 9669 Loss: 0.007496558595448732\n",
      "Epoch: 9670 Loss: 0.0074934023432433605\n",
      "Epoch: 9671 Loss: 0.007493134122341871\n",
      "Epoch: 9672 Loss: 0.007492254488170147\n",
      "Epoch: 9673 Loss: 0.0074903578497469425\n",
      "Epoch: 9674 Loss: 0.007489325478672981\n",
      "Epoch: 9675 Loss: 0.007487513590604067\n",
      "Epoch: 9676 Loss: 0.007486273068934679\n",
      "Epoch: 9677 Loss: 0.0074853310361504555\n",
      "Epoch: 9678 Loss: 0.007485081907361746\n",
      "Epoch: 9679 Loss: 0.007483320776373148\n",
      "Epoch: 9680 Loss: 0.0074822427704930305\n",
      "Epoch: 9681 Loss: 0.0074807144701480865\n",
      "Epoch: 9682 Loss: 0.007480771280825138\n",
      "Epoch: 9683 Loss: 0.007477761246263981\n",
      "Epoch: 9684 Loss: 0.007478773593902588\n",
      "Epoch: 9685 Loss: 0.007475561928004026\n",
      "Epoch: 9686 Loss: 0.007474902551621199\n",
      "Epoch: 9687 Loss: 0.007473578676581383\n",
      "Epoch: 9688 Loss: 0.007472971919924021\n",
      "Epoch: 9689 Loss: 0.007470734417438507\n",
      "Epoch: 9690 Loss: 0.007471012882888317\n",
      "Epoch: 9691 Loss: 0.00746888155117631\n",
      "Epoch: 9692 Loss: 0.007468212395906448\n",
      "Epoch: 9693 Loss: 0.007466017734259367\n",
      "Epoch: 9694 Loss: 0.0074652149342000484\n",
      "Epoch: 9695 Loss: 0.007464060094207525\n",
      "Epoch: 9696 Loss: 0.007463640999048948\n",
      "Epoch: 9697 Loss: 0.007461594417691231\n",
      "Epoch: 9698 Loss: 0.007460962515324354\n",
      "Epoch: 9699 Loss: 0.007460108958184719\n",
      "Epoch: 9700 Loss: 0.0074578216299414635\n",
      "Epoch: 9701 Loss: 0.007456826977431774\n",
      "Epoch: 9702 Loss: 0.007454514503479004\n",
      "Epoch: 9703 Loss: 0.007452616933733225\n",
      "Epoch: 9704 Loss: 0.007454050239175558\n",
      "Epoch: 9705 Loss: 0.007452193181961775\n",
      "Epoch: 9706 Loss: 0.007450751960277557\n",
      "Epoch: 9707 Loss: 0.007450138684362173\n",
      "Epoch: 9708 Loss: 0.007448546122759581\n",
      "Epoch: 9709 Loss: 0.007447898853570223\n",
      "Epoch: 9710 Loss: 0.007445459719747305\n",
      "Epoch: 9711 Loss: 0.007443601731210947\n",
      "Epoch: 9712 Loss: 0.0074449400417506695\n",
      "Epoch: 9713 Loss: 0.007443102542310953\n",
      "Epoch: 9714 Loss: 0.007440982852131128\n",
      "Epoch: 9715 Loss: 0.007439735811203718\n",
      "Epoch: 9716 Loss: 0.007438334636390209\n",
      "Epoch: 9717 Loss: 0.007437581662088633\n",
      "Epoch: 9718 Loss: 0.007436745800077915\n",
      "Epoch: 9719 Loss: 0.007436206564307213\n",
      "Epoch: 9720 Loss: 0.007433414924889803\n",
      "Epoch: 9721 Loss: 0.007431921549141407\n",
      "Epoch: 9722 Loss: 0.007430392317473888\n",
      "Epoch: 9723 Loss: 0.007430658210068941\n",
      "Epoch: 9724 Loss: 0.007429381832480431\n",
      "Epoch: 9725 Loss: 0.00742813665419817\n",
      "Epoch: 9726 Loss: 0.007427423261106014\n",
      "Epoch: 9727 Loss: 0.007424834184348583\n",
      "Epoch: 9728 Loss: 0.007424978073686361\n",
      "Epoch: 9729 Loss: 0.007423629052937031\n",
      "Epoch: 9730 Loss: 0.007420834619551897\n",
      "Epoch: 9731 Loss: 0.007420763839036226\n",
      "Epoch: 9732 Loss: 0.007421503774821758\n",
      "Epoch: 9733 Loss: 0.007417776621878147\n",
      "Epoch: 9734 Loss: 0.007417640648782253\n",
      "Epoch: 9735 Loss: 0.007416166830807924\n",
      "Epoch: 9736 Loss: 0.007414133753627539\n",
      "Epoch: 9737 Loss: 0.007413612212985754\n",
      "Epoch: 9738 Loss: 0.007412092760205269\n",
      "Epoch: 9739 Loss: 0.007412318605929613\n",
      "Epoch: 9740 Loss: 0.007410361897200346\n",
      "Epoch: 9741 Loss: 0.007408543024212122\n",
      "Epoch: 9742 Loss: 0.007406691554933786\n",
      "Epoch: 9743 Loss: 0.007406697142869234\n",
      "Epoch: 9744 Loss: 0.007405589800328016\n",
      "Epoch: 9745 Loss: 0.007404274307191372\n",
      "Epoch: 9746 Loss: 0.007402223069220781\n",
      "Epoch: 9747 Loss: 0.007401134818792343\n",
      "Epoch: 9748 Loss: 0.007400467060506344\n",
      "Epoch: 9749 Loss: 0.007399371825158596\n",
      "Epoch: 9750 Loss: 0.007398481015115976\n",
      "Epoch: 9751 Loss: 0.0073971995152533054\n",
      "Epoch: 9752 Loss: 0.007396752946078777\n",
      "Epoch: 9753 Loss: 0.007393811829388142\n",
      "Epoch: 9754 Loss: 0.007394118700176477\n",
      "Epoch: 9755 Loss: 0.007391772698611021\n",
      "Epoch: 9756 Loss: 0.007390801794826984\n",
      "Epoch: 9757 Loss: 0.007391509134322405\n",
      "Epoch: 9758 Loss: 0.007388216909021139\n",
      "Epoch: 9759 Loss: 0.007387246936559677\n",
      "Epoch: 9760 Loss: 0.007386765908449888\n",
      "Epoch: 9761 Loss: 0.0073844511061906815\n",
      "Epoch: 9762 Loss: 0.007383596617728472\n",
      "Epoch: 9763 Loss: 0.007381768431514502\n",
      "Epoch: 9764 Loss: 0.007383827120065689\n",
      "Epoch: 9765 Loss: 0.007380530703812838\n",
      "Epoch: 9766 Loss: 0.007379865739494562\n",
      "Epoch: 9767 Loss: 0.007377945352345705\n",
      "Epoch: 9768 Loss: 0.0073767416179180145\n",
      "Epoch: 9769 Loss: 0.007374915294349194\n",
      "Epoch: 9770 Loss: 0.007375572342425585\n",
      "Epoch: 9771 Loss: 0.007373365573585033\n",
      "Epoch: 9772 Loss: 0.007372600492089987\n",
      "Epoch: 9773 Loss: 0.007371443789452314\n",
      "Epoch: 9774 Loss: 0.007369280327111483\n",
      "Epoch: 9775 Loss: 0.007369132712483406\n",
      "Epoch: 9776 Loss: 0.007367291487753391\n",
      "Epoch: 9777 Loss: 0.007366265170276165\n",
      "Epoch: 9778 Loss: 0.007364868652075529\n",
      "Epoch: 9779 Loss: 0.007364852353930473\n",
      "Epoch: 9780 Loss: 0.007362657226622105\n",
      "Epoch: 9781 Loss: 0.007361757569015026\n",
      "Epoch: 9782 Loss: 0.0073601240292191505\n",
      "Epoch: 9783 Loss: 0.0073590511456131935\n",
      "Epoch: 9784 Loss: 0.007359027396887541\n",
      "Epoch: 9785 Loss: 0.007356111891567707\n",
      "Epoch: 9786 Loss: 0.0073569584637880325\n",
      "Epoch: 9787 Loss: 0.007355470210313797\n",
      "Epoch: 9788 Loss: 0.007352503482252359\n",
      "Epoch: 9789 Loss: 0.007351611740887165\n",
      "Epoch: 9790 Loss: 0.007350592873990536\n",
      "Epoch: 9791 Loss: 0.007348968647420406\n",
      "Epoch: 9792 Loss: 0.0073500340804457664\n",
      "Epoch: 9793 Loss: 0.007347009144723415\n",
      "Epoch: 9794 Loss: 0.007346124853938818\n",
      "Epoch: 9795 Loss: 0.007345321122556925\n",
      "Epoch: 9796 Loss: 0.007342966739088297\n",
      "Epoch: 9797 Loss: 0.007343363482505083\n",
      "Epoch: 9798 Loss: 0.007342006079852581\n",
      "Epoch: 9799 Loss: 0.007341390009969473\n",
      "Epoch: 9800 Loss: 0.00733902445062995\n",
      "Epoch: 9801 Loss: 0.007338634226471186\n",
      "Epoch: 9802 Loss: 0.007336258422583342\n",
      "Epoch: 9803 Loss: 0.007335761561989784\n",
      "Epoch: 9804 Loss: 0.00733352592214942\n",
      "Epoch: 9805 Loss: 0.007332067936658859\n",
      "Epoch: 9806 Loss: 0.007334438618272543\n",
      "Epoch: 9807 Loss: 0.007330312393605709\n",
      "Epoch: 9808 Loss: 0.007329993415623903\n",
      "Epoch: 9809 Loss: 0.007328570354729891\n",
      "Epoch: 9810 Loss: 0.007327740546315908\n",
      "Epoch: 9811 Loss: 0.007325481157749891\n",
      "Epoch: 9812 Loss: 0.007325456477701664\n",
      "Epoch: 9813 Loss: 0.0073233237490057945\n",
      "Epoch: 9814 Loss: 0.0073225959204137325\n",
      "Epoch: 9815 Loss: 0.007321817800402641\n",
      "Epoch: 9816 Loss: 0.007320291828364134\n",
      "Epoch: 9817 Loss: 0.007319832220673561\n",
      "Epoch: 9818 Loss: 0.007317844312638044\n",
      "Epoch: 9819 Loss: 0.007317759096622467\n",
      "Epoch: 9820 Loss: 0.007316505070775747\n",
      "Epoch: 9821 Loss: 0.007314147427678108\n",
      "Epoch: 9822 Loss: 0.007313389331102371\n",
      "Epoch: 9823 Loss: 0.007312584202736616\n",
      "Epoch: 9824 Loss: 0.007312009576708078\n",
      "Epoch: 9825 Loss: 0.007310370448976755\n",
      "Epoch: 9826 Loss: 0.007309469860047102\n",
      "Epoch: 9827 Loss: 0.007307334803044796\n",
      "Epoch: 9828 Loss: 0.007306634448468685\n",
      "Epoch: 9829 Loss: 0.007305482402443886\n",
      "Epoch: 9830 Loss: 0.007305022794753313\n",
      "Epoch: 9831 Loss: 0.007302931975573301\n",
      "Epoch: 9832 Loss: 0.007301902398467064\n",
      "Epoch: 9833 Loss: 0.0073011573404073715\n",
      "Epoch: 9834 Loss: 0.0072996364906430244\n",
      "Epoch: 9835 Loss: 0.007297774776816368\n",
      "Epoch: 9836 Loss: 0.007297962438315153\n",
      "Epoch: 9837 Loss: 0.007296296767890453\n",
      "Epoch: 9838 Loss: 0.007294830400496721\n",
      "Epoch: 9839 Loss: 0.0072939046658575535\n",
      "Epoch: 9840 Loss: 0.007291375193744898\n",
      "Epoch: 9841 Loss: 0.0072919148951768875\n",
      "Epoch: 9842 Loss: 0.007290052715688944\n",
      "Epoch: 9843 Loss: 0.007290230132639408\n",
      "Epoch: 9844 Loss: 0.007287877146154642\n",
      "Epoch: 9845 Loss: 0.007288357708603144\n",
      "Epoch: 9846 Loss: 0.0072858319617807865\n",
      "Epoch: 9847 Loss: 0.007284957449883223\n",
      "Epoch: 9848 Loss: 0.007282329257577658\n",
      "Epoch: 9849 Loss: 0.007281663827598095\n",
      "Epoch: 9850 Loss: 0.007281668018549681\n",
      "Epoch: 9851 Loss: 0.007280086632817984\n",
      "Epoch: 9852 Loss: 0.007278511766344309\n",
      "Epoch: 9853 Loss: 0.007277787197381258\n",
      "Epoch: 9854 Loss: 0.007276709657162428\n",
      "Epoch: 9855 Loss: 0.007274948991835117\n",
      "Epoch: 9856 Loss: 0.007274468429386616\n",
      "Epoch: 9857 Loss: 0.007273492868989706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9858 Loss: 0.007271279580891132\n",
      "Epoch: 9859 Loss: 0.007270950824022293\n",
      "Epoch: 9860 Loss: 0.007270221132785082\n",
      "Epoch: 9861 Loss: 0.0072693112306296825\n",
      "Epoch: 9862 Loss: 0.007266562897711992\n",
      "Epoch: 9863 Loss: 0.00726598035544157\n",
      "Epoch: 9864 Loss: 0.0072646550834178925\n",
      "Epoch: 9865 Loss: 0.0072630527429282665\n",
      "Epoch: 9866 Loss: 0.007262321189045906\n",
      "Epoch: 9867 Loss: 0.00726131210103631\n",
      "Epoch: 9868 Loss: 0.007261947728693485\n",
      "Epoch: 9869 Loss: 0.007259030360728502\n",
      "Epoch: 9870 Loss: 0.0072572557255625725\n",
      "Epoch: 9871 Loss: 0.007256685756146908\n",
      "Epoch: 9872 Loss: 0.007256521377712488\n",
      "Epoch: 9873 Loss: 0.007253957912325859\n",
      "Epoch: 9874 Loss: 0.0072546727024018764\n",
      "Epoch: 9875 Loss: 0.007252660114318132\n",
      "Epoch: 9876 Loss: 0.007251051254570484\n",
      "Epoch: 9877 Loss: 0.007249149028211832\n",
      "Epoch: 9878 Loss: 0.0072498260997235775\n",
      "Epoch: 9879 Loss: 0.007247134577482939\n",
      "Epoch: 9880 Loss: 0.007246037945151329\n",
      "Epoch: 9881 Loss: 0.007246627006679773\n",
      "Epoch: 9882 Loss: 0.007244156673550606\n",
      "Epoch: 9883 Loss: 0.00724228797480464\n",
      "Epoch: 9884 Loss: 0.0072429305873811245\n",
      "Epoch: 9885 Loss: 0.0072402083314955235\n",
      "Epoch: 9886 Loss: 0.007240487728267908\n",
      "Epoch: 9887 Loss: 0.007238373626023531\n",
      "Epoch: 9888 Loss: 0.00723785487934947\n",
      "Epoch: 9889 Loss: 0.007236534729599953\n",
      "Epoch: 9890 Loss: 0.0072346157394349575\n",
      "Epoch: 9891 Loss: 0.0072355447337031364\n",
      "Epoch: 9892 Loss: 0.00723297568038106\n",
      "Epoch: 9893 Loss: 0.007231429684907198\n",
      "Epoch: 9894 Loss: 0.007231155410408974\n",
      "Epoch: 9895 Loss: 0.007231609430164099\n",
      "Epoch: 9896 Loss: 0.0072274114936590195\n",
      "Epoch: 9897 Loss: 0.007227960042655468\n",
      "Epoch: 9898 Loss: 0.007225933484733105\n",
      "Epoch: 9899 Loss: 0.00722516281530261\n",
      "Epoch: 9900 Loss: 0.0072237346321344376\n",
      "Epoch: 9901 Loss: 0.007222291547805071\n",
      "Epoch: 9902 Loss: 0.007222502492368221\n",
      "Epoch: 9903 Loss: 0.007218833547085524\n",
      "Epoch: 9904 Loss: 0.007219766266644001\n",
      "Epoch: 9905 Loss: 0.007218270096927881\n",
      "Epoch: 9906 Loss: 0.00721767358481884\n",
      "Epoch: 9907 Loss: 0.007217423990368843\n",
      "Epoch: 9908 Loss: 0.007215326186269522\n",
      "Epoch: 9909 Loss: 0.00721265422180295\n",
      "Epoch: 9910 Loss: 0.007213584613054991\n",
      "Epoch: 9911 Loss: 0.007211311720311642\n",
      "Epoch: 9912 Loss: 0.007209602277725935\n",
      "Epoch: 9913 Loss: 0.007209479343146086\n",
      "Epoch: 9914 Loss: 0.007209224626421928\n",
      "Epoch: 9915 Loss: 0.007206800393760204\n",
      "Epoch: 9916 Loss: 0.007207244634628296\n",
      "Epoch: 9917 Loss: 0.00720417033880949\n",
      "Epoch: 9918 Loss: 0.007203911431133747\n",
      "Epoch: 9919 Loss: 0.007202708628028631\n",
      "Epoch: 9920 Loss: 0.007200967520475388\n",
      "Epoch: 9921 Loss: 0.007201723754405975\n",
      "Epoch: 9922 Loss: 0.007198520936071873\n",
      "Epoch: 9923 Loss: 0.007197619415819645\n",
      "Epoch: 9924 Loss: 0.00719628669321537\n",
      "Epoch: 9925 Loss: 0.007195822894573212\n",
      "Epoch: 9926 Loss: 0.007194192614406347\n",
      "Epoch: 9927 Loss: 0.007193068042397499\n",
      "Epoch: 9928 Loss: 0.00719230342656374\n",
      "Epoch: 9929 Loss: 0.00719157001003623\n",
      "Epoch: 9930 Loss: 0.007189915049821138\n",
      "Epoch: 9931 Loss: 0.007188078481703997\n",
      "Epoch: 9932 Loss: 0.007187235169112682\n",
      "Epoch: 9933 Loss: 0.00718636205419898\n",
      "Epoch: 9934 Loss: 0.007184832356870174\n",
      "Epoch: 9935 Loss: 0.00718449242413044\n",
      "Epoch: 9936 Loss: 0.007184382528066635\n",
      "Epoch: 9937 Loss: 0.007181860040873289\n",
      "Epoch: 9938 Loss: 0.007181279826909304\n",
      "Epoch: 9939 Loss: 0.007179424166679382\n",
      "Epoch: 9940 Loss: 0.007178441621363163\n",
      "Epoch: 9941 Loss: 0.007177087944000959\n",
      "Epoch: 9942 Loss: 0.007175486534833908\n",
      "Epoch: 9943 Loss: 0.00717519037425518\n",
      "Epoch: 9944 Loss: 0.007174511440098286\n",
      "Epoch: 9945 Loss: 0.007174134720116854\n",
      "Epoch: 9946 Loss: 0.007172631565481424\n",
      "Epoch: 9947 Loss: 0.007171669974923134\n",
      "Epoch: 9948 Loss: 0.007168577052652836\n",
      "Epoch: 9949 Loss: 0.007169073913246393\n",
      "Epoch: 9950 Loss: 0.00716891884803772\n",
      "Epoch: 9951 Loss: 0.00716613931581378\n",
      "Epoch: 9952 Loss: 0.0071649374440312386\n",
      "Epoch: 9953 Loss: 0.007164740934967995\n",
      "Epoch: 9954 Loss: 0.007163658272475004\n",
      "Epoch: 9955 Loss: 0.007161914836615324\n",
      "Epoch: 9956 Loss: 0.0071606445126235485\n",
      "Epoch: 9957 Loss: 0.007160832639783621\n",
      "Epoch: 9958 Loss: 0.007158802822232246\n",
      "Epoch: 9959 Loss: 0.007157717831432819\n",
      "Epoch: 9960 Loss: 0.0071567646227777\n",
      "Epoch: 9961 Loss: 0.007155006751418114\n",
      "Epoch: 9962 Loss: 0.007153885439038277\n",
      "Epoch: 9963 Loss: 0.00715318089351058\n",
      "Epoch: 9964 Loss: 0.007151714060455561\n",
      "Epoch: 9965 Loss: 0.007150903344154358\n",
      "Epoch: 9966 Loss: 0.007149281911551952\n",
      "Epoch: 9967 Loss: 0.00714835524559021\n",
      "Epoch: 9968 Loss: 0.007148590870201588\n",
      "Epoch: 9969 Loss: 0.007147200871258974\n",
      "Epoch: 9970 Loss: 0.007144824136048555\n",
      "Epoch: 9971 Loss: 0.007144981995224953\n",
      "Epoch: 9972 Loss: 0.007142739370465279\n",
      "Epoch: 9973 Loss: 0.007141798734664917\n",
      "Epoch: 9974 Loss: 0.007140640635043383\n",
      "Epoch: 9975 Loss: 0.007140126544982195\n",
      "Epoch: 9976 Loss: 0.007138977758586407\n",
      "Epoch: 9977 Loss: 0.007136476691812277\n",
      "Epoch: 9978 Loss: 0.007135154213756323\n",
      "Epoch: 9979 Loss: 0.0071357497945427895\n",
      "Epoch: 9980 Loss: 0.007134723477065563\n",
      "Epoch: 9981 Loss: 0.0071321818977594376\n",
      "Epoch: 9982 Loss: 0.007132748141884804\n",
      "Epoch: 9983 Loss: 0.007130317389965057\n",
      "Epoch: 9984 Loss: 0.007130277343094349\n",
      "Epoch: 9985 Loss: 0.007128851022571325\n",
      "Epoch: 9986 Loss: 0.007127039600163698\n",
      "Epoch: 9987 Loss: 0.0071263983845710754\n",
      "Epoch: 9988 Loss: 0.0071244570426642895\n",
      "Epoch: 9989 Loss: 0.00712429778650403\n",
      "Epoch: 9990 Loss: 0.0071231829933822155\n",
      "Epoch: 9991 Loss: 0.007121746893972158\n",
      "Epoch: 9992 Loss: 0.007121157832443714\n",
      "Epoch: 9993 Loss: 0.00712023489177227\n",
      "Epoch: 9994 Loss: 0.007118294481188059\n",
      "Epoch: 9995 Loss: 0.007117146626114845\n",
      "Epoch: 9996 Loss: 0.007116447202861309\n",
      "Epoch: 9997 Loss: 0.007115072570741177\n",
      "Epoch: 9998 Loss: 0.007114453241229057\n",
      "Epoch: 9999 Loss: 0.007113711908459663\n"
     ]
    }
   ],
   "source": [
    "# Start training it\n",
    "BATCH_SIZE = 128\n",
    "for epoch in range(10000):                          # 训练10000次\n",
    "    for start in range(0, len(trX), BATCH_SIZE):    # 每次训练中再分批处理\n",
    "        end = start + BATCH_SIZE\n",
    "        batchX = trX[start:end]\n",
    "        batchY = trY[start:end]\n",
    "        \n",
    "        # 训练数据放到CUDA\n",
    "#         if torch.cuda.is_available():\n",
    "#             batchX = batchX.cuda()\n",
    "#             batchY = batchY.cuda()\n",
    "        \n",
    "        # forward pass\n",
    "        y_pred = model(batchX)\n",
    "        loss = loss_fn(y_pred, batchY)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "\n",
    "    # Find loss on training data\n",
    "    loss = loss_fn(model(trX), trY).item()\n",
    "    print('Epoch:', epoch, 'Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后我们用训练好的模型尝试在1到100这些数字上玩FizzBuzz游戏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fizzbuzz', '2', 'fizz', 'buzz', 'buzz', 'fizz', '7', '8', '9', 'buzz', '11', '12', '13', '14', 'fizzbuzz', '16', '17', 'fizz', '19', 'buzz', 'fizz', '22', '23', '24', 'buzz', '26', 'fizz', '28', '29', 'fizzbuzz', '31', '32', 'fizz', 'buzz', 'buzz', 'fizz', '37', '38', 'fizz', 'buzz', '41', 'fizz', '43', '44', 'fizzbuzz', '46', '47', 'fizz', '49', 'buzz', 'fizz', '52', '53', 'fizz', 'buzz', '56', 'fizz', '58', '59', 'fizzbuzz', '61', '62', 'fizz', 'buzz', 'buzz', 'fizz', '67', '68', 'fizz', 'buzz', '71', 'fizz', '73', '74', 'fizzbuzz', '76', '77', 'fizz', '79', 'buzz', '81', '82', '83', 'fizz', 'buzz', '86', '87', '88', '89', 'fizzbuzz', '91', '92', 'fizz', '94', 'buzz', 'fizz', '97', '98', 'fizz', 'buzz']\n"
     ]
    }
   ],
   "source": [
    "# Output now\n",
    "testX = torch.Tensor([binary_encode(i, NUM_DIGITS) for i in range(1, 101)])\n",
    "with torch.no_grad():\n",
    "    testY = model(testX)\n",
    "predictions = zip(range(1, 101), list(testY.max(1)[1].data.tolist()))\n",
    "\n",
    "print([fizz_buzz_decode(i, x) for (i, x) in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.sum(testY.max(1)[1].numpy() == np.array([fizz_buzz_encode(i) for i in range(1,101)])))\n",
    "testY.max(1)[1].numpy() == np.array([fizz_buzz_encode(i) for i in range(1,101)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-Image-Classification  \n",
    "\n",
    "参考资料\n",
    "- [Stanford CS231n](http://cs231n.github.io/convolutional-networks/)\n",
    "- [AlexNet](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "- [VGG](https://arxiv.org/pdf/1409.1556.pdf)\n",
    "- [ResNet](https://arxiv.org/pdf/1512.03385.pdf)\n",
    "- [DenseNet](https://arxiv.org/pdf/1608.06993.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "# torchvision是独立于pytorch的关于图像操作的一些方便工具库。\n",
    "# torchvision的详细介绍在：https://pypi.org/project/torchvision/0.1.8/\n",
    "# torchvision主要包括一下几个包：\n",
    "# vision.datasets : 几个常用视觉数据集，可以下载和加载\n",
    "# vision.models : 流行的模型，例如 AlexNet, VGG, and ResNet 以及 与训练好的参数。\n",
    "# vision.transforms : 常用的图像操作，例如：随机切割，旋转等。\n",
    "# vision.utils : 用于把形似 (3 x H x W) 的张量保存到硬盘中，给一个mini-batch的图像可以产生一个图像格网。\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebd6970b78e4d0dada52a067035cd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist_data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2788150cc4a143c798e69825c85036a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist_data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6970bc36408846cfa6e0118377855387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist_data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded51ad3005a4d5983ad69913a629627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist_data\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(53113)  #cpu随机种子\n",
    "\n",
    "#没gpu下面可以忽略\n",
    "use_cuda = torch.cuda.is_available()  \n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")  \n",
    "batch_size = test_batch_size = 32  \n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "\n",
    "#torch.utils.data.DataLoader在训练模型时使用到此函数，用来把训练数据分成多个batch，\n",
    "#此函数每次抛出一个batch数据，直至把所有的数据都抛出，也就是个数据迭代器。\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./mnist_data', \n",
    "                   train=True, #如果true，从training.pt创建数据集\n",
    "                   download=True, #如果ture，从网上自动下载\n",
    "                   \n",
    "#transform 接受一个图像返回变换后的图像的函数，相当于图像先预处理下\n",
    "#常用的操作如 ToTensor, RandomCrop，Normalize等. \n",
    "#他们可以通过transforms.Compose被组合在一起 \n",
    "                   transform=transforms.Compose([\n",
    "                       \n",
    "                       transforms.ToTensor(), \n",
    "#.ToTensor()将shape为(H, W, C)的nump.ndarray或img转为shape为(C, H, W)的tensor，\n",
    "#其将每一个数值归一化到[0,1]，其归一化方法比较简单，直接除以255即可。\n",
    "                       \n",
    "                       transforms.Normalize((0.1307,), (0.3081,)) # 所有图片像素均值和方差\n",
    "#.Normalize作用就是.ToTensor将输入归一化到(0,1)后，再使用公式”(x-mean)/std”，将每个元素分布到(-1,1)  \n",
    "                   ])), # 第一个参数dataset：数据集\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,  #随机打乱数据\n",
    "    **kwargs)##kwargs是上面gpu的设置\n",
    "  \n",
    "\n",
    "# 测试数据集\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./mnist_data', \n",
    "                   train=False, #如果False，从test.pt创建数据集\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, \n",
    "    shuffle=True, \n",
    "    **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义CNN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们定义一个基于ConvNet的简单神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)  # 28*28的图像, kernel大小是5,步长是1,那么移动了28+1-5次, 产生24*24的特征\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1)\n",
    "        #in_channels：输入图像通道数，手写数字图像为1，彩色图像为3\n",
    "        #out_channels：输出通道数，这个等于卷积核的数量\n",
    "        #kernel_size：卷积核大小\n",
    "        #stride：步长\n",
    "         \n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1) # 24*24的特征, kernel大小是5,步长是1,那么移动了24+1-5次, 产生20*20的特征\n",
    "        #上个卷积网络的out_channels，就是下一个网络的in_channels，所以这里是20\n",
    "        #out_channels：卷积核数量50\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(4*4*50, 500)    # inf_features*out_features就是全连接层做矩阵乘法的右边矩阵\n",
    "        #全连接层torch.nn.Linear(in_features, out_features)\n",
    "        #in_features:输入特征维度，4*4*50是自己算出来的，跟输入图像维度有关\n",
    "        #out_features；输出特征维度\n",
    "        \n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        #输出维度10，10分类\n",
    "\n",
    "    def forward(self, x):  \n",
    "        #print(x.shape)  #手写数字的输入维度，(N,1,28,28), N为batch_size, 1为单通道灰度图像, 分辨率是28*28\n",
    "        x = F.relu(self.conv1(x)) # x = (N,20,24,24), 5*5的卷积核, 产生特征图是24*24\n",
    "        x = F.max_pool2d(x, 2, 2) # x = (N,20,12,12), 2*2的maxpool, 产生downsampling特征图是12*12\n",
    "        x = F.relu(self.conv2(x)) # x = (N,50,8,8), 5*5的卷积核, 产生特征图是(12+1-5)*(12+1-5)=8*8\n",
    "        x = F.max_pool2d(x, 2, 2) # x = (N,50,4,4), 2*2的maxpool, 产生downsampling特征图是4*4\n",
    "        x = x.view(-1, 4*4*50)    # x = (N,4*4*50), 将N*50*4*4的四维矩阵转为N*(4*4*50)的二维矩阵\n",
    "        x = F.relu(self.fc1(x))   # x = (N,4*4*50)*(4*4*50, 500)=(N,500), 全连接层, 就是矩阵乘法\n",
    "        x = self.fc2(x)           # x = (N,500)*(500, 10)=(N,10)\n",
    "        return F.log_softmax(x, dim=1)  # 带log的softmax分类，每张图片返回10个概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化模型和定义优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "\n",
    "#模型初始化, 将model放到device上\n",
    "model = Net().to(device) \n",
    "\n",
    "#定义优化器\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLL loss的定义\n",
    "\n",
    "$\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "        l_n = - w_{y_n} x_{n,y_n}, \\quad\n",
    "        w_{c} = \\text{weight}[c] \\cdot \\mathbb{1}\\{c \\not= \\text{ignore\\_index}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义训练和测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=100):\n",
    "    model.train() # 进入训练模式\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)  # data和target放到GPU上\n",
    "        optimizer.zero_grad() # 梯度归零\n",
    "        output = model(data)  # 输出的维度[N,10] 这里的data是函数的forward参数x\n",
    "        loss = F.nll_loss(output, target) #这里loss求的是平均数，除以了batch\n",
    "#F.nll_loss(F.log_softmax(input), target) ：\n",
    "#单分类交叉熵损失函数，一张图片里只能有一个类别，输入input的需要softmax\n",
    "#还有一种是多分类损失函数，一张图片有多个类别，输入的input需要sigmoid\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, \n",
    "                batch_idx * len(data), #100*32\n",
    "                len(train_loader.dataset), #60000\n",
    "                100. * batch_idx / len(train_loader), #len(train_loader)=60000/32=1875\n",
    "                loss.item()\n",
    "            ))\n",
    "            #print(len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval() #进入测试模式\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data) \n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            #reduction='sum'代表batch的每个元素loss累加求和，默认是mean求平均\n",
    "                       \n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            \n",
    "            #print(target.shape) #torch.Size([32])\n",
    "            #print(pred.shape) #torch.Size([32, 1])\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            #pred和target的维度不一样\n",
    "            #pred.eq()相等返回1，不相等返回0，返回的tensor维度(32，1)。\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看运行结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0.000000%)]\tLoss: 2.297938\n",
      "Train Epoch: 1 [3200/60000 (5.333333%)]\tLoss: 0.569983\n",
      "Train Epoch: 1 [6400/60000 (10.666667%)]\tLoss: 0.206423\n",
      "Train Epoch: 1 [9600/60000 (16.000000%)]\tLoss: 0.095930\n",
      "Train Epoch: 1 [12800/60000 (21.333333%)]\tLoss: 0.179087\n",
      "Train Epoch: 1 [16000/60000 (26.666667%)]\tLoss: 0.040764\n",
      "Train Epoch: 1 [19200/60000 (32.000000%)]\tLoss: 0.136779\n",
      "Train Epoch: 1 [22400/60000 (37.333333%)]\tLoss: 0.050968\n",
      "Train Epoch: 1 [25600/60000 (42.666667%)]\tLoss: 0.113659\n",
      "Train Epoch: 1 [28800/60000 (48.000000%)]\tLoss: 0.059484\n",
      "Train Epoch: 1 [32000/60000 (53.333333%)]\tLoss: 0.088600\n",
      "Train Epoch: 1 [35200/60000 (58.666667%)]\tLoss: 0.191012\n",
      "Train Epoch: 1 [38400/60000 (64.000000%)]\tLoss: 0.094172\n",
      "Train Epoch: 1 [41600/60000 (69.333333%)]\tLoss: 0.075000\n",
      "Train Epoch: 1 [44800/60000 (74.666667%)]\tLoss: 0.038324\n",
      "Train Epoch: 1 [48000/60000 (80.000000%)]\tLoss: 0.037892\n",
      "Train Epoch: 1 [51200/60000 (85.333333%)]\tLoss: 0.055766\n",
      "Train Epoch: 1 [54400/60000 (90.666667%)]\tLoss: 0.013408\n",
      "Train Epoch: 1 [57600/60000 (96.000000%)]\tLoss: 0.034500\n",
      "\n",
      "Test set: Average loss: 0.0657, Accuracy: 9794/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0.000000%)]\tLoss: 0.058053\n",
      "Train Epoch: 2 [3200/60000 (5.333333%)]\tLoss: 0.031086\n",
      "Train Epoch: 2 [6400/60000 (10.666667%)]\tLoss: 0.085865\n",
      "Train Epoch: 2 [9600/60000 (16.000000%)]\tLoss: 0.059233\n",
      "Train Epoch: 2 [12800/60000 (21.333333%)]\tLoss: 0.032802\n",
      "Train Epoch: 2 [16000/60000 (26.666667%)]\tLoss: 0.011673\n",
      "Train Epoch: 2 [19200/60000 (32.000000%)]\tLoss: 0.099366\n",
      "Train Epoch: 2 [22400/60000 (37.333333%)]\tLoss: 0.124382\n",
      "Train Epoch: 2 [25600/60000 (42.666667%)]\tLoss: 0.008728\n",
      "Train Epoch: 2 [28800/60000 (48.000000%)]\tLoss: 0.010999\n",
      "Train Epoch: 2 [32000/60000 (53.333333%)]\tLoss: 0.038323\n",
      "Train Epoch: 2 [35200/60000 (58.666667%)]\tLoss: 0.015801\n",
      "Train Epoch: 2 [38400/60000 (64.000000%)]\tLoss: 0.169800\n",
      "Train Epoch: 2 [41600/60000 (69.333333%)]\tLoss: 0.057192\n",
      "Train Epoch: 2 [44800/60000 (74.666667%)]\tLoss: 0.008103\n",
      "Train Epoch: 2 [48000/60000 (80.000000%)]\tLoss: 0.081236\n",
      "Train Epoch: 2 [51200/60000 (85.333333%)]\tLoss: 0.206504\n",
      "Train Epoch: 2 [54400/60000 (90.666667%)]\tLoss: 0.018167\n",
      "Train Epoch: 2 [57600/60000 (96.000000%)]\tLoss: 0.012856\n",
      "\n",
      "Test set: Average loss: 0.0463, Accuracy: 9852/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "\n",
    "save_model = True\n",
    "if (save_model):\n",
    "    torch.save(model.state_dict(),\"mnist_cnn.pt\")   #词典格式，model.state_dict()只保存模型参数\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./fashion_mnist_data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537586f595844c539ae7b04eefcc9088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./fashion_mnist_data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./fashion_mnist_data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./fashion_mnist_data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3397959633b74b9d8f42e21e8d90a255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./fashion_mnist_data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./fashion_mnist_data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./fashion_mnist_data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8177f2b812354c1db29c22534b918ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./fashion_mnist_data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./fashion_mnist_data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./fashion_mnist_data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9af6bd4da0f4f4c87e293bf1da09cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./fashion_mnist_data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./fashion_mnist_data\\FashionMNIST\\raw\n",
      "Processing...\n",
      "Done!\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0.000000%)]\tLoss: 2.279603\n",
      "Train Epoch: 1 [3200/60000 (5.333333%)]\tLoss: 0.957838\n",
      "Train Epoch: 1 [6400/60000 (10.666667%)]\tLoss: 1.018690\n",
      "Train Epoch: 1 [9600/60000 (16.000000%)]\tLoss: 0.541348\n",
      "Train Epoch: 1 [12800/60000 (21.333333%)]\tLoss: 0.627392\n",
      "Train Epoch: 1 [16000/60000 (26.666667%)]\tLoss: 0.510979\n",
      "Train Epoch: 1 [19200/60000 (32.000000%)]\tLoss: 0.560108\n",
      "Train Epoch: 1 [22400/60000 (37.333333%)]\tLoss: 0.527978\n",
      "Train Epoch: 1 [25600/60000 (42.666667%)]\tLoss: 0.666773\n",
      "Train Epoch: 1 [28800/60000 (48.000000%)]\tLoss: 0.296420\n",
      "Train Epoch: 1 [32000/60000 (53.333333%)]\tLoss: 0.298870\n",
      "Train Epoch: 1 [35200/60000 (58.666667%)]\tLoss: 0.229143\n",
      "Train Epoch: 1 [38400/60000 (64.000000%)]\tLoss: 0.470563\n",
      "Train Epoch: 1 [41600/60000 (69.333333%)]\tLoss: 0.722310\n",
      "Train Epoch: 1 [44800/60000 (74.666667%)]\tLoss: 0.513217\n",
      "Train Epoch: 1 [48000/60000 (80.000000%)]\tLoss: 0.462245\n",
      "Train Epoch: 1 [51200/60000 (85.333333%)]\tLoss: 0.383336\n",
      "Train Epoch: 1 [54400/60000 (90.666667%)]\tLoss: 0.494554\n",
      "Train Epoch: 1 [57600/60000 (96.000000%)]\tLoss: 0.622136\n",
      "\n",
      "Test set: Average loss: 0.4423, Accuracy: 8379/10000 (84%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0.000000%)]\tLoss: 0.376932\n",
      "Train Epoch: 2 [3200/60000 (5.333333%)]\tLoss: 0.321366\n",
      "Train Epoch: 2 [6400/60000 (10.666667%)]\tLoss: 0.306666\n",
      "Train Epoch: 2 [9600/60000 (16.000000%)]\tLoss: 0.353907\n",
      "Train Epoch: 2 [12800/60000 (21.333333%)]\tLoss: 0.445683\n",
      "Train Epoch: 2 [16000/60000 (26.666667%)]\tLoss: 0.365156\n",
      "Train Epoch: 2 [19200/60000 (32.000000%)]\tLoss: 0.373488\n",
      "Train Epoch: 2 [22400/60000 (37.333333%)]\tLoss: 0.398555\n",
      "Train Epoch: 2 [25600/60000 (42.666667%)]\tLoss: 0.323643\n",
      "Train Epoch: 2 [28800/60000 (48.000000%)]\tLoss: 0.348167\n",
      "Train Epoch: 2 [32000/60000 (53.333333%)]\tLoss: 0.498569\n",
      "Train Epoch: 2 [35200/60000 (58.666667%)]\tLoss: 0.283599\n",
      "Train Epoch: 2 [38400/60000 (64.000000%)]\tLoss: 0.329186\n",
      "Train Epoch: 2 [41600/60000 (69.333333%)]\tLoss: 0.424766\n",
      "Train Epoch: 2 [44800/60000 (74.666667%)]\tLoss: 0.414201\n",
      "Train Epoch: 2 [48000/60000 (80.000000%)]\tLoss: 0.449013\n",
      "Train Epoch: 2 [51200/60000 (85.333333%)]\tLoss: 0.348028\n",
      "Train Epoch: 2 [54400/60000 (90.666667%)]\tLoss: 0.412255\n",
      "Train Epoch: 2 [57600/60000 (96.000000%)]\tLoss: 0.233900\n",
      "\n",
      "Test set: Average loss: 0.3729, Accuracy: 8643/10000 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#同上\n",
    "torch.manual_seed(53113)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = test_batch_size = 32\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('./fashion_mnist_data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,)) \n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('./fashion_mnist_data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "\n",
    "save_model = True\n",
    "if (save_model):\n",
    "    torch.save(model.state_dict(),\"fashion_mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN模型的Transfer Learning (迁移学习) \n",
    "\n",
    "- 很多时候当我们需要训练一个新的图像分类任务，我们不会完全从一个随机的模型开始训练，而是利用_预训练_的模型来加速训练的过程。我们经常使用在`ImageNet`上的预训练模型。\n",
    "- 这是一种transfer learning的方法。我们常用以下两种方法做迁移学习。\n",
    "    - fine tuning: 从一个预训练模型开始，我们改变一些模型的架构，然后继续训练整个模型的参数。\n",
    "    - feature extraction: 我们不再改变与训练模型的参数，而是只更新我们改变过的部分模型参数。我们之所以叫它feature extraction是因为我们把预训练的CNN模型当做一个特征提取模型，利用提取出来的特征做来完成我们的训练任务。\n",
    "    \n",
    "以下是构建和训练迁移学习模型的基本步骤：\n",
    "- 初始化预训练模型\n",
    "- 把最后一层的输出层改变成我们想要分的类别总数\n",
    "- 定义一个optimizer来更新参数\n",
    "- 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据\n",
    "\n",
    "我们会使用*hymenoptera_data*数据集，[下载](https://download.pytorch.org/tutorial/hymenoptera_data.zip).\n",
    "\n",
    "这个数据集包括两类图片, **bees** 和 **ants**, 这些数据都被处理成了可以使用`ImageFolder <https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder>`来读取的格式。我们只需要把``data_dir``设置成数据的根目录，然后把``model_name``设置成我们想要使用的与训练模型：\n",
    "::\n",
    "   [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "\n",
    "其他的参数有：\n",
    "- ``num_classes``表示数据集分类的类别数\n",
    "- ``batch_size``\n",
    "- ``num_epochs``\n",
    "- ``feature_extract``表示我们训练的时候使用fine tuning还是feature extraction方法。如果``feature_extract = False``，整个模型都会被同时更新。如果``feature_extract = True``，只有模型的最后一层被更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms \n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"./hymenoptera_data\"\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "#蜜蜂和蚂蚁数据集不会自动下载，请到群文件下载，并放在当前代码目录下\n",
    "#os.path.join() 连接路径，相当于.../data_dir/train\n",
    "all_imgs = datasets.ImageFolder(os.path.join(data_dir, \"train\"),\n",
    "                                transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size), #把每张图片变成resnet需要输入的维度224\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]))\n",
    "loader = torch.utils.data.DataLoader(all_imgs, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "#训练数据分batch，变成tensor迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(iter(loader))[0] #这个img是一个batch的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unloader = transforms.ToPILImage()  # reconvert into PIL image\n",
    "#transforms：torchvision的子模块，常用的图像操作\n",
    "#.ToPILImage() 把tensor或数组转换成图像\n",
    "#详细转换过程可以看这个：https://blog.csdn.net/qq_37385726/article/details/81811466\n",
    "\n",
    "plt.ion() #交互模式，默认是交互模式，可以不写\n",
    "#详细了解看这个：https://blog.csdn.net/SZuoDao/article/details/52973621\n",
    "#plt.ioff()\n",
    "\n",
    "def imshow(tensor, title=None):\n",
    "    image = tensor.cpu().clone()  # we clone the tensor to not do changes on it\n",
    "    image = image.squeeze(0)      # remove the fake batch dimension \n",
    "    #这个.squeeze(0)看不懂，去掉也可以运行\n",
    "    \n",
    "    image = unloader(image) #tensor转换成图像\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(1) # pause a bit so that plots are updated\n",
    "    #可以去掉看看，只是延迟显示作用\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "imshow(img[8], title='Image') \n",
    "imshow(img[9], title='Image')\n",
    "imshow(img[10], title='Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把训练集和验证集分batch转换成迭代器\n",
    "\n",
    "现在我们知道了模型输入的size，我们就可以把数据预处理成相应的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "#把迭代器存放到字典里作为value，key是train和val，后面调用key即可。\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels=next(iter(dataloaders_dict[\"train\"])) #一个batch\n",
    "print(inputs.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, labels in dataloaders_dict[\"train\"]:\n",
    "    #print(inputs)\n",
    "    #print(labels)\n",
    "    print(labels.size()) #最后一个batch不足32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载resnet模型并修改全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "# Number of epochs to train for \n",
    "num_epochs = 2\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True  #只更新修改的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False #提取的参数梯度不更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    if model_name == \"resnet\":\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained) \n",
    "        #如果True，从imagenet上返回预训练的模型和参数\n",
    "        \n",
    "        set_parameter_requires_grad(model_ft, feature_extract)#提取的参数梯度不更新\n",
    "        #print(model_ft) 可以打印看下\n",
    "        num_ftrs = model_ft.fc.in_features \n",
    "        #model_ft.fc是resnet的最后全连接层\n",
    "        #(fc): Linear(in_features=512, out_features=1000, bias=True)\n",
    "        #in_features 是全连接层的输入特征维度\n",
    "        #print(num_ftrs)\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        #out_features=1000 改为 num_classes=2\n",
    "        input_size = 224 #resnet18网络输入图片维度是224，resnet34，50，101，152也是\n",
    "        \n",
    "    return model_ft, input_size\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看需要更新的参数、定义优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(model_ft.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(next(iter(model_ft.named_parameters()))) #是元组，只有两个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model_ft.named_parameters():\n",
    "    print(name) #看下都有哪些参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters() #需要更新的参数\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = [] #需要更新的参数存放在此\n",
    "    for name,param in model_ft.named_parameters(): \n",
    "        #model_ft.named_parameters()有啥看上面cell\n",
    "        if param.requires_grad == True: \n",
    "#这里要知道全连接层之前的层param.requires_grad == Flase\n",
    "#后面加的全连接层param.requires_grad == True\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else: #否则，所有的参数都会更新\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9) #定义优化器\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss() #定义损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练测试合一起了\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=5):\n",
    "    since = time.time()\n",
    "    val_acc_history = [] \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())#深拷贝上面resnet模型参数\n",
    "#.copy和.deepcopy区别看这个：https://blog.csdn.net/u011630575/article/details/78604226 \n",
    "    best_acc = 0.\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs-1))\n",
    "        print(\"-\"*10)\n",
    "        \n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            running_loss = 0.\n",
    "            running_corrects = 0.\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else: \n",
    "                model.eval()\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                with torch.autograd.set_grad_enabled(phase==\"train\"):\n",
    "                    #torch.autograd.set_grad_enabled梯度管理器，可设置为打开或关闭\n",
    "                    #phase==\"train\"是True和False，双等号要注意\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                #返回每一行最大的数和索引，prds的位置是索引的位置\n",
    "                #也可以preds = outputs.argmax(dim=1)\n",
    "                if phase == \"train\":\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                running_loss += loss.item() * inputs.size(0) #交叉熵损失函数是平均过的\n",
    "                running_corrects += torch.sum(preds.view(-1) == labels.view(-1)).item()\n",
    "                #.view(-1)展开到一维，并自己计算\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "       \n",
    "            print(\"{} Loss: {} Acc: {}\".format(phase, epoch_loss, epoch_acc))\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                #模型变好，就拷贝更新后的模型参数\n",
    "                \n",
    "            if phase == \"val\":\n",
    "                val_acc_history.append(epoch_acc) #记录每个epoch验证集的准确率\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print(\"Training compete in {}m {}s\".format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Best val Acc: {}\".format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts) #把最新的参数复制到model中\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate\n",
    "model_ft, ohist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the non-pretrained version of the model used for this run\n",
    "scratch_model,_ = initialize_model(model_name, \n",
    "                                   num_classes, \n",
    "                                   feature_extract=False, #所有参数都训练\n",
    "                                   use_pretrained=False)# 不要imagenet的参数\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), \n",
    "                              lr=0.001, momentum=0.9)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(scratch_model, \n",
    "                             dataloaders_dict, \n",
    "                             scratch_criterion, \n",
    "                             scratch_optimizer, \n",
    "                             num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number \n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# ohist = []\n",
    "# shist = []\n",
    "\n",
    "# ohist = [h.cpu().numpy() for h in ohist]\n",
    "# shist = [h.cpu().numpy() for h in scratch_hist]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),scratch_hist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
